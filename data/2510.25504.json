{
    "id": "2510.25504",
    "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions",
    "summary": "This paper summarizes the development of multi-objective search and highlights interdisciplinary opportunities, while pointing out open challenges defined by emerging frontiers in multi-objective search.",
    "abstract": "Multi-objective search (MOS) has emerged as a unifying framework for planning and decision-making problems where multiple, often conflicting, criteria must be balanced. While the problem has been studied for decades, recent years have seen renewed interest in the topic across AI applications such as robotics, transportation, and operations research, reflecting the reality that real-world systems rarely optimize a single measure. This paper surveys developments in MOS while highlighting cross-disciplinary opportunities, and outlines open challenges that define the emerging frontier of MOS",
    "category1": "Algorithms and Models",
    "category2": "",
    "category3": "Multi-Agent",
    "authors": "Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig",
    "subjects": [
        "Artificial Intelligence (cs.AI)"
    ],
    "comments": "",
    "keypoint": "Multi-objective search (MOS) is a framework for balancing multiple conflicting criteria in planning and decision-making.\nRecent years have seen renewed interest in MOS across AI applications such as robotics, transportation, and operations research.\nMOS algorithms compute the Pareto front (PF), which consists of solutions where no objective can be improved without degrading another.\nThe aggregation approach combines objectives into a single scalar value but requires prior knowledge of trade-offs.\nExact MOS aims to compute the full Pareto-optimal set, which is NP-hard due to potentially exponential solution count.\nApproximate MOS computes an ε-approximate PF to handle large Pareto fronts that are impractical to present to decision makers.\nAnytime MOS algorithms return progressively better subsets of the PF over time until terminated or completed.\nIncremental MOS reuses previous search efforts when queries or environments change dynamically.\nDynamic MOS accounts for temporal changes in graph structure or edge costs during planning.\nMulti-objective Stochastic Shortest Path (MOSSP) introduces probabilistic transitions while maintaining vector-valued costs.\nMulti-objective Markov Decision Processes (MOMDPs) generalize MOSSP with arbitrary horizons and sequential decision-making under uncertainty.\nMulti-objective Reinforcement Learning (MORL) learns policies through interaction without assuming known transition or reward models.\nMulti-objective optimization (MOO) is a broader field encompassing MOS, MOSSP, MOMDP, and MORL as structured subclasses.\nMOO typically uses evolutionary algorithms, particle swarm optimization, or simulated annealing rather than search-based methods.\nLabel-correcting and A*-based methods form the foundation of modern exact MOS algorithms.\nMulti-Objective A* (MOA*) generalizes A* to multi-objective settings and has been enhanced by techniques like lexicographic ordering and dimensionality reduction.\nBOA* improves efficiency for bi-objective problems by enabling O(1) dominance checks.\nPPA* and A*pex extend approximate search to bi-objective and general multi-objective cases using efficient pruning.\nA*pex achieves speedups by grouping similar-cost paths and exploiting cost correlations.\nParallelization of MOS algorithms remains largely unexplored but shows promise with recent work on shared bounds and SIMD vectorization.\nTheoretical advances include FPTAS for dynamic MOS and classification of vertices into must-expand, maybe-expand, and never-expand categories.\nMulti-Value Heuristics (MVHs) provide more information than ideal-point heuristics but incur higher computational overhead.\nBi-Objective Differential Heuristics (BO-DHs) reduce runtime by adapting memory-based heuristics from single-objective search.\nHeuristic search techniques have been adapted for MOSSP using extensions of LAO* and LRTDP.\nMOS techniques are applied to Multi-Objective Minimum Spanning Tree (MO-MST) problems despite their NP-hard nature.\nMOS with Objective Aggregation (MOS-OA) handles problems where intermediate states track hidden objectives not aligned with final solution objectives.\nA*pex was initially developed in the context of MOS-OA for robot inspection planning.\nMulti-Objective Multi-Agent Path Finding (MO-MAPF) integrates MOS with MAPF to generate plans trading off metrics like makespan, energy, and safety.\nConstrained shortest path problems can be generalized to require solutions from the Pareto front under upper-bound constraints.\nThe k-Shortest Simple Path problem can be reduced to bi-objective search for solving 2-SSP.\nMOS is used in automated design and synthesis, including retrosynthesis planning and molecular generation.\nIn multi-modal journey planning, MOS balances time, cost, and comfort across transport modes at metropolitan scale.\nOpenTripPlanner 2 uses MOS and has been deployed nationally in Norway and Finland.\nIn robotics, MOS balances cost, energy, and safety, with applications in inspection planning and autonomous vehicle rulebook compliance.\nRulebooks formalize hierarchical objectives in AV planning, generalizing flat MOS hierarchies.\nScalability remains a challenge as most MOS algorithms perform poorly beyond two or three objectives.\nDynamic and uncertain environments require practical algorithms for real-world deployment, but current methods are often theoretical or limited in scale.\nPreference elicitation integrated into search is an underexplored direction for improving user-centric decision support.\nCross-fertilization between MOS and other AI fields like reinforcement learning offers opportunities for mutual advancement.\nFragmented benchmarks across communities hinder comparison; a standardized suite spanning classical, stochastic, and application-inspired domains is needed.",
    "date": "2025-10-31",
    "paper": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions\nOren Salzman1, Carlos Hern´andez Ulloa2, Ariel Felner3, Sven Koenig4\n1Technion - Israel Institute of Technology\n2Universidad San Sebastian\n3Ben-Gurion University\n4University of California, Irvine\nosalzman@cs.technion.ac.il, carlos.hernandez@uss.cl, felner@bgu.ac.il, sven.koenig@uci.edu\nAbstract\nMulti-objective search (MOS) has emerged as a unify-\ning framework for planning and decision-making problems\nwhere multiple, often conflicting, criteria must be balanced.\nWhile the problem has been studied for decades, recent years\nhave seen renewed interest in the topic across AI applications\nsuch as robotics, transportation, and operations research, re-\nflecting the reality that real-world systems rarely optimize a\nsingle measure. This paper surveys developments in MOS\nwhile highlighting cross-disciplinary opportunities, and out-\nlines open challenges that define the emerging frontier of\nMOS research.\n1\nIntroduction\nMulti-objective Search (MOS) problems are pervasive in\nreal-world settings where decision makers must balance sev-\neral, often conflicting, objectives. For example, in route find-\ning applications, we are interested in simultaneously mini-\nmizing both travel time and fuel consumption, or distance\nand toll costs. In many such cases, improvements in one ob-\njective cannot be achieved without hinderring another ob-\njective, making the search for well-balanced solutions both\nchallenging and essential.\nWhen a decision maker can articulate how much loss in\none objective is acceptable for a given gain in another, all\nobjectives can be turned into one scalar value by, e.g., opti-\nmising a weighted sum or another order-preserving (mono-\ntone) aggregation. Then, the resulting problem can be solved\nby any standard single-objective algorithm. This aggregation\napproach, however, presupposes reliable apriori information\nabout acceptable trade-off for the decision maker, which is\noften not available to the algorithm.\nAn alternative approach to addressing the multidimen-\nsional trade-off is to use MOS algorithms that compute the\nbest attainable trade-offs wherein no objective can be im-\nproved without degrading at least one other objective. This\nset can then be presented to the decision maker for an a pos-\nteriori preference articulation and final choice.\nWhile being a decades-old problem (Vincke 1976;\nHansen 1980; Cl´ımaco and Pascoal 2012; Current and\nMarsh 1993; Skriver 2000; Tarapata 2007; Ulungu and\nCopyright © 2026, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nTeghem 1991), in recent years, the study of MOS has at-\ntracted growing attention across multiple research commu-\nnities. Dedicated workshops and tutorials addressing com-\nplex, often conflicting, objectives have been featured in\nmainstream AI venues (e.g., AAAI [2024], IJCAI [2023;\n2025], AAMAS [2024], ICAPS [2024], ECAI [2025] and\nSoCS [2023]), and in robotics and machine-learning venues\n(e.g., RSS [2025] and NeurIPS [2024]). Related devel-\nopments are also emerging in operations research (OR),\ntransportation science, and evolutionary computation, where\nmulti-objective optimization has a long tradition but is now\nbeing revisited with modern heuristic search, reinforcement\nlearning, and hybrid approaches. This convergence of inter-\nests reflects a shared recognition that real-world decision-\nmaking rarely optimizes a single criterion, and that princi-\npled multi-objective reasoning is essential for building intel-\nligent, robust, and adaptable systems.\nScope.\nIn this paper, we highlight recent advances in the\nfield in terms of problem variants, algorithms, applications\nand emerging directions. It is by no means a comprehen-\nsive literature review but an attempt to provide an accessible\nstarting point for any researcher interested in the field.\nHere, we focus on the setting of multi-objective search.\nHowever, we also highlight extensions and variants such as\nthose that include uncertainty. Importantly, due to lack of\nspace, we maintain a high-level description of approaches\nand refer the reader to (Salzman et al. 2023) for a technical\noverview of recent MOS advances.\n2\nProblem Setting & Variants\n2.1\nNotation\nBoldface font indicates vectors, lower-case and upper-case\nsymbols indicate elements and sets, respectively. The no-\ntation pi will be used to denote the i’th component of p.\nThe addition of two d-dimensional vectors p and q and the\nmultiplication of a real-valued scalar k and a d-dimensional\nvector p are defined as p + q = (p1 + q1, . . . , pd + qd) and\nkp = (kp1, . . . , kpd), respectively.\nLet p and q be d-dimensional vectors. For a minimiza-\ntion problem, we say that p dominates q and denote this\nas p ⪯q if ∀i, pi ≤qi. We say that p is lexicographically\nsmaller than q and denote this as p ≺lex q if pk < qk for\nthe first index k s.t. pk ̸= qk. Finally, let p and q be two\narXiv:2510.25504v1  [cs.AI]  29 Oct 2025\nc1\nc2\nπ1\nπ2\n7\n1\n3\n8\nFigure 1: Visualization of key MOS concepts for the spe-\ncial case of a bi-objective problem. Solutions on and not\non the PF are visualized as purple and black dots, re-\nspectively. Visualization of all solutions dominated and ap-\nproximately dominated by solutions π1 and π2 are visual-\nized by turquoise and orange regions respectively. Exam-\nple for sets of solutions that approximate the PF which lie\nand which do not lie on the PF are depicted with purple\nsquares and red diamonds, respective. Finally, the domi-\nnance factor DF(π1, π2) in this example is max(max(8/3−\n1, 0), max(1/7 −1, 0)) = 5/3.\nd-dimensional vectors and let ε be another d-dimensional\nvector such that ∀i εi ≥0. We say that p approximately\ndominates q with an approximation factor ε and denote this\nas p ⪯ε q if ∀i, pi ≤(1 + εi) · qi.\n2.2\nMOS—Problem definition and variants\nIn most variants of a MOS problem a directed graph G =\n(V, E) where each edge e ∈E has a nonnegative cost vector\nc(e) ∈Rd where d > 0 is the number of objectives. For the\nspecific cases where d = 1 and d = 2, we refer to the prob-\nlem as single-objective and bi-objective, respectively. For a\npath π = ⟨v1, . . . , vk⟩where (vi, vi+1) ∈E, its cost c(p) is\nthe sum of the edge costs. That is, c(π) = P\ni c(vi, vi+1).\nGiven start and target vertices s, t ∈V , a path from s to t is\ncalled a solution. A solution is Pareto-optimal iff its cost is\nnot dominated by any other solution. See Fig. 1.\nExact MOS.\nIn the basic MOS problem, we are given\nvertices s, t ∈V and the goal is to compute the set Π⋆\nof Pareto-optimal solutions, also known as the Pareto front\n(PF) (Salzman et al. 2023). Importantly, computing Π⋆is\nNP-hard (Serafini 1987) as its cardinality may be exponen-\ntial in |V | (Ehrgott 2005; Breugem, Dollevoet, and van den\nHeuvel 2017). Even determining whether a path belongs\nto Π⋆is NP-hard (Papadimitriou and Yannakakis 2000).\nIn certain settings, we would like to compute the PF from\na source s ∈V to every other vertex v ∈V (see, e.g., (Mar-\ntins 1984; de las Casas, Sede˜no-Noda, and Bornd¨orfer 2021;\nKurbanov, Cuch´y, and Vokr´ınek 2023)) or from any vertex\nu ∈V to every other vertex v ∈V (see, e.g., (Zhang et al.\n2023b; Cuch´y, Vokr´ınek, and Jakob 2024)).\nApproximate MOS.\nIn real-world settings, we are often\nnot interested in the entire PF as it may be too large to\npresent to decision makers (for example, there may be thou-\nsands of solutions in the PF of large road networks (Ren\net al. 2025)). Thus, we are often interested in computing a\nbounded approximation of Π⋆. Here, we are given an ap-\nproximation factor ε. The ε-approximate PF Π⋆\nε is a set of\nsolutions such that ∀π ∈Π⋆, ∃π′ ∈Π⋆\nε s.t. c(π′) ⪯ε c(π).\nNamely, every solution in Π⋆is approximately dominated by\nsome solution in in Π∗\nε. Importantly, (i) the ε-approximate\nPareto-optimal solution set is not necessarily unique and\n(ii) some variants of this definition require that Π⋆\nε ⊆Π⋆\nwhile others don’t (See Fig. 1). Alternatively, some prob-\nlem formulations seek a small representative set of solutions\nin Π⋆(Rivera, Baier, and Hern´andez 2022) (without any for-\nmal definition of “small”).\nAnytime MOS.\nMany applications benefit from obtaining\na subset ˜Π⋆of Π⋆as fast as possible. As more time is avail-\nable to the algorithm, additional solutions from Π⋆\\ ˜Π⋆are\nadded to ˜Π⋆. The algorithm terminates when either (i) the\ndecision maker or the algorithm that uses the solutions ter-\nminates the algorithm or (ii) the entire PF has been returned\n(i.e., ˜Π⋆= Π⋆). Formally, we define the dominance factor\nof a solution π over another solution π′ as\nDF(π, π′) =\nmax\ni=1,2...N\n\u0012\nmax\n\u001a ci(π)\nci(π′) −1\n\u001b\n, 0\n\u0013\n,\nwhich measures how “good” π approximates π′. DF(π, π′)\nencodes the smallest ε-value that satisfies π ⪯(ε,...,ε) π′ (See\nFig. 1). For a set of solutions Π, we define the approximation\nerror of Π as\nERR(Π) = max\nπ′∈Π⋆{min\nπ∈Π DF(π, π′)},\nwhich, roughly speaking, measure the solution in Π⋆that is\n“least” approximated by any solution in Π.\nNow, to measure the performance of an anytime MOS al-\ngorithm, we typically wish to minimize the Area Under the\nCurve (AUC) of the approximation error formally defined\nas AUC =\nR tlimit\n0\nERR(Π(t)), where tlimit is the runtime limit\nand (Π(t)) is solution set returned at time t.\nIncremental & Dynamic MOS.\nWhen the MOS problem\nis applied in an online fashion (i.e., planning is interleaved\nwith taking actions) and the query is updated (either because\nthe target is updated or because the environment’s represen-\ntation is updated), one may want to avoid calling an algo-\nrithm from scratch and instead reuse previous search efforts.\nIncremental multi-objective graph search algorithms (see,\ne.g., (Ren et al. 2022b) reuse previous searches to speed up\nsubsequent exact or approximate MOS searches.\nSimilarly, in MOS applications such as flight planning,\ndynamic traffic roadmaps, and telecommunication and data\nnetworks, the underlying graph changes over time since\neither its structure (edges, nodes) or the cost functions\n(weights, travel times, risks, etc.) evolve. In contrast to the\nincremental setting, here we are given the dynamics be-\nfore planning begins and need to account for the temporal\nchanges. This was only recently formulated by de las Casas\net al. (2021). For additional details, see also the recent work\nby Shovan, Khanda, and Das (2025).\n2.3\nBeyond MOS\nWhile MOS assumes a deterministic model, many real prob-\nlems demand richer models. To capture stochasticity, or gen-\neral optimization beyond paths, several extensions have been\nstudied. Each extends MOS along a different axis while\nkeeping Pareto optimality central. We briefly describe each\nmodel, highlighting the similarities and differences com-\npared to MOS.\nHandling uncertainty.\nRecall that a MOS problem is de-\nfined using a graph G = (V, E) together with edge costs c\nwhich present a deterministic model. A Multi-objective\nStochastic Shortest Path (MOSSP) problem extends the\nMOS framework by introducing probabilistic transitions be-\ntween states (Roijers and Whiteson 2017). Formally, we are\ngiven a graph G = (V, E) together with edge costs c and\na transition probability distribution over successor vertices.\nA policy µ maps vertices to successor edges, inducing a dis-\ntribution over paths from the start s to the target t. The cost\nof a policy is defined as the expected cumulative cost vector\nacross objectives. As in MOS, policies are compared using\ndominance: a policy µ1 dominates µ2 if it has no worse ex-\npected cost in every objective and is strictly better in at least\none. The goal is to compute a coverage PF of policies.\nA Multi-objective Markov Decision Process (MOMDP)\ngeneralizes MOSSP by adopting an MDP formalism. In con-\ntrast to MOSSP which focuses on reaching a target in a\nstochastic graph with vector costs, MOMDP allow arbitrary\nhorizon settings (e.g., finite, infinite, discounted) and se-\nquential decision-making under uncertainty, not just reach-\ning a target vertex.\nLearning.\nMulti-objective\nReinforcement\nLearning\n(MORL) extends the MOS framework to settings where\nthe agent interacts with an environment through repeated\ntrial-and-error learning rather than having an explicit model\nof the state-transition dynamics (Hayes et al. 2022; Felten,\nTalbi, and Danoy 2024). Formally, MORL is defined over\nthe same structure as an MOMDP, M = (S, A, P, c), with\nstate space S, action space A, transition function P, and\nvector-valued cost or reward function c(s, a) ∈Rd. How-\never, unlike MOMDPs, in MORL the transition probabilities\nand reward distributions are not assumed to be known a\npriori. Instead, the agent learns a policy µ : S →A through\nexperience, typically by interacting with the environment\nand receiving vector-valued feedback.\nMORL generalizes MOS in that it seeks Pareto-optimal\nsolutions across multiple objectives, but unlike MOS, it does\nnot assume a static graph with deterministic edges. Rela-\ntive to MOSSP and MOMDP, MORL replaces planning with\nlearning: instead of computing Pareto-optimal policies from\na known model of uncertainty, the agent must discover them\nthrough exploration and approximation. Thus, MORL in-\nherits the challenges of both reinforcement learning (e.g.,\nexploration-exploitation trade-offs, function approximation)\nand MOS (e.g., dominance checks). The goal in MORL re-\nmains to approximate the Pareto set of policies, but learning\nalgorithms must balance sample efficiency, preference sensi-\ntivity, and scalability in high-dimensional state and objective\nspaces.\nMulti-objective Optimization.\nIn this paper, we focus\non MOS which can be seen as an instance of the more\ngeneral multi-objective optimization (MOO) problem, (see,\ne.g., (Branke et al. 2008; Miettinen 2012; Roijers and White-\nson 2017; Hwang and Masud 2012; Emmerich and Deutz\n2018)). It is important to highlight the similarities and dif-\nferences between the two fields.\nMOO is the most general formulation of problems in\nwhich several, possibly conflicting, objectives must be opti-\nmized simultaneously. Formally, given a feasible set X and\nobjective functions fi : X →R for i = 1, . . . , d, the prob-\nlem is to find the set of non-dominated solutions\nX ⋆= {x ∈X | ∄y ∈X, f(y) ⪯f(x), f(y) ̸= f(x)},\nwhere f(x) = (f1(x), . . . , fd(x)). Here, X ⋆corresponds to\nthe Pareto set whose image in Rd is the PF.\nRelative to MOS, MOO generalizes the underlying do-\nmain: whereas MOS is defined over paths in a determin-\nistic graph with additive vector costs, MOO is agnostic to\nthe structure of the feasible set and can capture contin-\nuous, combinatorial, or black-box domains. Compared to\nstochastic settings such as MOSSP and MOMDP, MOO\ndoes not necessarily assume probabilistic dynamics or se-\nquential decision processes; instead, it focuses purely on the\noptimization of static or offline-defined objectives. In con-\ntrast to MORL, MOO assumes direct access to the objective\nfunctions rather than learning them through interaction. In\nthis sense, MOO serves as the broad umbrella under which\nMOS, MOSSP, MOMDP, and MORL can be seen as struc-\ntured subclasses with additional constraints on the represen-\ntation of X, the dynamics of decision-making, and the infor-\nmation available to the algorithm.\nFrom an algorithmic point of view, in contrast to MOS,\nwhich builds upon search algorithms, MOO typically builds\nupon local and global optimization methods such as genetic\nalgorithms (Deb et al. 2002; Deb and Jain 2013; Zhang and\nLi 2007), particle swarm optimization (Coello and Lechuga\n2002), and simulated annealing (Li and Landa-Silva 2011).\n3\nAlgorithmic Advances\nIn this section we outline recent algorithmic advances in\nMOS. We start with a brief historical overview and continue\nto outline tools, techniques and algorithms that advances the\nstate-of-the-art in MOS. We conclude with a brief descrip-\ntion of advances in generalizations of MOS (Sec. 2.3) that\nhave close ties to MOS algorithms\n3.1\nBrief historical overview\nEarly work on MOS established the algorithmic framework\nwhich is the basis of most modern algorithms (Hansen 1980;\nMartins 1984; Warburton 1987). For efficiently comput-\ning Π⋆, two notable approaches emerged. The first gener-\nalizes the label-correcting paradigm to the multi-objective\nsetting (Guerriero and Musmanno 2001). Label-correcting\nis an iterative shortest-path method that repeatedly updates\ntentative distance labels of vertices whenever a shorter path\nis found, allowing multiple updates per vertex until no fur-\nther improvements are possible. The second generalizes the\ncelebrated A∗algorithm (Hart, Nilsson, and Raphael 1968)\nwhich we detail next as most of the recent advancements fall\nunder this category.\nA notable contribution was the work by Stewart et\nal. (1991), who introduced Multi-Objective A* (MOA∗).\nMOA∗served as the foundation to multiple extensions (see,\ne.g., (Mandow and De La Cruz 2005, 2010)) which differ\nin which information is contained in the nodes, how nodes\nare ordered in the priority queue and how dominance checks\nare implemented and when they are performed (upon gen-\neration or upon expansion). A key insight that dramatically\nimproved the efficiency of these algorithms was to order the\nnodes in the priority queue in increasing lexicographic order\nand apply the notion of dimensionality reduction (Pulido,\nMandow, and P´erez-de-la Cruz 2015). See (Salzman et al.\n2023) for an overview of the approach. The resulting algo-\nrithm based on this idea was termed NAMOA-dr1.\nEarly approaches (Warburton 1987; Perny and Spanjaard\n2008; Tsaggouris and Zaroliagis 2009; Breugem, Dollevoet,\nand van den Heuvel 2017) to approximating Π⋆focused\non Fully Polynomial Time Approximation Schemes2 (FP-\nTAS) (Vazirani 2001). Unfortunately, running these ap-\nproaches on moderately-sized graphs (i.e., with roughly\n10, 000 vertices) is often impractical (Breugem, Dollevoet,\nand van den Heuvel 2017).\n3.2\nAlgorithmic advances in MOS\nExact approaches.\nIn recent years, several algorithms\ndramatically improved the efficiency of exact MOS al-\ngorithms (see, e.g., (de las Casas et al. 2023; de las\nCasas, Sede˜no-Noda, and Bornd¨orfer 2021; Ahmadi et al.\n2021; Ren et al. 2025)). Notable examples that reduce\nthe computational complexity of key operations include\n(i) BOA∗(Hern´andez et al. 2023) which adapted and sim-\nplified NAMOA-dr for the bi-objective setting performing\ndominance checks in O(1), and (ii) recent work (Zhang et al.\n2024b; Ren et al. 2022a) which improves node indexing and\ndata structures for dominance checks of two and three objec-\ntives to yield dramatic speedups. Finally, recent work (Ah-\nmadi et al. 2024) considered the more general set of graphs\nwith negative edges.\nApproximate approaches.\nGoldin and Salzman (2021)\nsuggested PPA∗, an extension of BOA∗that introduced new\npruning techniques to efficiently compute an ε-approximate\nPF Π⋆\nε for the bi-objective setting. PPA∗was later general-\nized by Zhang et al. (2022) who suggested the A∗pex al-\ngorithm which allows to compute Π⋆\nε for any number of ob-\njectives. The efficiency of A∗pex stems from the observation\nthat paths whose cost is very similar can be grouped in an ef-\nficient manner allowing to dramatically prune the PF. A∗pex\nwas later used to exploit correlation of edge costs (Halle\net al. 2025), develop anytime MOS algorithms (Zhang et al.\n2024c) and more (Zhang et al. 2024a), see also Sec. 4.\n1Here, ‘dr’ stands for dimensionality reduction.\n2An FPTAS is an approximation scheme whose time complex-\nity is polynomial in the input size and also polynomial in 1/ε\nwhere ε is the approximation factor.\nParallelization.\nWhile there has been some research on\nparallelizing MOS algorithms (see, e.g., (Sanders and\nMandow 2013; Erb, Kobitzsch, and Sanders 2014; Medrano\nand Church 2015), this research direction has been largely\nunexplored (Salzman et al. 2023). Two notable exceptions\ninclude (i) The work by Ahmadi et al. (2025) who ex-\nplored permutations of objective orderings in parallel while\nsharing bounds to collapse subproblems, achieving near-\nlinear speedups on many-core systems and (ii) the work\nby Hern´andez et al. (2024) who suggest an approach to\ncompute set dominance checks or SDC (a key procedure,\nwhich dominates the running time of many state-of-the-\nart MOS algorithms) in parallel. They exploit vectorized\nthe operations offered by “Single Instruction/Multiple Data”\n(SIMD) instructions to perform SDC on ubiquitous con-\nsumer CPUs thereby dramatically improving the runtime of\nexisting MOS algorithms.\nTheory.\nThere have not been many recent theoretical ad-\nvances. de las Casas et al. (2021) suggested an FPTAS for\nthe new setting of dynamic MOS in which edges cost can\nchange online. Skyler et al. (2024) extended theory from\nsingle-objective search (SOS) to MOS which characterizes\nthe set of vertices and search nodes that any unidirectional\nsearch algorithm must expand to prove the optimality of\nthe solution. Specifically, they introduce a classification of\nvertices into must-expand, maybe-expand, and never-expand\ncategories. The notable difference between SOS and MOS is\nthat vertices must be expanded to (i) prove that any path in\na PF is Pareto-optimal (these are called optimality vertices)\nand (ii) ensure that there are no more solution costs that are\nnot represented in the PF (these are called completness ver-\ntices). Completeness vertices have no analogy in SOS.\nHeuristics.\nKey to the success of heuristic search in gen-\neral, and heuristic MOS in particular, is the ability to in-\ncorporate domain knowledge using heuristics that guide the\nalgorithm. Almost all MOS algorithms use the “ideal point\nheuristic” hideal, which combines a set of d single-objective\nheuristics h1, . . . , hd. Here, hi : V →R≥0 corresponds to\nthe shortest path from each vertex according to the i’th ob-\njective and ∀v ∈V hideal(v) := (h1(v), . . . , hd(v)).\nHowever, in contrast to SOS, in the general case of MOS,\nthe heuristic value of a vertex v is not a single cost vector,\nbut a set of cost vectors (see (Mandow and De La Cruz 2010)\nfor original definition and (Salzman et al. 2023) for an in-\ndepth discussion). While such heuristics, called Multi-Value\nHeuristics (MVH) are much more informative, the overhead\nof computing and using MVHs in MOS algorithms can be\nlarge and the total runtime is often larger than when us-\ning hideal (Geißer et al. 2022).\nA notable example where MVHs are used is the recent\nwork by Zhang et al. (2023a), which generalize Differen-\ntial Heuristics (DHs) (Goldberg and Harrelson 2005), a class\nof memory-based heuristics for SOS, to bi-objective search,\nresulting in Bi-Objective Differential Heuristics (BO-DHs).\nThey propose several techniques to reduce the memory us-\nage and computational overhead of BO-DHs, demonstrating\nreductions in runtime of a bi-objective search algorithm by\nup to an order of magnitude.\n3.3\nAlgorithmic advances in MOS extensions\nWhile there has been many advances in MOSSP, MOMDP\nand MOO algorithms, which are not the focus of this pa-\nper, here we mention work that is closely related to MOS.\nRecent work by Chen, Trevizan, and Thi´ebaux (2023) sug-\ngests adapting heuristic-search algorithms (which are the\nfoundation of MOS algorithms) for MOSSP. This is done\nby extending (single-objective) stochastic shortest-path al-\ngorithms, such as LAO* (Hansen and Zilberstein 2001) and\nLRTDP (Bonet and Geffner 2001), to the multi-objective\nsetting. They also study how to guide their algorithms with\ndomain-independent heuristics to account for the probabilis-\ntic and multi-objective features of the problem.\n4\nMOS as an Algorithmic Toolbox\nRecently the algorithmic toolbox developed for MOS has\nalso proven useful in other domains. Some, are new variants\nof MOS while others are seemingly unrelated optimization\nproblems where MOS approaches have been useful.\nMulti-objective minimum spanning tree.\nThe Multi-\nObjective Minimum Spanning Tree (MO-MST) problem\ngeneralizes the classical MST problem to settings where\nedges are labeled with cost vectors. Instead of a single span-\nning tree with minimal total weight, the goal is to iden-\ntify a Pareto set of spanning trees that represent undomi-\nnated trade-offs among objectives. However, unlike MST,\nfor which there are polynomial time algorithms that solve\nit, MO-MST is NP-hard (Fernandes et al. 2020). MO-MST\nis important for communication networks, where spanning\ntrees must balance latency, bandwidth and resilience, and\nin transport and logistics, where constructing infrastructure\nwith multiple cost criteria is essential (see, e.g., (Levin and\nNuriakhmetov 2011)). MO-MST algorithms borrow heav-\nily from MOS techniques (see, e.g., (Sourd and Spanjaard\n2008; Fernandes et al. 2020; de las Casas, Sede˜no-Noda, and\nBornd¨orfer 2025)).\nMOS with objective aggregation.\nIn many real-world\nproblems with multiple objectives, the objectives interact in\na complex manner, leading to problem formulations that do\nnot allow out-of-the-box usage of MOS algorithms (Fu et al.\n2023; Slutsky et al. 2021; Axelrod, Kaelbling, and Lozano-\nP´erez 2018). Roughly speaking, this is because the search al-\ngorithms needs to treat differently paths that are and that are\nnot solutions. For example, in robot inspection planning (Fu\net al. 2023; Alpert et al. 2025), a robot is required to view as\nmany points of interest (POI) as possible using an on-board\nsensor while minimizing path length. The two objectives\nwhich define a solution π are the number of POIs viewed\nalong π and the length of π. However, every path that is not\na solution must keep track of which POI was viewed, es-\nsentially defining a binary objective for each POI. This is\nbecause two paths to the same vertex that viewed different\nPOIs cannot dominate one another as their final bi-objective\ncost depends on which POIs will be viewed in the future.\nThis creates a mismatch between objectives at intermedi-\nate nodes, which we term hidden objectives, and objectives\nat solution nodes, which we term solution objectives. The\nrelation between solution objectives and hidden objectives\nis captured via some method of objective aggregation (Peer\net al. 2025). Returning to our inspection-planning exam-\nple, there is one hidden objective that corresponds to each\nPOI as well as one for path length and there are two solu-\ntion objectives corresponding to number of POIs viewed and\npath length. Here objective aggregation is done by adding\nall (binary) cost values of POI hidden objectives. We call\nsuch problems MOS with objective aggregation (MOS-OA).\nImportantly, MOS-OA algorithms can naturally employ the\nMOS algorithmic toolbox. Indeed, early versions of A∗pex\nwere developed in the context of MOS-OA (Fu et al. 2023).\nMulti-objective Multi-Agent Path Finding.\nThe Multi-\nAgent Path Finding (MAPF) problem (Stern et al. 2019) in-\nvolves finding non-colliding paths for multiple agents from\ntheir start locations to their respective target locations in\na shared environment. The primary goal is to optimize a\nmetric such as the sum of travel time of all agents or the\nmakespan (i.e., task completion time). The Multi-Objective\nMAPF (MO-MAPF) problem extends the MAPF problem\nto multiple, often conflicting, optimization criteria such as\nmakespan, energy consumption, safety margin, or fairness\namong agents. The result is not a single plan but a PF of\nMAPF plans, each representing a different trade-off. Recent\nalgorithms (see, e.g., (Ren, Rathinam, and Choset 2021b,a,\n2023; Wang et al. 2024)) integrate MAPF and MOS to ob-\ntain scalable algorithms for this purpose.\nConstrained shortest path.\nIn the Constrained Shortest-\nPath problem (CSP) (Storandt 2012) we are interested in\ncomputing a shortest path subject to some constraints (e.g.,\nlimited energy consumption for an autonomous agent). This\nsetting was generalized by Skyler et al. (2022) who consider\nthe setting where we need to find a solution which belongs\nto Π⋆whose costs are below given upper bounds on each\nobjective. Later Zhang et al. (2024a) considered a similar\nsetting but where we need to find a solution which belongs\nto Π⋆\nε for some ε > 0.\nk-Shortest simple path.\nIn the k-Shortest Simple Path\n(k-SSP) problem, we are given a graph G = (V, E) with\nregular (scalar) edge costs. Given start and target vertices\ns, t ∈V and a parameter k, we are tasked to compute the\nk shortest paths between s and t. While this is a single-\nobjective problem, recently de las Casas et al. (2025) have\nshown that the 2-SSP can be solved by a reduction to a bi-\nobjective search problem.\n5\nEmerging Applications\nWe briefly review several diverse domains where MOS and\nits variants have been recently used. This showcases the ap-\nplicability of MOS despite its relative simplicity when com-\npared to the richer models reviewed in Sec. 2.3.\nAutomated design & synthesis.\nMOS has been applied to\ndesign problems in chemistry, biology, and engineering. One\nexample is retrosynthesis planning in computational chem-\nistry, which is the problem of finding reaction sequences that\nproduce a target molecule. Lai et al. (2025) consider multi-\nple objectives and, by searching for un-dominated synthesis\nroutes, they were able to present several candidate pathways\nto a human chemist to evaluate and choose from. Similarly,\nMOS found applications in drug discovery and generative\ndesign. For example, Southiratn et al. (2025) suggested a bi-\nobjective search algorithm for generating molecular struc-\ntures that balance affinity to two proteins while also satisfy-\ning drug-like property constraints The result is a set of novel\nmolecular candidates with high predicted efficacy and ac-\nceptable pharmacological profiles. which traditional single-\nobjective or scalarized approaches would have likely missed.\nMulti-modal journey planning.\nMulti-modal journey\nplanning determines routes combining different transport\nmodes (Bast et al. 2016), which inherently involves multi-\nobjective optimization such as time, cost and comfort. These\nmethods (see e.g., (Potthoff and Sauer 2022b,a)) build upon\nMOS algorithms to make queries tractable at metropolitan\nscale. Many real-world uses of such algorithms have re-\ncently been documented. For example, OpenTripPlanner 2\nis an open-source multi-modal journey planner for public\ntransportation in combination with bicycling, walking, and\nmobility services such as bike share and ride hailing. It has\nbeen deployed nationwide in Norway and Finland. In Port-\nland (Oregon), it provides about 40,000 trip plans on a typi-\ncal weekday (OTP 2025).\nRobotics.\nIn robotics, multiple objectives often need to be\nsimultaneously balanced (e.g., cost, energy and safety) In\nSec. 4 we discussed robot inspection planning in the con-\ntext of MOS-OA. Another example is autonomous vehicle\n(AV) planning using rulebooks (Slutsky et al. 2021; Censi\net al. 2019; Halder and Althoff 2025; Penlington, Zanardi,\nand Frazzoli 2024), where the system must generate a trajec-\ntory that complies with a set of potentially conflicting traf-\nfic rules. Consider, for instance, Singapore’s Final Theory of\nDriving that requires (i) maintaining at least a one-meter gap\nwhen passing a parked vehicle and (ii) prohibits crossing a\nsolid double white lane divider. When an AV encounters a\ncar improperly parked along such a divider, it may be im-\npossible to satisfy both requirements simultaneously. Fortu-\nnately, requirements often form in a hierarchy—e.g., avoid-\ning a collision is more important than keeping safety margin\nfrom parked vehicles and than maintaining lane. Rulebooks\nare a systematic way to address such settings. Here, a rule\ncorresponds to an objective and a rulebook defines a hierar-\nchy that induces a partial order. For example rule r1 (avoid-\ning collision) is more important than rules r2, r3 (maintain-\ning safety distance and lane) but rules r2, r3 are incompara-\nble. This generalizes MOS which is a “flat” hierarchy where\nno objective (rule) is more critical than any other one.\n6\nOpen Challenges and Opportunities\nDespite the progress reviewed in this paper, several funda-\nmental challenges remain open. In contrast to Salzman et al.\n(2023) who discuss technical challenges that are the foun-\ndations for advancing MOS algorithms, here we focus on\nchallenges and opportunities that will increase the impact of\nMOS.\nScalability and dimensionality.\nMost existing algorithms\nscale poorly when the number of objectives grows beyond\ntwo or three. Approximate and bounded suboptimal MOS\nalgorithms partially address this issue, but there is no con-\nsensus on how to effectively navigate high-dimensional cost\nspaces which may be essential in real-world applications.\nDynamic and uncertain environments.\nReal-world de-\nployment increasingly requires algorithms that adapt to\nchanging graphs or stochastic models. While recent works\nstudy dynamic MOS, MOSSP and MOMDP, current algo-\nrithms mostly remain theoretical or are limited to small in-\nstance sizes. Developing practical, general-purpose dynamic\nMOS algorithms is an interesting research opportunity.\nPreference elicitation and user modeling.\nIn many ap-\nplications, decision makers cannot provide trade-offs up-\nfront. Integrating preference elicitation into the search pro-\ncess—by interactively presenting Pareto-optimal candidates\nand learning from user choices—remains an underexplored\nyet impactful research direction. Combining MOS algo-\nrithms with methods from preference learning and human-\nin-the-loop AI is another research opportunity.\nCross-fertilization between research communities.\nIm-\nportant opportunities exist at the interface of MOS and other\nAI subfields. In reinforcement learning, MORL is rediscov-\nering many algorithmic ideas from MOS; conversely, MOS\ncan benefit from policy-gradient and distributional methods.\nIn many domains such as robotics, large-scale transport sys-\ntems and OR, multiple objectives are prevalent but existing\nMOS formulations need to be adapted to be applied effec-\ntively.\nBenchmarks.\nClassical MOS benchmarks focus on road\nnetworks and grid worlds, while robotics emphasizes\nmotion-planning roadmaps, and reinforcement learning re-\nlies on synthetic MO-MDPs. This fragmentation hampers\ncomparison across research communities.\nA standardized benchmark suite that spans classical\nMOS, stochastic and dynamic settings, and application-\ninspired domains (such as transportation, robotics and chem-\nistry) would be a major step forward. Beyond static datasets,\nbenchmarks should include interactive tasks for preference\nelicitation and evaluation metrics that reflect both efficiency\nand effectiveness. The community would benefit from a\nshared repository of graphs, environments, and evaluation\nprotocols to foster reproducibility and comparability.\n7\nConclusion\nMOS has rapidly expanded from a niche research topic to a\nbroad principle that influences many disciplines and applica-\ntions and studied by multiple communities. On the algorith-\nmic side, there have been significant improvements in exact\nsearch, new approximate and parallel algorithms, and theo-\nretical insights. On the applications side, numerous commu-\nnities have started to formulate their problems in terms of\ntrade-offs between different metrics and adopt MOS meth-\nods to handle these trade-offs. While MOS was the focus of\nthis paper, there should be more cross fertilization between\ndifferent multi-objective optimization approaches.\nAcknowledgments\nThis research was supported by Grant No. 2021643 from the\nUnited States-Israel Binational Science Foundation (BSF).\nReferences\nAAAI. 2024.\nTutorial on Recent Advances in Multi-\nObjective Search. https://sites.google.com/usc.edu/aaai24-\nmos-tutorial/home.\nAhmadi, S.; Sturtevant, N. R.; Harabor, D.; and Jalili, M.\n2024.\nExact Multi-objective Path Finding with Negative\nWeights. In International Conference on Automated Plan-\nning and Scheduling (ICAPS), 11–19.\nAhmadi, S.; Sturtevant, N. R.; Raith, A.; Harabor, D.; and\nJalili, M. 2025.\nParallelizing Multi-objective A* Search.\narXiv:2503.10075.\nAhmadi, S.; Tack, G.; Harabor, D.; and Kilby, P. 2021. Bi-\nObjective Search with Bi-Directional A*. In European Sym-\nposium on Algorithms (ESA), volume 204 of LIPIcs, 3:1–\n3:15.\nAlpert, S. D.; Solovey, K.; Klein, I.; and Salzman, O. 2025.\nInspection Planning Under Execution Uncertainty.\nIEEE\nTrans. Robotics, 41: 2406–2423.\nAxelrod, B.; Kaelbling, L. P.; and Lozano-P´erez, T. 2018.\nProvably safe robot navigation with obstacle uncertainty.\nThe International Journal of Robotics Research (IJRR),\n37(13-14): 1760–1774.\nBast, H.; Delling, D.; Goldberg, A. V.; M¨uller-Hannemann,\nM.; Pajor, T.; Sanders, P.; Wagner, D.; and Werneck, R. F.\n2016. Route Planning in Transportation Networks. In Klie-\nmann, L.; and Sanders, P., eds., Algorithm Engineering - Se-\nlected Results and Surveys, volume 9220 of Lecture Notes in\nComputer Science, 19–80.\nBonet, B.; and Geffner, H. 2001.\nPlanning as heuristic\nsearch. Artificial intelligence, 129(1-2): 5–33.\nBranke, J.; Deb, K.; Miettinen, K.; and Slowi´nski, R. 2008.\nMultiobjective optimization: Interactive and evolutionary\napproaches, volume 5252.\nSpringer Science & Business\nMedia.\nBreugem, T.; Dollevoet, T.; and van den Heuvel, W. 2017.\nAnalysis of FPTASes for the multi-objective shortest path\nproblem. Computers & Operations Research, 78: 44–58.\nCensi, A.; Slutsky, K.; Wongpiromsarn, T.; Yershov, D. S.;\nPendleton, S.; Fu, J. G. M.; and Frazzoli, E. 2019. Liabil-\nity, Ethics, and Culture-Aware Behavior Specification using\nRulebooks. In IEEE International Conference on Robotics\nand Automation (ICRA), 8536–8542.\nChen, D. Z.; Trevizan, F.; and Thi´ebaux, S. 2023. Heuris-\ntic Search for Multi-Objective Probabilistic Planning.\nIn\nAssociation for the Advancement of Artificial Intelligence\n(AAAI).\nCl´ımaco, J.; and Pascoal, M. 2012. Multicriteria path and\ntree problems: discussion on exact algorithms and applica-\ntions. Int. Trans. in OR, 19(1-2): 63–98.\nCoello, C. C.; and Lechuga, M. S. 2002. MOPSO: A pro-\nposal for multiple objective particle swarm optimization. In\nCongress on Evolutionary Computation (CEC), volume 2,\n1051–1056.\nCuch´y, M.; Vokr´ınek, J.; and Jakob, M. 2024.\nMulti-\nObjective Electric Vehicle Route and Charging Planning\nwith Contraction Hierarchies. In International Conference\non Automated Planning and Scheduling (ICAPS), 114–122.\nCurrent, J.; and Marsh, M. 1993. Multiobjective transporta-\ntion network design and routing problems: Taxonomy and\nannotation. Eur. J. of OR, 65(1): 4–19.\nde las Casas, P. M.; Bornd¨orfer, R.; Kraus, L.; and Sede˜no-\nNoda, A. 2021.\nAn FPTAS for Dynamic Multiobjective\nShortest Path Problems. Algorithms, 14(2): 43.\nde las Casas, P. M.; Kraus, L.; Sede˜no-Noda, A.; and\nBornd¨orfer, R. 2023. Targeted multiobjective Dijkstra al-\ngorithm. Networks, 82(3): 277–298.\nde las Casas, P. M.; Sede˜no-Noda, A.; and Bornd¨orfer, R.\n2021. An Improved Multiobjective Shortest Path Algorithm.\nComput. Oper. Res., 135: 105424.\nde las Casas, P. M.; Sede˜no-Noda, A.; and Bornd¨orfer, R.\n2025. New Dynamic Programming algorithm for the Multi-\nobjective Minimum Spanning Tree problem. Comput. Oper.\nRes., 173: 106852.\nde las Casas, P. M.; Sede˜no-Noda, A.; Bornd¨orfer, R.; and\nHuneshagen, M. 2025. K-shortest simple paths using biob-\njective path search. Math. Program. Comput., 17(2): 349–\n384.\nDeb, K.; and Jain, H. 2013. An evolutionary many-objective\noptimization algorithm using reference-point-based non-\ndominated sorting approach, part I: solving problems with\nbox constraints. IEEE transactions on evolutionary compu-\ntation, 18(4): 577–601.\nDeb, K.; Pratap, A.; Agarwal, S.; and Meyarivan, T. 2002.\nA fast and elitist multiobjective genetic algorithm: NSGA-\nII. IEEE transactions on evolutionary computation, 6(2):\n182–197.\nECAI. 2025. Multi-Objective Decision Making Workshop.\nhttps://modem2025.vub.ac.be/.\nEhrgott, M. 2005.\nMulticriteria Optimization (2nd ed.).\nSpringer.\nEmmerich, M.; and Deutz, A. 2018. A tutorial on multiob-\njective optimization: fundamentals and evolutionary meth-\nods. Natural computing, 17(3): 585–609.\nErb, S.; Kobitzsch, M.; and Sanders, P. 2014. Parallel bi-\nobjective shortest paths using weight-balanced b-trees with\nbulk updates. In SEA, 111–122.\nFelten, F.; Talbi, E.-G.; and Danoy, G. 2024.\nMulti-\nObjective Reinforcement Learning Based on Decomposi-\ntion: A Taxonomy and Framework. Journal of Artificial In-\ntelligence Research, 79.\nFernandes, I. F.; Goldbarg, E. F. G.; Maia, S. M.; and Gold-\nbarg, M. C. 2020. Empirical study of exact algorithms for\nthe multi-objective spanning tree. Computational Optimiza-\ntion and Applications, 75(2): 561–605.\nFu, M.; Kuntz, A.; Salzman, O.; and Alterovitz, R. 2023.\nAsymptotically optimal inspection planning via efficient\nnear-optimal search on sampled roadmaps.\nThe Interna-\ntional Journal of Robotics Research (IJRR), 42(4-5): 150–\n175.\nGeißer, F.; Haslum, P.; Thi´ebaux, S.; and Trevizan, F.\n2022. Admissible Heuristics for Multi-Objective Planning.\nIn International Conference on Automated Planning and\nScheduling (ICAPS), 100–109.\nGoldberg, A. V.; and Harrelson, C. 2005. Computing the\nshortest path: A search meets graph theory. In ACM-SIAM\nSymposium on Discrete Algorithms (SODA), volume 5, 156–\n165.\nGoldin, B.; and Salzman, O. 2021. Approximate Bi-Criteria\nSearch by Efficient Representation of Subsets of the Pareto-\nOptimal Frontier.\nIn\nInternational Conference on Auto-\nmated Planning and Scheduling (ICAPS), 149–158.\nGuerriero, F.; and Musmanno, R. 2001. Label correcting\nmethods to solve multicriteria shortest path problems.\nJ.\nOpt. Theory App., 111(3): 589–613.\nHalder, P.; and Althoff, M. 2025. Sampling-Based Motion\nPlanning with Preordered Objectives. In 2025 IEEE Intelli-\ngent Vehicles Symposium (IV), 125–131.\nHalle, Y.; Felner, A.; Koenig, S.; and Salzman, O. 2025.\nA Preprocessing Framework for Efficient Approximate Bi-\nObjective Shortest-Path Computation in the Presence of\nCorrelated Objectives.\nIn Symposium on Combinatorial\nSearch (SoCS), 65–73.\nHansen, E. A.; and Zilberstein, S. 2001. LAO*: A heuristic\nsearch algorithm that finds solutions with loops. Artificial\nintelligence, 129(1-2): 35–62.\nHansen, P. 1980. Bicriterion Path Problems. In Multiple Cri-\nteria Decision Making: Theory and Application, 109–127.\nHart, P. E.; Nilsson, N. J.; and Raphael, B. 1968. A For-\nmal Basis for the Heuristic Determination of Minimum Cost\nPaths. IEEE Transactions on Systems Science and Cyber-\nnetics, 4(2): 100–107.\nHayes, C. F.; R˘adulescu, R.; Bargiacchi, E.; K¨allstr¨om, J.;\nMacfarlane, M.; Reymond, M.; Verstraeten, T.; Zintgraf,\nL. M.; Dazeley, R.; Heintz, F.; Howley, E.; Irissappane,\nA. A.; Mannion, P.; Now´e, A.; Ramos, G.; Restelli, M.;\nVamplew, P.; and Roijers, D. M. 2022. A practical guide\nto multi-objective reinforcement learning and planning. Au-\ntonomous Agents and Multi-Agent Systems, 36(1).\nHern´andez, C.; Yeoh, W.; Baier, J. A.; Zhang, H.; Suazo,\nL.; Koenig, S.; and Salzman, O. 2023. Simple and efficient\nbi-objective search algorithms via fast dominance checks.\nArtificial intelligence, 314: 103807.\nHern´andez, C.; Zhang, H.; Koenig, S.; Felner, A.; and Salz-\nman, O. 2024. Efficient Set Dominance Checks in Multi-\nObjective Shortest-Path Algorithms via Vectorized Opera-\ntions. In Symposium on Combinatorial Search (SoCS), 208–\n212.\nHwang, C.-L.; and Masud, A. S. 2012. Multiple objective\ndecision making—methods and applications: a state-of-the-\nart survey, volume 164. Springer Science & Business Me-\ndia.\nICAPS. 2024. Finding Multiple Plans for Classical Planning\nProblems.\nhttps://icaps24.icaps-conference.org/program/\ntutorials/2024 t02 finding multiple plans/.\nIJCAI. 2023.\nFirst International Workshop on Search\nand Planning with Complex Objectives.\nhttp://idm-\nlab.org/wiki/complex-objective/.\nIJCAI. 2025. Gradient-Based Multi-Objective Deep Learn-\ning. https://gradnexus.github.io/IJCAI25 tutorial/.\nKurbanov, T.; Cuch´y, M.; and Vokr´ınek, J. 2023. Fast One-\nto-Many Multicriteria Shortest Path Search.\nIEEE Trans.\nIntell. Transp. Syst., 24(10): 10410–10419.\nLai, H.; Kannas, C.; Hassen, A. K.; Granqvist, E.; West-\nerlund, A. M.; Clevert, D.-A.; Preuss, M.; and Genheden,\nS. 2025.\nMulti-objective synthesis planning by means of\nMonte Carlo Tree search. Artificial Intelligence in the Life\nSciences, 7: 100130.\nLevin, M. S.; and Nuriakhmetov, R. I. 2011. Multicriteria\nSteiner Tree Problem for Communication Network. CoRR,\nabs/1102.2524.\nLi, H.; and Landa-Silva, D. 2011. An adaptive evolution-\nary multi-objective approach based on simulated annealing.\nEvolutionary computation, 19(4): 561–595.\nMandow, L.; and De La Cruz, J. L. P. 2005. A new approach\nto multiobjective A* search. In International Joint Confer-\nences on Artificial Intelligence (IJCAI), 218–223.\nMandow, L.; and De La Cruz, J. L. P. 2010. Multiobjective\nA* Search with Consistent Heuristics. Journal of the ACM,\n57(5): 1–25.\nMartins, E. Q. V. 1984. On a Multicriteria Shortest Path\nProblem. European Journal of Operational Research, 16(2):\n236–245.\nMedrano, F. A.; and Church, R. L. 2015. A parallel com-\nputing framework for finding the supported solutions to a\nbiobjective network optimization problem. J. Multi-Criteria\nDecis. Anal., 22(5-6): 244–259.\nMiettinen, K. 2012. Nonlinear multiobjective optimization,\nvolume 12. Springer Science & Business Media.\nNeurIPS.\n2024.\nPluralistic\nAlignmen\nworkshop.\nhttps://pluralistic-alignment.github.io/.\nOTP. 2025.\nOpenTripPlanner Deployments Worldwide.\nhttps://docs.opentripplanner.org/en/latest/Deployments/.\nPapadimitriou, C. H.; and Yannakakis, M. 2000.\nOn the\napproximability of trade-offs and optimal access of web\nsources. In EEE Symposium on Foundations of Computer\nScience (FOCS), 86–92.\nPeer, H.; Weiss, E.; Alterovitz, R.; and Salzman, O.\n2025. Generalizing Multi-Objective Search via Objective-\nAggregation Functions. CoRR, abs/2509.22085.\nPenlington, M.; Zanardi, A.; and Frazzoli, E. 2024.\nOp-\ntimization of Rulebooks via Asymptotically Represent-\ning Lexicographic Hierarchies for Autonomous Vehicles.\narXiv:2409.11199.\nPerny, P.; and Spanjaard, O. 2008. Near Admissible Algo-\nrithms for Multiobjective Search. In European Conference\non Artificial Intelligence (ECAI), 490–494.\nPotthoff, M.; and Sauer, J. 2022a. Efficient Algorithms for\nFully Multimodal Journey Planning. In Symposium on Al-\ngorithmic Approaches for Transportation Modelling, Opti-\nmization, and Systems (ATMOS), volume 106, 14:1–14:15.\nPotthoff, M.; and Sauer, J. 2022b. Fast Multimodal Journey\nPlanning for Three Criteria.\nIn Symposium on Algorithm\nEngineering and Experiments (ALENEX), 145–157.\nPulido, F.-J.; Mandow, L.; and P´erez-de-la Cruz, J.-L. 2015.\nDimensionality reduction in multiobjective shortest path\nsearch. Computers & Operations Research, 64: 60–70.\nRen, L.; Han, B.; Ma, H. M.; Huang, Z.; Wang, Y.; and Chen,\nX. 2022a. Enhanced Multi-Objective A* Using Balanced\nBinary Search Trees. arXiv:2202.08992.\nRen, Z.; Hern´andez, C.; Likhachev, M.; Felner, A.; Koenig,\nS.; Salzman, O.; Rathinam, S.; and Choset, H. 2025.\nEMOA*: A framework for search-based multi-objective\npath planning. Artificial Intelligence, 339: 104260.\nRen, Z.; Rathinam, S.; and Choset, H. 2021a.\nMulti-\nobjective Conflict-based Search for Multi-agent Path Find-\ning. In IEEE International Conference on Robotics and Au-\ntomation (ICRA). IEEE.\nRen, Z.; Rathinam, S.; and Choset, H. 2021b.\nSubdi-\nmensional Expansion for Multi-Objective Multi-Agent Path\nFinding.\nIEEE Robotics and Automation Letters, 6(4):\n7153–7160.\nRen, Z.; Rathinam, S.; and Choset, H. 2023. A Conflict-\nBased Search Framework for Multiobjective Multiagent\nPath Finding. IEEE transactions on automation science and\nengineering, 20(2): 1262–1274.\nRen, Z.; Rathinam, S.; Likhachev, M.; and Choset, H. 2022b.\nMulti-Objective Path-Based D* Lite.\nIEEE Robotics and\nAutomation Letters, 7(2): 3318–3325.\nRivera, N.; Baier, J. A.; and Hern´andez, C. 2022. Subset\nApproximation of Pareto Regions with Bi-objective A*. In\nAssociation for the Advancement of Artificial Intelligence\n(AAAI), 10345–10352.\nRoijers, D. M.; and Whiteson, S. 2017. Multi-Objective De-\ncision Making, volume 12 of Synthesis Lectures on Artificial\nIntelligence and Machine Learning.\nMorgan & Claypool\nPublishers. ISBN 9781627058648.\nRSS. 2025. Workshop on Multi-Objective Optimization and\nPlanning in Robotics.\nhttps://sites.google.com/view/moo-\nrss25/home.\nSalzman, O.; Felner, A.; Hern´andez, C.; Zhang, H.; Chan,\nS.; and Koenig, S. 2023. Heuristic-Search Approaches for\nthe Multi-Objective Shortest-Path Problem: Progress and\nResearch Opportunities. In International Joint Conferences\non Artificial Intelligence (IJCAI), 6759–6768.\nSanders, P.; and Mandow, L. 2013.\nParallel label-setting\nmulti-objective shortest path search. In Int. Symp. on Par-\nallel and Distributed Processing, 215–224.\nSerafini, P. 1987. Some considerations about computational\ncomplexity for multi objective combinatorial problems. In\nRecent advances and historical development of vector opti-\nmization, 222–232. Springer.\nShovan, S. M.; Khanda, A.; and Das, S. K. 2025. Parallel\nMulti Objective Shortest Path Update Algorithm in Large\nDynamic Networks. IEEE Trans. Parallel Distributed Syst.,\n36(5): 932–944.\nSkriver, A. J. 2000. A classification of bicriterion shortest\npath (BSP) algorithms. Asia Pacific J. of Oper. Res., 17(2):\n199–212.\nSkyler, S.; Atzmon, D.; Felner, A.; Salzman, O.; Zhang, H.;\nKoenig, S.; Yeoh, W.; and Ulloa, C. H. 2022. Bounded-cost\nbi-objective heuristic search. In Symposium on Combinato-\nrial Search (SoCS), volume 15, 239–243.\nSkyler, S.; Shperberg, S. S.; Atzmon, D.; Felner, A.; Salz-\nman, O.; Chan, S.; Zhang, H.; Koenig, S.; Yeoh, W.; and\nUlloa, C. H. 2024.\nTheoretical Study on Multi-objective\nHeuristic Search. In International Joint Conferences on Ar-\ntificial Intelligence (IJCAI), 7021–7028.\nSlutsky, K.; Yershov, D. S.; Wongpiromsarn, T.; and Fraz-\nzoli, E. 2021.\nHierarchical Multiobjective Shortest Path\nProblems. In Workshop on the Algorithmic Foundations of\nRobotics (WAFR), volume 17, 261–276.\nSOCS.\n2023.\nMaster\nClass\nOn\nClashing\nWave-\nfronts\nin\nPareto\nSearch.\nhttps://socs23.search-\nconference.org/program/master-classes.\nSourd, F.; and Spanjaard, O. 2008.\nA Multiobjective\nBranch-and-Bound Framework: Application to the Biobjec-\ntive Spanning Tree Problem. INFORMS J. Comput., 20(3):\n472–484.\nSouthiratn, T.; Koo, B.; Lu, Y.; and Kim, S. 2025. Com-\nbiMOTS: Combinatorial Multi-Objective Tree Search for\nDual-Target Molecule Generation. In International Confer-\nence on Machine Learning (ICML).\nStern, R.; Sturtevant, N. R.; Felner, A.; Koenig, S.; Ma, H.;\nWalker, T. T.; Li, J.; Atzmon, D.; Cohen, L.; Kumar, T. K. S.;\nBart´ak, R.; and Boyarski, E. 2019. Multi-Agent Pathfinding:\nDefinitions, Variants, and Benchmarks. In Symposium on\nCombinatorial Search (SoCS), 151–158.\nStewart, B. S.; and White III, C. C. 1991. Multiobjective A*.\nJournal of the ACM (JACM), 38(4): 775–814.\nStorandt, S. 2012. Route planning for bicycles—exact con-\nstrained shortest paths made practical via contraction hier-\narchy. In International Conference on Automated Planning\nand Scheduling (ICAPS), 234–242.\nTarapata, Z. M. 2007. Selected multicriteria shortest path\nproblems: An analysis of complexity, models and adaptation\nof standard algorithms.\nInt. J. Appl. Math. Comput. Sci.,\n17(2).\nTsaggouris, G.; and Zaroliagis, C. D. 2009. Multiobjective\nOptimization: Improved FPTAS for Shortest Paths and Non-\nLinear Objectives with Applications. Theory of Com. Sys.,\n45(1): 162–186.\nUlungu, E.; and Teghem, J. 1991. Multi-objective shortest\npath problem: A survey. In Workshop on Multicriteria Deci-\nsion Making: Methods–Algorithms–Applications, 176–188.\nVazirani, V. V. 2001. Approximation algorithms. Springer.\nVincke, P. 1976.\nA New Approach to Multiple Criteria\nDecision-Making.\nIn Multiple Criteria Decision Making,\n341–350.\nWang, F.; Zhang, H.; Koenig, S.; and Li, J. 2024. Efficient\nApproximate Search for Multi-Objective Multi-Agent Path\nFinding. In International Conference on Automated Plan-\nning and Scheduling (ICAPS), 613–622.\nWarburton, A. 1987. Approximation of Pareto Optima in\nMultiple-Objective Shortest-Path Problems. Operations Re-\nsearch, 35(1): 70–79.\nZhang, H.; Salzman, O.; Felner, A.; Kumar, T. K. S.;\nand Koenig, S. 2024a.\nBounded-Suboptimal Weight-\nConstrained Shortest-Path Search via Efficient Representa-\ntion of Paths. In International Conference on Automated\nPlanning and Scheduling (ICAPS), 680–688.\nZhang, H.; Salzman, O.; Felner, A.; Kumar, T. K. S.; Skyler,\nS.; Ulloa, C. H.; and Koenig, S. 2023a. Towards Effective\nMulti-Valued Heuristics for Bi-objective Shortest-Path Al-\ngorithms via Differential Heuristics. In Symposium on Com-\nbinatorial Search (SoCS), 101–109.\nZhang, H.; Salzman, O.; Felner, A.; Kumar, T. K. S.; Ul-\nloa, C. H.; and Koenig, S. 2023b. Efficient Multi-Query Bi-\nObjective Search via Contraction Hierarchies. In Interna-\ntional Conference on Automated Planning and Scheduling\n(ICAPS), 452–461.\nZhang, H.; Salzman, O.; Felner, A.; Kumar, T. K. S.; Ul-\nloa, C. H.; and Koenig, S. 2024b. Speeding Up Dominance\nChecks in Multi-Objective Search: New Techniques and\nData Structures.\nIn Symposium on Combinatorial Search\n(SoCS), 228–232.\nZhang, H.; Salzman, O.; Felner, A.; Ulloa, C. H.; and\nKoenig, S. 2024c. A-A*pex: Efficient Anytime Approxi-\nmate Multi-Objective Search. In Symposium on Combinato-\nrial Search (SoCS).\nZhang, H.; Salzman, O.; Kumar, T. S.; Felner, A.; Ulloa,\nC. H.; and Koenig, S. 2022. A*pex: Efficient approximate\nmulti-objective search on graphs. In International Confer-\nence on Automated Planning and Scheduling (ICAPS), vol-\nume 32, 394–403.\nZhang, Q.; and Li, H. 2007.\nMOEA/D: A multiobjec-\ntive evolutionary algorithm based on decomposition. IEEE\nTransactions on evolutionary computation, 11(6): 712–731.\n",
    "content": "# Interpretation of the Multi-Objective Search (MOS) Paper\n\n## 1. Core Content and Key Contributions\n\nThis survey paper, titled **\"Multi-Objective Search: Algorithms, Applications, and Emerging Directions\"**, systematically reviews recent advances in the field of Multi-Objective Search (MOS), covering algorithms, applications, and future research directions. Its core content and main contributions are as follows:\n\n### Core Content:\n- **Definition and Problem Modeling**: Clearly defines the fundamental framework of MOS—finding the Pareto-optimal path set (Pareto Front) in graph structures, i.e., a set of solutions where no objective can be improved without worsening at least one other.\n- **Classification of Problem Variants**: Divides MOS into multiple subcategories, including exact MOS, approximate MOS, anytime MOS, incremental/dynamic MOS, and extends to models under uncertainty such as MOSSP, MOMDP, and MORL.\n- **Algorithmic Evolution**: Traces the development from classical label-correcting methods and MOA\\* to modern efficient algorithms like BOA\\*, NAMOA-dr, PPA\\*, and A\\*pex, highlighting key breakthroughs in heuristic design, parallelization, and data structure optimization.\n- **Cross-Domain Tool Transfer**: Highlights that MOS algorithms have moved beyond traditional path planning, demonstrating generality in problems such as minimum spanning trees, multi-agent path finding (MAPF), and constrained shortest paths.\n- **Emerging Application Scenarios**: Illustrates successful real-world applications of MOS in robotics, autonomous driving rulebooks, molecular synthesis, and multimodal transportation planning.\n- **Open Challenges and Outlook**: Identifies current critical challenges, including scalability in high-dimensional objective spaces, adaptability to dynamic environments, user preference modeling, interdisciplinary collaboration, and standardized benchmark construction.\n\n### Key Contributions:\n1. **Unified Perspective Integration**: Provides a cohesive analytical framework for multi-objective decision-making methods scattered across AI, operations research, robotics, and other fields.\n2. **State-of-the-Art Technical Summary**: Comprehensively summarizes recent algorithmic innovations in efficiency improvements (e.g., vectorized operations accelerating dominance checks), approximation algorithms (e.g., A\\*pex), and anytime search.\n3. **Promoting Interdisciplinary Convergence**: Explicitly highlights the complementary potential between MOS and other AI subfields such as reinforcement learning, planning, and human-computer interaction.\n4. **Guiding Future Research**: Offers clear direction for follow-up studies through its \"open challenges\" section, emphasizing practicality and cross-disciplinary cooperation.\n\n---\n\n## 2. Breakthroughs and Innovations\n\nAlthough this is a review paper, it distills and emphasizes a series of significant breakthroughs and innovative ideas developed in recent years within the field:\n\n| Innovation Category | Specific Breakthroughs |\n|---------------------|------------------------|\n| **Algorithm Efficiency Improvements** | - **BOA\\*** and **EMOA\\*** achieve O(1) dominance checking for bi-objective cases;<br>- **A\\*pex** introduces an efficient ε-approximate method for computing the Pareto front, scalable to arbitrary dimensions;<br>- Use of **balanced binary trees** and **SIMD instruction-level parallelism** significantly accelerates dominance checks. |\n| **Theoretical Advancements** | - Introduces vertex classification theory (\"must-expand,\" \"may-expand,\" \"never-expand\"), revealing essential differences between MOS and single-objective search;<br>- Clearly distinguishes two types of expansion requirements: \"proof of optimality\" vs. \"guarantee of completeness.\" |\n| **New Problem Formulations** | - Proposes the **MOS with Objective Aggregation (MOS-OA)** framework to address mismatches between intermediate and final state objectives (e.g., inspection tasks);<br>- Extends MOS to **dynamic graphs** (edge weights changing over time), enhancing real-world relevance. |\n| **Innovative Heuristic Design** | - Successfully generalizes **differential heuristics (DH)** from single-objective to bi-objective scenarios (**BO-DH**), drastically reducing runtime;<br>- While MVH offers better performance, its computational cost is high, making practical heuristics a focus area. |\n| **Cross-Domain Generalization Capability** | - Demonstrates that the **k-shortest simple paths problem** can be solved via bi-objective search, showcasing MOS as a universal optimization tool;<br>- Integrates MOS into **multi-agent pathfinding (MO-MAPF)** to generate diverse trade-off solutions. |\n| **Paradigm Shifts in Applications** | - Moves from \"aggregate then optimize\" to \"generate Pareto solution set first, then let humans choose,\" aligning better with real-world decision processes;<br>- In autonomous driving, introduces **hierarchical rulebooks** to manage multiple objectives with different priorities. |\n\nThese innovations collectively drive MOS from theoretical foundations toward large-scale practical deployment, especially in systems requiring transparency, interpretability, and diversified choices.\n\n---\n\n## 3. Startup Ideas Inspired by This Paper\n\nBased on the technological trends and application potentials revealed in this paper, here are several commercially promising startup concepts:\n\n### 🚀 Startup Idea 1: **OptiRoute — Intelligent Multi-Objective Urban Mobility Recommendation Platform**\n\n#### Project Description:\nDevelop a SaaS platform for public or enterprise users that goes beyond time and distance in route planning. It integrates up to 5–8 dimensions—including carbon emissions, cost (fuel/electricity/tolls), comfort (bumpiness, transfer frequency), safety (accident-prone areas), and public transit congestion—and outputs a set of Pareto-optimal routes for user selection.\n\n#### Technical Foundation:\n- Utilizes **A\\*pex or EMOA\\*** for fast approximate Pareto search on large-scale road networks;\n- Incorporates **dynamic traffic prediction models** to update edge weights and support real-time replanning;\n- Includes a **user preference elicitation module** that learns from historical choices to automatically rank recommendations.\n\n#### Business Value:\n- B2C: Integrated as a premium feature in mapping apps (e.g., Amap, Baidu Maps);\n- B2B: Offers low-carbon logistics routing services for delivery companies;\n- Government Partnerships: Assesses policy impacts on citizen mobility (e.g., traffic restrictions, carbon credits).\n\n#### Differentiation:\n> Instead of offering just the “fastest” or “cheapest” route, OptiRoute presents a spectrum of trade-offs among speed, cost, and sustainability, empowering users to make informed decisions.\n\n---\n\n### 🤖 Startup Idea 2: **RoboPlanner Pro — Multi-Objective Motion Planning Engine for Industrial Robots**\n\n#### Project Description:\nProvide an SDK-level multi-objective path planning engine for robots in manufacturing and warehouse logistics, simultaneously optimizing path length, energy consumption, joint wear, obstacle clearance margin, and task completion time—suitable for robotic arms, AGVs, and drones.\n\n#### Technical Foundation:\n- Built on the **MOS-OA framework** to handle complex task objectives (e.g., visual inspection coverage + path length);\n- Supports **online incremental updates (Incremental MOS)** to adapt to new obstacles;\n- Visualizes the Pareto frontier of different strategies, aiding engineers in tuning and debugging.\n\n#### Business Value:\n- License software to robot manufacturers;\n- Offer a cloud-based simulation testing platform to evaluate performance trade-offs under various configurations;\n- Deep integration with ROS 2 to capture entry points in the open-source ecosystem.\n\n#### Differentiation:\n> Most current robotic systems use weighted-sum methods to crudely combine objectives, lacking flexibility. This product provides genuine multi-solution options, improving system robustness and energy efficiency.\n\n---\n\n### 🔬 Startup Idea 3: **SynthPath AI — AI-Powered Platform for Chemical Synthesis Path Discovery and Evaluation**\n\n#### Project Description:\nBuild an inverse synthesis analysis system based on MOS for pharmaceutical R&D companies, automatically generating multiple feasible synthetic routes and comparing them across dimensions such as **reaction success rate, total steps, number of toxic intermediates, raw material cost, and environmental impact**.\n\n#### Technical Foundation:\n- Constructs a knowledge graph of chemical reactions as the search space;\n- Applies a hybrid **MOS + MCTS (Monte Carlo Tree Search)** strategy (inspired by Lai et al., 2025);\n- Outputs a set of Pareto-optimal synthetic pathways to assist chemists in decision-making.\n\n#### Business Value:\n- SaaS subscription model targeting pharmaceutical R&D departments;\n- Integration with electronic lab notebook (ELN) systems;\n- Expandable to materials science and catalyst design domains.\n\n#### Differentiation:\n> Unlike traditional approaches focused solely on \"highest yield\" or \"fewest steps,\" this platform reveals hidden trade-offs, helping avoid local optima traps.\n\n---\n\n### 🌐 Startup Idea 4: **PrefLearn Studio — Toolkit for User Preference Modeling in Multi-Objective Decision Making**\n\n#### Project Description:\nDevelop an API and visualization toolkit enabling businesses to progressively learn user preferences through interactive questioning in multi-attribute choice scenarios (e.g., insurance plans, travel packages, electronics configuration), then recommend the most suitable Pareto-optimal options.\n\n#### Technical Foundation:\n- Integrates **MORL + Preference Learning** techniques;\n- Uses **Anytime MOS** algorithms to quickly return initial candidate sets;\n- Employs active learning strategies to minimize user interaction burden.\n\n#### Business Value:\n- Next-generation personalized recommendation engine for e-commerce;\n- Portfolio recommendation in financial services;\n- B2B configurator for customized solutions.\n\n#### Differentiation:\n> Traditional recommender systems assume fixed preference functions, while this tool dynamically captures users' true trade-off psychology, boosting conversion rates and satisfaction.\n\n---\n\n## Conclusion\n\nThis paper is not merely an excellent survey of the MOS field—it serves as a blueprint for next-generation intelligent decision systems. It reminds us that: **real-world optimization has never been about optimizing a single metric, but rather an art of balancing multiple values**. Entrepreneurs who embrace the core idea of *\"generating diverse high-quality options + supporting human final decisions\"*—and apply it to concrete industry pain points—can build AI products that combine deep technical innovation with strong commercial viability.",
    "github": "",
    "hf": ""
}