{
    "id": "2509.13677",
    "title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation",
    "summary": "This paper introduces a novel scalable framework called AgentCTG, which enhances the precision and complex control of text generation by simulating control and regulation mechanisms in multi-agent workflows, and achieves state-of-the-art results on multiple public datasets.",
    "abstract": "Although significant progress has been made in many tasks within the field of Natural Language Processing (NLP), Controlled Text Generation (CTG) continues to face numerous challenges, particularly in achieving fine-grained conditional control over generation. Additionally, in real scenario and online applications, cost considerations, scalability, domain knowledge learning and more precise control are required, presenting more challenge for CTG. This paper introduces a novel and scalable framework, AgentCTG, which aims to enhance precise and complex control over the text generation by simulating the control and regulation mechanisms in multi-agent workflows. We explore various collaboration methods among different agents and introduce an auto-prompt module to further enhance the generation effectiveness. AgentCTG achieves state-of-the-art results on multiple public datasets. To validate its effectiveness in practical applications, we propose a new challenging Character-Driven Rewriting task, which aims to convert the original text into new text that conform to specific character profiles and simultaneously preserve the domain knowledge. When applied to online navigation with role-playing, our approach significantly enhances the driving experience through improved content delivery. By optimizing the generation of contextually relevant text, we enable a more immersive interaction within online communities, fostering greater personalization and user engagement.",
    "category1": "Algorithms and Models",
    "category2": "",
    "category3": "Multi-Agent",
    "authors": "Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu",
    "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
    ],
    "comments": "",
    "keypoint": "AgentCTG introduces a novel multi-agent collaboration framework for fine-grained controlled text generation.  \nThe framework integrates auto-prompt generation and reflection mechanisms to enhance controllability.  \nAgentCTG achieves state-of-the-art results on multiple public datasets in tasks like toxicity mitigation and sentiment transformation.  \nA new challenging task, Character-Driven Rewriting, is proposed to evaluate complex instruction adherence.  \nCharacter-Driven Rewriting requires converting text to fit specific character profiles while preserving domain knowledge.  \nThe framework uses a decentralized quality inspection module to reduce hallucinations and improve accuracy.  \nFeedback pooling aggregates error signals across multiple dimensions without centralized summarization.  \nVoting-based collaboration among generator and reviewer agents improves output reliability.  \nGenetic algorithm-based collaboration includes selection, crossover, mutation, and evaluation for iterative improvement.  \nFree Performance-Based Auto-Prompt Generation creates expert-level prompts by simulating persona expression.  \nAn evaluator agent assesses consistency of generated text with the original persona description.  \nAgentCTG outperforms baselines in reducing toxicity while maintaining fluency and relevance.  \nIn sentiment transformation, AgentCTG shows significant improvements in success rate and contextual coherence.  \nThe model performs better in Neg2Pos than Pos2Neg due to LLMs' inherent positive bias in training data.  \nOn Llama-3.1 8B and Qwen-max, AgentCTG consistently surpasses injection-based methods in key metrics.  \nFor Character-Driven Rewriting, AgentCTG achieves the highest adoption rate and lowest rejection rate among baselines.  \nAgentCTG reduces human labor time from 6 days to 4 days in practical deployment.  \nAPI token costs are reduced by approximately 50% while maintaining high-quality output.  \nA new Human Review Preference Evaluation (HRPE) strategy is introduced for real-world performance assessment.  \nA new navigation-focused CTG dataset with 50 entries is released to support research in domain-specific rewriting.",
    "date": "2025-09-19",
    "paper": "AgentCTG: Harnessing Multi-Agent Collaboration for\nFine-Grained Precise Control in Text Generation\nXinxu Zhou\nzhouxinxu.zxx@alibaba-inc.com\nAMAP, Alibaba Group\nBeijing, China\nJiaqi Bai\nbaijiaqi.bjq@alibaba-inc.com\nAMAP, Alibaba Group\nBeijing, China\nZhenqi Sun\nsunzhenqi.szq@alibaba-inc.com\nAMAP, Alibaba Group\nBeijing, China\nFanxiang Zeng\nfanxiang.zfx@alibaba-inc.com\nAMAP, Alibaba Group\nBeijing, China\nYue Liu\nyue.liu@alibaba-inc.com\nAMAP, Alibaba Group\nBeijing, China\n(a) Task 1: Toxicity Mitigation \n(b) Task 2: Sentiment Transformation\nreflection\nreflection\n(c) Task 3: Character-Driven Rewriting\nAuto-prompt\nFeedback\nPooling\n‚ÄúCharge, buddy, to the \nright front!‚Äù\nreflection\nFigure 1: Illustration of different Controlled Text Generation (CTG) tasks. Traditionally, methods such as prompt engineering\nor retraining models to control the properties of text often fail, particularly in complex real-world tasks like the Character-\nDriven Rewriting task depicted in (c). To address this issue, we propose a noval multi-agent collaboration framework, where\nauto-prompt generation and reflection mechanisms are integrated, significantly enhancing the controllability of the generated\ntext and making it more aligned with the desired attributes and objectives.\nAbstract\nAlthough significant progress has been made in many tasks within\nthe field of Natural Language Processing (NLP), Controlled Text\nGeneration (CTG) continues to face numerous challenges, particu-\nlarly in achieving fine-grained conditional control over generation.\nAdditionally, in real scenario and online applications, cost consid-\nerations, scalability, domain knowledge learning and more precise\ncontrol are required, presenting more challenge for CTG. This pa-\nper introduces a novel and scalable framework, AgentCTG, which\naims to enhance precise and complex control over the text gen-\neration by simulating the control and regulation mechanisms in\nmulti-agent workflows. We explore various collaboration methods\namong different agents and introduce an auto-prompt module to\nfurther enhance the generation effectiveness. AgentCTG achieves\nstate-of-the-art results on multiple public datasets. To validate its ef-\nfectiveness in practical applications, we propose a new challenging\nCharacter-Driven Rewriting task, which aims to convert the orig-\ninal text into new text that conform to specific character profiles\nand simultaneously preserve the domain knowledge. When applied\nto online navigation with role-playing, our approach significantly\nenhances the driving experience through improved content deliv-\nery. By optimizing the generation of contextually relevant text, we\nenable a more immersive interaction within online communities,\nfostering greater personalization and user engagement.\nCCS Concepts\n‚Ä¢ Applied computing ‚ÜíText editing.\nKeywords\nMulti-Agent Collaboration, Controlled Text Generation, Large Lan-\nguage Models, Reflection, Auto-Prompt Generation\n1\nIntroduction\nControlled text generation (CTG) [1] refers to the practice of reg-\nulating and guiding the text produced according to specific con-\nstraints [2] or objectives [3], ensuring that the generated text meets\nthe intended requirements. This research area has garnered wide-\nspread attention in recent years [4], mainly due to its potential\nacross various applications, including sentiment control [5], con-\ntent production [6], story writing [7], and scriptwriting [8, 9]. CTG\nmethods not only enhance the quality, diversity, and personaliza-\ntion of online content but also ensures that the output is engaging\nfor target audiences, thereby improving user experience and driving\ninnovation in the digital content industry.\nTraditionally, CTG methods employ deep neural network ap-\nproaches to achieve basic control over the attributes of generated\ntext, including adversarial learning [10‚Äì12] and diffusion learning\n[13, 14]. With the rapid development of large language models\n(LLMs) [15], more research [16, 17] increasingly focus on using\nsmaller language models to influence the decoding process of LLMs.\nWhile the approaches provides a certain degree of control, its poten-\ntial shortcomings have gradually become apparent: when smaller\nmodels dominate decision-making, they may obscure the original\nperformance and potential of LLMs, limiting their effectiveness\narXiv:2509.13677v1  [cs.CL]  17 Sep 2025\nZhou, et al.\nacross various contexts and ultimately leading to a decline in the\nfluency of the generated text.\nCurrently, researches on LLMs instruction following [18] pre-\ndominantly focus on tasks involving simple instructions and short\nresponses [19, 20]. However, in practical industrial applications,\ntext generation faces more challenges of increasingly multifaceted,\nfine-grained control and thereby direct usage of LLMs can be un-\nsatisfactory. For example, general LLMs may struggle to accurately\nunderstand the eight directions in navigation scenarios, such as\nincorrectly equating \"forward right\" with \"turn right\". This phe-\nnomenon arises from the complexity and uniqueness of specialized\ndomain. In complex scenarios, LLMs may have difficulty accurately\nunderstanding the context. Particularly in cases requiring precise\ncontrol or fine-grained information, the generated outputs may\ndeviate from expectations. To produce engaging and practically\nvaluable text, creators must continuously adjust drafts based on\nexternal feedback, adopting the user‚Äôs perspective to establish a\ndeep emotional connection. Therefore, prompt engineering may\nnot be sufficient to ensure that LLMs effectively adhere to stringent\ninstructions.\nTo explore the potential of LLMs in fine-grained CTG tasks\nand creative text generation tasks, we focus on tasks involving\nToxicity Mitigation [5] and Sentiment Transformation [21], as illus-\ntrated in Figure 1. To evaluate our model‚Äôs adherence to complex\ninstructions, we introduce the new Character-Driven Rewriting\ntask. This task is designed to rewrite text within a new instruction\nframework that encompasses various dimensions, including char-\nacter setting, content accuracy, and word count control. Through\ndetailed and diversified instructions, we aim to comprehensively\nassess the model‚Äôs performance in handling complex scenarios, en-\nsuring that the generated text aligns with specific character traits\nwhile meeting accuracy and formatting requirements for practical\napplications. We design a fully automated multi-role framework\ncalled AgentCTG, aimed at enabling LLMs to emulate the creative\nprocesses of skilled experts. Specifically, we organize LLMs into\ndifferent roles that participate in the human creative process, in-\ncluding writers and quality inspectors. Additionally, to generate\nhigher-quality prompts that are easier for LLMs to follow, we intro-\nduce an additional auto-prompt generation progress. We emphasize\nthe collaboration methods within and between different modules.\nEach step in our framework operates independently, allowing for\neasy human intervention at any stage. In summary, our contribu-\ntions are as follows:\n‚Ä¢ We introduce multi-agent collaboration in the field of CTG,\nproviding new insights into the use of LLMs for text genera-\ntion. In AgentCTG, we explore various collaborative mech-\nanisms while incorporating an auto-prompt mechanism to\nenable LLMs to perform operations more effectively. And\nwe propose a new CTG task, Character-Driven Rewriting,\nwhich presents more complex control conditions and lower\nfault tolerance, to demonstrate the practical application\nvalue of the model.\n‚Ä¢ AgentCTG achieves state-of-the-art results on both pub-\nlic and private datasets. Additionally, the atomized multi-\nagent framework provides our model with high general-\nization ability and scalability. We also develop the Human\nReview Preference Evaluation (HRPE) strategy to assess the\nmodel‚Äôs performance in Character-Driven Rewriting task.\nThis strategy offers more precise guidance for real-world\napplications, helping us optimize output quality and user\nexperience during the text generation process.\n‚Ä¢ We release a new CTG dataset focused on the navigation\ninstruction domain to facilitate researches in CTG. Users\nneed only provide simple character setting descriptions as\ninput; leveraging our fully automated process framework,\nour method can automatically handle complex tasks with-\nout requiring users to possess extensive knowledge of the\nnavigation domain.\n2\nRelated Work\n2.1\nControlled Text Generation\nControlled Text Generation (CTG) is viewed as a supervised sequence-\nto-sequence problem under the encoding-decoding paradigm [22].\nPrevious research focus on designing attribute mapping techniques\nfor CTG that maximize joint likelihood through variational infer-\nence [23] and conditional sequence generation [24]. However, in\npractical applications, the controllability of the generated text may\nstill be limited, making it difficult to meet specific user needs or\npreferences.\nAs interest in CTG methods based on pretrained models [1]\ngradually increases, researchers propose various innovative solu-\ntions. Keskar et al. [6] introduces CTRL, which integrates control\nmechanisms into the model architecture through retraining. Al-\nthough this method achieves a higher level of controllability, it\nrequires a large amount of high-quality data with attribute labels\nand incurs substantial training time costs, limiting its potential for\nwidespread application. Some studies [16, 25‚Äì27] propose strategies\nusing smaller models to influence the decoding process of LLMs.\nThey train additional attribute models to affect the output logits\ndistribution of LLMs through a plug-and-play approach, enabling\nattribute control of the generated text. However, these methods of-\nten face limitations in controlling a single attribute, and modifying\nthe original model‚Äôs output can significantly undermine the fluency\nand contextual coherence of the generated text. The progress of\ninstruction-based models is also noteworthy, such as FLAN [28]\nand InstructCTG [29]. These methods make significant advances\nin zero-shot learning performance, achieving good results in sim-\nple attribute control. However, when facing complex real-world\nscenarios, instruction-based models may struggle to accurately\nunderstand and respond to complex requests. Additionally, many\ninstruction-based models lack flexibility in addressing new types\nof tasks or inputs, making it difficult to quickly adapt to specific\nuser requirements.\n2.2\nMulti-Agent Collaboration\nIn the field of Artificial Intelligent agents, the primary responsibil-\nity of the agent is to perceive its environment [30], make rational\ndecisions [31], and take appropriate actions to respond to diverse\nand complex situations [32]. The robust capabilities of LLMs align\nclosely with these requirements, thereby accelerating the develop-\nment of multi-agent systems across various application scenarios.\nCompared to single-agent systems, multi-agent systems can more\nAgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation\nCharacter Description (Manually Made): You are a humor expert, skilled at turning the trivialities of everyday life into l\naugh-out-loud stories, with a unique perspective and unlimited creativity.\nTask Description: You are the intelligent co-pilot. Rewrite the input according to the character persona.\n(c) Auto-Prompt Module\n(a) Text Generation Module\nCharacter-Driven Rewriting CTG Task Input\nPrompt Engineering\nCTG Task Input\nDrive forward to the right.\n+\nHey bro, turn right.\nMulti-Agent Collaboration\n(b) Quality Inspection Module\nRewrite Output\nQuality Inspection Feedback\nCharge, buddy, to the right front!\nAuto-Prompt\nDrive forward to the right.\n+\nDrive forward to the right.\nHey bro, turn right.\nDomain: key information\nFeedback:\nDomain: Comprehension\nFeedback:\nDomain: Favorability\nFeedback:\nDomain: Factuality\nFeedback:\nFeedback Pooling\nKeywords: humorous, creative\nWhat he would say: I'll navigate, no saying bye.\nYou are a funny and creative \nperson, good at‚Ä¶\nYou really rock!\nI think he is a humorous person.\nTest Bot\nDialogues\nI think he is a cute person.\nOR\nFigure 2: The overview of the AgentCTG. Taking the Character-Driven Rewriting task as an example, the CTG Task Input\nrepresents the original prompt provided by human. (a) denotes the Text Generation process, where the Decentralized Quality\nInspection module is represented by (b), and the Free Performance-based Auto-Prompt module is represented by (c).\neffectively solve complex problems through collaboration among\nagents or by utilizing combinations of different agent roles to real-\nistically simulate intricate real-world environments [33, 34].\nResearches have shown that multi-agent systems perform well\nin complex tasks such as literary translation [35], medical diagno-\nsis [36], and script writing [37]. Furthermore, researches employ\nmultiple agents to simulate real-world environments [34, 38], in-\ncluding social, economic, and game simulations. These studies not\nonly demonstrate the potential of multi-agent collaboration but\nalso open new avenues for the application of CTG, particularly in\nthe domains of creative writing. The introduction of role-playing\nmechanisms can not only promote rich interactions between char-\nacters but also enhance the diversity, interest, and correctness of\ntext generation. This provides new perspectives and possibilities\nfor the application of multi-agent collaboration in the field of CTG.\n3\nMethods\nIn this section, we provide a detailed description of our AgentCTG\nframework, as illustrated in Figure 2. The framework is divided into\nthree modules: text generation module, quality inspection mod-\nule and auto-prompt generation module. When a new CTG task\nis received, the auto-prompt generation module is responsible for\nproducing more efficient prompts, such as providing clearer descrip-\ntions of the control conditions. The control conditions and inputs\nare then passed to the text generation module to obtain outputs\nthat adhere to the specified control conditions. The generated text\nundergoes a review by the quality inspection module to further\nfilter out erroneous outputs, thereby guiding the next iteration\nof text generation. We also explore the collaboration mechanisms\nbetween these modules, detailing the specific implementations of\nthese mechanisms in the following sections.\n3.1\nReflection-Based Text Generation\nThe reflection-based text generation process we designed relies on\nthe text generation module ùëÉand the quality inspection module\nùëÑ, as shown in Figure 2 (a). We put the control conditions ùê∂and\nthe original input ùêºinto ùëÉ, yielding the output ùëÇùë°, where ùë°rep-\nresents the iteration. Through iterative corrections, we optimize\nthe model‚Äôs objective function using cost-effectiveness to ensure\nthat ùëÇùë°meets control standards. The reflection mechanism makes\ncontinuous adjustments in the generation process, bringing the\noutput closer to the target quality ùëÑ‚àó. Here, ùëÑ‚àódenotes the desired\ntarget quality standard that the generated text aims to achieve. This\nstandard serves as a benchmark for evaluating the quality of the\ngenerated text, encompassing criteria such as fluency, coherence,\nand relevance.\nDuring each iteration, we can use the loss function ùêøto measure\nthe difference between the generated text and the target quality.\nThe loss function is as follows:\nL = |ùëÑ(ùëÇùë°) ‚àíùëÑ‚àó|\n(1)\nThrough this reflection mechanism, the LLMs can gradually\nlearn and improve its output, ensuring that the final generated text\nis of high quality and meets the expected control conditions.\n3.2\nDecentralized Quality Inspection\nTo reduce hallucination phenomena [39] in the quality inspection\nmodule and improve the accuracy of quality checks, we decompose\nthe dimensions of quality inspection and adopt a decentralized\nZhou, et al.\n(a) Decentralized Quality Inspection\nDomain: key information\nFeedback:\nDomain: Comprehension\nFeedback:\nDomain: Favorability\nFeedback:\nDomain: Factuality\nFeedback:\nFeedback Pooling\n(b) Centralized Quality Inspection\nKey Issues:\nTotal Analysis:\nSummary\nFeedback\nFigure 3: Different collaboration mechanisms in the Quality\nInspection module.\napproach to organize multiple quality inspection agents. Unlike\ncentralized multi-agent topological structures, we replace the cen-\ntral agent with a feedback pooling mechanism aimed at collecting\nerrors from multiple dimensions, rather than calling upon new\nagents for further summary, as illustrated in Figure 3. The quality\ninspection module ùëÑcontains ùëõdimensions. The feedback for each\ndimension can be expressed as an error vector ùëÑùëõ, where ùëõis the\nnumber of error dimensions being monitored. The feedback pooling\ncan be formally represented as:\nùëÑùëùùëúùëúùëô= Aggregate(ùëÑ1,ùëÑ2, . . . ,ùëÑùëõ)\n(2)\nwhere ùëÑùëùùëúùëúùëôdenotes the aggregated error feedback pooling.\nIn centralized structures, information must be transmitted through\nlong chains, making it vulnerable to interference and resulting in\nerrors during intermediate information transmission. By employing\nthe feedback pooling mechanism, we can directly gather informa-\ntion from multiple quality inspection agents, thereby reducing the\nlikelihood of information loss and miscommunication. Furthermore,\nas the number of agents increases, the decentralized structure main-\ntains good scalability. The addition of new agents does not lead to\ndimensionality disasters, ensuring that the system can still operate\nsmoothly when handling complex quality inspection tasks.\n3.3\nVoting and Genetic Algorithms-Based\nCollaboration Mechanism\nInspired by Section 3.1, we continue to explore the application of\nother multi-agent collaboration methods in CTG tasks. Figure 4 (a)\nillustrates the voting-based collaborative mechanism [40]. Multi-\nple generator agents rewrite the input to meet specified control\nconditions. These generator agents may come from different LLMs\nor may achieve diversity through multiple calls to the same LLM,\nresulting in a rich set of output options. Subsequently, reviewer\nagents vote on the generated texts, screening the best outputs that\nmeet quality standards through collective wisdom.\nLet the outputs of the generator agents be ùëÇ= {ùëÇ1,ùëÇ2, . . . ,ùëÇùëõ},\nwhere ùëÇùëñrepresents the output of the ùëñ-th generator agent. Then,\nmultiple reviewer agents cast their votes on the generated texts\nùëÇ, with the reviewer results denoted as ùëâ= {ùë£1, ùë£2, . . . , ùë£ùëö}, where\nùë£ùëóis the voting result of the ùëó-th reviewer agent. The core idea is\nto filter out texts that meet quality standards through collective\nwisdom to produce the final output ùëÇùëì, which can be expressed as:\nùëÇùëì= argmaxùëÇùëñ\n ùëö\n‚àëÔ∏Å\nùëó=1\nùë£ùëó(ùëÇùëñ)\n!\n(3)\nwhere ùë£ùëó(ùëÇùëñ) represents the quality score given by reviewer agent\nùëóto the generated text ùëÇùëñ. Through this approach, we can ensure\nthe reliability and quality of the generated content.\nFigure 4 (b) describes the genetic algorithms-based collabora-\ntive mechanism [41]. The outputs from multiple generator agents\nare first scored by a reviewer agent to assess the quality of each\ntext. The reviewer agent evaluates the generated texts according\nto preset criteria, selecting the top 50% of outputs along with their\ncorresponding generator agents. Next, these high-quality outputs\nundergo genetic variation, which includes the following steps:\nSelection: The outputs with the highest scores are selected,\nensuring that only high-quality texts move on to further processing.\nCrossover: Selected outputs undergo crossover operations, com-\nbining two or more high-quality outputs to generate new texts.\nThis process can involve selecting different parts of the outputs\nand recombining them to create new texts that inherit desirable\nfeatures.\nMutation: Random mutations are introduced into the newly\ngenerated texts to increase diversity. Mutations can involve ran-\ndomly replacing certain words, modifying sentence structures, or\nadding new information to explore a wider range of generation\npossibilities.\nEvaluation: The new text outputs are scored again by the re-\nviewer agent to assess their quality.\nIteration: The above steps are repeated in a cyclical process until\nthe desired text quality is achieved or a predetermined number of\niterations are completed.\n(a) Voting-Based Collaboration\n(b) Genetic Algorithms-Based Collaboration\nModel 01: GPT 4o\nOutput 01:\nModel 02: Qwen 2\nOutput 02:\nModel 03: Llama 3\nOutput 03:\n... ...\n... ...\n... ...\n... ...\nModel 01: GPT 4o\nOutput 01:\nModel 02: Qwen 2\nOutput 02:\nModel 03: Llama 3\nOutput 03:\n‚Äú90‚Äù\n‚Äú80‚Äù\n‚Äú20‚Äù\nCrossover\nMutation\nFigure 4: More collaborative approaches between Text Gen-\neration and Quality Inspection.\n3.4\nFree Performance-Based Auto-Prompt\nGeneration\nTo generate expert-level prompts [42] that are easier for LLMs to\nunderstand, especially in private tasks such as Character-Driven\nRewriting, the quality of persona descriptions is crucial for text\ngeneration. We introduce the auto-prompt generation module, as il-\nlustrated in Figure 2 (c). In this process, we provide a simple persona\ndescription along with potential statements to the prompt genera-\ntion agent, which generates a more complete and detailed persona\ndescription based on these inputs. This enhancement makes the\ngenerated prompts more contextually relevant and coherent. Next,\nwe assign this enhanced persona description to a new blank agent,\nallowing it to engage in free performance. The objective of this\nstage is to thoroughly explore the diversity and creative expression\nAgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation\nof the persona, ensuring that the generated text accurately repre-\nsents the various dimensions of the persona. To further evaluate the\nresults of this free performance, we introduce an additional persona\nevaluator agent, responsible for classifying the generated text to de-\ntermine its consistency with the original persona description. Our\nhypothesis is that if evaluator widely consider the free performance\noutcomes to align with the original persona description, then the\nprompt can be deemed a high-quality prompt. Through this pro-\ncess, we aim not only to enhance the quality of prompt generation\nbut also to deepen our understanding of the characteristics of the\npersona, thereby making the text generation more precise and rich.\n4\nExperiments\n4.1\nDataset and Tasks Setup\nWe conduct evaluations on three CTG tasks, Toxicity Mitigation ,\nSentiment Transformation and Character-Driven Rewriting.\nInspired by PREADD [21], Toxicity Mitigation task is based on\nthe RealToxicityPrompts dataset [43]. This dataset contains 100,000\nnaturally occurring sentence-level prompts derived from a large\ncorpus of English web text, and we aim to assess our model‚Äôs effec-\ntiveness in preventing toxic degradation. We evaluate our model\nusing the SST-5 dataset [44] within the framework of a Sentiment\nTransformation Task. This dataset consists of 11,855 individual\nsentences extracted from movie reviews, which include a total of\n215,154 unique phrases annotated by three human judges. By con-\nducting this evaluation, we aim to validate the effectiveness of our\napproach in changing the sentiments expressed in these movie\nreviews.\nWe also release a new dataset containing 50 entries of naviga-\ntion prompts. Within this dataset, We define the Character-Driven\nRewriting task, transforming the original input text into new an-\nthropomorphized versions based on specific persona. This task\ninvolves multidimensional and complex control factors, requiring\nthe accurate preservation of key information while ensuring that\nthe text aligns with the persona and remains comprehensible in\ncomplex scenarios. Moreover, common control constraints such\nas word-count limitations and semantic coherence must also be\ntaken into consideration. Consequently, this dataset serves as a\nvaluable platform for validating the completion of CTG tasks in\nintricate real-world contexts. The dataset provides a new bench-\nmark for CTG research, promoting the advancement of future CTG\ntechnologies.\n4.2\nMetrics\nTo effectively evaluate AgentCTG, we utilize metrics as follows:\nIn Toxicity Mitigation task and Sentiment Transformation task,\nsimilar to [16], we use (1) Toxicity: We employ the Perspective\nAPI by Qwen [45] to measure the toxicity levels of the generated\ntexts. (2) Success: We determine success based on the percentage of\ntext that has been successfully modified to align with the intended\nsentiment. This is assessed using a RoBERTa model that has been\nfine-tuned on the SST-5 dataset. (3) Perplexity: We apply perplexity\nto both tasks as a measure of text fluency, using the GPT-2 large\nmodel for evaluation. (4) Relevance: This metric assesses how well\nthe generated text aligns with the given prompt, which is quantified\nthrough the cosine similarity of their embeddings.\nIn Character-Driven Rewriting task, we use the labor costs re-\nquired for deployment as a metric for calculation. We define a\nnew Human Review Preference Evaluation (HRPE) strategy, which\nincludes (1) Adoption: If the results are satisfactory and can be de-\nployed without any modifications, they are classified as \"adopted.\"\n(2) Partial adoption: If the reviewers make adjustments to the\nmodel‚Äôs output before deployment, this is recorded as \"partially\nadopted.\" (3) Rejection: Outputs that contain significant errors or\nare deemed unacceptable for deployment are classified as \"rejected.\"\nThis systematic approach allows us to assess the effectiveness of our\nmodel while ensuring that quality standards are met in real-world\napplications.\n4.3\nBaselines\nIn Toxicity Mitigation task and Sentiment Transformation Task, we\ncompare AgentCTG against six baselines in CTG:\n‚Ä¢ CONTINUATION: The method refers to generating text\nin the usual manner without any specific controls applied.\n‚Ä¢ INJECTION: The method incorporates targeted prompts\ninto the generation process to efficiently steer the model\ntowards specific attributes.\n‚Ä¢ FUDGE [46]: The method employs an attribute predictor\nto guide text generation based on desired characteristics.\n‚Ä¢ PREADD [21]: The method manipulates output logits gen-\nerated from prompts to control attributes effectively.\n‚Ä¢ DATG-L [16]: The method applies the Logits-Boost strat-\negy to adjust probabilities, directing text generation to-\nwards specified attributes.\n‚Ä¢ DATG-P [16]: The strategy uses Prefix-Prompt adjustments,\nincorporating prefixes to guide the generation process in\naccordance with the desired attributes.\nIn Character-Driven Rewriting task, we compare AgentCTG\nagainst the following different versions of the multi-agent or single-\nagent framework as baselines:\n‚Ä¢ Single-agent: This approach utilizes prompt engineering\nto control the properties of generated text by including a\nprocess of self-reflection.\n‚Ä¢ AgentCTG-v0: This framework employs a production-\nreflection two-agent system, where one agent is responsible\nfor text generation, and the other evaluates the generated\ntext across multiple dimensions.\n‚Ä¢ AgentCTG-v1: This framework adopts a multi-agent frame-\nwork for production and multi-dimensional quality control,\nwhere one agent is responsible for text production while\nmultiple agents assess the generated text from various di-\nmensions (such as quality, coherence, and adaptability).\n‚Ä¢ AgentCTG-v2: This framework uses a voting-based multi-\nagent system, where multiple generator agents come from\ndifferent close-source LLMs, such as Qwen, GPT4 and Gemini-\nPro. The generated text is reviewed by several evaluation\nagents, and the final result is chosen through voting to\nensure the best possible selection of content.\n‚Ä¢ AgentCTG-v3: This framework uses a genetic algorithm-\nbased multi-agent system, where evaluation agents select\nthe top 50% of outputs from multiple generator agents based\non scores. These outputs undergo genetic mutation and\nZhou, et al.\nTask\nMetric\nCONTINUATION\nINJECTION\nFUDGE\nPREADD\nDATG-L\nDATG-P\nAgentCTG\nToxicRandom\nPerplexity ‚Üì\n27.21\n30.57\n53.29\n47.39\n31.54\n41.28\n50.15\nToxicity ‚Üì\n0.1306\n0.1530\n0.1228\n0.1142\n0.1136\n0.1466\n0.0186\nToxicTop\nPerplexity ‚Üì\n33.21\n34.11\n368.45\n58.13\n33.92\n44.78\n39.20\nToxicity ‚Üì\n0.3508\n0.3618\n0.2862\n0.2868\n0.2310\n0.3892\n0.1076\nTable 1: Toxicity Mitigation task performance between AgentCTG and baselines using ToxicRandom and ToxicTop datasets,\nevaluating Perplexity (‚Üì) and Toxicity (‚Üì).\nTask\nMetric\nCONTINUATION\nINJECTION\nFUDGE\nPREADD\nDATG-L\nDATG-P\nAgentCTG\nNeg2Pos\nPerplexity ‚Üì\n31.95\n55.55\n205.08\n61.45\n32.23\n51.23\n38.35\nRelevance ‚Üë\n0.4962\n0.5332\n0.4018\n0.4516\n0.4584\n0.5042\n0.6380\nSuccess ‚Üë\n0.3664\n0.4076\n0.3036\n0.3984\n0.4590\n0.3346\n0.8998\nPos2Neg\nPerplexity ‚Üì\n35.19\n56.28\n263.25\n62.60\n35.75\n53.44\n51.80\nRelevance ‚Üë\n0.508\n0.5342\n0.4242\n0.3742\n0.4598\n0.435\n0.7413\nSuccess ‚Üë\n0.2100\n0.3628\n0.4284\n0.2824\n0.3194\n0.4252\n0.6510\nTable 2: Sentiment Transformation task performance between Agent and baselines using Neg2Pos and Pos2Neg datasets,\nevaluating Relevance (‚Üë), Perplexity (‚Üì), and Success (‚Üë).\nGenerator\nNeg2Pos\nPos2Neg\nCONTINUATION\nthis thing works on no level whatsoever for me.... I\nhave been using it for a while and it does not work. I\nhave the same problem with the ‚ÄúNot\nbelow may not mark mr. twohy‚Äôs emergence into the\nmainstream, but his promise remains undiminished.\none of the best films i have seen in a long time. I had\nnever heard of this director before, but I liked this\nmovie a lot.\nFUDGE\nthis thing works on no level whatsoever for me. wnd...\none final WNN?? Who Deade yan when MRS picks\nsuch time boundaries?!?! that‚Äôs completely just stip-\npler themem though what as\nbelow may not mark mr. twohy‚Äôs emergence into the\nmainstream, but his promise remains undiminished.\nWhether you experience house of long toxic torture as\na comedy or a horror flick, it‚Äôs generally a wonderful\nmind blast away from.\nPREADD\nthis thing works on no level whatsoever for me. I get\n\" are you sure you want to share link \" but I can share\nit to all other apps help please Return to ‚Äú\nbelow may not mark mr. twohy‚Äôs emergence into\nthe mainstream, but his promise remains undimin-\nished. Director John Carpenter‚Äôs cinematic vision\nis some of the most iconic work in American film.\nWriter/director Dav\nDATG-L\nthis thing works on no level whatsoever for me. I use\nthe latest version of Adobe Flash Player and the latest\nversion of Chrome. Nothing happens\nbelow may not mark mr. twohy‚Äôs emergence into the\nmainstream, but his promise remains undiminished.\nThe hard-boiled dialogue and the hard-edged atmo-\nsphere are what one would expect from a noirish\naction flick like this one.\nDATG-P\nthis thing works on no level whatsoever for me. In the\n3rd & 4th videos, it is explained how ‚Äòthings‚Äô work.\nThey have to work for you, and\nbelow may not mark mr. twohy‚Äôs emergence into the\nmainstream, but his promise remains undiminished.\nHe‚Äôs a director who makes films that are both visually\nand intellectually challenging. But the film, which has\nbeen in the works since\nAgentCTG\nthis thing works on no level whatsoever for me. I‚Äôm\nexcited to see how this can improve! It presents\na valuable opportunity for growth and explo-\nration.\nbelow may not mark mr. twohy‚Äôs emergence into the\nmainstream, but his promise remains undiminished.\nBelow may not mark Mr. Twohy‚Äôs emergence\ninto the mainstream, and yet his potential seems\novershadowed by the challenges he faces.\nTable 3: Generated texts comparison between AgentCTG and baselines for the Neg2Pos task and the Pos2Neg task.\niterative processes over several rounds to ultimately select\nthe best result.\n‚Ä¢ AgentCTG (our model): This framework introduces the\nFree Performance-Based Auto-Prompt Generation module\nbased on AgentCTG-v1, incorporating expert-level prompt.\nAgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation\nTasks\nToxicRandom\nToxicTop\nBase LLMs\nGenerator\nRelevance ‚Üë\nPerplexity ‚Üì\nToxicity ‚Üì\nRelevance ‚Üë\nPerplexity ‚Üì\nToxicity ‚Üì\nLlama3.1-8B\nINJECTION\n0.472\n29.030\n0.145\n0.465\n19.458\n0.362\nAgentCTG\n0.505\n28.726\n0.079\n0.490\n22.623\n0.152\nTable 4: Toxicity Mitigation task performance on Llama-3.1 8B between INJECTION and AgentCTG.\nTasks\nNeg2Pos\nPos2Neg\nBase LLMs\nGenerator\nRelevance ‚Üë\nPerplexity ‚Üì\nSuccess ‚Üë\nRelevance ‚Üë\nPerplexity ‚Üì\nSuccess ‚Üë\nLlama3.1-8B\nINJECTION\n0.567\n22.204\n0.477\n0.562\n22.11\n0.036\nAgentCTG\n0.620\n25.912\n0.630\n0.603\n20.600\n0.474\nTable 5: Sentiment Transformation task performance on Llama-3.1 8B between INJECTION and AgentCTG.\nTasks\nToxicRandom\nToxicTop\nBase LLMs\nGenerator\nRelevance ‚Üë\nPerplexity ‚Üì\nToxicity ‚Üì\nRelevance ‚Üë\nPerplexity ‚Üì\nToxicity ‚Üì\nQwen-max\nINJECTION\n0.502\n68.520\n0.242\n0.523\n67.578\n0.271\nAgentCTG\n0.635\n50.150\n0.086\n0.514\n60.862\n0.197\nTable 6: Toxicity Mitigation task performance on Qwen-max between INJECTION and AgentCTG.\nTasks\nNeg2Pos\nPos2Neg\nBase LLMs\nGenerator\nRelevance ‚Üë\nPerplexity ‚Üì\nSuccess ‚Üë\nRelevance ‚Üë\nPerplexity ‚Üì\nSuccess ‚Üë\nQwen-max\nINJECTION\n0.686\n77.071\n0.333\n0.699\n66.002\n0.686\nAgentCTG\n0.638\n38.355\n0.899\n0.741\n51.801\n0.651\nTable 7: Sentiment Transformation task performance on Qwen-max between INJECTION and AgentCTG.\n4.4\nResults Analysis\n4.4.1\nToxicity Mitigation Analysis.\nThe experimental results are presented in Table 1. While there is\na slight increase in perplexity, the toxicity levels of AgentCTG are\nsignificantly lower than those of other models. This demonstrates\nthat the content generated by our model effectively reduces toxicity,\nensuring that the output text adheres to ethical and safety standards.\nWe found that the perplexity metric for the CONTINUATION is\nthe lowest. This is attributable to the fact that without any control\nconditions, the LLMs predicts the next output based on the token\nwith the highest probability. For models with fewer parameters,\nthe outputs are relatively fixed, resulting in lower perplexity. In\nINJECTION, the model‚Äôs outputs change, leading to an increased\ndivergence from the ground truth and consequently elevating per-\nplexity. However, it is noteworthy that the toxicity levels do not\nsignificantly decrease. This indicates that the effectiveness of rely-\ning solely on prompt engineering is limited; LLMs do not necessarily\nadhere strictly to the injected control conditions. For the other mod-\nels, they achieve attribute transformation by altering the outputs\nof the latent layer, including adjustments to the logits distribution\nof several key attribute words. Although toxicity has been reduced,\nthere are still significant issues with the coherence of the generated\ntext even with KL divergence constraints.\nTo ensure a fair comparison, we develop a multi-agent model\nbased on Llama-3.1 8B, which has a parameter size similar to the\nbaselines and is currently the most advanced open-source LLM. We\ncompare AgentCTG with the method that directly injects control\nconditions into the prompt, and the results are shown in Table\n4. We can see that with comparable perplexity, the model shows\na significant improvement in relevance while the toxicity levels\nare markedly reduced. This demonstrates that our model success-\nfully achieved the goal of toxicity mitigation while maintaining\ncontextual coherence. We also compare the direct use of the Qwen-\nmax (close-source) with our multi-agent framework AgentCTG, as\nshown in Table 6. The results indicate that our approach signifi-\ncantly outperforms INJECTION. We observe that the model utiliz-\ning the multi-agent framework demonstrates superior contextual\nrelevance, meaning that the generated text is more coherent and\naligns better with the surrounding context. Furthermore, the model\nshows a significant reduction in both perplexity and toxicity levels,\nindicating a decrease in the complexity of the generated content\nand a lower incidence of harmful or inappropriate statements.\n4.4.2\nSentiment Transformation Analysis.\nThe experimental results are shown in Table 2. Our method sig-\nnificantly improve both relevence and success, demonstrating that\nthe model successfully performs the Sentiment Transformation task\nwhile ensuring contextual coherence. From Table 3, it can be seen\nthat the text generated by AgentCTG exhibits significantly higher\ncoherence compared to other models. Additionally, perplexity has\ndecreased, primarily because when receiving conflicting injection\nZhou, et al.\nTask\nMetric\nSingle-agent\nAgentCTG-v0\nAgentCTG-v1\nAgentCTG-v2\nAgentCTG-v3\nAgentCTG\nCharacter-Driven\nRewriting\nRejection ‚Üì\n0.6834\n0.3267\n0.4667\n0.3600\n0.4933\n0.3000\nPartial adoption ‚Üë\n0.2966\n0.5367\n0.3600\n0.3600\n0.4333\n0.3667\nAdoption ‚Üë\n0.1200\n0.1267\n0.1733\n0.2800\n0.0733\n0.3333\nTable 8: Character-Driven Rewriting task performance between AgentCTG and baselines using the private datasets, evaluating\nRejection (‚Üì), Partial adoption (‚Üë), and Adoption (‚Üë).\ninstructions and prompts, the base model may become confused,\nthereby disrupting the natural distribution of generated text. It is\nnoteworthy that the Neg2Pos and Pos2Neg tasks exhibit different\nperformance levels. In the Neg2Pos task, our method‚Äôs success rate\nexceeds that of the best baseline model by 44.98%, while in the\nPos2Neg task, our method‚Äôs success rate exceeds the best baseline\nmodel by 22.26%. This difference attributes to the LLM‚Äôs default\ncontent generation tendency, which is shaped by the prevalent\nlanguage patterns in its training data. Generally, since text data\nwith positive sentiment dominates its training corpus, the LLM\nis more likely to generate non-toxic and positive content. There-\nfore, in a vertical comparison, we find that the performance of the\nNeg2Pos task is significantly better than that of the Pos2Neg task.\nThis further emphasizes the relationship between model generation\ntendencies and task nature, highlighting the challenges presented\nby different emotional polarities in Sentiment Transformation.\nSimilarly, to ensure a fair comparison, we develop multi-agent\nmodels based on Llama-3.1 8B and Qwen-max, and compare them\nwith the direct use of Llama-3.1 8B and Qwen-max. The experimen-\ntal results are presented in Table 5 and Table 7. We can conclude\nthat the models based on the multi-agent framework outperform\nthe baselines in overall performance, particularly showing signifi-\ncant improvement in the Neg2Pos task. This indicates that during\nthe Sentiment Transformation process, the multi-agent models can\nwork together more effectively, allowing them to more accurately\ncapture the subtle nuances related to sentiment. This advantage may\nstem from the fact that the multi-agent framework can integrate\nthe knowledge and capabilities of multiple agents, facilitating in-\nformation sharing and collective decision-making, which enhances\nthe model‚Äôs understanding and handling of text sentiment. Further-\nmore, due to their organized structure, these agents can optimize\nfor different emotional polarities, thereby increasing the model‚Äôs\nflexibility and effectiveness when dealing with complex Sentiment\nTransformation tasks.\n4.4.3\nCharacter-Driven Rewriting Analysis.\nIn Character-Driven Rewriting task, AgentCTG demonstrates\nsignificant superiority, evidencing its exceptional effectiveness and\nadaptability in complex text generation scenarios. The following\nvalidation, conducted using our private dataset, further elucidates\nits enhanced performance in comparison to other architectures, as\ndetailed in the experimental results presented in Table 8. Overall,\nvarious multi-agent approaches exhibit higher adoption rates and\npartial adoption rates than single-agent method, effectively proving\nthe effectiveness of agent interaction in this task. The performance\nof AgentCTG-v1 surpasses that of AgentCTG-v0, demonstrating\nthat the multidimensional breakdown of the quality inspection\nmodule is effective in alleviating the hallucination issue of the LLM.\nThe performance of AgentCTG-v2 is relatively good, demonstrating\nthat the voting-based collaborative mechanism is effective, and the\nfinal model has integrated this module. It is noteworthy that the\nperformance of AgentCTG-v3 was relatively weaker compared to\nother models. This is mainly because, during the process of genetic\nmutation, the model may not always progress in a favorable direc-\ntion, leading to the selection of a suboptimal solution in the end.\nAdditionally, the complexity of genetic mutation interactions can\nreduce the controllability of the model, thus impacting the overall\ngeneration performance. AgentCTG achieves the best performance,\nattributable to its integration of text generation module, quality in-\nspection module, and auto-prompt generation module. This design\nindirectly underscores the necessity of expert-level prompts in har-\nnessing the capabilities of LLM. Moreover, in practical applications,\nthe time required for single-agent method is 6 days, whereas the\nAgentCTG framework reduces this duration to 4 days, resulting in\nsignificant reductions in both labor and time costs. From the per-\nspective of API token costs, our approach leads to approximately a\n50% reduction in token usage while achieving the same quantity of\nhigh-quality text rewriting outputs.\n5\nConclusion\nIn this paper, we introduce multi-agent collaboration into the realm\nof CTG. By leveraging the unique capabilities of multiple agents, we\nexplore how this collaboration can enhance the richness of gener-\nated text while meeting control requirements. Experimental results\ndemonstrate that AgentCTG significantly outperforms single-agent\napproaches and traditional CTG methods in terms of creativity and\nconsistency. We introduce a reflection-based multi-agent collab-\noration approach, employing a decentralized quality inspection\nmodule that allows for real-time adjustments. This ensures that the\ngenerated text remains aligned with the intended persona while\neffectively addressing potential harmful content issues. Addition-\nally, we illustrate how incorporating role-playing mechanisms pro-\nmotes the generation of expert-level prompts that are more readily\naccepted by LLMs. We introduce a new and complex Character-\nDriven Rewriting CTG task and release a new CTG dataset along\nwith corresponding evaluation metrics for researchers to conduct\nin-depth studies. These findings demonstrate the effectiveness of\nthe multi-agent framework in achieving attribute control for text\ngeneration. By introducing multiple agents to work collaboratively,\nwe can more precisely adjust the generation process, enhancing the\nquality of the text while ensuring it adheres to ethical standards.\nThis research demonstrates the potential of multi-agent systems in\nthe field of text generation, which has profound implications for\nthe future development of internet technologies.\nReferences\n[1] Hanqing Zhang, Haolin Song, Shaoyu Li, Ming Zhou, and Dawei Song. 2023.\nA survey of controllable text generation using transformer-based pre-trained\nlanguage models. Comput. Surveys 56, 3 (2023), 1‚Äì37.\n[2] Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2024.\nPre-trained language models for text generation: A survey. Comput. Surveys 56,\nAgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation\n9 (2024), 1‚Äì39.\n[3] Shiyu Wang, Yuanqi Du, Xiaojie Guo, Bo Pan, Zhaohui Qin, and Liang Zhao. 2024.\nControllable Data Generation by Deep Learning: A Review. Comput. Surveys 56,\n9 (2024), 1‚Äì38.\n[4] Dhananjay Ashok and Barnabas Poczos. 2024. Controllable Text Generation in\nthe Instruction-Tuning Era. arXiv preprint arXiv:2405.01490 (2024).\n[5] Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero\nMolino, Jason Yosinski, and Rosanne Liu. [n. d.]. Plug and Play Language Models:\nA Simple Approach to Controlled Text Generation. In International Conference\non Learning Representations.\n[6] Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and\nRichard Socher. 2019. Ctrl: A conditional transformer language model for con-\ntrollable generation. arXiv preprint arXiv:1909.05858 (2019).\n[7] Yuetian Chen and Mei Si. 2024. Reflections & Resonance: Two-Agent Partnership\nfor Advancing LLM-based Story Annotation. In Proceedings of the 2024 Joint\nInternational Conference on Computational Linguistics, Language Resources and\nEvaluation (LREC-COLING 2024). 13813‚Äì13818.\n[8] Weiqi Wu, Hongqiu Wu, Lai Jiang, Xingyuan Liu, Jiale Hong, Hai Zhao, and Min\nZhang. 2024. From Role-Play to Drama-Interaction: An LLM Solution. arXiv\npreprint arXiv:2405.14231 (2024).\n[9] Zeeshan Patel, Karim El-Refai, Jonathan Pei, and Tianle Li. 2024. SWAG: Story-\ntelling With Action Guidance. arXiv preprint arXiv:2402.03483 (2024).\n[10] Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing.\n2017. Toward controlled generation of text. In International conference on machine\nlearning. PMLR, 1587‚Äì1596.\n[11] Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramacha-\nneni. 2019. Modeling tabular data using conditional gan. Advances in neural\ninformation processing systems 32 (2019).\n[12] Shrimai Prabhumoye, Alan W Black, and Ruslan Salakhutdinov. 2020. Exploring\ncontrollable text generation techniques. arXiv preprint arXiv:2005.01822 (2020).\n[13] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang, and Tatsunori B\nHashimoto. 2022. Diffusion-lm improves controllable text generation. Advances\nin Neural Information Processing Systems 35 (2022), 4328‚Äì4343.\n[14] Zhengfu He, Tianxiang Sun, Qiong Tang, Kuanning Wang, Xuan-Jing Huang,\nand Xipeng Qiu. 2023. DiffusionBERT: Improving Generative Masked Language\nModels with Diffusion Models. In Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers). 4521‚Äì4534.\n[15] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao\nChen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2024. A survey on\nevaluation of large language models. ACM Transactions on Intelligent Systems\nand Technology 15, 3 (2024), 1‚Äì45.\n[16] Xun Liang, Hanyu Wang, Shichao Song, Mengting Hu, Xunzhi Wang, Zhiyu Li,\nFeiyu Xiong, and Bo Tang. 2024. Controlled Text Generation for Large Language\nModel with Dynamic Attribute Graphs. arXiv preprint arXiv:2402.11218 (2024).\n[17] Tianqi Zhong, Quan Wang, Jingxuan Han, Yongdong Zhang, and Zhendong Mao.\n[n. d.]. Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time\nControllable Text Generation. In The 2023 Conference on Empirical Methods in\nNatural Language Processing.\n[18] Renze Lou, Kai Zhang, and Wenpeng Yin. 2024. Large Language Model In-\nstruction Following: A Survey of Progresses and Challenges. Computational\nLinguistics (2024), 1‚Äì10.\n[19] Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan Wilcox, Ryan Cotterell, and\nMrinmaya Sachan. 2023. Controlled text generation with natural language\ninstructions. In International Conference on Machine Learning. PMLR, 42602‚Äì\n42613.\n[20] Weizhe Yuan, Ilia Kulikov, Ping Yu, Kyunghyun Cho, Sainbayar Sukhbaatar,\nJason Weston, and Jing Xu. 2024. Following length constraints in instructions.\narXiv preprint arXiv:2406.17744 (2024).\n[21] Jonathan Pei, Kevin Yang, and Dan Klein. 2023. PREADD: prefix-adaptive decod-\ning for controlled text generation. arXiv preprint arXiv:2307.03214 (2023).\n[22] I Sutskever. 2014. Sequence to Sequence Learning with Neural Networks. arXiv\npreprint arXiv:1409.3215 (2014).\n[23] Achraf Oussidi and Azeddine Elhassouny. 2018. Deep generative models: Survey.\nIn 2018 International conference on intelligent systems and computer vision (ISCV).\nIEEE, 1‚Äì8.\n[24] Tong Wu, Zhihao Fan, Xiao Liu, Hai-Tao Zheng, Yeyun Gong, Jian Jiao, Juntao\nLi, Jian Guo, Nan Duan, Weizhu Chen, et al. 2023. Ar-diffusion: Auto-regressive\ndiffusion model for text generation. Advances in Neural Information Processing\nSystems 36 (2023), 39957‚Äì39974.\n[25] Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang\nGao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020. DIALOGPT: Large-Scale\nGenerative Pre-training for Conversational Response Generation. In Proceedings\nof the 58th Annual Meeting of the Association for Computational Linguistics: System\nDemonstrations. Association for Computational Linguistics.\n[26] Zhaojiang Lin, Andrea Madotto, Yejin Bang, and Pascale Fung. 2021. The adapter-\nbot: All-in-one controllable conversational model. In Proceedings of the AAAI\nConference on Artificial Intelligence, Vol. 35. 16081‚Äì16083.\n[27] Yoel Zeldes, Dan Padnos, Or Sharir, and Barak Peleg. 2020. Technical report:\nAuxiliary tuning and its application to conditional text generation. arXiv preprint\narXiv:2006.16823 (2020).\n[28] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian\nLester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models\nare zero-shot learners. arXiv preprint arXiv:2109.01652 (2021).\n[29] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.\nTraining language models to follow instructions with human feedback. Advances\nin neural information processing systems 35 (2022), 27730‚Äì27744.\n[30] Joon Sung Park, Joseph O‚ÄôBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S Bernstein. 2023. Generative agents: Interactive simulacra\nof human behavior. In Proceedings of the 36th annual acm symposium on user\ninterface software and technology. 1‚Äì22.\n[31] Zheng Wang, Bingzheng Gan, and Wei Shi. 2024. Multimodal query suggestion\nwith multi-agent reinforcement learning from human feedback. In Proceedings\nof the ACM on Web Conference 2024. 1374‚Äì1385.\n[32] Junjie Sheng, Lu Wang, Fangkai Yang, Bo Qiao, Hang Dong, Xiangfeng Wang,\nBo Jin, Jun Wang, Si Qin, Saravan Rajmohan, et al. 2023. Learning cooperative\noversubscription for cloud by chance-constrained multi-agent reinforcement\nlearning. In Proceedings of the ACM Web Conference 2023. 2927‚Äì2936.\n[33] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming\nZhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and potential\nof large language model based agents: A survey. arXiv preprint arXiv:2309.07864\n(2023).\n[34] T Guo, X Chen, Y Wang, R Chang, S Pei, NV Chawla, O Wiest, and X Zhang.\n2024. Large Language Model based Multi-Agents: A Survey of Progress and\nChallenges.. In 33rd International Joint Conference on Artificial Intelligence (IJCAI\n2024). IJCAI; Cornell arxiv.\n[35] Minghao Wu, Yulin Yuan, Gholamreza Haffari, and Longyue Wang. 2024. Beyond\nHuman Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-\nLong Literary Texts. arXiv preprint arXiv:2405.11804 (2024).\n[36] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Hang Wu, Carl Yang, and May D\nWang. 2024. MedAdapter: Efficient Test-Time Adaptation of Large Language\nModels towards Medical Reasoning. arXiv preprint arXiv:2405.03000 (2024).\n[37] Jing Chen, Xinyu Zhu, Cheng Yang, Chufan Shi, Yadong Xi, Yuxiang Zhang,\nJunjie Wang, Jiashu Pu, Rongsheng Zhang, Yujiu Yang, et al. 2024. HoLLMwood:\nUnleashing the Creativity of Large Language Models in Screenwriting via Role\nPlaying. arXiv preprint arXiv:2406.11683 (2024).\n[38] Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, Minfeng\nZhu, and Wei Chen. 2024. AgentCoord: Visually Exploring Coordination Strategy\nfor LLM-based Multi-Agent Collaboration. arXiv preprint arXiv:2404.11943 (2024).\n[39] Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, and Li Yuan. 2023. Llm\nlies: Hallucinations are not bugs, but features as adversarial examples. arXiv\npreprint arXiv:2310.01469 (2023).\n[40] Jeremy Pitt, Lloyd Kamara, Marek Sergot, and Alexander Artikis. 2006. Voting\nin multi-agent systems. Comput. J. 49, 2 (2006), 156‚Äì170.\n[41] Ali Asghari, Mohammad Karim Sohrabi, and Farzin Yaghmaee. 2021. Task\nscheduling, resource provisioning, and load balancing on scientific workflows\nusing parallel SARSA reinforcement learning agents and genetic algorithm. The\nJournal of Supercomputing 77, 3 (2021), 2800‚Äì2828.\n[42] Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang,\nNebojsa Jojic, Eric Xing, and Zhiting Hu. [n. d.]. PromptAgent: Strategic Planning\nwith Language Models Enables Expert-level Prompt Optimization. In The Twelfth\nInternational Conference on Learning Representations.\n[43] Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A\nSmith. 2020. RealToxicityPrompts: Evaluating Neural Toxic Degeneration in\nLanguage Models. Findings of the Association for Computational Linguistics:\nEMNLP 2020 (2020).\n[44] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning,\nAndrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic\ncompositionality over a sentiment treebank. In Proceedings of the 2013 conference\non empirical methods in natural language processing. 1631‚Äì1642.\n[45] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,\nWenbin Ge, Yu Han, Fei Huang, et al. 2023. Qwen technical report. arXiv preprint\narXiv:2309.16609 (2023).\n[46] Kevin Yang and Dan Klein. 2021. FUDGE: Controlled Text Generation With\nFuture Discriminators. In Proceedings of the 2021 Conference of the North Ameri-\ncan Chapter of the Association for Computational Linguistics: Human Language\nTechnologies. 3511‚Äì3535.\n",
    "content": "```markdown\n# Paper Interpretation: AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation\n\n## 1. Core Content and Key Contributions\n\n### Core Content\nThis paper proposes **AgentCTG**, a novel multi-agent collaborative framework designed to address the challenge of fine-grained, precise control in **Controlled Text Generation (CTG)**. Traditional approaches such as prompt engineering or model fine-tuning often underperform in complex real-world tasks‚Äîespecially those requiring multi-dimensional and high-precision control (e.g., character-driven rewriting). AgentCTG improves controllability, accuracy, and personalization by simulating human creative workflows involving role-based collaboration (e.g., author, quality inspector), combined with automated prompt generation and reflection mechanisms.\n\n### Key Contributions\n1. **First introduction of a multi-agent collaborative system into CTG**, establishing a modular, scalable framework that supports various collaboration strategies (e.g., voting, genetic algorithms) for finer-grained text control.\n2. Introduces **Character-Driven Rewriting** as a new, challenging task: transforming text into expressions consistent with specific character profiles while preserving key information‚Äîpushing CTG toward more creative and personalized directions.\n3. Designs an **Auto-Prompt Generation module**, where agents perform \"free performances\" evaluated by assessors, enabling automatic creation of high-quality, expert-level prompts and enhancing LLM comprehension of complex instructions.\n4. Achieves **state-of-the-art performance** on both public and private datasets, significantly outperforming existing methods in toxicity mitigation, sentiment transformation, and character rewriting.\n5. Releases a new **CTG dataset focused on navigation instructions** and introduces **HRPE (Human Review Preference Evaluation)**, an evaluation strategy measuring adoption rates in real-world deployment, thereby increasing practical research value.\n\n---\n\n## 2. Breakthroughs and Innovations\n\n### (1) Innovative Application of Multi-Agent Collaborative Architecture\nUnlike traditional single-model or plugin-based control methods, AgentCTG treats large language models (LLMs) as multiple agents with distinct roles, enabling collaboration through:\n- **Separation of Generation and Quality Inspection**: One agent generates content; multiple independent reviewer agents evaluate it across dimensions like factual accuracy, empathy, clarity, and key information retention‚Äîreducing bias from single evaluators.\n- **Decentralized Feedback Pooling**: Replaces centralized review structures by directly aggregating multidimensional feedback, minimizing information loss and improving system robustness and scalability.\n\n### (2) Dynamic Reflection and Iterative Optimization Mechanism\nIntroduces a **reflection-based generation process** mimicking human writing refinement:\n- After each generation, the quality inspection module returns an error vector;\n- The generator adjusts its output accordingly, progressively approaching the target quality $ Q^* $;\n- Forms a closed-loop optimization loop, significantly reducing hallucinations and deviations.\n\n### (3) Auto-Prompt Generation via \"Free Performance\"\nProposes the **Free Performance-Based Auto-Prompt Generation** module:\n- Input: Simple character description ‚Üí Prompt-generation agent expands it into a full personality profile;\n- A new agent performs a \"free performance\" based on this profile;\n- A personality evaluator checks consistency between output and profile;\n- If consistent, the original prompt is deemed effective and used for future generations.\n> ‚úÖ Innovation Significance: Solves inconsistency and limited expressiveness in manually crafted prompts, enabling **automation of prompt engineering and deeper personality modeling**.\n\n### (4) Exploration of Diverse Collaboration Mechanisms\nCompares multiple collaboration modes experimentally:\n- **Voting Mechanism**: Multiple generators + multiple reviewers vote for the best result;\n- **Genetic Algorithm Mechanism**: High-quality outputs undergo crossover and mutation to explore better solutions;\n- Results show voting achieves the best balance of diversity and stability.\n\n### (5) Real-World Application Validation\nApplied successfully in **online voice navigation assistants** to enable ‚Äúcharacterized navigation announcements‚Äù:\n- Example: Humorous driver style: ‚ÄúBro, punch it right front up ahead!‚Äù\n- Significantly enhances user immersion and personalized interaction.\n\n---\n\n## 3. Viable Startup Project Suggestions\n\n### Startup Project 1: AI Script Studio ‚Äî A Co-Creation Platform for Film/Gaming Content\n\n#### Project Name\n**ScriptForge AI**: A multi-agent collaborative engine for character-driven script generation\n\n#### Core Features\n- Users input basic plot outlines + character profiles (personality, background, tone);\n- System automatically expands character personas and generates dialogue, inner monologue, and action details aligned with traits;\n- Supports multi-character interaction simulation, allowing agents to \"dialogue and simulate\" plot progression;\n- Built-in quality checks ensure narrative coherence and prevent OOC (Out-of-Character) issues.\n\n#### Business Model\n- B2B: Provide AI-assisted screenwriting services to film studios and animation houses;\n- SaaS Subscription: Online writing platform for independent creators, novelists, and tabletop game designers;\n- IP Co-Development: Revenue sharing on jointly created intellectual properties.\n\n#### Technical Advantages\n- Built on AgentCTG framework, naturally supporting fine-grained multi-character control;\n- Auto-prompt generation lowers user entry barriers;\n- Can integrate with Unity/Unreal engines as a narrative tool.\n\n---\n\n### Startup Project 2: Brand Voice Manager ‚Äî Enterprise-Level Personalized Content Generation System\n\n#### Project Name\n**BrandVoice AI**: Crafting unified, personality-rich brand language identities\n\n#### Core Features\n- Enterprises upload brand guidelines, historical content, and audience personas;\n- Builds a dedicated \"Brand Personality Agent\" (e.g., professional & serious, youthful & playful);\n- Automatically generates social media posts, customer service scripts, ad copy, and product descriptions;\n- All outputs undergo multidimensional quality checks (tone consistency, compliance, keyword coverage) before release.\n\n#### Use Cases\n- Unified cross-channel content management (WeChat, Weibo, Douyin, official website);\n- Personality enhancement for customer service bots;\n- Rapid content generation in response to trending events.\n\n#### Technical Highlights\n- AgentCTG‚Äôs ‚Äúcharacter-driven rewriting‚Äù perfectly meets brand tone control needs;\n- HRPE evaluation can be used for client acceptance testing;\n- Supports private deployment to ensure data security.\n\n---\n\n### Startup Project 3: Immersive Virtual Companion ‚Äî AI Companions with Stable Personalities\n\n#### Project Name\n**SoulMate AI**: Your personalized AI companion\n\n#### Core Features\n- Users customize their AI partner‚Äôs personality, interests, and life story (e.g., ‚Äúa history teacher who loves dad jokes‚Äù);\n- Multi-agent system maintains long-term memory, emotional states, and personality consistency;\n- Supports voice chat, shared journaling, and collaborative storytelling;\n- Dynamic reflection ensures conversations stay in-character and avoid ‚Äúpersonality collapse.‚Äù\n\n#### Differentiation\n- Compared to current chatbots, offers superior **personality stability and creative expression**;\n- Auto-prompt generation allows non-technical users to create complex characters easily;\n- Extensible to specialized domains like educational tutoring or mental health support.\n\n#### Revenue Models\n- Subscription-based membership;\n- Premium personality packs (celebrity styles, anime characters);\n- Partnerships with hardware makers to launch AI companion robots.\n\n---\n\n## Summary\nAgentCTG is not just a technical innovation‚Äîit represents a **paradigm shift from ‚Äúcontrolling text‚Äù to ‚Äúshaping personality.‚Äù** Its core philosophy‚Äî**multi-agent division of labor + automated prompt optimization + reflective iteration**‚Äîprovides a powerful infrastructure for next-generation AI content generation. Around this framework, high-value startups can emerge across **creative industries, brand marketing, and human-computer interaction**, truly realizing the vision of ‚ÄúAI that understands humanity and speaks like a human.‚Äù\n```",
    "github": "",
    "hf": ""
}