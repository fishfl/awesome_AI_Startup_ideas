{
    "id": "/xtekky/gpt4free",
    "issues": "11",
    "watch": "484",
    "fork": "13.7k",
    "star": "65.2k",
    "topics": [
        "chatbot",
        "reverse-engineering",
        "openai",
        "chatbots",
        "gpt",
        "language-model",
        "openai-api",
        "gpt-4",
        "gpt4",
        "chatgpt",
        "chatgpt-api",
        "openai-chatgpt",
        "chatgpt-free",
        "chatgpt-4",
        "chatgpt4",
        "gpt4-api",
        "deepseek",
        "gpt-4o",
        "deepseek-api",
        "deepseek-r1"
    ],
    "license": "GNU General Public License v3.0",
    "languages": [
        "Python,98.2%"
    ],
    "contributors": [
        "https://avatars.githubusercontent.com/u/983577?s=64&v=4",
        "https://avatars.githubusercontent.com/u/98614666?s=64&v=4",
        "https://avatars.githubusercontent.com/u/166700875?s=64&v=4",
        "https://avatars.githubusercontent.com/u/22415463?s=64&v=4",
        "https://avatars.githubusercontent.com/u/36830534?s=64&v=4",
        "https://avatars.githubusercontent.com/u/139662282?s=64&v=4",
        "https://avatars.githubusercontent.com/u/20585236?s=64&v=4",
        "https://avatars.githubusercontent.com/u/36051603?s=64&v=4",
        "https://avatars.githubusercontent.com/u/73485421?s=64&v=4",
        "https://avatars.githubusercontent.com/u/185073927?s=64&v=4",
        "https://avatars.githubusercontent.com/u/69082498?s=64&v=4",
        "https://avatars.githubusercontent.com/u/100193740?s=64&v=4",
        "https://avatars.githubusercontent.com/u/63782903?s=64&v=4"
    ],
    "about": "The official gpt4free repository | various collection of powerful language models | o4, o3 and deepseek r1, gpt-4.1, gemini 2.5",
    "is_AI": "y",
    "category": "Language Model Frameworks",
    "summary": "```markdown\n# GPT4Free (g4f) Project Analysis\n\n## 1. Core Content and Problems Solved\n\nGPT4Free (short for g4f) is a **community-driven open-source project** that aims to provide users with a **free, flexible, and easy-to-use AI model interface** by aggregating multiple accessible large language models (LLMs) and media generation services.\n\n### Key Problems Addressed:\n- **Lowering Usage Barriers**: Many powerful AI models (e.g., GPT-4, Gemini, DeepSeek) require paid APIs or complex configurations. G4F integrates various free-access channels, enabling users to leverage these advanced models at no cost.\n- **Unified Interface Experience**: Wraps diverse model services into a standardized OpenAI-compatible API, greatly simplifying integration for developers.\n- **Localization and Privacy Protection**: Supports running GUI and API services locally, allowing users to invoke models in private environments and avoid leaking sensitive data.\n- **Multi-platform Support**: Offers Python clients, JavaScript browser clients, Docker deployment, CLI tools, etc., suitable for use cases ranging from personal projects to lightweight production systems.\n\n---\n\n## 2. Breakthroughs and Innovations\n\n### ‚úÖ Multi-source Aggregation + Automatic Routing\n- Supports various models including `OpenAI-like` (o4, o3), `Gemini`, `DeepSeek`, `MetaAI`, `PerplexityLabs`, and automatically selects the best currently available provider.\n- Implements \"failover\" capability‚Äîswitches to alternative sources when one service becomes unavailable.\n\n### ‚úÖ Out-of-the-box OpenAI-Compatible Interface (Interference API)\n- Provides a local proxy service (built with FastAPI) fully compatible with OpenAI v1 API standards, allowing existing code to run freely by simply changing the URL.\n- Can serve as a backend alternative for mainstream AI frameworks such as LangChain and Pydantic-AI.\n\n### ‚úÖ Full-stack Cross-platform Support\n- **Python Library**: Sync/async clients ideal for scripting.\n- **Browser JS Client**: Direct front-end invocation without requiring backend relay.\n- **Docker Image**: One-click deployment of full service (GUI + API), supports ARM architecture (usable on Raspberry Pi or mobile devices).\n- **Windows Executable**: Runs with zero dependencies‚Äîaccessible even to non-technical users.\n\n### ‚úÖ Multimedia Generation Support (Images/Audio)\n- Integrates image generation services like Pollinations for text-to-image capabilities.\n- Supports local persistent storage of generated content (images, HAR files, cookies).\n\n### ‚úÖ Community-First Philosophy\n- Licensed under GPLv3, emphasizing openness, sharing, and anti-monopoly values.\n- Encourages community contributions of new Provider plugins, fostering an ecosystem loop.\n\n---\n\n## 3. Startup Ideas Inspired by This Project\n\nHere are viable entrepreneurial directions derived from the technical capabilities of GPT4Free:\n\n### üöÄ Startup Idea 1: Low-Cost AI Assistant SaaS Platform for SMEs\n- **Positioning**: Deliver AI-powered services‚Äîsuch as smart customer support, copywriting, meeting summarization‚Äîto small and medium enterprises without API fees.\n- **Advantage**: Leverage g4f backend to reduce costly OpenAI API usage; build branded products with custom frontend.\n- **Monetization**: Subscription model (freemium + premium features) or pay-per-task pricing.\n- **Scalability**: Integrate with enterprise platforms like WeChat Work, Feishu, or DingTalk.\n\n### üéØ Startup Idea 2: Offline / Edge Computing AI Terminal Devices\n- **Hardware Form Factor**: Embedded boxes (e.g., Raspberry Pi-based), portable AI translators, educational robots.\n- **Core Technology**: Combine g4f with local inference engines (e.g., llama.cpp) to enable AI responses in offline or low-connectivity environments.\n- **Use Cases**: Remote education, military field operations, privacy-sensitive sectors (healthcare, finance) for decision support.\n\n### üí¨ Startup Idea 3: Privacy-First Personal AI Assistant App\n- **Features**: Fully local AI assistant app (Android/iOS) where all requests bypass third-party servers.\n- **Core Tech**: Package g4f‚Äôs Docker Slim image into mobile containers, secured via Tor or internal network tunneling.\n- **Selling Point**: ‚ÄúYour conversations belong to no one‚Äù‚Äîemphasizing data sovereignty and privacy protection.\n\n### üåê Startup Idea 4: Decentralized AI Gateway Network (DAO-style)\n- **Vision**: Build a distributed AI proxy network powered by volunteer nodes worldwide.\n- **Mechanism**: Each node runs g4f and shares partial computing power; users randomly connect to available nodes for responses‚Äîan ‚ÄúAI version of Tor.‚Äù\n- **Incentive Model**: Reward active nodes with tokens to prevent abuse.\n- **Social Impact**: Combat AI monopolies and promote equitable global access to intelligent resources.\n\n### üß† Startup Idea 5: AI Study Companion ‚Äî Student-Focused Browser Extension\n- **Design**: Integrate g4f.js to directly call GPT-4-level models within browsers, helping students solve problems, write essays, and learn programming.\n- **Ethical Compliance**: Include plagiarism detection and guided questioning mechanisms to discourage academic dishonesty.\n- **Business Model**: School-wide licenses + parental subscriptions for value-added services (learning reports, knowledge tracking).\n\n---\n\n> ‚≠ê Summary:  \n> GPT4Free is more than just a tool to \"use GPT for free\"‚Äîit is an **infrastructure driving AI democratization**. By lowering technological barriers, it empowers more people to innovate with AI. Entrepreneurs can build upon it to create next-generation AI products that are low-cost, highly available, and privacy-conscious.\n```",
    "text": "GPT4Free (g4f)\nCreated by\n@xtekky\n,\nmaintained by\n@hlohaus\nSupport the project on\nGitHub Sponsors\n‚ù§Ô∏è\nLive demo & docs:\nhttps://g4f.dev\n| Documentation:\nhttps://g4f.dev/docs\nGPT4Free (g4f) is a community-driven project that aggregates multiple accessible providers and interfaces to make working with modern LLMs and media-generation models easier and more flexible. GPT4Free aims to offer multi-provider support, local GUI, OpenAI-compatible REST APIs, and convenient Python and JavaScript clients ‚Äî all under a community-first license.\nThis README is a consolidated, improved, and complete guide to installing, running, and contributing to GPT4Free.\nTable of contents\nWhat‚Äôs included\nQuick links\nRequirements & compatibility\nInstallation\nDocker (recommended)\nSlim Docker image\nWindows (.exe)\nPython (pip / from source / partial installs)\nRunning the app\nGUI (web client)\nFastAPI / Interference API\nCLI\nOptional provider login (desktop in container)\nUsing the Python client\nSynchronous text example\nImage generation example\nAsync client example\nUsing GPT4Free.js (browser JS client)\nProviders & models (overview)\nLocal inference & media\nConfiguration & customization\nRunning on smartphone\nInterference API (OpenAI‚Äëcompatible)\nExamples & common patterns\nContributing\nHow to create a new provider\nHow AI can help you write code\nSecurity, privacy & takedown policy\nCredits, contributors & attribution\nPowered-by highlights\nChangelog & releases\nManifesto / Project principles\nLicense\nContact & sponsorship\nAppendix: Quick commands & examples\nWhat‚Äôs included\nPython client library and async client.\nOptional local web GUI.\nFastAPI-based OpenAI-compatible API (Interference API).\nOfficial browser JS client (g4f.dev distribution).\nDocker images (full and slim).\nMulti-provider adapters (LLMs, media providers, local inference backends).\nTooling for image/audio/video generation and media persistence.\nQuick links\nWebsite & docs:\nhttps://g4f.dev\n|\nhttps://g4f.dev/docs\nPyPI:\nhttps://pypi.org/project/g4f\nDocker image:\nhttps://hub.docker.com/r/hlohaus789/g4f\nReleases:\nhttps://github.com/xtekky/gpt4free/releases\nIssues:\nhttps://github.com/xtekky/gpt4free/issues\nCommunity: Telegram (\nhttps://telegram.me/g4f_channel\n) ¬∑ Discord News (\nhttps://discord.gg/5E39JUWUFa\n) ¬∑ Discord Support (\nhttps://discord.gg/qXA4Wf4Fsm\n)\nRequirements & compatibility\nPython 3.10+ recommended.\nGoogle Chrome/Chromium for providers using browser automation.\nDocker for containerized deployment.\nWorks on x86_64 and arm64 (slim image supports both).\nSome provider adapters may require platform-specific tooling (Chrome/Chromium, etc.). Check provider docs for details.\nInstallation\nDocker (recommended)\nInstall Docker:\nhttps://docs.docker.com/get-docker/\nCreate persistent directories:\nExample (Linux/macOS):\nmkdir -p\n${PWD}\n/har_and_cookies\n${PWD}\n/generated_media\nsudo chown -R 1200:1201\n${PWD}\n/har_and_cookies\n${PWD}\n/generated_media\nPull image:\ndocker pull hlohaus789/g4f\nRun container:\ndocker run -p 8080:8080 -p 7900:7900 \\\n  --shm-size=\n\"\n2g\n\"\n\\\n  -v\n${PWD}\n/har_and_cookies:/app/har_and_cookies \\\n  -v\n${PWD}\n/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest\nNotes:\nPort 8080 serves GUI/API; 7900 can expose a VNC-like desktop for provider logins (optional).\nIncrease --shm-size for heavier browser automation tasks.\nSlim Docker image (x64 & arm64)\nmkdir -p\n${PWD}\n/har_and_cookies\n${PWD}\n/generated_media\nchown -R 1000:1000\n${PWD}\n/har_and_cookies\n${PWD}\n/generated_media\n\ndocker run \\\n  -p 1337:8080 -p 8080:8080 \\\n  -v\n${PWD}\n/har_and_cookies:/app/har_and_cookies \\\n  -v\n${PWD}\n/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim\nNotes:\nThe slim image can update the g4f package on startup and installs additional dependencies as needed.\nIn this example, the Interference API is mapped to 1337.\nWindows Guide (.exe)\nDownload the release artifact\ng4f.exe.zip\nfrom:\nhttps://github.com/xtekky/gpt4free/releases/latest\nUnzip and run\ng4f.exe\n.\nOpen GUI at:\nhttp://localhost:8080/chat/\nIf Windows Firewall blocks access, allow the application.\nPython Installation (pip / from source / partial installs)\nPrerequisites:\nPython 3.10+ (\nhttps://www.python.org/downloads/\n)\nChrome/Chromium for some providers.\nInstall from PyPI (recommended):\npip install -U g4f[all]\nPartial installs\nTo install only specific functionality, use optional extras groups. See docs/requirements.md in the project docs.\nInstall from source:\ngit clone https://github.com/xtekky/gpt4free.git\ncd\ngpt4free\npip install -r requirements.txt\npip install -e\n.\nNotes:\nSome features require Chrome/Chromium or other tools; follow provider-specific docs.\nRunning the app\nGUI (web client)\nRun via Python:\nfrom\ng4f\n.\ngui\nimport\nrun_gui\nrun_gui\n()\nOr via CLI:\npython -m g4f.cli gui --port 8080 --debug\nOpen:\nhttp://localhost:8080/chat/\nFastAPI / Interference API\nStart FastAPI server:\npython -m g4f --port 8080 --debug\nIf using slim docker mapping, Interference API may be available at\nhttp://localhost:1337/v1\nSwagger UI:\nhttp://localhost:1337/docs\nCLI\nStart GUI server:\npython -m g4f.cli gui --port 8080 --debug\nOptional provider login (desktop within container)\nAccessible at:\nhttp://localhost:7900/?autoconnect=1&resize=scale&password=secret\nUseful for logging into web-based providers to obtain cookies/HAR files.\nUsing the Python client\nInstall:\npip install -U g4f[all]\nSynchronous text example:\nfrom\ng4f\n.\nclient\nimport\nClient\nclient\n=\nClient\n()\nresponse\n=\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\nmodel\n=\n\"gpt-4o-mini\"\n,\nmessages\n=\n[{\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"Hello, how are you?\"\n}],\nweb_search\n=\nFalse\n)\nprint\n(\nresponse\n.\nchoices\n[\n0\n].\nmessage\n.\ncontent\n)\nExpected:\nHello! How can I assist you today?\nImage generation example:\nfrom\ng4f\n.\nclient\nimport\nClient\nclient\n=\nClient\n()\nresponse\n=\nclient\n.\nimages\n.\ngenerate\n(\nmodel\n=\n\"flux\"\n,\nprompt\n=\n\"a white siamese cat\"\n,\nresponse_format\n=\n\"url\"\n)\nprint\n(\nf\"Generated image URL:\n{\nresponse\n.\ndata\n[\n0\n].\nurl\n}\n\"\n)\nAsync client example:\nfrom\ng4f\n.\nclient\nimport\nAsyncClient\nimport\nasyncio\nasync\ndef\nmain\n():\nclient\n=\nAsyncClient\n()\nresponse\n=\nawait\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\nmodel\n=\n\"gpt-4o-mini\"\n,\nmessages\n=\n[{\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"Explain quantum computing briefly\"\n}],\n    )\nprint\n(\nresponse\n.\nchoices\n[\n0\n].\nmessage\n.\ncontent\n)\nasyncio\n.\nrun\n(\nmain\n())\nNotes:\nSee the full API reference for streaming, tool-calling patterns, and advanced options:\nhttps://g4f.dev/docs/client\nUsing GPT4Free.js (browser JS client)\nUse the official JS client in the browser‚Äîno backend required.\nExample:\n<\nscript\ntype\n=\"\nmodule\n\"\n>\nimport\nClient\nfrom\n'https://g4f.dev/dist/js/client.js'\n;\nconst\nclient\n=\nnew\nClient\n(\n)\n;\nconst\nresult\n=\nawait\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\n{\nmodel\n:\n'gpt-4.1'\n,\n// Or \"gpt-4o\", \"deepseek-v3\", etc.\nmessages\n:\n[\n{\nrole\n:\n'user'\n,\ncontent\n:\n'Explain quantum computing'\n}\n]\n}\n)\n;\nconsole\n.\nlog\n(\nresult\n.\nchoices\n[\n0\n]\n.\nmessage\n.\ncontent\n)\n;\n</\nscript\n>\nNotes:\nThe JS client is distributed via the g4f.dev CDN for easy usage. Review CORS considerations and usage limits.\nProviders & models (overview)\nGPT4Free integrates many providers including (but not limited to) OpenAI-compatible endpoints, PerplexityLabs, Gemini, MetaAI, Pollinations (media), and local inference backends.\nModel availability and behavior depend on provider capabilities. See the providers doc for current, supported provider/model lists:\nhttps://g4f.dev/docs/providers-and-models\nProvider requirements may include:\nAPI keys or tokens (for authenticated providers)\nBrowser cookies / HAR files for providers scraped via browser automation\nChrome/Chromium or headless browser tooling\nLocal model binaries and runtime (for local inference)\nLocal inference & media\nGPT4Free supports local inference backends. See\ndocs/local.md\nfor supported runtimes and hardware guidance.\nMedia generation (image, audio, video) is supported through providers (e.g., Pollinations). See\ndocs/media.md\nfor formats, options, and sample usage.\nConfiguration & customization\nConfigure via environment variables, CLI flags, or config files. See\ndocs/config.md\n.\nTo reduce install size, use partial requirement groups. See\ndocs/requirements.md\n.\nProvider selection: learn how to set defaults and override per-request at\ndocs/selecting_a_provider.md\n.\nPersistence: HAR files, cookies, and generated media persist in mapped directories (e.g., har_and_cookies, generated_media).\nRunning on smartphone\nThe web GUI is responsive and can be accessed from a phone by visiting your host IP:8080 or via a tunnel. See\ndocs/guides/phone.md\n.\nInterference API (OpenAI‚Äëcompatible)\nThe Interference API enables OpenAI-like workflows routed through GPT4Free provider selection.\nDocs:\ndocs/interference-api.md\nDefault endpoint (example slim docker):\nhttp://localhost:1337/v1\nSwagger UI:\nhttp://localhost:1337/docs\nExamples & common patterns\nStreaming completions, stopping criteria, system messages, and tool-calling patterns are documented in:\ndocs/client.md\ndocs/async_client.md\ndocs/requests.md\nIntegrations (LangChain, PydanticAI):\ndocs/pydantic_ai.md\nLegacy examples:\ndocs/legacy.md\nContributing\nContributions are welcome ‚Äî new providers, features, docs, and fixes are appreciated.\nHow to contribute:\nFork the repository.\nCreate a branch for your change.\nRun tests and linters.\nOpen a Pull Request with a clear description and tests/examples if applicable.\nRepository:\nhttps://github.com/xtekky/gpt4free\nHow to create a new provider\nRead the guide:\ndocs/guides/create_provider.md\nTypical steps:\nImplement a provider adapter in\ng4f/Provider/\nAdd configuration and dependency notes\nInclude tests and usage examples\nRespect third‚Äëparty code licenses and attribute appropriately\nHow AI can help you write code\nSee:\ndocs/guides/help_me.md\nfor prompt templates and workflows to accelerate development.\nSecurity, privacy & takedown policy\nDo not store or share sensitive credentials. Use per-provider recommended security practices.\nIf your site appears in the project‚Äôs links and you want it removed, send proof of ownership to\ntakedown@g4f.ai\nand it will be removed promptly.\nFor production, secure the server with HTTPS, authentication, and firewall rules. Limit access to provider credentials and cookie/HAR storage.\nCredits, contributors & attribution\nCore creators:\n@xtekky\n(original), maintained by\n@hlohaus\n.\nFull contributor graph:\nhttps://github.com/xtekky/gpt4free/graphs/contributors\nNotable code inputs and attributions:\nhar_file.py\n‚Äî input from\nxqdoo00o/ChatGPT-to-API\nPerplexityLabs.py\n‚Äî input from\nnathanrchn/perplexityai\nGemini.py\n‚Äî input from\ndsdanielpark/Gemini-API\nand\nHanaokaYuzu/Gemini-API\nMetaAI.py\n‚Äî inspired by\nmeta-ai-api by Strvm\nproofofwork.py\n‚Äî input from\nmissuo/FreeGPT35\nMany more contributors are acknowledged in the repository.\nPowered-by highlights\nPollinations AI ‚Äî generative media:\nhttps://github.com/pollinations/pollinations\nMoneyPrinter V2 ‚Äî example project using GPT4Free:\nhttps://github.com/FujiwaraChoki/MoneyPrinterV2\nFor a full list of projects and sites using GPT4Free, see:\ndocs/powered-by.md\nChangelog & releases\nReleases and full changelog:\nhttps://github.com/xtekky/gpt4free/releases\nSubscribe to Discord/Telegram for announcements.\nManifesto / Project principles\nGPT4Free is guided by community principles:\nOpen access to AI tooling and models.\nCollaboration across providers and projects.\nOpposition to monopolistic, closed systems that restrict creativity.\nCommunity-centered development and broad access to AI technologies.\nPromote innovation, creativity, and accessibility.\nhttps://g4f.dev/manifest\nLicense\nThis program is licensed under the GNU General Public License v3.0 (GPLv3). See the full license:\nhttps://www.gnu.org/licenses/gpl-3.0.txt\nSummary:\nYou may redistribute and/or modify under the terms of GPLv3.\nThe program is provided WITHOUT ANY WARRANTY.\nCopyright notice\nxtekky/gpt4free: Copyright (C) 2025 xtekky\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nContact & sponsorship\nMaintainers:\nhttps://github.com/hlohaus\nSponsorship:\nhttps://github.com/sponsors/hlohaus\nIssues & feature requests:\nhttps://github.com/xtekky/gpt4free/issues\nTakedown requests:\ntakedown@g4f.ai\nAppendix: Quick commands & examples\nInstall (pip):\npip install -U g4f[all]\nRun GUI (Python):\npython -m g4f.cli gui --port 8080 --debug\n#\nor\npython -c\n\"\nfrom g4f.gui import run_gui; run_gui()\n\"\nDocker (full):\ndocker pull hlohaus789/g4f\ndocker run -p 8080:8080 -p 7900:7900 \\\n  --shm-size=\n\"\n2g\n\"\n\\\n  -v\n${PWD}\n/har_and_cookies:/app/har_and_cookies \\\n  -v\n${PWD}\n/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest\nDocker (slim):\ndocker run -p 1337:8080 -p 8080:8080 \\\n  -v\n${PWD}\n/har_and_cookies:/app/har_and_cookies \\\n  -v\n${PWD}\n/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim\nPython usage patterns:\nclient.chat.completions.create(...)\nclient.images.generate(...)\nAsync variants via\nAsyncClient\nDocs & deeper reading\nFull docs:\nhttps://g4f.dev/docs\nClient API docs:\nhttps://g4f.dev/docs/client\nAsync client docs:\nhttps://g4f.dev/docs/async_client\nProvider guides:\nhttps://g4f.dev/docs/guides\nLocal inference:\nhttps://g4f.dev/docs/local\nThank you for using and contributing to GPT4Free ‚Äî together we make powerful AI tooling accessible, flexible, and community-driven.",
    "readme": "# GPT4Free (g4f)\n\n[![PyPI](https://img.shields.io/pypi/v/g4f)](https://pypi.org/project/g4f) [![Docker Hub](https://img.shields.io/badge/docker-hlohaus789%2Fg4f-blue)](https://hub.docker.com/r/hlohaus789/g4f) [![License: GPL v3](https://img.shields.io/badge/License-GPLv3-red.svg)](https://www.gnu.org/licenses/gpl-3.0.txt)\n\n<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/7f60c240-00fa-4c37-bf7f-ae5cc20906a1\" alt=\"GPT4Free logo\" height=\"200\" />\n</p>\n\n<p align=\"center\">\n  <span style=\"background: linear-gradient(45deg, #12c2e9, #c471ed, #f64f59); -webkit-background-clip: text; -webkit-text-fill-color: transparent;\">\n    <strong>Created by <a href=\"https://github.com/xtekky\">@xtekky</a>,<br> maintained by <a href=\"https://github.com/hlohaus\">@hlohaus</a></strong>\n  </span>\n</p>\n<p align=\"center\">\n<span>Support the project on</span>\n      <a href=\"https://github.com/sponsors/hlohaus\" target=\"_blank\" rel=\"noopener noreferrer\">\n        GitHub Sponsors\n      </a>\n      ‚ù§Ô∏è\n</p>\n<p align=\"center\">\nLive demo & docs: https://g4f.dev | Documentation: https://g4f.dev/docs\n</p>\n\n---\n\nGPT4Free (g4f) is a community-driven project that aggregates multiple accessible providers and interfaces to make working with modern LLMs and media-generation models easier and more flexible. GPT4Free aims to offer multi-provider support, local GUI, OpenAI-compatible REST APIs, and convenient Python and JavaScript clients ‚Äî all under a community-first license.\n\nThis README is a consolidated, improved, and complete guide to installing, running, and contributing to GPT4Free.\n\nTable of contents\n- [What‚Äôs included](#whats-included)\n- [Quick links](#quick-links)\n- [Requirements & compatibility](#requirements--compatibility)\n- [Installation](#installation)\n  - [Docker (recommended)](#docker-recommended)\n  - [Slim Docker image](#slim-docker-image)\n  - [Windows (.exe)](#windows-exe)\n  - [Python (pip / from source / partial installs)](#python-pip--from-source--partial-installs)\n- [Running the app](#running-the-app)\n  - [GUI (web client)](#gui-web-client)\n  - [FastAPI / Interference API](#fastapi--interference-api)\n  - [CLI](#cli)\n  - [Optional provider login (desktop in container)](#optional-provider-login-desktop-in-container)\n- [Using the Python client](#using-the-python-client)\n  - [Synchronous text example](#synchronous-text-example)\n  - [Image generation example](#image-generation-example)\n  - [Async client example](#async-client-example)\n- [Using GPT4Free.js (browser JS client)](#using-gpt4freejs-browser-js-client)\n- [Providers & models (overview)](#providers--models-overview)\n- [Local inference & media](#local-inference--media)\n- [Configuration & customization](#configuration--customization)\n- [Running on smartphone](#running-on-smartphone)\n- [Interference API (OpenAI‚Äëcompatible)](#interference-api-openai-compatible)\n- [Examples & common patterns](#examples--common-patterns)\n- [Contributing](#contributing)\n  - [How to create a new provider](#how-to-create-a-new-provider)\n  - [How AI can help you write code](#how-ai-can-help-you-write-code)\n- [Security, privacy & takedown policy](#security-privacy--takedown-policy)\n- [Credits, contributors & attribution](#credits-contributors--attribution)\n- [Powered-by highlights](#powered-by-highlights)\n- [Changelog & releases](#changelog--releases)\n- [Manifesto / Project principles](#manifesto--project-principles)\n- [License](#license)\n- [Contact & sponsorship](#contact--sponsorship)\n- [Appendix: Quick commands & examples](#appendix-quick-commands--examples)\n\n---\n\n## What‚Äôs included\n- Python client library and async client.\n- Optional local web GUI.\n- FastAPI-based OpenAI-compatible API (Interference API).\n- Official browser JS client (g4f.dev distribution).\n- Docker images (full and slim).\n- Multi-provider adapters (LLMs, media providers, local inference backends).\n- Tooling for image/audio/video generation and media persistence.\n\n---\n\n## Quick links\n- Website & docs: https://g4f.dev | https://g4f.dev/docs  \n- PyPI: https://pypi.org/project/g4f  \n- Docker image: https://hub.docker.com/r/hlohaus789/g4f  \n- Releases: https://github.com/xtekky/gpt4free/releases  \n- Issues: https://github.com/xtekky/gpt4free/issues  \n- Community: Telegram (https://telegram.me/g4f_channel) ¬∑ Discord News (https://discord.gg/5E39JUWUFa) ¬∑ Discord Support (https://discord.gg/qXA4Wf4Fsm)\n\n---\n\n## Requirements & compatibility\n- Python 3.10+ recommended.\n- Google Chrome/Chromium for providers using browser automation.\n- Docker for containerized deployment.\n- Works on x86_64 and arm64 (slim image supports both).\n- Some provider adapters may require platform-specific tooling (Chrome/Chromium, etc.). Check provider docs for details.\n\n---\n\n## Installation\n\n### Docker (recommended)\n1. Install Docker: https://docs.docker.com/get-docker/\n2. Create persistent directories:\n   - Example (Linux/macOS):\n     ```bash\n     mkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media\n     sudo chown -R 1200:1201 ${PWD}/har_and_cookies ${PWD}/generated_media\n     ```\n3. Pull image:\n   ```bash\n   docker pull hlohaus789/g4f\n   ```\n4. Run container:\n   ```bash\n   docker run -p 8080:8080 -p 7900:7900 \\\n     --shm-size=\"2g\" \\\n     -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n     -v ${PWD}/generated_media:/app/generated_media \\\n     hlohaus789/g4f:latest\n   ```\nNotes:\n- Port 8080 serves GUI/API; 7900 can expose a VNC-like desktop for provider logins (optional).\n- Increase --shm-size for heavier browser automation tasks.\n\n### Slim Docker image (x64 & arm64)\n```bash\nmkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media\nchown -R 1000:1000 ${PWD}/har_and_cookies ${PWD}/generated_media\n\ndocker run \\\n  -p 1337:8080 -p 8080:8080 \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim\n```\nNotes:\n- The slim image can update the g4f package on startup and installs additional dependencies as needed.\n- In this example, the Interference API is mapped to 1337.\n\n### Windows Guide (.exe)\n1. Download the release artifact `g4f.exe.zip` from:\n   https://github.com/xtekky/gpt4free/releases/latest\n2. Unzip and run `g4f.exe`.\n3. Open GUI at: http://localhost:8080/chat/\n4. If Windows Firewall blocks access, allow the application.\n\n### Python Installation (pip / from source / partial installs)\n\nPrerequisites:\n- Python 3.10+ (https://www.python.org/downloads/)\n- Chrome/Chromium for some providers.\n\nInstall from PyPI (recommended):\n```bash\npip install -U g4f[all]\n```\n\nPartial installs\n- To install only specific functionality, use optional extras groups. See docs/requirements.md in the project docs.\n\nInstall from source:\n```bash\ngit clone https://github.com/xtekky/gpt4free.git\ncd gpt4free\npip install -r requirements.txt\npip install -e .\n```\n\nNotes:\n- Some features require Chrome/Chromium or other tools; follow provider-specific docs.\n\n---\n\n## Running the app\n\n### GUI (web client)\n- Run via Python:\n```python\nfrom g4f.gui import run_gui\nrun_gui()\n```\n- Or via CLI:\n```bash\npython -m g4f.cli gui --port 8080 --debug\n```\n- Open: http://localhost:8080/chat/\n\n### FastAPI / Interference API\n- Start FastAPI server:\n```bash\npython -m g4f --port 8080 --debug\n```\n- If using slim docker mapping, Interference API may be available at `http://localhost:1337/v1`\n- Swagger UI: `http://localhost:1337/docs`\n\n### CLI\n- Start GUI server:\n```bash\npython -m g4f.cli gui --port 8080 --debug\n```\n\n### Optional provider login (desktop within container)\n- Accessible at:\n  ```\n  http://localhost:7900/?autoconnect=1&resize=scale&password=secret\n  ```\n- Useful for logging into web-based providers to obtain cookies/HAR files.\n\n---\n\n## Using the Python client\n\nInstall:\n```bash\npip install -U g4f[all]\n```\n\nSynchronous text example:\n```python\nfrom g4f.client import Client\n\nclient = Client()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n    web_search=False\n)\nprint(response.choices[0].message.content)\n```\nExpected:\n```\nHello! How can I assist you today?\n```\n\nImage generation example:\n```python\nfrom g4f.client import Client\n\nclient = Client()\nresponse = client.images.generate(\n    model=\"flux\",\n    prompt=\"a white siamese cat\",\n    response_format=\"url\"\n)\nprint(f\"Generated image URL: {response.data[0].url}\")\n```\n\nAsync client example:\n```python\nfrom g4f.client import AsyncClient\nimport asyncio\n\nasync def main():\n    client = AsyncClient()\n    response = await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing briefly\"}],\n    )\n    print(response.choices[0].message.content)\n\nasyncio.run(main())\n```\n\nNotes:\n- See the full API reference for streaming, tool-calling patterns, and advanced options: https://g4f.dev/docs/client\n\n---\n\n## Using GPT4Free.js (browser JS client)\nUse the official JS client in the browser‚Äîno backend required.\n\nExample:\n```html\n<script type=\"module\">\n  import Client from 'https://g4f.dev/dist/js/client.js';\n\n  const client = new Client();\n  const result = await client.chat.completions.create({\n      model: 'gpt-4.1',  // Or \"gpt-4o\", \"deepseek-v3\", etc.\n      messages: [{ role: 'user', content: 'Explain quantum computing' }]\n  });\n  console.log(result.choices[0].message.content);\n</script>\n```\n\nNotes:\n- The JS client is distributed via the g4f.dev CDN for easy usage. Review CORS considerations and usage limits.\n\n---\n\n## Providers & models (overview)\n- GPT4Free integrates many providers including (but not limited to) OpenAI-compatible endpoints, PerplexityLabs, Gemini, MetaAI, Pollinations (media), and local inference backends.\n- Model availability and behavior depend on provider capabilities. See the providers doc for current, supported provider/model lists: https://g4f.dev/docs/providers-and-models\n\nProvider requirements may include:\n- API keys or tokens (for authenticated providers)\n- Browser cookies / HAR files for providers scraped via browser automation\n- Chrome/Chromium or headless browser tooling\n- Local model binaries and runtime (for local inference)\n\n---\n\n## Local inference & media\n- GPT4Free supports local inference backends. See [docs/local.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/local.md) for supported runtimes and hardware guidance.\n- Media generation (image, audio, video) is supported through providers (e.g., Pollinations). See [docs/media.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/media.md) for formats, options, and sample usage.\n\n---\n\n## Configuration & customization\n- Configure via environment variables, CLI flags, or config files. See [docs/config.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/config.md).\n- To reduce install size, use partial requirement groups. See [docs/requirements.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/requirements.md).\n- Provider selection: learn how to set defaults and override per-request at [docs/selecting_a_provider.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/selecting_a_provider.md).\n- Persistence: HAR files, cookies, and generated media persist in mapped directories (e.g., har_and_cookies, generated_media).\n\n---\n\n## Running on smartphone\n- The web GUI is responsive and can be accessed from a phone by visiting your host IP:8080 or via a tunnel. See [docs/guides/phone.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/phone.md).\n\n---\n\n## Interference API (OpenAI‚Äëcompatible)\n- The Interference API enables OpenAI-like workflows routed through GPT4Free provider selection.\n- Docs: [docs/interference-api.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/interference-api.md)\n- Default endpoint (example slim docker): `http://localhost:1337/v1`\n- Swagger UI: `http://localhost:1337/docs`\n\n---\n\n## Examples & common patterns\n- Streaming completions, stopping criteria, system messages, and tool-calling patterns are documented in:\n  - [docs/client.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/client.md)\n  - [docs/async_client.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/async_client.md)\n  - [docs/requests.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/requests.md)\n- Integrations (LangChain, PydanticAI): [docs/pydantic_ai.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/pydantic_ai.md)\n- Legacy examples: [docs/legacy.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/legacy.md)\n\n---\n\n## Contributing\nContributions are welcome ‚Äî new providers, features, docs, and fixes are appreciated.\n\nHow to contribute:\n1. Fork the repository.\n2. Create a branch for your change.\n3. Run tests and linters.\n4. Open a Pull Request with a clear description and tests/examples if applicable.\n\nRepository: https://github.com/xtekky/gpt4free\n\n### How to create a new provider\n- Read the guide: [docs/guides/create_provider.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/create_provider.md)\n- Typical steps:\n  - Implement a provider adapter in `g4f/Provider/`\n  - Add configuration and dependency notes\n  - Include tests and usage examples\n  - Respect third‚Äëparty code licenses and attribute appropriately\n\n### How AI can help you write code\n- See: [docs/guides/help_me.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/guides/help_me.md) for prompt templates and workflows to accelerate development.\n\n---\n\n## Security, privacy & takedown policy\n- Do not store or share sensitive credentials. Use per-provider recommended security practices.\n- If your site appears in the project‚Äôs links and you want it removed, send proof of ownership to takedown@g4f.ai and it will be removed promptly.\n- For production, secure the server with HTTPS, authentication, and firewall rules. Limit access to provider credentials and cookie/HAR storage.\n\n---\n\n## Credits, contributors & attribution\n- Core creators: [@xtekky](https://github.com/xtekky) (original), maintained by [@hlohaus](https://github.com/hlohaus).\n- Full contributor graph: https://github.com/xtekky/gpt4free/graphs/contributors\n- Notable code inputs and attributions:\n  - `har_file.py` ‚Äî input from [xqdoo00o/ChatGPT-to-API](https://github.com/xqdoo00o/ChatGPT-to-API)\n  - `PerplexityLabs.py` ‚Äî input from [nathanrchn/perplexityai](https://github.com/nathanrchn/perplexityai)\n  - `Gemini.py` ‚Äî input from [dsdanielpark/Gemini-API](https://github.com/dsdanielpark/Gemini-API) and [HanaokaYuzu/Gemini-API](https://github.com/HanaokaYuzu/Gemini-API)\n  - `MetaAI.py` ‚Äî inspired by [meta-ai-api by Strvm](https://github.com/Strvm/meta-ai-api)\n  - `proofofwork.py` ‚Äî input from [missuo/FreeGPT35](https://github.com/missuo/FreeGPT35)\n\nMany more contributors are acknowledged in the repository.\n\n---\n\n## Powered-by highlights\n- Pollinations AI ‚Äî generative media: https://github.com/pollinations/pollinations\n- MoneyPrinter V2 ‚Äî example project using GPT4Free: https://github.com/FujiwaraChoki/MoneyPrinterV2\n- For a full list of projects and sites using GPT4Free, see: [docs/powered-by.md](https://github.com/gpt4free/g4f.dev/blob/main/docs/powered-by.md)\n\n---\n\n## Changelog & releases\n- Releases and full changelog: https://github.com/xtekky/gpt4free/releases\n- Subscribe to Discord/Telegram for announcements.\n\n---\n\n## Manifesto / Project principles\nGPT4Free is guided by community principles:\n1. Open access to AI tooling and models.\n2. Collaboration across providers and projects.\n3. Opposition to monopolistic, closed systems that restrict creativity.\n4. Community-centered development and broad access to AI technologies.\n5. Promote innovation, creativity, and accessibility.\n\nhttps://g4f.dev/manifest\n\n---\n\n## License\nThis program is licensed under the GNU General Public License v3.0 (GPLv3). See the full license: https://www.gnu.org/licenses/gpl-3.0.txt\n\nSummary:\n- You may redistribute and/or modify under the terms of GPLv3.\n- The program is provided WITHOUT ANY WARRANTY.\n\nCopyright notice\n```\nxtekky/gpt4free: Copyright (C) 2025 xtekky\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n```\n\n---\n\n## Contact & sponsorship\n- Maintainers: https://github.com/hlohaus  \n- Sponsorship: https://github.com/sponsors/hlohaus  \n- Issues & feature requests: https://github.com/xtekky/gpt4free/issues  \n- Takedown requests: takedown@g4f.ai\n\n---\n\n## Appendix: Quick commands & examples\n\nInstall (pip):\n```bash\npip install -U g4f[all]\n```\n\nRun GUI (Python):\n```bash\npython -m g4f.cli gui --port 8080 --debug\n# or\npython -c \"from g4f.gui import run_gui; run_gui()\"\n```\n\nDocker (full):\n```bash\ndocker pull hlohaus789/g4f\ndocker run -p 8080:8080 -p 7900:7900 \\\n  --shm-size=\"2g\" \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest\n```\n\nDocker (slim):\n```bash\ndocker run -p 1337:8080 -p 8080:8080 \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim\n```\n\nPython usage patterns:\n- `client.chat.completions.create(...)`\n- `client.images.generate(...)`\n- Async variants via `AsyncClient`\n\nDocs & deeper reading\n- Full docs: https://g4f.dev/docs  \n- Client API docs: https://g4f.dev/docs/client  \n- Async client docs: https://g4f.dev/docs/async_client  \n- Provider guides: https://g4f.dev/docs/guides  \n- Local inference: https://g4f.dev/docs/local\n\n---\n\nThank you for using and contributing to GPT4Free ‚Äî together we make powerful AI tooling accessible, flexible, and community-driven.",
    "author": "xtekky",
    "project": "gpt4free",
    "date": "2025-10-06"
}