{
    "id": "2506.03984",
    "title": "Around the World in 24 Hours: Probing LLM Knowledge of Time and Place",
    "summary": "This paper proposes the first assessment of a language model's ability to reason in both temporal and spatial dimensions, and introduces the language model dataset GeoTemp for evaluation.",
    "abstract": "Reasoning over time and space is essential for understanding our world. However, the abilities of language models in this area are largely unexplored as previous work has tested their abilities for logical reasoning in terms of time and space in isolation or only in simple or artificial environments. In this paper, we present the first evaluation of the ability of language models to jointly reason over time and space. To enable our analysis, we create GeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37 time zones. Using GeoTemp, we evaluate eight open chat models of three different model families for different combinations of temporal and geographic knowledge. We find that most models perform well on reasoning tasks involving only temporal knowledge and that overall performance improves with scale. However, performance remains constrained in tasks that require connecting temporal and geographical information. We do not find clear correlations of performance with specific geographic regions. Instead, we find a significant performance increase for location names with low model perplexity, suggesting their repeated occurrence during model training. We further demonstrate that their performance is heavily influenced by prompt formulation - a direct injection of geographical knowledge leads to performance gains, whereas, surprisingly, techniques like chain-of-thought prompting decrease performance on simpler tasks.",
    "category1": "Algorithms and Models",
    "category2": "",
    "category3": "Non-Agent",
    "authors": "Carolin Holtermann,Paul Röttger,Anne Lauscher",
    "subjects": [
        "Computation and Language (cs.CL)"
    ],
    "comments": "",
    "keypoint": "- Most language models perform well on reasoning tasks involving only temporal knowledge, with performance improving with model scale. However, they struggle with tasks requiring the connection of temporal and geographical information.\n- No clear correlations were found between model performance and specific geographic regions. Instead, there was a significant performance increase for location names with low model perplexity, suggesting their repeated occurrence during model training.\n- Model performance is heavily influenced by prompt formulation; direct injection of geographical knowledge leads to performance gains, whereas chain-of-thought prompting decreases performance on simpler tasks.\n- Larger models show better performance on basic temporal calculations but still struggle with combining temporal and geographical knowledge.\n- The best-performing model (Llama3-70B) achieves only 25.4% accuracy on questions requiring both temporal and geographical knowledge.\n- Explicitly injecting geographical knowledge improves performance on complex tasks, but mainly for locations where the models already know the time zone.\n- Models fail to effectively retrieve and combine necessary knowledge for complex tasks, even when they possess the required individual pieces of knowledge.\n- Increasing model size alone may not solve the problem; improvements in systematic and stepwise knowledge retrieval or tool usage might be necessary.\n- Performance varies drastically across models and tasks, with VERIFICATION and TIMETIME tasks being more solvable than those requiring location-specific knowledge.\n- There are consistent scaling effects, with larger models showing improved performance across all tasks, though gains diminish for some models like Qwen2.\n- Instruction types significantly affect performance, with concise answers decreasing performance on complex tasks and chain-of-thought prompting worsening results on simpler tasks.\n- Robustness analysis shows stable trends between models, their sizes, and instruction types, with low error for TIMEPLACE and TIMETIMEPLACE tasks.\n- No significant country biases were observed; model performance was not consistently better or worse for Western, higher-income, or population-dense countries.\n- Location name perplexity significantly affects performance, with models performing better on locations that likely appear more frequently in training data.\n- Error analysis reveals issues with handling DST/UTC conversions, incorrect time differences, and failure to use correct UTC information.\n- Models can predict correct time zones for at least 65% of locations when explicitly prompted, indicating general geographical competencies but struggles in combining this knowledge with temporal reasoning.",
    "date": "2025-06-06",
    "paper": "arXiv:2506.03984v1  [cs.CL]  4 Jun 2025\nAround the World in 24 Hours\nProbing LLM Knowledge of Time and Place\nCarolin Holtermann1, Paul Röttger2, Anne Lauscher1\n1University of Hamburg, Germany\n2University of Bocconi, Italy\ncarolin.holtermann@uni-hamburg.de\nAbstract\nReasoning over time and space is essential for\nunderstanding our world. However, the abilities\nof language models in this area are largely un-\nexplored as previous work has tested their abil-\nities for logical reasoning in terms of time and\nspace in isolation or only in simple or artificial\nenvironments. In this paper, we present the first\nevaluation of the ability of language models to\njointly reason over time and space. To enable\nour analysis, we create GEOTEMP, a dataset\nof 320k prompts covering 289 cities in 217\ncountries and 37 time zones. Using GEOTEMP,\nwe evaluate eight open chat models from three\nmodel families for different combinations of\ntemporal and geographic knowledge. We find\nthat most models perform well on reasoning\ntasks involving only temporal knowledge and\nthat overall performance improves with scale.\nHowever, performance remains poor in tasks\nthat require connecting temporal and geograph-\nical information. We do not find clear correla-\ntions of performance with specific geographic\nregions. Instead, we find a significant perfor-\nmance increase for location names with low\nmodel perplexity, suggesting their repeated oc-\ncurrence during model training. We further\ndemonstrate that model performance is heav-\nily influenced by prompt formulation – a di-\nrect injection of geographical knowledge leads\nto performance gains, whereas, surprisingly,\ntechniques like chain-of-thought prompting de-\ncrease performance on simpler tasks.1\n1\nIntroduction\n“Stop worrying about the world ending\ntoday. It’s already tomorrow in Australia.”\n— Charles M. Schulz\nHuman civilization has developed systems and con-\nventions to organize life and foster community,\nsuch as a standardized global time and calendar\n1We release all data and code at https://github.com/\nUhhDS/GeoTemp.\n...now? \n... in \n? \n5 hours\n... now  \nin \n?\nLondon\n... in \n  \nin \n?\n5 hours\nLondon\nTemporal Knowledge\nGeographical Knowledge\nIt’s currently 5 pm in Paris.  \nWhat time is it ...\n12\n11\n10\n9\n8 7\n4\n6 5\n1\n3\n2\n12\n11\n10\n9\n8 7\n4\n6 5\n1\n3\n2\nFigure 1: Combinations of temporal and geographic\nknowledge we test with GEOTEMP. Models struggle\nmost with jointly reasoning over space and time.\nsystem, time zones based on geographic location,\nand daylight saving time to align activities across\ndifferent regions (Hayden, 1987). These conven-\ntions, deeply rooted in our understanding of the\nworld, play a crucial role in decision-making, espe-\ncially in today’s globalized working environment.\nAs technology advances, large language models\n(LLMs) will increasingly be used to simplify and\noptimize tasks (Eloundou et al., 2023), for example\nin the logistical planning of cross-border shipping\nor the optimal planning of business trips. To re-\nliably perform such tasks, they must be able to\nincorporate temporal and geographical information\ninto their reasoning process. Prior work has evalu-\nated the temporal reasoning ability of LLMs (e.g.\nDhingra et al., 2022; Fatemi et al., 2024) as well\nas their spatial understanding of the world (e.g.\nGurnee and Tegmark, 2024; Moayeri et al., 2024).\nHowever, little work has been done on evaluating\nLLM ability to reason jointly over space and time,\noutside of simple and artificial settings such as\nmultiple-choice questions (Wang and Zhao, 2024)\nor synthetic data (Fatemi et al., 2024).\nIn this paper, we address this gap by analyz-\ning the ability of LLMs to combine geographical\nand temporal knowledge in reasoning tasks, using\nglobal time zones as a testbed. To this end, we\npresent GEOTEMP, which contains 320k question\nprompts covering 289 locations in 37 time zones.\nGEOTEMP is explicitly designed to evaluate LLM\nacross different levels of temporal and geograph-\nical reasoning (Figure 1). Using GEOTEMP we\nanswer the following research questions:\n1) How well do LLMs reason about time, place,\nand their combination? We test eight state-of-the-\nart chat-optimized LLMs on four different tasks\nrequiring different levels of temporal and/or geo-\ngraphical knowledge (§5). We find that most mod-\nels are able to perform simple calculations of time,\nbut fail as soon as they have to perform additional\ngeographical reasoning. Although we see improve-\nments with model scale, the best-performing model\nis only 25.4% accurate on questions requiring both\ntemporal and geographical knowledge.\n2) What factors influence model performance\non geotemporal tasks? In contrast to prior work\non geographic knowledge (Moayeri et al., 2024),\nwe do not find clear performance disparities across\ngeographic regions (§6). However, we do observe a\nsignificant correlation between model performance\nand location name perplexities. Direct probing of\ntime zones reveals that models generally possess\nknowledge of individual geographical and temporal\nfacts, but are unable to combine the two effectively,\nwhich limits performance on geotemporal tasks.\n3) Can model performance be improved by in-\njecting geotemporal knowledge? We provide\nmodels with location-specific time zones to guide\ntheir reasoning (§7), and find significant perfor-\nmance improvements. However, surprisingly, these\nimprovements are mostly for locations for which,\nin our prior probing, we found the models to know\nthe time zone of already. This suggests that, while\nbasic geotemporal facts may be already present in\nthe models, this knowledge requires activation to\nsolve more complex geotemporal tasks.\n2\nRelated Work\nTesting temporal knowledge\nSeveral studies\nbenchmark the temporal knowledge of LLMs. The\nTimeBank corpus (Pustejovsky et al., 2003) focuses\non annotating news articles for temporal expres-\nsions, events, and their links. Recent work expands\nto analyze temporal knowledge beyond event ex-\ntraction, with benchmarks like McTaco (Zhou et al.,\n2019), TempLama (Dhingra et al., 2022), or Situ-\natedQA (Zhang and Choi, 2021) probing models’\nfactual knowledge of time-varying. Other stud-\nies explore their temporal reasoning capabilities,\nincluding relations between temporal expressions\n(Thukral et al., 2021), event ordering (Tan et al.,\n2023; Wei et al., 2023; Xiong et al., 2024), and du-\nration (Vashishtha et al., 2020), and more complex\ntasks like multi-hop reasoning (Tan et al., 2024) or\nvideo reasoning (Liao et al., 2024). Recent work\nalso examines the temporal knowledge alignment\nof LLMs to given timestamps (Kasai et al., 2024;\nLiska et al., 2022; Zhao et al., 2024). Finally, Ny-\nlund et al. (2024) and Gurnee and Tegmark (2024)\nanalyze temporal representations within models\nthrough probing and methods from task arithmetic.\nTesting geographical knowledge\nPrevious work\non geographic knowledge in LLMs focuses on the\nprediction of geolocations (Godey et al., 2024),\ntheir internal model representation (Gurnee and\nTegmark, 2024), and how this knowledge can be\nadapted (Liétard et al., 2021). Other works extend\nthese efforts by evaluating the ability of LLMs to\nrecall information about different countries and ex-\namine model-intrinsic and location-specific biases\n(Moayeri et al., 2024; Manvi et al., 2024b,a).\nTesting geotemporal knowledge\nTwo recent\nworks partially address geotemporal reasoning but\nprovide limited insight into the ability of models\nto combine geographical and temporal knowledge.\n1) The TRAM corpus (Wang and Zhao, 2024) eval-\nuates temporal reasoning, including time zone cal-\nculations as a subtask. However, it focuses on\nmodel performance and does not provide a deeper\nanalysis of the model’s ability to combine tempo-\nral and geographical knowledge. Moreover, its\nmultiple-choice format does not allow open-ended\nresponses and thus strongly guides the model in its\nresponse. 2) The TOT benchmark (Fatemi et al.,\n2024) is a fully synthetic data set that tests tempo-\nral reasoning without including real-world location\ninformation. It evaluates time zone calculations,\nbut based on the provision of time zones, not geo-\ngraphic locations.\n3\nGEOTEMP\nWe introduce GEOTEMP, the first probing dataset\nspecifically designed to evaluate the geotempo-\nTask Name\nTemplate\nVERIFICATION\nWhat time is it now in l1?\nTIMETIME\nWhat time is it in x hours?\nTIMEPLACE\nWhat time is it now in l2?\nTIMETIMEPLACE\nWhat time is it in x hours in l2?\nTable 1: Overview of tasks and their templates we use\nto construct test prompts in GEOTEMP. We prepend to\neach template information about the current date, time,\nand location as follows: Today is {Time&Date} in {l1}.\nral knowledge of LLMs. By carefully construct-\ning synthetic prompts that progressively require\nmore complex geotemporal reasoning, GEOTEMP\nallows us to isolate failure points while minimizing\nthe risk of using exact prompts seen during train-\ning. However, grounded in real-world LLM usage,\nGEOTEMP combines temporal and geographical\nknowledge, using global time zones as its basis.\n3.1\nDataset Creation\nWe create GEOTEMP in three steps: 1) We col-\nlect time zones along with cities located in them;\n2) We craft four task templates representing varying\ncombinations of geotemporal knowledge, coupling\neach of these tasks with one or two of our locations,\ndepending on the task template; 3) We compose\nthe final dataset by sampling representative task-\nlocation combinations from above, and embedding\nthem into the task templates.\n1) Collecting time zones and locations\nWe use\nthe Olson Time Zone Database (OTZD) to compile\na diverse selection of locations across countries\nand time zones.2 The OTZD contains time zone\ninformation for 596 representative locations world-\nwide, including rules for daylight saving time. It is\nactively maintained by the non-profit organization\nICANN, ensuring reliability and accuracy.3\nThe 596 timezone names we extract from the\nOTZD typically follow a naming convention of\nArea/City (e.g. Europe/Madrid). To ensure that all\nentries in our dataset refer to precise locations, we\nmanually exclude time zones that represent entire\nregions, such as Brazil/West, as well as outdated\ntime zones that are no longer in use. After applying\nthese filters, we are left with a refined set of 460\ndistinct and precise locations. For each of these\nlocations, we gather additional city-level data, in-\ncluding population, latitude, and longitude, using\n2https://www.iana.org/time-zones\n3https://www.icann.org/\nthe Opendatasoft API, to enable more comprehen-\nsive analysis later on.4\n2) Crafting task templates\nNext, we define four\ntasks requiring different combinations of geotem-\nporal knowledge. We present these in Table 1.\nVERIFICATION provides the model with a date\nand time in a given location l1, and asks for that\nsame time again (e.g. Today is Monday, June 19th\nat 10:33 AM in 2023 in Novokuznetsk, Russia.\nWhat time is it now in Novokuznetsk, Russia?). This\nallows us to assess the model’s basic comprehen-\nsion of the task and its ability to respond with a\ncorrectly formatted time.\nTIMETIME provides a date and time and a spe-\ncific location l1, then asks what the time will be in\nthat same location in a specified number of hours\n(e.g. What time is it in 3 hours?). To accomplish\nthis task, the model only needs to perform basic\ntemporal reasoning, whereas geographical reason-\ning is irrelevant. This template is adapted from\nprior work on LLM temporal knowledge and rea-\nsoning (Dhingra et al., 2022; Tan et al., 2024).\nTIMEPLACE gives the model the current date\nand time at a specified location l1 and asks for\nthe current time at another given location l2. To\nsolve this task, the model requires knowledge of\nthe time zones at each location and must determine\nthe resulting time zone difference.\nTIMETIMEPLACE provides the model with a\ndate and time at a specific location l1, then asks the\nmodel for the time in another location l2 but in a\nspecific number of hours. Solving this requires the\nmodel to consider the time shift before or after the\ntime zone change, in addition to TIMEPLACE. This\ntests the model’s ability to handle both temporal\nshifts and geographic knowledge simultaneously.\n3) Composing the test set\nWith GEOTEMP, we\nwant to cover a wide variety of locations while\navoiding over-representing any particular combina-\ntion of locations. To do this, we select a representa-\ntive sample from the 460 locations obtained from\nOTZD, such that all 37 UTC time zones and 217\nISO country codes are included. This results in a re-\nfined selection of 289 locations. Next, we generate\nthe Cartesian product of all selected locations l1×l2\nto cover all possible combinations within the TIME-\nPLACE and TIMETIMEPLACE templates. Finally,\nwe construct all evaluation prompts of GEOTEMP\n4https://public.opendatasoft.com/explore/\ndataset/geonames-all-cities-with-a-population-500/\napi/?disjunctive.country\nFigure 2: Geographical distribution of all 289 loca-\ntions in GEOTEMP. Color indicates UTC time zone.\n<500\n<50K\n<100K\n<500K\n<1M\n<5M\n>5M\n0\n5\n10\n15\n20\n25\n% of all Locations\nFigure 3: Distribution of cities included in GEOTEMP\naccording to their number of inhabitants. For each\nbin, we show the percentage of locations in our dataset\nthat belong to this bin.\nby applying every task template of Table 1 to each\nl1 × l2 location combinations. To avoid confusion\nwith city names that exist in multiple countries (e.g.\nLondon in the US vs. London in the UK), we in-\nclude the country information alongside the city\nname in the prompt. For each input prompt, we\nselect the time and date at random within the year\n2023, i.e. a recent year, to avoid outdated refer-\nences and automatically calculate the target time\nand date which serves as the ground truth label for\nour evaluation algorithm. This results in a final set\nof 332,928 test prompts.\n3.2\nDataset Analysis\nGEOTEMP covers a diverse set of locations and\ntime zones across all continents, as shown in Fig-\nure 2, including Antarctica and several islands.\nGEOTEMP also represents smaller and therefore\noften less well-known cities, such as “Atikokan” in\nCanada. The distribution of the number of inhabi-\ntants per city is shown in Figure 3. More than 6%\nof the locations in our dataset have ≤500 inhabi-\ntants, and 50% of the cities have ≤500k inhabitants.\nFor a detailed statistical analysis of the location in-\nformation in GEOTEMP, see Appendix A.\n4\nOverall Experimental Setup\n4.1\nModels and Inference\nWe test eight openly accessible chat-optimized\nLLMs spanning three model families and differ-\nent model sizes on GEOTEMP. All models have\nshown competitive performance on the LMSyS\nLeaderboard.5 Specifically, we evaluate Llama2-\nChat (Touvron et al., 2023) in the model sizes 7B,\n13B and 70B, Llama3-Instruct (AI@Meta, 2024)\nin both available model sizes (8B and 70B) and\nQwen2-Instruct (Yang et al., 2024) in the model\nsizes 1.5B, 7B and 72B. We run all models on 1-4\nNvidia A6000 GPUs using the simplegen python\nlibrary (Attanasio, 2023). In all experiments, we\nuse a maximum length of 256 and a temperature of\n0 to make model responses deterministic.\nDuring inference, we run each prompt of\nGEOTEMP using three instruction templates to ana-\nlyze their effect on model performance. The first in-\nstruction type (neutral) is shown in Table 1 and pro-\nvides no additional information on how the model\nshould answer the question. This leaves the model\nthe ability to choose its own explanation method-\nology. The second type appends the suffix “Think\nstep by step.”, asking the model to apply chain-\nof-thought (CoT) reasoning. Lastly, the third type\nappends the suffix “Keep your answer short and\njust answer with the correct time and date”, which\nencourages concise responses (short).\n4.2\nEvaluation Protocol: Regex\nWe use a custom matching algorithm based on\nregex patterns to extract the time and date from\nthe model responses. For example, from a response\nlike “In 5 hours it is 02:17 AM”, we extract “02:17\nAM” and compare it to the gold standard answer.\nWe chose to parse the model’s response rather than\nenforce a strict output format. This allows us to\nkeep prompts more natural and ensures that we\ndo not penalize correct answers that only slightly\ndeviate from the expected structure.\nWe develop and test the regex evaluator in two\nsteps. First, we ask two independent annotators\nto evaluate a sample of 3,600 model responses\nfor their correctness (true / false) compared to the\ngold answers. Second, we split this data 50:50\ninto a development set, for constructing and opti-\nmizing regex patterns and a test set for evaluation.\nWe achieve an almost perfect Cohen’s κ annotator\n5https://huggingface.co/spaces/lmsys/\nchatbot-arena-leaderboard\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\n0\n20\n40\n60\n80\n100\nVerification\nTimeTime\nTimePlace\nTimeTimePlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nFigure 4: Model accuracy on GEOTEMP. We show the\npercent of correct model responses (obtained via major-\nity vote across different instruction types) for different\nmodels for our four geotemporal tasks (VERIFICATION,\nTIMETIME, TIMEPLACE, TIMETIMEPLACE).\nagreement on the labeling task according to the\nscale of Landis and Koch (1977), with agreements\nin the range of 90.8-99.2% across models, ensuring\nthe quality of the obtained labels. Our regex evalu-\nator achieves an accuracy of at least 98 % for each\nmodel on the test set portion of the annotated sub-\nset. These scores confirm that we can use our regex\nevaluator for our experiments without introducing\nsubstantial noise into the evaluation results. Note\nalso that the regex, with near-perfect accuracy, is\nvastly more efficient than training a response clas-\nsifier or using LLM-as-a-judge. For further details\non the validation process, see Appendix B.\n5\nHow Well Do LLMs Reason About\nTime, Place, and their Combination?\nFor a reliable performance estimate on our dataset,\nwe show aggregated results across all three instruc-\ntion types: We use the majority vote per input in-\nstance, i.e., the answer obtained for at least two\ncorresponding instructions. This procedure thus\nalso reflects possible improvements through chain-\nof-thought prompting on more complex tasks. We\npresent these combined results in Figure 4 and\nshow detailed results in Appendix C.\n5.1\nOverall Results\nPerformance varies drastically across models and\ntasks. Generally, while the VERIFICATION and\nTIMETIME tasks are solvable for most models,\nthey struggle when asked to incorporate location-\nspecific knowledge. For instance, Llama3-70B\nyields the best results with 56.1% of correctly an-\nswered prompts for the TIMEPLACE category and\n33.4% correct answers for the TIMETIMEPLACE\ncategory. Interestingly, even though one would\nexpect a monotonous performance decrease with\nhigher task complexity, as for Llama2-13B and the\nsmaller Qwen2 models, all other models seem to\nstruggle with the VERIFICATION task while per-\nforming much better on the TIMETIME task. We\nhypothesize this may be linked to ongoing training\non mathematical problems, as LLMs have generally\nbeen shown to struggle with such tasks (Dziri et al.,\n2024). Very simple or even rhetorical questions,\nsuch as our VERIFICATION question, are probably\nless frequently included in the training data as they\ndo not contain a common task to be solved. An\nanalysis of several model responses shows that the\nmodels often attempt to read into the question a\ntask that is not actually posed, such as providing\nfurther current times in other time zones.\n5.2\nModel Scaling\nWhile we see consistently poor performance for all\nmodels on the two tasks that require geographical\nknowledge (TIMEPLACE and TIMETIMEPLACE),\nwe also observe consistent scaling effects. For\nLlama2, this effect is more apparent for the two\nother and less complex tasks, while for Llama3 and\nQwen2, a performance increase can be observed\nfor all four tasks as the model size increases. In the\n70B version, Llama3 thus achieves almost 100% ac-\ncuracy for the VERIFICATION and TIMETIME task\nand a performance increase of 29.3% for TIME-\nPLACE and 23.0% on TIMETIMEPLACE compared\nto Llama3-8B. For Qwen2, however, an increase in\nmodel size results in only marginal improvements,\nwith final performances of 18.0% and 9.4% on the\ncomplex tasks, respectively. For Llama2, the gains\nare even less apparent. This raises doubts as to\nwhether the models will understand the underly-\ning mechanisms for solving these tasks simply by\nupscaling.\n5.3\nInstruction Types\nPreviously, we analyzed aggregated results across\nthe three instruction types (neutral, chain-of-\nthought, short), but examining them individually\nalso reveals interesting patterns. Forcing concise\nanswers (short) leads to decreased performance\non complex tasks across all models, while improv-\ning results on simpler tasks, except for Qwen2. In\ncontrast, chain-of-thought instructions result in sig-\nnificantly worse performance on simpler tasks for\nLlama2 and slightly worse for Llama3 compared to\nneutral, particularly for Llama2-70B in the VERI-\nFICATION task. Qualitative analysis of the model’s\nanswers suggests that the model is trying to solve\na more difficult task than requested and ultimately\ngets stuck in its own explanations. These results\nare related to the work of Sprague et al. (2024),\nwho show that chain-of-thought prompting primar-\nily benefits math-related tasks. This highlights the\nneed for a more comprehensive analysis of the ef-\nfect of different instruction types on questions of\nvarying difficulty, which we leave for future work.\nWe provide detailed results in the Appendix C.\n5.4\nRobustness\nSince the exact prompt formulation can have a\nstrong impact on performance (Sclar et al., 2024),\nwe additionally perform a robustness analysis. For\neach instruction type, we randomly sample 1,000\ninstances and generate results for two additional\nprompts with slight variations in wording. To en-\nable comparison with state-of-the-art closed mod-\nels, we also conduct the same experiment using\ngpt4o-mini. In Figure 5a, we show the mean\nand standard deviation across all models for the in-\nstruction type neutral, while Figure 5b presents de-\ntailed results for all instruction types obtained with\nLlama3-70B. Results for the remaining models are\nprovided in Appendix C. While we observe signifi-\ncant performance fluctuations for some models and\ntasks, importantly, the overall trends between the\nmodels, their sizes, and instruction types are sta-\nble. Encouragingly, the error for the TIMEPLACE\nand TIMETIMEPLACE tasks, which we mainly an-\nalyze, is very low, highlighting the robustness of\nour findings.\n6\nWhat Factors Influence Model\nPerformance?\n6.1\nCountry Biases\nFollowing Moayeri et al. (2024), we investigate\nperformance differences based on location, com-\nparing Western vs. Non-Western countries, varying\nincome levels, and population densities. For this,\nwe focus on the tasks requiring location-specific\nknowledge (TIMEPLACE and TIMETIMEPLACE),\naggregating results by start and target country. Fig-\nure 6 depicts the response accuracy aggregated by\nthe target country of Llama3-70B. We provide re-\nsults for the aggregation by start country in Ap-\npendix C.2, which show no significant differences.\nLlama3-70B performs best on questions that in-\nclude African countries. Similarly, the model per-\nforms well for cities in South America and around\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\nmini\n0\n20\n40\n60\n80\n100\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nGPT4o\n(a) Robustness results for the neutral instruction type.\nCoT\nneutral\nshort\n0\n20\n40\n60\n80\n100\nVerification\nTimeTime\nTimePlace\nTimeTimePlace\nCorrect Responses in %\n(b) Llama3-70B results across instruction types.\nFigure 5: Robustness analysis. We show the mean and\nstandard deviation of model answers across three differ-\nent prompt variations. In (a), the results for the neutral\ninstruction type across all models. In (b) we show the\nresults obtained by Llama3-70B for each instruction\ntype (neutral, chain-of-thought, short).\nRussia.\nFor cities in North America, Oceania,\nAntarctica, and Greenland, on the other hand, we\nsee significantly worse results. This is contrary to\nour hypothesis that models develop a performance\nbias towards Western countries. Further aggrega-\ntions at the continental level, population size, and\nincome level did not reveal any clear patterns in\nthis direction either.\n6.2\nLocation Name Perplexity\nSince we could not identify a clear location bias in\nthe models, we explored other factors that might\ninfluence their performance.\nDetailed setup\nWe hypothesize that the familiar-\nity of the models with certain locations leads to\nthem performing better in a task. Since we cannot\naccess the models’ training data, we make use of\nthe models’ perplexity as a proxy to assess their\nfamiliarity with specific locations. To this end, we\nuse a simple and static sentence template: “I live\nin {city}, {country}”, replace the placeholders with\nthe corresponding city and country information\nfor each location l from GEOTEMP and compute\nthe perplexity for each model. To better interpret\nthe perplexity levels, we categorize the resulting\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nFigure 6: Model accuracy aggregated by target coun-\ntry for the tasks TIMEPLACE and TIMETIMEPLACE.\nWe neither observe biases towards Western nor towards\nhigher-income or population-dense countries.\nperplexity scores into four bins. Specifically, for\neach model, we determine the perplexity distribu-\ntion over all locations in our dataset and classify\nlocations with a perplexity score within the 25%\nquantile of this distribution as “very low” perplex-\nity, those up to the 50% quantile as “low”, up to the\n75% quantile as “high” and the remaining values as\n“very high”. We then associate these with the cor-\nresponding start and target locations in our dataset\nand compute the average model performance in\npercent of correct answers for each combination of\nperplexity scores of the two locations in question.\nNote that, again, we are limiting this analysis to the\nTIMEPLACE and TIMETIMEPLACE tasks, where\nlocation information is relevant.\nResults\nWe focus on the result of Llama3-70B,\nshown in Figure 7, because of its strong perfor-\nmance across tasks. However, we find that these\nfindings also hold for most other models which we\nshow in the Appendix C.3. For Llama3 we observe\na gradual decrease in accuracy from low to very\nhigh perplexity locations, with a surprisingly high\nperformance drop between the combination of low\nx low (53.9) and very high x very high (29.9%) of\n22.5%. This trend is also visible for Qwen2-72B\nwith a performance difference of 15.5% between\nthe combinations very low x very low and very\nhigh x very high. Our findings thus suggest that\nmodel performance is biased in favor of locations\nthat likely appear more frequently in model training\ndata, rather than being biased per se in the direction\nof Western countries, as one might have expected.\n6.3\nError Analysis\nTo get more precise insights into why models\nfail to combine temporal and geographical knowl-\nedge, we perform a manual error analysis for the\nbest-performing model, Llama3-70B. We randomly\n52.3\n53.3\n48.2\n35.9\n52.2\n53.9\n50.4\n36.1\n47\n48.3\n43\n31.6\n36.1\n37\n34.5\n29.9\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\nFigure 7: Effect of location perplexities. We show the\nperformance of Llama3-70B on the TIMEPLACE and\nTIMETIMEPLACE task aggregated by the perplexity of\nthe start location and target location.\n0\n10\n20\n30\n40\n50\nUTC not known\nMixed up DST and UTC\nUTC Difference wrong\nTime Difference wrong\nAM/PM incorrect\nProportion of annotated responses in (%)\nFigure 8: Results of our error analysis. We show the\nproportion of model errors (in %) per error category.\nsample 200 of the model’s incorrect responses on\nthe TIMETIMEPLACE task. One author then an-\nnotated this sample, assigning errors to one of five\nerror categories (Figure 8). We find that 25.3%\nof errors are attributable to the model’s failure to\nappropriately handle the conversion between DST\nand UTC for the current time. 22.3% of errors re-\nsult from the fact that, despite correct UTC knowl-\nedge for both locations, the time difference was not\ncalculated correctly. However, 48.2% of the errors\nare due to the fact that the model does not use the\ncorrect UTC in its decision-making process for at\nleast one of the locations.\n6.4\nLocation-Specific Knowledge\nWe seek to further investigate why models per-\nform so poorly on tasks requiring a combination of\ntemporal and geographical knowledge. From our\nTIMETIME task, it is evident that models are gener-\nally able to perform basic time calculations, hence\nwe look at the time zone knowledge of the models\nfor the locations. To do this, we prompt the models\nto provide us with the corresponding time zone for\neach location in our dataset. For an easier parsing\nof the results, we additionally force the model to\nrespond following the scheme: “City: UTC±X”.\nThe outcomes of this evaluation, presented in Table\n2, are surprising in light of the previous results: All\nModel\nSize\nUTC Known (%)\n7B\n70.9\nLlama2\n13B\n71.3\n70B\n80.9\nLlama3\n8B\n84.1\n70B\n90.0\n1.5B\n39.3\nQwen2\n7B\n65.4\n72B\n86.3\nTable 2: Knowledge about time zones. We present\nthe proportion of locations where models assigned the\ncorrect time zone (in % of all locations in our dataset)\nwhen explicitly prompted to do so.\nmodels can predict the correct UTC timezone for at\nleast 65% of the locations, except for Qwen2-1.5B\nwith only 39.3%. For Llama3-70B, it is as much\nas 90%. Consequently, the poor results from our\nmain experiments (Figure 4) cannot be attributed\nsolely to a lack of knowledge about the cities and\ntheir geographical locations. Rather, models fail\nto make use of this knowledge when not explicitly\nasked to provide it.\n7\nCan Model Performance be Improved\nby Injecting Geotemporal Knowledge?\nDetailed setup\nSo far, we found that the models\nare generally able to perform temporal calculations\nand that knowledge about the individual locations\nis present, yet they fail when combining the two. In\na final experiment, we now examine whether explic-\nitly injecting geographical knowledge by providing\ntime zone information helps to activate the required\nknowledge (and thus, improve performance on the\nmost complex task TIMETIMEPLACE). We exam-\nine two different setups: In the first setup, we add\nthe respective time zone information of the city in\naddition to the input prompt (“add time zone”). In\nthe second variant, we omit the city names from\nthe prompt and replace them entirely with the time\nzone information (“replace by time zone”).\nResults\nWe present model performance with in-\njected information in comparison to prior perfor-\nmance on the TIMETIMEPLACE task in Figure 9.\nWe see that the injection of geotemporal knowl-\nedge improves performance across models. For\nLlama2, however, improvements are limited, point-\ning to a general lack of understanding of the con-\ncept of time zones. For the large versions of the\nother models, we see a significantly larger effect.\nLlama3-70B achieves a performance of 76.3% by\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\n0\n20\n40\n60\n80\n100\nnone\nAdd time zone\nReplace by time zone\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nFigure 9: Results of UTC knowledge injection on\nthe TIMETIMEPLACE task. Colors respond to different\namounts of knowledge injected.\nadding the time zone information, and Qwen2-72B\nof 53%. We also find that models do not perform\nas well when city information is replaced with time\nzone information as when time zone information is\nadded on top. This suggests that models do draw\non their geographical knowledge to solve this task.\n8\nDiscussion\nCurrent language models struggle to perform\ngeotemporal reasoning. Our dataset and analysis al-\nlowed us to identify reasons for this. First, we find\nthat the only model with fewer than 7 billion param-\neters in our test (Qwen2-1.5B) is largely ineffective\nfor geotemporal reasoning as required by the tasks\nin our dataset. In contrast, we show that bigger\nmodels can indeed perform basic temporal calcula-\ntions, indicating a solid understanding of temporal\nconcepts like the 24-hour format and AM/PM nota-\ntion. Especially, the example of Llama3-70B, with\nalmost 100% accuracy on this task (TEMPTEMP),\nshows that targeted training (e.g., high-quality data\nand specific training for STEM tasks) can achieve\na significant performance improvement. Second,\nmost models – except for Qwen2-1.5B – correctly\ndetermine time zones for at least 65% of the loca-\ntions when explicitly asked to do so, demonstrating\ngeneral geographic competencies. Third, despite\nthis, their performance on tasks combining tempo-\nral and geographical knowledge is poor. Our quali-\ntative analysis reveals that when models have to per-\nform complex tasks that require them to access and\ncombine different types of knowledge simultane-\nously, they are no longer able to retrieve time zone\ninformation that they knew in isolation and instead\nstart hallucinating. Our knowledge injection tests\nsupport this finding, as reducing task complexity by\nlimiting the amount of information to be retrieved\nat once significantly improves model performance.\nThis analysis points to a broader issue: models\nmay often possess the necessary knowledge but\nfail to retrieve and combine it effectively for\ncomplex tasks (and steering techniques like chain-\nof-thought may only partially help). Looking into\nthe future, we also believe that simply increasing\nthe model size will not solve the problem. Instead,\nimprovements towards more systematic and step-\nwise knowledge retrieval or the use of tools may be\nnecessary to prevent hallucinations and sustainably\nenhance performance on complex reasoning tasks.\n9\nConclusion\nIn this article, we introduced GEOTEMP, the first\nbenchmark designed to evaluate the ability of\nLLMs to reason over both temporal and geographi-\ncal knowledge at different combinations of knowl-\nedge. GEOTEMP consists of over 320k prompts\ncovering 289 locations across 37 timezones. Using\nour dataset, we analyzed eight open chat-optimized\nLLMs across varying sizes and found that, while\nmodels perform adequately on tasks involving only\ntemporal knowledge, their performance signifi-\ncantly drops when they are required to combine\ntemporal and geographical information. Our find-\nings indicate that this limitation persists also at\nlarger model scales, suggesting that even the best\nmodels today struggle with more complex reason-\ning tasks involving the interplay of time and space.\nWe also observed that the models perform better\nfor locations where they exhibit low perplexity,\nwhich may indicate that prior exposure to certain\ngeographic locations during training helps.\nLimitations\nRegex Evaluation\nWe use a self-developed algo-\nrithm to evaluate the open-ended model responses,\nwhich inevitably causes some degree of noise. This\nwas necessary as a full human evaluation for a\ndataset of this size would not be feasible, and LLM\nas a judge would be too resource-intensive and also\nnot fully reliable. However, we are conducting\na comprehensive validation of our methodology,\nproviding very high accuracy, which leads us to\nbelieve that we can consider the noise to be low.\nWe are therefore confident that our results remain\nvalid.\nPrompt Robustness Evaluation on Selected Sub-\nset\nDue to resource constraints, we conduct ro-\nbustness checks only on a subset of our dataset. It is\ntherefore possible that the true uncertainties around\nour results are larger. Third, in our experiments, we\nevaluate models for which we unfortunately do not\nhave any precise information about their pretrain-\ning data. To make a statement about the model’s\nfamiliarity with certain terms, we thus use model\nperplexity as a proxy for the frequency of the term’s\noccurrence in the training data. Yet, this metric is\nnot fully reliable and may introduce inaccuracies.\nA future evaluation of fully open models and their\ntraining data could provide additional insights.\nNo Tasks Involving Location Alone\nGEOTEMP\ndoes not cover purely location-based tasks, as such\na task would closely resemble existing work and\nmight not significantly advance the field. Further-\nmore, a task that involves predicting a location is\nless conducive to leveraging temporal information\ncompared to the task we have chosen to focus on.\nAcknowledgements\nPaul Röttger is a member of the Data and Market-\ning Insights research unit of the Bocconi Institute\nfor Data Science and Analysis, and is supported\nby a MUR FARE 2020 initiative under grant agree-\nment Prot.\nR20YSMBZ8S (INDOMITA). The\nwork of Carolin Holtermann and Anne Lauscher is\nfunded by the Excellence Strategy of the German\nFederal Government and the Federal States.\nReferences\nAI@Meta. 2024. Llama 3 model card.\nGiuseppe Attanasio. 2023. Simple Generation. https:\n//github.com/MilaNLProc/simple-generation.\nBhuwan Dhingra, Jeremy R. Cole, Julian Martin\nEisenschlos, Daniel Gillick, Jacob Eisenstein, and\nWilliam W. Cohen. 2022. Time-aware language mod-\nels as temporal knowledge bases. Transactions of the\nAssociation for Computational Linguistics, 10:257–\n273.\nNouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine\nLi, Liwei Jiang, Bill Yuchen Lin, Peter West, Chan-\ndra Bhagavatula, Ronan Le Bras, Jena D. Hwang,\nSoumya Sanyal, Sean Welleck, Xiang Ren, Allyson\nEttinger, Zaid Harchaoui, and Yejin Choi. 2024.\nFaith and fate: limits of transformers on composi-\ntionality. In Proceedings of the 37th International\nConference on Neural Information Processing Sys-\ntems, NIPS ’23, Red Hook, NY, USA. Curran Asso-\nciates Inc.\nTyna Eloundou, Sam Manning, Pamela Mishkin, and\nDaniel Rock. 2023. Gpts are gpts: An early look at\nthe labor market impact potential of large language\nmodels. Preprint, arXiv:2303.10130.\nBahare Fatemi, Mehran Kazemi, Anton Tsitsulin,\nKarishma Malkan, Jinyeong Yim, John Palowitch,\nSungyong Seo, Jonathan Halcrow, and Bryan Perozzi.\n2024. Test of time: A benchmark for evaluating llms\non temporal reasoning. Preprint, arXiv:2406.09170.\nNathan Godey, Éric de la Clergerie, and Benoît Sagot.\n2024. On the scaling laws of geographical represen-\ntation in language models. In Proceedings of the\n2024 Joint International Conference on Computa-\ntional Linguistics, Language Resources and Evalu-\nation (LREC-COLING 2024), pages 12416–12422,\nTorino, Italia. ELRA and ICCL.\nWes Gurnee and Max Tegmark. 2024.\nLanguage\nmodels represent space and time.\nPreprint,\narXiv:2310.02207.\nF. Gregory Hayden. 1987. Evolution of time constructs\nand their impact on socioeconomic planning. Journal\nof Economic Issues, 21(3):1281–1312.\nJungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi,\nRonan Le Bras, Akari Asai, Xinyan Velocity Yu,\nDragomir Radev, Noah A. Smith, Yejin Choi, and\nKentaro Inui. 2024. Realtime qa: what’s the answer\nright now? In Proceedings of the 37th International\nConference on Neural Information Processing Sys-\ntems, NIPS ’23, Red Hook, NY, USA. Curran Asso-\nciates Inc.\nJ. Richard Landis and Gary G. Koch. 1977. The mea-\nsurement of observer agreement for categorical data.\nBiometrics, 33(1):159–174.\nRuotong Liao, Max Erler, Huiyu Wang, Guangyao Zhai,\nGengyuan Zhang, Yunpu Ma, and Volker Tresp. 2024.\nVideoinsta: Zero-shot long video understanding via\ninformative spatial-temporal reasoning with llms.\nBastien Liétard, Mostafa Abdou, and Anders Søgaard.\n2021. Do language models know the way to Rome?\nIn Proceedings of the Fourth BlackboxNLP Workshop\non Analyzing and Interpreting Neural Networks for\nNLP, pages 510–517, Punta Cana, Dominican Repub-\nlic. Association for Computational Linguistics.\nAdam Liska, Tomas Kocisky, Elena Gribovskaya, Tay-\nfun Terzi, Eren Sezener, Devang Agrawal, Cyprien\nDe Masson D’Autume, Tim Scholtes, Manzil Zaheer,\nSusannah Young, Ellen Gilsenan-Mcmahon, Sophia\nAustin, Phil Blunsom, and Angeliki Lazaridou. 2022.\nStreamingQA: A benchmark for adaptation to new\nknowledge over time in question answering models.\nIn Proceedings of the 39th International Conference\non Machine Learning, volume 162 of Proceedings\nof Machine Learning Research, pages 13604–13622.\nPMLR.\nRohin Manvi, Samar Khanna, Marshall Burke, David\nLobell, and Stefano Ermon. 2024a.\nLarge lan-\nguage models are geographically biased. Preprint,\narXiv:2402.02680.\nRohin Manvi, Samar Khanna, Gengchen Mai, Marshall\nBurke, David Lobell, and Stefano Ermon. 2024b.\nGeollm: Extracting geospatial knowledge from large\nlanguage models. Preprint, arXiv:2310.06213.\nMazda Moayeri, Elham Tabassi, and Soheil Feizi. 2024.\nWorldbench: Quantifying geographic disparities in\nllm factual recall. In Proceedings of the 2024 ACM\nConference on Fairness, Accountability, and Trans-\nparency, FAccT ’24, page 1211–1228, New York,\nNY, USA. Association for Computing Machinery.\nKai Nylund, Suchin Gururangan, and Noah Smith. 2024.\nTime is encoded in the weights of finetuned language\nmodels. In Proceedings of the 62nd Annual Meeting\nof the Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 2571–2587, Bangkok,\nThailand. Association for Computational Linguistics.\nJames Pustejovsky, Patrick Hanks, Roser Saurí, An-\ndrew See, Rob Gaizauskas, Andrea Setzer, Dragomir\nRadev, Beth Sundheim, David Day, Lisa Ferro, and\nMarcia Lazo. 2003. The timebank corpus. Proceed-\nings of Corpus Linguistics.\nMelanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane\nSuhr. 2024. Quantifying language models’ sensitiv-\nity to spurious features in prompt design or: How i\nlearned to start worrying about prompt formatting.\nIn The Twelfth International Conference on Learning\nRepresentations.\nZayne Sprague, Fangcong Yin, Juan Diego Rodriguez,\nDongwei Jiang, Manya Wadhwa, Prasann Singhal,\nXinyu Zhao, Xi Ye, Kyle Mahowald, and Greg\nDurrett. 2024.\nTo cot or not to cot?\nchain-of-\nthought helps mainly on math and symbolic reason-\ning. Preprint, arXiv:2409.12183.\nQingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023.\nTowards benchmarking and improving the temporal\nreasoning capability of large language models. In\nProceedings of the 61st Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 14820–14835, Toronto, Canada.\nAssociation for Computational Linguistics.\nQingyu Tan, Hwee Tou Ng, and Lidong Bing. 2024.\nTowards robust temporal reasoning of large language\nmodels via a multi-hop QA dataset and pseudo-\ninstruction tuning. In Findings of the Association for\nComputational Linguistics ACL 2024, pages 6272–\n6286, Bangkok, Thailand and virtual meeting. Asso-\nciation for Computational Linguistics.\nShivin Thukral, Kunal Kukreja, and Christian Kavouras.\n2021. Probing language models for understanding of\ntemporal expressions. In Proceedings of the Fourth\nBlackboxNLP Workshop on Analyzing and Interpret-\ning Neural Networks for NLP, pages 396–406, Punta\nCana, Dominican Republic. Association for Compu-\ntational Linguistics.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models. Preprint, arXiv:2307.09288.\nSiddharth Vashishtha, Adam Poliak, Yash Kumar Lal,\nBenjamin Van Durme, and Aaron Steven White. 2020.\nTemporal reasoning in natural language inference.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2020, pages 4070–4078, Online.\nAssociation for Computational Linguistics.\nYuqing Wang and Yun Zhao. 2024. TRAM: Bench-\nmarking temporal reasoning for large language mod-\nels. In Findings of the Association for Computational\nLinguistics ACL 2024, pages 6389–6415, Bangkok,\nThailand and virtual meeting. Association for Com-\nputational Linguistics.\nYifan Wei, Yisong Su, Huanhuan Ma, Xiaoyan Yu,\nFangyu Lei, Yuanzhe Zhang, Jun Zhao, and Kang\nLiu. 2023. MenatQA: A new dataset for testing the\ntemporal comprehension and reasoning abilities of\nlarge language models. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2023,\npages 1434–1447, Singapore. Association for Com-\nputational Linguistics.\nSiheng Xiong, Ali Payani, Ramana Kompella, and Fara-\nmarz Fekri. 2024. Large language models can learn\ntemporal reasoning. In Proceedings of the 62nd An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 10452–\n10470, Bangkok, Thailand. Association for Compu-\ntational Linguistics.\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng,\nBowen Yu, Chang Zhou, Chengpeng Li, Chengyuan\nLi, Dayiheng Liu, Fei Huang, Guanting Dong, Hao-\nran Wei, Huan Lin, Jialong Tang, Jialin Wang,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin\nMa, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai,\nJinzheng He, Junyang Lin, Kai Dang, Keming Lu, Ke-\nqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni,\nPei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize\nGao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan,\nTianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge,\nXiaodong Deng, Xiaohuan Zhou, Xingzhang Ren,\nXinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing\nLiu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan,\nYunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang,\nZhifang Guo, and Zhihao Fan. 2024. Qwen2 techni-\ncal report. Preprint, arXiv:2407.10671.\nMichael Zhang and Eunsol Choi. 2021. SituatedQA: In-\ncorporating extra-linguistic contexts into QA. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing, pages 7371–\n7387, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nBowen Zhao, Zander Brumbaugh, Yizhong Wang, Han-\nnaneh Hajishirzi, and Noah A. Smith. 2024. Set the\nclock: Temporal alignment of pretrained language\nmodels. Preprint, arXiv:2402.16797.\nBen Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth.\n2019. “going on a vacation” takes longer than “go-\ning for a walk”: A study of temporal commonsense\nunderstanding. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 3363–3369, Hong Kong, China. Association\nfor Computational Linguistics.\nAppendix\nTable of Contents\nA Dataset\n13\nA.1\nSources\n. . . . . . . . . . . .\n13\nA.2\nQuantitative Analysis . . . . .\n14\nB\nEvaluation Setup\n15\nC Experimental Results\n16\nC.1\nRobustness Analysis . . . . . .\n16\nC.2\nCountry Bias Analysis . . . . .\n17\nC.3\nPerplexity Analysis\n. . . . . .\n18\nD Qualitative Model Responses\n19\nA\nDataset\nA.1\nSources\nWe present a list of datasets and frameworks, we use for creating GeoTemp. The timezone information is\nobtained from the OTZD which we access using the Python libraries pytz and datetime.\nPurpose\nName\nSource\nLicense\nCountry population,\nWorldbank https://data.worldbank.org/\nCC BY 4.0\nDatasets\nCountry names,\nIncome Level, Regions\nCity population\nGeonames/Opendatasoft\nhttps://public.\nopendatasoft.com/explore/dataset/\ngeonames-all-cities-with-a-population-500/\napi/?disjunctive.country\nCC BY 4.0\nFrameworks\npytz==2024.1\nhttps://pypi.org/project/pytz/\npython-dateutil==2.8.2\nhttps://docs.python.org/3/library/\ndatetime.html\nTable 3: Overview of datasets and frameworks used in our work.\nA.2\nQuantitative Analysis\n<1M\n<5M\n<10M\n<20M\n<50M\n>50M\n0\n5\n10\n15\n20\n25\nDistribution of Country Population\n% of all Locations\nFigure 10: Histogram Country Population\nLow income\nLower middle income\nUpper middle income\nHigh income\nNot classified\n0\n10\n20\n30\n40\nDistribution of City Income Level\n% of all Locations\nFigure 11: Histogram Country Income Level\nAfrica\nAsia\nOceania\nSouth America\nNorth America\nEurope\nAntarctica\n0\n5\n10\n15\n20\nDistribution of Continents\n% of all Locations\nFigure 12: Histogram Continents of Locations\n−11\n−10\n−9\n−8\n−7\n−6\n−5\n−4\n−3\n−2\n−1\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n0\n2\n4\n6\n8\n10\n12\n14\nUTC Distribution of Cities\n% of all Locations\nFigure 13: Histogram UTC of Locations\nB\nEvaluation Setup\nAnnotation\nWe have two independent human an-\nnotators label this set of answers for their correct-\nness with regard to the target answer given by the\npytz package. Both annotators are fluent in English\nand are familiar with the task at hand. Since the\nannotators both worked in the authors’ research\nenvironment, they did not receive any compensa-\ntion. They were also informed about how their\nannotations would be used.\nExpectedly, we achieve an overall agreement of\n96.4% of Cohen’s κ on the annotation set, con-\nstituting a very high agreement between the an-\nnotators and thus very reliable labels. In a quali-\ntative analysis, it can be seen that most disagree-\nment was caused by either random errors or on\nthe Verification task. This is because models\nare often confused by this rather rhetorical type of\nquestion, and instead of returning the answer, they\nconvert the time at a location into the corresponding\ntime in UTC. This is generally not a wrong answer,\nbut we specify for the annotation guidelines that\nthe model must also respond with the correct time\nat the respective location. To obtain the final la-\nbel, disagreements between the annotators were\noverruled by an expert decision judgment.\nModel\nSize\nCohen’s κ\n7B\n90.8\nLlama2\n13B\n94.3\n70B\n97.5\nLlama3\n8B\n97.5\n70B\n99.2\n1.5B\n96.9\nQwen2\n7B\n97.4\n72B\n97.4\nTable 4: Inter-annotator agreement on a sample of\n3,600 model answers from GeoTemp. We present the\nCohen’s κ between the two annotators in percent.\nValidation\nNext, we split the annotated subset\nusing a 50:50 split into a calibration and a test por-\ntion. Note that, since we are not actually training\na new model but rather using the set to calibrate\nour own matching algorithm, a larger test portion\nto validate the generalization of our approach on\nunseen data is more important than the calibration\nportion. The evaluation results for our matching\nalgorithm compared to the human annotations are\nshown in Table 5.\nThe results show, that we can achieve an accu-\nModel\nSize\nAcc\nP\nR\n7B\n99.5\n98.4\n100.0\nLlama2\n13B\n98.0\n95.9\n98.6\n70B\n98.0\n98.9\n96.7\nLlama3\n8B\n98.5\n97.8\n98.9\n70B\n98.5\n100.0\n98.2\n1.5B\n99.5\n94.7\n100.0\nQwen2\n7B\n98.0\n97.5\n97.5\n72B\n99.0\n100.0\n98.3\nTable 5: Performance of our regex evaluator. Eval-\nuation results on the sample test set of our dataset.\nWe present the accuracy, precision, and recall for each\nmodel in percent on an annotated subset of 100 prompts\neach.\nracy of at least 98% on the test set portions for each\nmodel using our algorithm. The lowest precision\nscore of 94.7% was achieved for the 1.5B version\nof Qwen2. This is due to the fact that the model\nprovides very few correct answers, and thus the\ntrue positive rate is very low, causing the precision\nscore to decrease rapidly even though there is only\none misclassified instance. Our validation results\ntherefore suggest that our evaluation method deliv-\ners reliable results for the succeeding analysis.\nC\nExperimental Results\nC.1\nRobustness Analysis\nWe present the accuracy results on the whole dataset and the robustness results on a subset of 1000\nprompts with three different prompt variations across the three different instruction types: (1) neutral, (2)\nshort, and (3) CoT. We prompt GPT-4O-MINI-2024-07-18 in the same way as the other models, which\nwe detailed in Section 4.1 via the OpenAI API6.\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\n(a) Overall Results\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\nmini\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nGPT4o\n(b) Robustnesschecks\nFigure 14: Model Accuracy neutral prompt\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\n(a) Overall Results\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\nmini\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nGPT4o\n(b) Robustnesschecks\nFigure 15: Model Accuracy short prompt\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\n(a) Overall Results\n7b\n13b\n70b\n8B\n70B\n1.5B\n7B\n72B\nmini\n0\n20\n40\n60\n80\n100\nVerification\nTimexTime\nTimexPlace\nTimexTimexPlace\nCorrect Responses in %\nLlama 2\nLlama 3\nQwen 2\nGPT4o\n(b) Robustnesschecks\nFigure 16: Model Accuracy CoT prompt\n6https://platform.openai.com/docs/overview\nC.2\nCountry Bias Analysis\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nFigure 17: Model accuracy aggregated by start country for the tasks TIMEPLACE and TIMETIMEPLACE. We\nneither observe biases towards Western nor towards higher-income or population-dense countries.\nC.3\nPerplexity Analysis\n5.1\n3.8\n3.6\n2.3\n4.2\n3.5\n3.4\n2.3\n4.2\n3.6\n2.8\n2.5\n2.6\n2.3\n2.4\n2.2\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(a) Llama2 7B\n5.6\n5.1\n4.4\n3\n5.5\n5\n4.2\n3.3\n4.4\n4.1\n3.8\n3\n2.8\n2.8\n2.5\n2.8\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(b) Llama2 13B\n8\n7.3\n6.6\n3.8\n8.1\n7\n6.8\n3.6\n7.4\n7.5\n7.3\n4.6\n4.3\n3.8\n4.7\n3.4\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(c) Llama2 70B\nFigure 18: Llama2 accuracy distribution for different City Perplexities\n27.5\n25.8\n20.3\n13.3\n25.7\n23.5\n17.9\n13.2\n21.2\n20.1\n16.1\n10.6\n12.4\n12.3\n10.3\n7.9\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(a) Llama3 8B\n52.3\n53.3\n48.2\n35.9\n52.2\n53.9\n50.4\n36.1\n47\n48.3\n43\n31.6\n36.1\n37\n34.5\n29.9\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(b) Llama3 70B\nFigure 19: Llama3 accuracy distribution for different City Perplexities\n0.5\n0.6\n0.5\n0.6\n0.5\n0.6\n0.6\n0.8\n0.5\n0.7\n0.4\n0.6\n0.4\n0.6\n0.8\n0.7\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(a) Qwen2 1.5B\n4.6\n4.3\n3.6\n3.1\n3.8\n4.6\n3.9\n3.4\n3.3\n3.9\n3.1\n2.6\n2.8\n3.2\n3.1\n2.7\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(b) Qwen2 7B\n22.3\n21.8\n16.9\n9.9\n19.3\n21.5\n12.7\n7.9\n16.3\n17.5\n14.9\n8.5\n11.5\n11.2\n9\n6.8\nvery low\nlow\nhigh\nvery high\nvery low\nlow\nhigh\nvery high\n0\n20\n40\n60\n80\n100\nAccuracy (%)\nPerplexity Targetcity\nPerplexity Startcity\n(c) Qwen2 72B\nFigure 20: Qwen2 accuracy distribution for different City Perplexities\nD\nQualitative Model Responses\nQualitative Examples of Model Responses\nWe present examples of model responses obtained for the\nthree different instruction types: (1) short, (2) neutral, and (3) CoT, respectively.\nModel\nTask\nInput Prompt\nAnswer\nModel Response\nLabel\nQwen2-\n1.5B\nVERIFICATION\nToday is Friday, January 6th at\n09:28 AM in 2023 in Valletta,\nMalta. What time is it now in\nValletta, Malta? [...]\n2023-01-06\n09:28 AM\nuser 10:47 PM\n✗\nQwen2-\n7B\nTIMETIMEPLACE Today is Sunday, June 18th at\n09:34 PM in 2023 in Mazatlan,\nMexico. What time is it in 4\nhours in Luxembourg, Luxem-\nbourg? [...]\n2023-06-19\n10:34 AM\nAssistant: Wednesday, June 22nd, 2023,\n01:34 AM in Luxembourg, Luxembourg.\n✗\nQwen2-\n7B\nTIMETIME\nToday is Monday, December 4th\nat 02:19 AM in 2023 in Nome,\nUnited States. What time is it in\n7 hours? [...]\n2023-12-04\n09:19 AM\nanswer Tuesday, December 4th at 09:19 AM\nin 2023\n✓\nLlama3-\n8B\nTIMETIMEPLACE Today is Friday, February 3rd at\n06:36 AM in 2023 in Gambier\nIslands, French Polynesia. What\ntime is it in 2 hours in Manila,\nPhilippines? [...]\n2023-02-04\n01:36 AM\nassistant February 3rd, 2023, 08:36 PM\n✗\nLlama3-\n8B\nTIMETIME\nToday is Tuesday, May 23rd at\n05:32 AM in 2023 in Dublin,\nIreland.\nWhat time is it in 2\nhours? [...]\n2023-05-23\n07:32 AM\nassistant 07:32 AM, May 23rd, 2023\n✓\nLlama3-\n70B\nTIMEPLACE\nToday is Thursday, September\n14th at 05:24 PM in 2023 in\nZagreb, Croatia. What time is\nit now in Managua, Nicaragua?\n[...]\n2023-09-14\n09:24 AM\nassistant September 14th, 2023, 11:24 AM\n✗\nLlama3-\n70B\nTIMETIME\nToday is Sunday, June 4th at\n03:27 AM in 2023 in Aden,\nYemen.\nWhat time is it in 4\nhours? [...]\n2023-06-04\n07:27 AM\nassistant Sunday, June 4th, 07:27 AM\n✓\nLlama2-\n7B\nTIMETIMEPLACE Today is Saturday, October 21st\nat 07:47 PM in 2023 in Rothera\nPoint, Adelaide Island. What\ntime is it in 4 hours in Tbilisi,\nGeorgia? [...]\n2023-10-22\n06:47 AM\nIn 4 hours from 07:47 PM in Rothera Point,\nAdelaide Island on October 21st, 2023, it\nwill be 11:47 PM in Tbilisi, Georgia on Oc-\ntober 21st, 2023.\n✗\nLlama2-\n13B\nVERIFICATION\nToday is Saturday, December\n2nd at 01:06 AM in 2023 in As-\ntrakhan, Russia. What time is it\nnow in Astrakhan, Russia? [...]\n2023-12-02\n01:06 AM\nSure! It is currently Saturday, December 2nd\nat 01:06 AM in Astrakhan, Russia.\n✓\nLlama2-\n70B\nTIMETIME\nToday is Tuesday, July 18th at\n02:09 AM in 2023 in Cocos,\nAustralia. What time is it in 2\nhours? [...]\n2023-07-18\n04:09 AM\nSure! In 2 hours, it will be: 04:09 AM on\nTuesday, July 18th, 2023.\n✓\nLlama2-\n70B\nTIMETIMEPLACE Today is Sunday, February 5th\nat 12:56 AM in 2023 in Alofi,\nNiue. What time is it in 7 hours\nin Brisbane, Australia? [...]\n2023-02-06\n04:56 AM\nSure! In 7 hours, it will be 7:56 AM on Sun-\nday, February 5th, 2023 in Brisbane, Aus-\ntralia.\n✗\nTable 6: Examples of the model responses on the short instruction template.\nModel\nTask\nInput Prompt\nAnswer\nModel Response\nLabel\nQwen2-\n1.5B\nTIMEPLACE\nToday is Saturday, October\n28th at 11:50 PM in 2023\nin Vilnius, Lithuania. What\ntime is it now in Chita, Rus-\nsia?\n2023-10-29\n05:50 AM\nassistant It is currently 9:50 AM on October 29th, 2023\nin Chita, Russia.\n✗\nQwen2-\n7B\nTIMETIME\nToday is Tuesday,\nJune\n27th at 01:36 PM in 2023\nin Grand Turk, Turks and\nCaicos Islands. What time\nis it in 8 hours?\n2023-06-27\n09:36 PM\nanswer To calculate the time 8 hours from now from\n01:36 PM on Tuesday, June 27th, 2023, in Grand Turk,\nTurks and Caicos Islands, we simply add 8 hours to this\ntime. 01:36 PM + 8 hours = 09:36 PM Therefore, 8\nhours from now, it will be 09:36 PM on the same day,\nTuesday, June 27th, 2023, in Grand Turk, Turks and\nCaicos Islands.\n✓\nQwen2-\n72B\nVERIFICATION\nToday is Thursday, August\n10th at 05:04 PM in 2023\nin Novokuznetsk, Russia.\nWhat time is it now in No-\nvokuznetsk, Russia?\n2023-08-10\n05:04 PM\n[Incomplete Generation] :04 PM on Thursday, August\n10th, 2023 in Novokuznetsk, Russia. However, if you’re\nasking for the current time and it’s after that date and\ntime, you would need to adjust for the time that has\npassed since then. Since I can’t provide real-time in-\nformation, you should check the current time using a\nreliable time source or a device that updates in real-time.\n✗\nLlama3-\n8B\nTIMETIMEPLACE Today is Friday, August\n11th at 08:52 AM in 2023 in\nLjubljana, Slovenia. What\ntime is it in 9 hours in\nPalmer Station, Anvers Is-\nland?\n2023-08-11\n12:52 PM\nassistant A nice geography and time zone question!\nLjubljana, Slovenia is in the Central European Sum-\nmer Time (CEST) zone, which is UTC+2. Palmer Sta-\ntion, Anvers Island is in the Antarctic Time (ANT) zone,\nwhich is UTC-3. To find the time in Palmer Station, we\nneed to subtract 5 hours from the current time in Ljubl-\njana. Since it’s 08:52 AM in Ljubljana, we subtract 5\nhours to get: 08:52 AM - 5 hours = 03:52 AM So, it\nwould be 03:52 AM in Palmer Station, Anvers Island.\n✗\nLlama3-\n8B\nTIMETIME\nToday is Thursday, July\n27th at 02:32 PM in 2023 in\nBrisbane, Australia. What\ntime is it in 7 hours?\n2023-07-27\n09:32 PM\nassistant Since it’s 02:32 PM in Brisbane, Australia,\nwhich is in the Australian Eastern Standard Time (AEST)\nzone, it’s already past the standard time zone’s 12:00\nPM (noon) mark. In 7 hours, it would be: 02:32 PM + 7\nhours = 09:32 PM So, in 7 hours, it would be 09:32 PM\non Thursday, July 27th, 2023, in Brisbane, Australia.\n✓\nLlama3-\n70B\nVERIFICATION\nToday is Thursday, February\n2nd at 12:36 PM in 2023 in\nJohannesburg, South Africa.\nWhat time is it now in Jo-\nhannesburg, South Africa?\n2023-02-02\n12:36 PM\nassistant That’s an easy one! According to the infor-\nmation you provided, the current time in Johannesburg,\nSouth Africa is 12:36 PM on Thursday, February 2nd,\n2023.\n✓\nLlama2-\n7B\nTIMEPLACE\nToday is Sunday, July 16th\nat 01:08 PM in 2023 in Bro-\nken Hill, Australia. What\ntime is it now in Rarotonga,\nCook Islands?\n2023-07-15\n05:38 PM\nTo find out what time it is in Rarotonga, Cook Islands,\nwe need to consider the time difference between Broken\nHill, Australia and Rarotonga. Rarotonga is located\nin the Cook Islands, which are located in the Pacific\nOcean, about 3,000 miles (4,800 km) south of Broken\nHill, Australia. Rarotonga is 18 hours ahead of Broken\nHill. So, if it is 01:08 PM (13:08) on July 16th in Broken\nHill, Australia, it would be 6:08 AM on July 16th in\nRarotonga, Cook Islands (UTC+13).\n✗\nLlama2-\n13B\nTIMEPLACE\nToday is Thursday, Septem-\nber 14th at 05:45 PM in\n2023\nin\nTunis,\nTunisia.\nWhat time is it now in Syd-\nney, Australia?\n2023-09-15\n02:45 AM\nSydney, Australia is 10 hours ahead of Tunis, Tunisia.\nSo, if it is 05:45 PM in Tunis on Thursday, September\n14th, 2023, it would be 11:45 PM in Sydney on Thursday,\nSeptember 14th, 2023.\n✗\nLlama2-\n70B\nTIMEPLACE\nToday is Wednesday, Jan-\nuary 11th at 08:58 AM in\n2023 in Qostanay, Kaza-\nkhstan. What time is it now\nin Tehran, Iran?\n2023-01-11\n06:28 AM\nTehran, Iran is in the Iran Standard Time (IRST) time\nzone, which is 3 hours and 30 minutes ahead of Qostanay,\nKazakhstan. So, if it is 08:58 AM in Qostanay, it would\nbe 12:28 PM in Tehran.\n✗\nTable 7: Examples of the model responses on the neutral instruction template.\nModel\nTask\nInput Prompt\nAnswer\nModel Response\nLabel\nQwen2-\n7B\nTIMETIME\nToday is Thursday, September\n21st at 01:07 PM in 2023 in\nCaracas, Venezuela. What time\nis it in 2 hours? Think step by\nstep.\n2023-09-21\n03:07 PM\nuser To find out what time it will be in 2 hours\nfrom now in Caracas, Venezuela, given that it’s\ncurrently Thursday, September 21st at 01:07 PM\nin 2023, follow these steps: 1. **Add the hours\nto the current time**: - Current time: 01:07 PM\n- Adding 2 hours: 01:07 PM + 2 hours = 03:07\nPM So, in 2 hours from now, it will be 03:07 PM\non Thursday, September 21st, 2023, in Caracas,\nVenezuela. 2. **Check for any time zone ad-\njustments**: - Caracas uses UTC-4 (or UTC-5\nduring Daylight Saving Time). However, since\nwe’re only adding 2 hours and not considering\nDaylight Saving Time changes, there’s no ad-\njustment needed for this calculation. Therefore,\nthe final answer is that in 2 hours from now, it\nwill be 03:07 PM on Thursday, September 21st,\n2023, in Caracas, Venezuela.\n✓\nQwen2-\n72B\nTIMETIMEPLACE Today is Sunday, January 8th\nat 03:12 PM in 2023 in Lisbon,\nPortugal. What time is it in 9\nhours in Noronha, Brazil? Think\nstep by step.\n2023-01-08\n10:12 PM\nFernando de Noronha, Brazil is 2 hours behind\nLisbon, Portugal. If it’s 03:12 PM on Sunday,\nJanuary 8th in Lisbon, then it would be 01:12\nPM on the same day in Fernando de Noronha. If\nyou add 9 hours to the current time in Fernando\nde Noronha: 01:12 PM + 9 hours = 10:12 PM\nSo, in 9 hours from now, it will be 10:12 PM on\nSunday, January 8th in Fernando de Noronha,\nBrazil.\n✓\nLlama3-\n70B\nTIMETIME\nToday is Thursday, January 26th\nat 05:10 PM in 2023 in Efate,\nVanuatu. What time is it in 6\nhours? Think step by step.\n2023-01-26\n11:10 PM\nassistant Let’s break it down step by step. Cur-\nrent time: 05:10 PM (17:10) on Thursday, Jan-\nuary 26th, 2023 in Efate, Vanuatu. To find the\ntime in 6 hours, I’ll add 6 hours to the current\ntime: 1. Current hour: 17 (05:10 PM) 2. Add 6\nhours: 17 + 6 = 23 Since 23 is greater than 24,\nI’ll subtract 24 to get the correct hour: 23 - 24\n= -1 So, the hour will be 23 - 1 = 22 (10:00 PM)\nThe minutes remain the same: 10 Therefore, in\n6 hours, the time will be 10:10 PM on Thursday,\nJanuary 26th, 2023 in Efate, Vanuatu.\n✗\nLlama2-\n7B\nTIMETIME\nToday is Saturday, February\n18th at 05:24 AM in 2023 in Port\nMoresby, Papua New Guinea.\nWhat time is it in 1 hours? Think\nstep by step.\n2023-02-18\n06:24 AM\nGreat, let’s do this!\nCurrent time in Port\nMoresby, Papua New Guinea: 05:24 AM (18th\nFebruary 2023) 1 hour from now: 06:24 AM\n(18th February 2023) So, the time in 1 hour from\nnow is 06:24 AM.\n✓\nLlama2-\n13B\nTIMETIME\nToday is Wednesday, August\n2nd at 08:35 AM in 2023 in\nManama, Bahrain. What time\nis it in 8 hours? Think step by\nstep.\n2023-08-02\n04:35 PM\nTo find the time in 8 hours, we need to add 8\nhours to the current time in Manama, Bahrain.\nCurrent time in Manama, Bahrain: 08:35 AM\nTo add 8 hours: 08:35 AM + 8 hours = 08:35\nAM + 8 x 60 = 08:35 AM + 480 = 08:35 AM +\n480 = 12:15 PM Therefore, the time in 8 hours\nfrom now in Manama, Bahrain is 12:15 PM.\n✗\nLlama2-\n70B\nVERIFICATION\nToday is Friday, August 11th at\n11:49 AM in 2023 in Macau,\nChina. What time is it now in\nMacau, China? Think step by\nstep.\n2023-08-11\n11:49 AM\nSure, I can help you with that! 1. First, let’s\ncheck the time zone of Macau, China. Macau\nis in the China Standard Time (CST) time zone,\nwhich is UTC+8. 2. Next, let’s convert the time\nyou provided, 11:49 AM, to military time. In\nmilitary time, 11:49 AM is written as 1149 hours.\n3. Now, let’s add the offset for the time zone.\nSince Macau is in the UTC+8 time zone, we\nneed to add 8 hours to the military time. So,\n1149 hours + 8 hours = 1949 hours. 4. Finally,\nwe need to convert the military time back to\ncivilian time. In civilian time, 1949 hours is\nequivalent to 7:49 PM. Therefore, the current\ntime in Macau, China is 7:49 PM on Friday,\nAugust 11th, 2023.\n✗\nTable 8: Examples of the model responses on the CoT instruction template.\nQualitative Analysis Errors Llama3-70B\nWe present examples from the human-annotated error\nanalysis of the responses from Llama3-70B for the task TIMETIMEPLACE.\nPrompt\nModel Response\nCorrect\nl1\nl1\nl2\nl2\nl1\nl1\nl2\nl2\nTimediff. UTC–Diff.\nAnswer\nUTC DST UTC DST UTC? DST? UTC? DST? correct?\ncorrect?\nToday is Tuesday, August\n8th at 10:52 PM in 2023 in\nAlmaty, Kazakhstan. What\ntime is it in 2 hours in\nTallinn, Estonia?\nAlmaty, Kazakhstan is 4 hours ahead of UTC,\nand Tallinn, Estonia is 3 hours ahead of UTC. So\nTallinn is 1 hour behind Almaty. It’s currently\n10:52 PM in Almaty, so in 2 hours it will be\n12:52 AM. In Tallinn, which is 1 hour behind, it\nwill be 11:52 PM.\"\n2023-08-08\n21:52\n+6.0\n+5.0\n3.0\n2.0\n✗\n✗\n✓\n✗\n✓\n✗\nToday is Monday, April\n10th at 07:06 PM in 2023\nin Zagreb, Croatia. What\ntime is it in 1 hours in La-\ngos, Nigeria?\nZagreb, Croatia is in the Central European Sum-\nmer Time (CEST) zone, which is UTC+2. Lagos,\nNigeria is in the West Africa Time (WAT) zone,\nwhich is UTC+1. So, Lagos is 1 hour behind Za-\ngreb. Current time in Zagreb: 07:06 PM (19:06)\non April 10th, 2023 Add 1 hour to account for\nthe time difference: 08:06 PM (20:06) on April\n10th, 2023 So, in 1 hour, it will be 08:06 PM\n(20:06) on April 10th, 2023 in Lagos, Nigeria.\"\n2023-04-10\n19:06\n2.0\n+1.0\n1.0\n1.0\n✓\n✗\n✓\n✗\n✓\n✗\nToday is Friday, October\n20th at 11:16 PM in 2023 in\nVaduz, Liechtenstein. What\ntime is it in 7 hours in Libre-\nville, Gabon?\nVaduz, Liechtenstein is in the Central European\nTime (CET) zone, which is UTC+1. Libreville,\nGabon is in the West Africa Time (WAT) zone,\nwhich is UTC+1 as well. So, 7 hours from 11:16\nPM on Friday, October 20th, 2023 in Vaduz\nwould be 6:16 AM on Saturday, October 21st,\n2023 in Libreville.\n2023-10-21\n05:16\n+2.0\n+1.0\n+1.0\n+1.0\n✗\n✓\n✓\n✗\n✓\n✗\nToday is Friday, January\n13th at 12:21 AM in 2023\nin Bandar Seri Begawan,\nBrunei.\nWhat time is it\nin 3 hours in Atka, United\nStates?\nBandar Seri Begawan, Brunei is UTC+8. Atka,\nUnited States is UTC-10. So Atka is 18 hours\nbehind Bandar Seri Begawan. It is currently\n12:21 AM on Friday, January 13th in Bandar\nSeri Begawan. In 3 hours, it will be 3:21 AM\non Friday, January 13th in Bandar Seri Begawan.\nTo find the time in Atka, we need to subtract\n18 hours. So it will be 6:21 AM on Thursday,\nJanuary 12th in Atka.\n2023-01-12\n09:21\n8.0\n8.0\n-10.0\n-9.0\n✓\n✗\n✓\n✗\n✗\n✗\nTable 9: Examples of the qualitative error analysis.\n",
    "content": "# Analysis of the AI Academic Paper *Around the World in 24 Hours: Probing LLM Knowledge of Time and Place*\n\n## 1. Core Content and Main Contributions\n\nThe core content of this paper is the investigation into the reasoning capabilities of large language models (LLMs) with respect to time and geographic knowledge. The authors created a dataset called GEOTEMP, which includes over 320,000 question prompts covering 289 locations and 37 time zones. By using the GEOTEMP dataset, they evaluated eight open-chat-optimized LLMs from three model families on tasks that combine different temporal and geographic knowledge.\n\n**Main Contributions:**\n- **Creation of the GEOTEMP Dataset**: This is the first dataset specifically designed to evaluate the combined reasoning ability of LLMs regarding time and geography.\n- **Comprehensive Evaluation of LLM Capabilities**: Analyzes the performance of multiple LLMs on tasks involving only time knowledge, only geographic knowledge, or both combined.\n- **Revealing Model Performance Bottlenecks**: It was found that while most models perform well on tasks involving only time knowledge, their performance deteriorates significantly when both time and geographic information need to be integrated.\n- **Proposing Improvement Methods**: Injecting geographic knowledge significantly improves model performance on complex tasks.\n\n---\n\n## 2. Breakthroughs and Innovations\n\n**Breakthroughs and Innovation Points:**\n\n1. **First Comprehensive Assessment of Temporal and Geographic Reasoning**:\n   - Previous studies mostly evaluated LLMs' temporal reasoning and geographic knowledge separately. This study is the first to systematically combine and assess both areas.\n\n2. **Revealing Limitations in Knowledge Integration**:\n   - It was discovered that although LLMs can independently grasp time and geographic knowledge, they struggle when both types of knowledge are required simultaneously. This indicates difficulties for current LLMs in integrating knowledge for complex reasoning tasks.\n\n3. **Proposing Knowledge Injection-Based Improvements**:\n   - Providing explicit timezone information significantly enhances model performance on complex tasks. This method provides new ideas for future LLM improvements.\n\n4. **In-depth Analysis of Model Error Patterns**:\n   - A detailed classification and analysis of model errors revealed common issues such as time conversion, timezone understanding, and AM/PM handling.\n\n---\n\n## 3. Good Ideas for Startup Projects\n\nBased on the content of this paper, the following startup projects can be developed:\n\n### **1. Intelligent Travel Assistant**\n- **Core Functionality**: Utilize LLMs combined with time and geographic knowledge to provide real-time travel recommendations, such as flight schedule adjustments, destination time zone reminders, and optimal travel times.\n- **Application Scenarios**: Business travelers, international tourists, organizers of cross-border meetings.\n- **Technical Implementation**: Train models based on the GEOTEMP dataset to enhance their understanding of global time zones and geographical positions.\n\n### **2. Cross-Border Logistics Optimization Platform**\n- **Core Functionality**: Provide precise time and geographic calculation services to logistics companies for optimizing cross-border transportation plans.\n- **Application Scenarios**: Freight transport, courier delivery, supply chain management.\n- **Technical Implementation**: Use LLM knowledge injection techniques to ensure accurate handling of complex time zone and geographic information.\n\n### **3. Educational Tool: Geography and Time Zone Learning Assistant**\n- **Core Functionality**: Develop an educational tool to help students learn about time zones, geographic knowledge, and time conversion rules around the world.\n- **Application Scenarios**: School education, online learning platforms, self-improvement users.\n- **Technical Implementation**: Build an interactive learning environment based on the GEOTEMP dataset, guiding users through Q&A sessions to facilitate learning.\n\n### **4. Real-Time Question Answering System**\n- **Core Functionality**: Construct a system capable of answering user questions related to time and location in real-time.\n- **Application Scenarios**: News websites, social media, corporate customer service.\n- **Technical Implementation**: Combine the knowledge injection methods described in the paper to improve model accuracy in complex time and geography reasoning tasks.\n\n### **5. International Meeting Coordination Tool**\n- **Core Functionality**: Provide automated meeting time coordination services for cross-border teams, minimizing inconveniences caused by time differences.\n- **Application Scenarios**: Remote collaboration teams, international conference organizers.\n- **Technical Implementation**: Leverage LLM's geographic and time zone reasoning abilities to recommend optimal meeting times and generate corresponding reminders.\n\n---\n\nThrough the development of these projects, it is not only possible to promote the practical application of LLMs but also to further validate and improve the theories and technical methods proposed in the paper.",
    "github": "",
    "hf": ""
}