{
    "id": "2510.18499",
    "title": "Alibaba International E-commerce Product Search Competition DILAB Team Technical Report",
    "summary": "This paper introduces the multilingual e-commerce search system developed by the DILAB team, which secured 5th place on the final leaderboard with a score of 0.8819, demonstrating stable and high performance across multiple evaluation metrics. It proposes a multi-stage pipeline approach to address the challenges of multilingual query-item understanding.",
    "abstract": "This study presents the multilingual e-commerce search system developed by the DILAB team, which achieved 5th place on the final leaderboard with a competitive overall score of 0.8819, demonstrating stable and high-performing results across evaluation metrics. To address challenges in multilingual query-item understanding, we designed a multi-stage pipeline integrating data refinement, lightweight preprocessing, and adaptive modeling. The data refinement stage enhanced dataset consistency and category coverage, while language tagging and noise filtering improved input quality. In the modeling phase, multiple architectures and fine-tuning strategies were explored, and hyperparameters optimized using curated validation sets to balance performance across query-category (QC) and query-item (QI) tasks. The proposed framework exhibited robustness and adaptability across languages and domains, highlighting the effectiveness of systematic data curation and iterative evaluation for multilingual search systems. The source code is available atthis https URL.",
    "category1": "Algorithms and Models",
    "category2": "",
    "category3": "Non-Agent",
    "authors": "Hyewon Lee,Junghyun Oh,Minkyung Song,Soyoung Park,Seunghoon Han",
    "subjects": [
        "Machine Learning (cs.LG)"
    ],
    "comments": "Comments:CIKM Alibaba E-commerce Search Challenge 2025",
    "keypoint": "The DILAB team achieved 5th place in the Alibaba International E-commerce Product Search Competition with an overall score of 0.8819.  \nA multi-stage pipeline was designed, integrating data refinement, lightweight preprocessing, and adaptive modeling for multilingual query–item understanding.  \nData refinement improved dataset consistency and category coverage through Quality Refinement (QR) and language-specific threshold tuning.  \nLanguage Tagging (LT) and noise filtering were applied to enhance input quality across languages.  \nHierarchical Category Tagging (HCT) was introduced for the Query-Category (QC) task to make category hierarchy explicit.  \nSemantic Item Tagging (SIT) and Description Generation (DG) were used in the Query–Item (QI) task to enrich item representations.  \nIn-context Learning (ICL) and Chain-of-Thought (CoT) reasoning were incorporated to improve multilingual reasoning and generalization.  \nThe Qwen2.5-14B-Instruct model outperformed other backbones in both QC and QI tasks.  \nLoRA was used for parameter-efficient fine-tuning, staying within the 15 billion parameter limit.  \nThe proposed framework achieved a QC score of 0.8861 and a QI score of 0.8778, surpassing the baseline XLM-R by 0.0648 and 0.0842 respectively.  \nAblation studies showed that QR consistently improved performance in both tasks.  \nFor QC, HCT had a greater individual impact than LT, and combining QR, LT, and HCT yielded the best result.  \nFor QI, SIT contributed more individually than LT or DG, and full integration of QR, LT, SIT, and DG achieved peak performance.  \nThe system demonstrated strong cross-lingual generalization, especially on languages not seen during training.  \nThe source code is publicly available at https://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search.",
    "date": "2025-10-23",
    "paper": "Alibaba International E-commerce Product Search Competition\nDILAB Team Technical Report\nHyewon Lee\nChungnam National University\nDaejeon, Republic of Korea\nnoweyh927@g.cnu.ac.kr\nJunghyun Oh\nChungnam National University\nDaejeon, Republic of Korea\nojh7839@o.cnu.ac.kr\nMinkyung Song\nChungnam National University\nDaejeon, Republic of Korea\nkyung@o.cnu.ac.kr\nSoyoung Park\nChungnam National University\nDaejeon, Republic of Korea\nsypark1452@o.cnu.ac.kr\nSeunghoon Han\nChungnam National University\nDaejeon, Republic of Korea\ntmdgns129@g.cnu.ac.kr\nAbstract\nThis study presents the multilingual e-commerce search system\ndeveloped by the DILAB team, which achieved 5th place on the final\nleaderboard with a competitive overall score of 0.8819, demonstrat-\ning stable and high-performing results across evaluation metrics. To\naddress challenges in multilingual query–item understanding, we\ndesigned a multi-stage pipeline integrating data refinement, light-\nweight preprocessing, and adaptive modeling. The data refinement\nstage enhanced dataset consistency and category coverage, while\nlanguage tagging and noise filtering improved input quality. In the\nmodeling phase, multiple architectures and fine-tuning strategies\nwere explored, and hyperparameters optimized using curated vali-\ndation sets to balance performance across query-category (QC) and\nquery–item (QI) tasks. The proposed framework exhibited robust-\nness and adaptability across languages and domains, highlighting\nthe effectiveness of systematic data curation and iterative evalua-\ntion for multilingual search systems. The source code is available at\nhttps://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search.\nCCS Concepts\n• Information systems →Retrieval effectiveness; • Comput-\ning methodologies →Supervised learning by classification;\nInformation extraction.\nKeywords\nMultilingual Information Retrieval, E-commerce Search, Query-\nCategory (QC), Query–Item (QI), Large Language Model (LLM).\n1\nIntroduction\nAlibaba International Digital Commerce (AIDC)1 operates AliEx-\npress, Lazada, Daraz, Trendyol, and Mirivia, serving users in over\n100 countries and 20 languages. The search engine is a core com-\nponent for product discovery, and optimizing multilingual search\nquality is critical for user satisfaction and competitiveness. We ad-\ndress the problem of Multilingual E-commerce Product Search,\nfocusing on two key tasks: the Query-Category (QC) relevance task,\nwhich determines whether a query matches a product category,\n1https://www.alibabagroup.com\nPresented at the 34th ACM International Conference on Information and Knowledge\nManagement (CIKM’25), November 10–14, 2025, Seoul, Republic of Korea.\n© 2025 DILAB. Licensed under CC BY 4.0.\nand the Query-Item (QI) relevance task, which evaluates whether\na query corresponds to a specific product listing. Together, these\ntasks form the foundation of multilingual e-commerce search.\nTable 1: Per-language sample counts in the QC and QI train\nand test datasets, illustrating the distribution of data across\nlanguages for multilingual relevance evaluation.\nLanguage\nCode\nQC\nQI\nTrain\nTest\nTrain\nTest\nEnglish\nen\n50k\n10k\n50k\n10k\nSpanish\nes\n50k\n10k\n50k\n10k\nFrench\nfr\n50k\n10k\n50k\n10k\nJapanese\nja\n50k\n10k\n45k\n10k\nKorean\nko\n50k\n10k\n45k\n10k\nPortuguese\npt\n50k\n10k\n50k\n10k\nThai\nth\n–\n–\n50k\n10k\nArabic\nar\n–\n10k\n–\n10k\nGerman\nde\n–\n10k\n–\n10k\nItalian\nit\n–\n10k\n–\n10k\nPolish\npl\n–\n10k\n–\n10k\nIndonesian\nid\n–\n–\n–\n10k\nVietnamese\nvn\n–\n–\n–\n10k\nMeanwhile, the datasets used in this competition — namely, the\nQC and QI datasets — were constructed from multilingual search\nlogs and annotated by domain experts. Each dataset includes the\nquery language, original query text, a corresponding element (either\na category path or an item title), and a binary relevance label. Table 1\nsummarizes key statistics of the QC and QI datasets, indicating that\nsome languages appear only in the dev and test sets but not in the\ntraining data. Figure 1 further illustrates a mild label imbalance and\nvariations in language distribution across the datasets; however,\nneither issue was severe enough to require correction [2, 5, 9].\nThis finding underscores the importance of multilingual process-\ning and the ability to generalize to unseen languages. To address this\nchallenge, large language models (LLMs) with strong cross-lingual\ntransfer and generalization capabilities have proven particularly ef-\nfective. However, the performance of LLMs depends not only on the\nquantity of available data but, more critically, on its quality. Prior\nstudies have emphasized that massive amounts of high-quality data\narXiv:2510.18499v1  [cs.LG]  21 Oct 2025\nTeam DILAB\nFigure 1: Label ratio distribution across languages in the QC\nand QI training datasets.\nare essential for effective LLM training [12], and have further shown\nthat systematic data filtering can yield better performance than\nusing raw data indiscriminately [6]. In line with these findings, our\nstudy highlights that data quality management and refinement are\nnot optional but indispensable for successful model development.\nTo address this, our team applied lightweight preprocessing and\nmodeling strategies, including Quality Refinement (QR) to filter\nout low-quality data and enhance overall dataset quality, and Lan-\nguage Tagging (LT) for explicit multilingual signals. Task-specific\nstrategies, such as Hierarchical Category Tagging (HCT) in QC,\nand Semantic Item Tagging (SIT) and Description Generation (DG)\nin QI, were also deployed. In addition, we incorporated advanced\nmodeling techniques such as In-context Learning (ICL) and Chain-\nof-Thought (CoT) reasoning to strengthen the model’s ability to\ngeneralize across languages and complex query structures. Together,\nthese strategies are designed to enhance the model’s cross-lingual\nrelevance prediction, consistent with prior studies showing the\neffectiveness of query augmentation for improving multilingual\nsearch performance [1, 10].\nWe focus on developing and applying LLMs\nthat can handle multilingual data in e-\ncommerce search. Using the QC and QI\ndatasets, we leverage the multilingual ca-\npabilities of a pre-trained LLM with light-\nweight preprocessing strategies to improve\nrelevance prediction across languages and\ntasks, ultimately enhancing search quality in\nglobal e-commerce environments. Our team\nadvanced to the final round and achieved\n5th place on the final leaderboard.\nOur main contributions can be summarized as follows:\n• We propose an efficient multilingual search framework that\ncombines lightweight preprocessing with LLMs to improve\ncross-lingual relevance prediction for both QC and QI tasks.\n• We introduce task-specific enhancements, including HCT\nfor QC and SIT with DG for QI, which enhance data quality\nand model interpretability.\n• Our team’s rigorous approach to data tagging and modeling\nwas recognized with a Special Award at the Alibaba Inter-\nnational E-commerce Product Search Competition, high-\nlighting the originality and impact of our work.\nThe following sections describe our methodology and experi-\nments in detail. Section 2 presents the proposed approach based on\nthe insights above, Section 3 outlines the experimental setup and\nresults, and Section 4 concludes with findings and future directions.\n2\nMethodology\nIn this section, we present the overall methodology for the QC and\nQI tasks in multilingual e-commerce search. Our approach follows\na unified pipeline. This pipeline, illustrated in Figure 2, is composed\nof the following four key components:\n(1) Quality Refinement (QR): filters out noisy or low-quality\nsamples to improve dataset reliability.\n(2) Tagging: injects explicit linguistic and structural cues to\nenhance representational richness.\n(3) In-Context Learning (ICL) and Chain-of-Thought (CoT):\nstrengthen multilingual reasoning and generalization.\n(4) LLM Training and Prediction: integrates all components\ninto a unified multilingual relevance model.\nThis pipeline is specifically designed to improve both data qual-\nity and the generalization ability of large language models across\ndiverse languages and product domains.\n2.1\nQuality Refinement (QR)\nTo improve dataset quality, we designed a self-evaluation refine-\nment that integrates model predictions with lexical similarity mea-\nsures. The QR process operates in two steps: (1) LLM Fine-Tuning\nand Prediction; and (2) Self-Evaluation and Quality Cleaning.\nThis refinement pipeline ensures that mislabeled or noisy data\nare filtered out before downstream training. By embedding TF-\nIDF/Jaccard–based lexical similarity within a self-evaluation phase,\nthe model not only learns from the data but also validates and im-\nproves data quality. The proposed refinement strategy significantly\nenhances robustness and cross-lingual adaptability, making the\nrefined datasets more reliable for multilingual e-commerce search\ntasks, and serving as a solid foundation for the subsequent tagging,\nICL/CoT, and LLM training stages.\n2.1.1\nLLM Fine-Tuning and Prediction. Raw QC and QI data are\nreformatted into lightweight instruction–input pairs and used to\nfine-tune the eCeLLM-M [7] model with LoRA adaptation. In this\nstep, we adopt the basic version of the prompt, which excludes\nLanguage Tagging, Semantic Item Tagging, and Description Genera-\ntion, unlike the enriched prompt format used in the final stage. The\nfine-tuned model then re-predicts the same training data, producing\nprobabilities and binary relevance labels.\n2.1.2\nSelf-Evaluation and Quality Cleaning. The probabilities and\nbinary relevance labels from the previous step are combined with\nlexical similarity features—specifically TF-IDF cosine similarity\nand Jaccard overlap—between queries and paired categories/items.\nLanguage-specific thresholds are automatically tuned, and keyword-\nbased guards mitigate false positive/negative bias. Samples with\nstrong disagreement between labels, predictions, and similarity\nscores are flagged as suspect and removed. The final refined dataset\nis saved in JSONL format while preserving the original schema.\n2.2\nTagging\nPrior studies in e-commerce have demonstrated that explicit\ntagging of hierarchical categories and item attributes improves fine-\ngrained relevance modeling and retrieval performance [13]. Moti-\nvated by these findings, we designed task-specific tagging schemes.\nWe define four complementary tagging strategies as follows:\nAlibaba International E-commerce Product Search Competition DILAB Team Technical Report\nOrigin QC\nOrigin QI\nFinal QC\nFinal QI\nTagging\n[ATTR] category : mobile_phone_lens,\nsize : 67mm ...\nSIT\n[GEN_TAGS] mobile_phone_lens_feature\n[ GEN_DESC ] A 67mm phone lens ...\nDG\n[D1] food [/ D1] [D2] grocery [/ D2] ...\nHCT\nQuery : [ LANG = en ] baking\nLT\nQuality Refinement\nLLM Training & Prediction\nssssssssssssssssssssssss\n(1) LLM Fine-Tuning Prediction\nQuality Refinement\n(2) Self-Evaluation & Quality Cleaning\nLLM Fine-tuning\nOutput & Probs\nRaw Data\nSelf-Evaluation\nTF-IDF & Jacarrd\nRefined Data\nRelevant : matches user intent\nNot relevant : unrelated or wrong (category or item)\nCoT\nDecide if the category is relevant to the query.\n{COT} Respond only with \"yes\" or \"no\".\n[Example1]\nQuery: {Tagging Query}\nCategory or Item : {Tagging Category or Item}\nAnswer: yes or no\n[Example2]\n...\nICL\nICL & CoT\nICL & CoT\nTagging\nHCT\nLT\nDG\nSIT\nQC\nQI\nFigure 2: Overview of the proposed DILAB framework for the QC and QI tasks.\n1\n# QC Prompt\n2\nI n s t r u c t i o n :\n3\nYou are\ngiven a\nuser\nquery\n4\nand a product\ncategory .\n5\nDecide\ni f\nthe\ncategory\ni s\n6\nr e l e v a n t\nto\nthe\nquery .\n7\nRelevant :\nmatches\nuser\ni n t e n t\n8\n( c o r r e c t\ncategory ) .\n9\nNot\nr e l e v a n t :\nu n r e l a t e d\nor\n10\nwrong category .\n11\nRespond\nonly\nwith\n\" yes \"\nor\n\" no \" .\n12\n13\nQuery :\n[LANG=en ]\nbaking\n14\nCategory :\n[D1]\nfood\n[ / D1]\n15\n[D2]\ngrocery\n[ / D2]\n16\n[D3]\nf l o u r\n[ / D3]\n17\n[D4]\nbaking and cooking\n[ / D4]\n18\n[D5]\nd e c o r a t i o n s\n[ / D5]\n19\nAnswer :\nyes\n20\nOptions :\n{ In −Context\nLearning }\nFigure 3: Representative QC prompt structure.\n• Language Tagging (LT): Both QC and QI datasets were\nannotated with language tags (e.g., Arabic queries marked\nas [LANG=ar]) to enhance multilingual recognition.\n• Hierarchical Category Tagging (HCT): QC data are\ncategory-driven and hierarchically organized. We introduce\nstructured tags such as [D1] apparel accessories [/D1] to\nmake the depth explicit, enabling the model to distinguish\ndetailed category levels. A representative HCT prompt is\nshown in Figure 3.\n• Semantic Item Tagging (SIT): QI data require richer anno-\ntation. We adopt a hybrid pipeline that combines rule-based\nattribute tagging (brand, color, size, material, style, etc.)\nwith LLM-based attribute enrichment. Detected attributes\nare standardized as [ATTR] tags.\n1\n# QI Prompt\n2\nI n s t r u c t i o n :\n3\nYou are\ngiven a\nuser\nquery\n4\nand a product\nt i t l e .\n5\nDecide\ni f\nthe\nproduct\ni s\n6\nr e l e v a n t\nto\nthe\nquery .\n7\nRelevant :\nmatches\nuser\ni n t e n t\n8\n( category / type match ,\n9\nbrand / specs may\nd i f f e r ) .\n10\nNot\nr e l e v a n t :\nu n r e l a t e d\ntype\n11\nor\naccessory\ni n s t e a d\nof\n12\nmain item .\n13\nRespond\nonly\nwith\n\" yes \"\nor\n\" no \" .\n14\n15\nQuery :\n[LANG=en ]\n16\nApexel 60x\nt e l e p h o t o\nl e n s\n17\nProduct :\n67mm Phone\nF i l t e r\n18\nHolder Mount Lens\nF i l t e r\nClip\n19\nWith Cold Shoe Adapter\ns\n20\nU n i v e rs a l\nFor\nIPhone\n21\nPhotography Camera\nA c c e s s o r i e s\n22\n[ATTR]\ncategory :\nmobile_phone_lens ,\n23\ns i z e :\n67mm,\nq c _ l e a f :\nmobile_phone_lens\n24\n[GEN_TAGS]\nmobile_phone_lens_feature\n25\n[GEN_DESC] A 67mm phone\nl e n s\n26\nf i l t e r\nholder mount\nf o r\n27\niPhone\nphotography\na c c e s s o r i e s .\n28\nAnswer :\nno\n29\nOptions :\n{ In −Context\nLearning }\nFigure 4: Representative QI prompt structure.\n• Description Generation (DG): To further enrich the input\nrepresentation, an instruction-tuned LLM (Meta-Llama-3-\n8B-Instruct [3] via vLLM) generates short descriptive sen-\ntences and binary relevance labels in a controlled format.\nA representative SIT+DG prompt is shown in Figure 4.\nTeam DILAB\n2.3\nIn-Context Learning and Chain-of-Thought\nAccording to previous studies in the e-commerce domain, inte-\ngrating ICL and CoT has been shown to improve model reasoning\nand relevance prediction [8]. Building on this finding, we applied\nICL and CoT in our fine-tuning process. Specifically, ICL provided\nmultilingual positive and negative examples to guide contextual\nunderstanding, while CoT offered explicit step-by-step reasoning\ncues that defined the relevance criteria, as shown in Figure 2. This\napproach proved effective in enhancing the fine-tuning process. Fig-\nures 3 and 4 illustrate CoT guidelines for each task, and the overall\ncontext of both CoT and ICL can also be observed in Figure 2.\n2.4\nLLM Training and Prediction\nWe experimented with several backbone models used in e-commerce\nresearch, including Qwen2.5-14B-Instruct [11], Meta-LLaMA-3-8B-\nInstruct [3], and eCeLLM [7]. Among them, Qwen2.5-14B-Instruct\nachieved the best performance across the QC and QI tasks.\nWe then performed task-specific fine-tuning on this instruction-\ntuned backbone. This process was unified across the QC and QI\ntasks for consistent optimization, and parameter-efficient adapta-\ntion was performed via LoRA [4]. To ensure reproducibility, the\nfine-tuned model was applied to the development and test inputs\nusing the same setup as in training. This process yields the final,\noptimized model used for all subsequent evaluations.\n3\nExperiments\nTo evaluate the effectiveness of the proposed method, we conducted\nexperiments on the provided test dataset. This section presents the\nexperimental settings, implementation, and results, including data\npreprocessing, model training, prediction, and ablation analysis.\n3.1\nRequirements\nAll experiments were conducted in a Conda-based Python 3.11\nenvironment. Table 2 summarizes the hardware and software setup\nused throughout the experiments.\nTable 2: Experimental environment setup\nComponent\nSpecification\nOS\nLinux\nPython\n3.11\nPyTorch\n2.7.1\nTransformers\n4.44.0\nGPU\nNVIDIA H100 PCIe (80GB VRAM)\nCUDA / Driver\nCUDA 12.4 / Driver 550.54.14\n3.2\nImplementation\nThis subsection provides an overview of the implementation pro-\ncess of our proposed method. We describe the overall code structure,\ndata preprocessing steps, model training procedure, and prediction\npipeline. Each component is designed to ensure reproducibility and\nefficiency throughout the entire workflow.\n3.2.1\nCode Structure. The directory is organized into modular com-\nponents to ensure clarity and reproducibility, as shown in Figure 5.\n• data/: raw (original), refine (refinement data), preprocessed\n(final data).\n• model/: fine-tuned checkpoints.\n• outputs/: submission files (submit_QC.txt, submit_QI.txt).\n• src/data_preprocess/: tagging, captioning, format conver-\nsion.\n• src/quality_refinement/: data cleaning and ICL conver-\nsion.\n• src/prompter.py, src/templates/: prompt templates &\nlogic.\n• src/train.py, src/predict.py: training and inference entry\npoints.\n• script/: bash wrappers for reproducibility.\nproject/\ndata/\nraw/...............................original\nrefine/....................refinement data\npreprocessed/. .................. final data\nmodel/..................fine-tuned checkpoints\noutputs/......................submission files\nsubmit_QC.txt\nsubmit_QI.txt\nsrc/\ndata_preprocess/. ..... tagging, captioning,\nformat conversion\nquality_refinement/. data cleaning and ICL\nconversion\nprompter.py.prompt templates & logic builder\ntemplates/..........JSON prompt templates\ntrain.py...............training entry point\npredict.py............inference entry point\nscript/.......bash wrappers for reproducibility\n*.........................utility shell scripts\nFigure 5: Project directory tree with descriptions.\n3.2.2\nData Preprocessing. As shown in Listing 1, the QC and QI\ndatasets are processed with an integrated script that converts raw\ndata (data/raw/) into training and test sets through two stages:\nrefinement, which improves data quality, and preprocessing, which\napplies tagging and format conversion.\n\u000b\n\b\n#\nQuality\nRefinement\n(QR)\nbash\ns c r i p t / q u a l i t y _ r e f i n e m e n t . sh\n#\nP r e p r o c e s s i n g\nr e f i n e d\ndata\nbash\ns c r i p t / da ta _pr epr oc ess . sh\n\n\t\nListing 1: QR and Preprocessing commands.\nAlibaba International E-commerce Product Search Competition DILAB Team Technical Report\n3.2.3\nTraining. As illustrated in Listing 2, model training is launched\nwith the following arguments:\n• <num_epochs>: number of training epochs (e.g., 2).\n• <model>: backbone LLM (e.g., Qwen2.5-14B, Meta-Llama-\n3-8B, eCeLLM-M).\n• <task>: target task (QC or QI).\nThe fine-tuned model checkpoints are saved in ./model/ directory.\n\u000b\n\b\n#\nTrain QC and QI\n# bash\ns c r i p t / t r a i n . sh <num epochs >\n<model > < task >\nbash\ns c r i p t / t r a i n . sh 2 Qwen2.5 −14B QC\nbash\ns c r i p t / t r a i n . sh 2 Qwen2.5 −14B QI\n\n\t\nListing 2: Training commands for QC and QI.\n3.2.4\nPrediction. As depicted in Listing 3, inference is launched\nwith the following arguments:\n• <model>: backbone LLM (must match the fine-tuned model).\n• <task>: target task (QC or QI).\nThis process produces two final submission files: submit_QC.txt\nand submit_QI.txt, which are located in the ./outputs/ folder.\n\u000b\n\b\n#\nP r e d i c t QC and QI\n# bash\ns c r i p t / p r e d i c t . sh <model > < task >\nbash\ns c r i p t / p r e d i c t . sh Qwen2.5 −14B QC\nbash\ns c r i p t / p r e d i c t . sh Qwen2.5 −14B QI\n\n\t\nListing 3: Prediction commands for QC and QI.\n3.3\nResults\nTable 3: Comparison of overall F1 scores on the QC and QI\ndatasets among LLM-based models.\nMethod\nScore_QC\nScore_QI\nScore\nXLM-R\n0.8213\n0.7936\n0.8075\nQwen2.5-1.5B\n0.8315\n0.8137\n0.8226\nQwen2.5-7B\n0.8607\n0.8487\n0.8544\nQwen2.5-14B\n0.8684\n0.8667\n0.8676\nOurs\n0.8861\n0.8778\n0.8819\nWe applied task-specific strategies that led to the performance\nimprovements summarized in Table 3. Specifically, on the test set,\nour approach achieved gains of 0.0177 on QC and 0.0111 on QI,\nresulting in an overall improvement of 0.0143 compared to the\nprevious best-performing model, Qwen2.5-14B. Furthermore, com-\npared to the baseline XLM-R model provided in the competition\nbaseline code, our strategy yielded improvements of 0.0648 on QC,\n0.0842 on QI, and an overall gain of 0.0744. These results demon-\nstrate the effectiveness of our proposed approaches.\nTable 4: Ablation studies on QC and QI datasets.\n(a) QC dataset\nQR\nLT\nHCT\nScore\n✓\n0.8718\n✓\n0.8798\n✓\n✓\n0.8836\n✓\n✓\n✓\n0.8861\n(b) QI dataset\nQR\nLT\nSIT\nDG\nScore\n✓\n0.8701\n✓\n0.8741\n✓\n0.8736\n✓\n✓\n✓\n0.8751\n✓\n✓\n✓\n✓\n0.8778\n3.4\nAblation Study\nWe evaluate the effectiveness of the proposed strategies as presented\nin Tables 4𝑎and 4𝑏. It is observed that QR, applied consistently\nacross QC and QI, yields uniform performance improvements, sub-\nstantiating the critical importance of foundational data quality. For\nthe QC task, HCT has a greater individual impact on performance\nthan LT. Furthermore, the combination of QR, LT, and HCT achieves\nthe highest performance of 0.8861, demonstrating a strong additive\neffect among the strategies in the QC domain. Similarly, for the QI\ntask, the individual use of SIT shows the strongest result compared\nto LT and DG. Crucially, applying all four strategies (QR, LT, SIT,\nand DG) achieves the highest overall performance of 0.8778, demon-\nstrating that maximum performance in the QI task is also realized\nthrough the synergistic application of the full set of preprocessing\nand modeling enhancements.\n3.5\nParameter Limitation\nAs outlined above, we adopt task-specific strategies that lead to\nimproved predictive performance, while employing a model com-\nprising 14.98 billion parameters, thereby remaining compliant with\nthe competition’s regulation limit of 15 billion parameters.\n4\nConclusion and Future Work\nOur research successfully demonstrated the feasibility of using\nlarge language models (LLMs) for the Multilingual E-commerce\nProduct Search problem, securing a top-tier rank in the preliminary\nround. This was achieved through a thorough understanding of\nthe task and carefully designed strategies for data preprocessing,\ntraining, and inference, which ensured both computational and\ntime efficiency. Importantly, these approaches enabled the model\nto remain robust when evaluated on test datasets containing previ-\nously unseen languages, confirming its effectiveness in challenging\nmultilingual settings. Ultimately, we fulfilled our original goal of\nshowing that LLM-based methods can reliably advance multilingual\nproduct search by achieving accurate and stable performance in\nnoisy, real-world e-commerce environments.\nOverall, this work confirms that LLM-based approaches provide\npractical and reliable solutions for multilingual product search,\nbridging the gap between large-scale model capability and domain-\nspecific adaptation. While our current system already achieves\nrobust performance across diverse languages and product domains,\nfuture work will focus on further streamlining the fine-tuning pro-\ncess to reduce computational cost and exploring lightweight adap-\ntation techniques to enable scalable real-world deployment.\nTeam DILAB\nReferences\n[1] Altan Cakir and Mert Gurkan. 2023. Modified query expansion through genera-\ntive adversarial networks for information extraction in e-commerce. Machine\nLearning with Applications 14 (2023), 100509.\n[2] Kushankur Ghosh, Colin Bellinger, Roberto Corizzo, Paula Branco, Bartosz\nKrawczyk, and Nathalie Japkowicz. 2024. The class imbalance problem in deep\nlearning. Machine Learning 113, 7 (2024), 4845–4901.\n[3] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Ab-\nhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schel-\nten, Alex Vaughan, et al. 2024. The llama 3 herd of models. arXiv preprint\narXiv:2407.21783 (2024).\n[4] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean\nWang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of\nLarge Language Models. In International Conference on Learning Representations.\nhttps://openreview.net/forum?id=nZeVKeeFYf9\n[5] Justin M Johnson and Taghi M Khoshgoftaar. 2019. Survey on deep learning\nwith class imbalance. Journal of big data 6, 1 (2019), 1–54.\n[6] Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning\nCheng, and Tianyi Zhou. 2024. Superfiltering: Weak-to-strong data filtering for\nfast instruction-tuning. arXiv preprint arXiv:2402.00530 (2024).\n[7] Bo Peng, Xinyi Ling, Ziru Chen, Huan Sun, and Xia Ning. 2024. ecellm: Gen-\neralizing large language models for e-commerce from large-scale, high-quality\ninstruction data. arXiv preprint arXiv:2402.08831 (2024).\n[8] Jayant Sachdev, Sean D Rosario, Abhijeet Phatak, He Wen, Swati Kirti, and\nChittaranjan Tripathy. 2024. Automated Query-Product Relevance Labeling\nusing Large Language Models for E-commerce Search. In Proceedings of the 2024\n8th International Conference on Natural Language Processing and Information\nRetrieval. 32–40.\n[9] Ruben Van den Goorbergh, Maarten van Smeden, Dirk Timmerman, and Ben\nVan Calster. 2022. The harm of class imbalance corrections for risk prediction\nmodels: illustration and simulation using logistic regression. Journal of the\nAmerican Medical Informatics Association 29, 9 (2022), 1525–1534.\n[10] Yujing Wang, Yiren Chen, Huoran Li, Chunxu Xu, Yuchong Luo, Xianghui Mao,\nCong Li, Lun Du, Chunyang Ma, Qiqi Jiang, et al. 2025. CSRM-LLM: Embracing\nMultilingual LLMs for Cold-Start Relevance Matching in Emerging E-commerce\nMarkets. arXiv preprint arXiv:2509.01566 (2025).\n[11] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng,\nBowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. 2025. Qwen3 technical\nreport. arXiv preprint arXiv:2505.09388 (2025).\n[12] Jifan Zhang, Ziyue Luo, Jia Liu, Ness Shroff, and Robert Nowak. 2024. GPT-4o as\nthe Gold Standard: A Scalable and General Purpose Approach to Filter Language\nModel Pretraining Data. arXiv preprint arXiv:2410.02755 (2024).\n[13] Qi Zhang, Zijian Yang, Yilun Huang, Ze Chen, Zijian Cai, Kangxu Wang, Jiewen\nZheng, Jiarong He, and Jin Gao. 2022. A semantic alignment system for multilin-\ngual query-product retrieval. arXiv preprint arXiv:2208.02958 (2022).\n",
    "content": "# Interpretation of the DILAB Team's Technical Report on the Alibaba International E-commerce Product Search Competition\n\n## 1. Core Content and Key Contributions of the Paper\n\nThis paper, authored by the DILAB team from Chungnam National University in South Korea, presents their multilingual e-commerce search system developed for the **Alibaba International E-commerce Product Search Competition**, where they achieved an outstanding **5th place** (with a total score of 0.8819). The research focuses on two critical tasks:\n\n- **Query–Category (QC)**: Determining whether a user query matches a product category;\n- **Query–Item (QI)**: Assessing whether a query corresponds to a specific product title.\n\n### Core Methodological Framework\nThe team proposed a **multi-stage, lightweight yet highly effective processing pipeline**, consisting of four key modules:\n1. **Data Quality Optimization (Quality Refinement, QR)**\n2. **Structured Tag Enhancement (Tagging)**\n3. **In-Context Learning & Chain-of-Thought Reasoning (ICL & CoT)**\n4. **LLM-Based Training and Prediction**\n\nThrough this systematic design, high performance and strong generalization capabilities were achieved without relying on extremely large-scale models.\n\n### Summary of Main Contributions\n1. **Proposed an efficient and reproducible multilingual e-commerce search framework**: By combining lightweight preprocessing with large language models (LLMs), the system significantly improves cross-lingual relevance prediction.\n2. **Introduced task-specific data augmentation strategies**:\n   - **Hierarchical Category Tagging (HCT)** for QC tasks\n   - **Semantic Item Tagging (SIT) + Description Generation (DG)** for QI tasks\n3. **Emphasized the importance of data quality**: Implemented a self-evaluation mechanism combined with lexical similarity filtering (e.g., TF-IDF/Jaccard) to remove noisy or mislabeled samples, enhancing data reliability.\n4. **Awarded a Special Prize**: Recognizing the innovation and practical impact of their approach.\n5. **Open-sourced code**: The project has been made publicly available on GitHub, facilitating replication and future research.\n\n---\n\n## 2. Breakthroughs and Innovations Analysis\n\nAlthough no novel model architecture was introduced, the work features **significant innovations in engineering design and system integration**, making it particularly suitable for real-world deployment:\n\n| Innovation Dimension | Specific Advancements |\n|----------------------|------------------------|\n| ✅ **Active Data Quality Management** | Introduced a \"Self-Evaluation Refinement\" process: First, use a small fine-tuned model to label data; then apply TF-IDF/Jaccard similarity checks to verify consistency, automatically filtering out noisy or incorrectly labeled samples. This is more intelligent and adaptive than traditional passive cleaning methods. |\n| ✅ **Explicit Structured Annotation System** | First to integrate multiple structured prompting techniques into a unified tagging framework:<br>• `LT`: Language tags → enhance multilingual recognition<br>• `HCT`: Hierarchical path tags `[D1]...[D5]` → clarify category depth<br>• `SIT`: Standardized attribute tags `[ATTR]`<br>• `DG`: LLM-generated descriptive text → enrich semantic information |\n| ✅ **ICL and CoT Enhanced Inference** | Embedded multilingual examples (ICL) and logical reasoning chains (CoT) within prompts to guide the model in understanding what constitutes \"relevance\", improving comprehension of complex queries and zero-shot transfer ability. |\n| ✅ **Lightweight Adaptation + Unified Multi-Task Training** | Employed LoRA to efficiently fine-tune Qwen2.5-14B, achieving joint optimization for both tasks while complying with the competition’s ≤15B parameter constraint—balancing performance and cost. |\n| ✅ **End-to-End Reproducible Engineering Architecture** | Fully open-sourced code structure, scripts, and directory organization, greatly enhancing feasibility for industrial deployment. |\n\n> 🔍 **Key Highlight**: **Without using proprietary data or custom models, the team surpassed the baseline XLM-R model by over 7.4% in overall F1 score—solely through high-quality data construction, clever prompt engineering, and LLM fine-tuning.** This validates the effectiveness of the \"data-as-model\" philosophy in e-commerce search.\n\n---\n\n## 3. Startup Project Recommendations (Inspired by This Paper)\n\nBelow are three high-potential entrepreneurial directions inspired by the core technologies of this paper, ideal for startups entering cross-border e-commerce, AI search, and SaaS tools markets:\n\n---\n\n### 🚀 Startup Project One: **MultilingoSearch — Multilingual E-commerce Search-as-a-Service Platform**\n\n#### 💡 Positioning\nProvide **out-of-the-box multilingual search solutions** for small-to-medium cross-border e-commerce platforms (e.g., Shopify merchants, local Southeast Asian platforms), solving inaccurate search results in non-English markets.\n\n#### 🔧 Technical Foundation\n- Reuse the paper’s QR + Tagging + LoRA fine-tuning pipeline\n- Support multilingual input (including long-tail languages like ar, th, id, pl)\n- Automatically generate semantic product tags (brand, specs, usage, etc.)\n\n#### 🎯 Core Features\n- Multilingual query understanding and intent classification\n- Semantic completion and structured parsing of product titles\n- Real-time relevance scoring via API\n- Support for cold-start language transfer (few-shot / zero-shot)\n\n#### 📈 Business Model\n- SaaS subscription (pay-per-query or tiered plans)\n- Integration with plugin marketplaces (Shopify, Magento, WooCommerce)\n- Visual dashboard: Identify failed searches → auto-recommend optimization strategies\n\n#### ✅ Market Opportunity\nOver **5 million active independent stores** globally lack professional search capabilities, while solutions from Alibaba or Amazon are not accessible. This project fills the \"middle layer\" gap.\n\n---\n\n### 🚀 Startup Project Two: **AutoTagger.ai — AI-Powered Automated Metadata Engine for Products**\n\n#### 💡 Positioning\nHelp businesses automatically generate high-quality product metadata (attributes, descriptions, category mappings), reducing manual operational costs.\n\n#### 🔧 Technical Foundation\n- Based on SIT (Semantic Item Tagging) + DG (Description Generation) from the paper\n- Use LLMs to extract fields such as brand, color, size, material, usage scenarios\n- Combine rule engines and small verification models to ensure accuracy\n\n#### 🎯 Core Features\n- Input raw product title → output structured JSON attributes\n- Auto-generate SEO-friendly short product descriptions\n- Automatic categorization into standard taxonomies (compatible with GB/T, eClass, UNSPSC)\n- Batch processing support for millions of SKUs\n\n#### 📈 Application Scenarios\n- Automate form filling when cross-border sellers upload products\n- Accelerate compliance review during platform onboarding\n- Data governance: unify product naming across different suppliers\n\n#### 💰 Revenue Model\n- B2B API call pricing\n- Integration with ERP and PIM (Product Information Management) systems\n- On-premise deployment options for large retailers\n\n---\n\n### 🚀 Startup Project Three: **SearchLens — Diagnostic and Optimization Tool for E-commerce Search Engines**\n\n#### 💡 Positioning\nAn analytics platform that monitors search quality and provides improvement recommendations—similar to an \"SEO tool\" but for e-commerce search engines.\n\n#### 🔧 Technical Foundation\n- Inspired by ablation study methodology in the paper, build an “impact factor analyzer”\n- Apply QR methods to detect dirty data (e.g., incorrect labels, ambiguous titles)\n- Simulate user queries to test recall and precision\n\n#### 🎯 Core Features\n- Automatically crawl platform search logs → analyze failure cases\n- Identify common issues: category mismatches, missing synonyms, translation errors\n- Provide actionable suggestions: which synonyms to add? Which titles need rewriting?\n- Generate A/B testing reports comparing pre- and post-optimization performance\n\n#### 📊 Output Format\n- Dashboard showing Search Health Score\n- Auto-generated priority optimization checklist\n- Exportable CSV/Excel reports for operations teams\n\n#### 📈 Target Customers\n- Emerging-market e-commerce platforms (Latin America, Middle East, Africa)\n- Chinese brands expanding overseas\n- Third-party service providers (e-commerce agencies)\n\n---\n\n## Conclusion\n\n| Dimension | Summary |\n|---------|--------|\n| **Paper Value** | Demonstrates how systematic engineering + LLMs can solve real-world multilingual e-commerce search challenges, emphasizing that **“data quality > model scale”**. |\n| **Key Insight** | Under resource constraints, **meticulous data processing + structured prompt design = strong competitive advantage**. |\n| **Entrepreneurial Potential** | All three directions can evolve into standalone SaaS products, tapping into the wave of digital transformation in cross-border e-commerce, with clear customer needs and technical moats. |\n\n> 🔗 Open-source repository: [https://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search](https://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search)  \n> Entrepreneurs are encouraged to fork this repo and build MVPs quickly to validate market demand.",
    "github": "https://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search",
    "hf": ""
}