{
    "id": "2508.15030",
    "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism",
    "summary": "Collab-REC is a multi-agent framework that generates travel recommendations from different angles using three agents based on large language models, and combines and optimizes the suggestions through multiple rounds of negotiation to enhance diversity and relevance.",
    "abstract": "We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions from complementary perspectives. A non-LLM moderator then merges and refines these proposals via multi-round negotiation, ensuring each agent's viewpoint is incorporated while penalizing spurious or repeated responses. Experiments on European city queries show that Collab-REC improves diversity and overall relevance compared to a single-agent baseline, surfacing lesser-visited locales that often remain overlooked. This balanced, context-aware approach addresses over-tourism and better aligns with constraints provided by the user, highlighting the promise of multi-stakeholder collaboration in LLM-driven recommender systems.",
    "category1": "Application Implementation",
    "category2": "Personal Tools",
    "category3": "Multi-Agent",
    "authors": "Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang W√∂rndl,Yashar Deldjoo",
    "subjects": [
        "Artificial Intelligence (cs.AI)"
    ],
    "comments": "",
    "keypoint": "- Collab-Rec is a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations.\n- Three LLM-based agents ‚Äî Personalization, Popularity, and Sustainability ‚Äî generate city suggestions from complementary perspectives.\n- A non-LLM moderator merges and refines the proposals via multi-round negotiation.\n- The negotiation process ensures each agent‚Äôs viewpoint is incorporated while penalizing spurious or repeated responses.\n- Experiments show Collab-Rec improves diversity and overall relevance compared to a single-agent baseline.\n- The framework surfaces lesser-visited locales that are often overlooked by traditional recommenders.\n- Collab-Rec addresses over-tourism and aligns better with user constraints.\n- The approach highlights the promise of multi-stakeholder collaboration in LLM-driven recommender systems.\n- The system uses a scoring function that integrates agent success, reliability, and hallucination penalty.\n- Multi-round negotiation significantly broadens recommendation diversity.\n- Collab-Rec outperforms non-LLM, single-agent, and single-round baselines in final success scores.\n- The framework reduces popularity bias and boosts recommendation diversity measured by GINI and Entropy metrics.\n- Agents become more reliable and reduce hallucinations across multiple negotiation rounds.\n- Multi-round negotiation increases computational overhead compared to single-round baselines.",
    "date": "2025-08-25",
    "paper": "Collab-REC: An LLM-based Agentic Framework for Balancing\nRecommendations in Tourism\nAshmi Banerjee\nashmi.banerjee@tum.de\nTechnical University of Munich\nMunich, Germany\nFitri Nur Aisyah\nfitri.aisyah@tum.de\nTechnical University of Munich\nMunich, Germany\nAdithi Satish\nadithi.satish@tum.de\nTechnical University of Munich\nMunich, Germany\nWolfgang W√∂rndl\nwoerndl@in.tum.de\nTechnical University of Munich\nMunich, Germany\nYashar Deldjoo\nyashar.deldjoo@poliba.it\nPolytechnic University of Bari\nBari, Italy\nAbstract\nWe propose Collab-Rec a multi-agent framework designed to coun-\nteract popularity bias and enhance diversity in tourism recommen-\ndations. In our setting, three LLM-based agents ‚Äî Personalization,\nPopularity, and Sustainability generate city suggestions from\ncomplementary perspectives. A non-LLM moderator then merges\nand refines these proposals via multi-round negotiation, ensuring\neach agent‚Äôs viewpoint is incorporated while penalizing spurious\nor repeated responses. Experiments on European city queries show\nthat Collab-Rec improves diversity and overall relevance com-\npared to a single-agent baseline, surfacing lesser-visited locales\nthat often remain overlooked. This balanced, context-aware ap-\nproach addresses over-tourism and better aligns with constraints\nprovided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.\nACM Reference Format:\nAshmi Banerjee, Fitri Nur Aisyah, Adithi Satish, Wolfgang W√∂rndl, and Yashar\nDeldjoo. 2025. Collab-REC: An LLM-based Agentic Framework for Balanc-\ning Recommendations in Tourism. In . ACM, New York, NY, USA, 11 pages.\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n1\nIntroduction and Context\nMotivation. Modern tourism platforms depend heavily on recom-\nmender systems to help users navigate a profusion of choices. Be-\nyond personalization, Tourism Recommender Systems (TRS) must\nalso consider destination popularity and sustainability factors,\nincluding reduced crowding, lower environmental impact, and eco-\nfriendly travel [2]. However, balancing these three aspects remains\nchallenging for any single recommender algorithm, those powered\nby large language models (LLMs) [4].\nRecent advances in generative recommenders show that LLMs\ncan enhance richer user experiences through natural explanations,\ndialogue, and nuanced personalization [13, 23, 25, 41]. However,\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nConference‚Äô17, Washington, DC, USA\n¬© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nthey also risk hallucinating content, amplifying biases, or leaking\nsensitive information [9, 18, 31, 32]. These emerging capabilities\nblur traditional boundaries between retrieval, ranking, and expla-\nnation, and single-LLM pipelines may yield opaque decisions, weak\nfactual grounding, or one-sided trade-offs (e.g., ignoring sustainabil-\nity factors because the model leans heavily on popularity data) [20].\nWhy Agentic Design? Distributing objectives across special-\nized agents offers a promising alternative [26]. Rather than relying\non a monolithic LLM to jointly optimize personalization, popu-\nlarity, and sustainability, an agentic design assigns each goal to a\ndedicated LLM agent. For instance, a Personalization Agent tailors\nrecommendations to user preferences like budget and interests, a\nPopularity Agent promotes diverse or lesser-known locations, and a\nSustainability Agent prioritizes eco-friendly or off-peak destinations.\nBy combining their outputs, the system leverages their \"collective\nintelligence\" while preventing any single objective, particularly\npopularity, from dominating results.\nHowever, simply assembling specialized agents is insufficient, as\neach LLM has inherent limitations: a popularity agent may overfit to\nmajor capitals, a sustainability agent may hallucinate environmen-\ntal data, and a personalization agent may misinterpret preferences\nor budget constraints.\nTo address these multifaceted requirements, we propose Collab-\nRec, an agentic framework in which multiple LLM-based agents\nfocus on different stakeholder objectives ‚Äî consumer person-\nalization, popularity, and sustainability, and negotiate in multiple\nrounds to produce city trip recommendations. As depicted in Fig-\nure 1, Collab-Rec encompasses three specialized agents, each fo-\ncusing on distinct stakeholder objectives:\n‚Ä¢ Popularity Agent: promotes lesser-exposed destinations;\n‚Ä¢ Personalization Agent: enforces strict filters (e.g., budget,\ntravel dates, interests);\n‚Ä¢ Sustainability Agent: prioritizes eco-centric criteria such\nas air quality, seasonality, and walkability.\nA non-LLM moderator then combines and scores the candidates\nproposed by these agents. During each round of iterative refinement,\nthe moderator:\n‚Ä¢ Grounds recommendations in an external knowledge base\nof 200 European cities to avert hallucination;\n‚Ä¢ Computes composite scores balancing relevance, reliability,\nand penalties for invalid or repeated (hallucinated) proposals;\nand\narXiv:2508.15030v1  [cs.AI]  20 Aug 2025\nConference‚Äô17, July 2017, Washington, DC, USA\nBanerjee et al.\n‚Ä¢ Releases a Collective Offer that becomes the basis for the next\nnegotiation round.\nOverall, research on multi-agent LLM systems shows that special-\nist agents, each with a narrow remit, can negotiate or debate their\nway to better answers on complex tasks [5, 7, 22, 43]. In recommen-\ndation, prototypes such as MACRec [37] and MATCHA [17] already\nsplit the work between a manager and various sub-agents, yet none\nhave been tailored to multistakeholder tourism and the three-way\ntension among consumer (user preferences), item provider (desti-\nnation popularity), and society (sustainability). We argue that an\nagentic architecture is particularly apt here for four reasons:\n‚Ä¢ Objective isolation: Each agent can optimize a single stake-\nholder goal. A Popularity Agent deliberately searches the\nlong tail; a Personalization Agent enforces hard filters; and a\nSustainability Agent promotes eco-friendly choices.\n‚Ä¢ Transparent negotiation: A non-LLM moderator can au-\ndit, penalize, or reward each agent‚Äôs behavior ‚Äî curbing\nhallucinations and revealing implicit trade-offs.\n‚Ä¢ Mitigation of model-internal bias: By design, the three\nagents pull in different directions. Their iterative compro-\nmise, orchestrated by the moderator, naturally dampens the\npopularity bias that a single LLM would otherwise reinforce.\n‚Ä¢ Graceful extensibility: New stakeholder roles (e.g., safety,\naccessibility) can be plugged in as additional agents with-\nout re-training the whole system, echoing calls for holistic\nevaluation and modular guardrails in the next-generation\nGen-RecSys [18].\nRelated Work\nWe now briefly review key research areas related to our approach.\nLLM-based Multi-Agent Systems. LLMs are increasingly deployed\nas autonomous, role-specific agents for tasks from problem-solving\nto decision-making [15, 38], with surveys [30, 42] reviewing inter-\naction, evaluation, and deployment challenges. While promising\nfor domains like CRM [16], such systems need reliability checks,\ndomain expertise, and remain prone to jailbreaks [1].\nFacilitating Interaction Between Agents. Effective multi-agent col-\nlaboration hinges on robust communication and negotiation proto-\ncols [5, 34, 40]. Multi-Agent Debate [6, 7, 10, 22, 44] enables iterative\ncritique and consensus, with studies [35] showing gains in summa-\nrization and Q&A. However, explicit majority voting can reduce\ndiversity [39], motivating implicit feedback and distinctive agent\nroles.\nMulti-Agent Recommender Systems. In recommendation, LLM-\nbased multi-agent systems appear mainly in conversational se-\ntups [12, 27, 36], often with a central \"manager\" or \"moderator\"\noverseeing specialized user, item, or retrieval agents. MATCHA [17]\nadds safeguard and explainability agents for gaming, while Liu et al.\n[21] apply multi-agent planning, communication, and profiling in\ntourism. Yet, these approaches overlook the joint influence of user\nconstraints, popularity, and sustainability, and rarely employ multi-\nround negotiation with penalties for repetition or invalidity‚Äîkey to\nreducing popularity bias and surfacing less-exposed options.\nLimitations of Existing Approaches. Most current multi-\nagent LLM frameworks either focus on domain-agnostic tasks (e.g.,\nQ&A) or treat recommendation from a purely single-objective lens\n(e.g., maximizing personalization alone) [21]. Meanwhile, existing\nmulti-stakeholder tourism recommenders have not leveraged LLM-\nbased multi-agent negotiation. This gap leaves open the question\nof how to jointly optimize personalization, popularity, and sustain-\nability within a single, integrated conversation pipeline. Our work\naims to fill this void, exploring the feasibility and benefits of an\niterative, penalty-aware approach that explicitly balances different\nstakeholder goals.\nContributions\nWe introduce Collab-Rec, a collaborative, multi-agent framework\nfor LLM-based tourism recommendations that explicitly balances\nuser constraints, popularity, and sustainability. Our main contribu-\ntions are as follows:\n‚Ä¢ Agentic Multi-Stakeholder Design: By delegating the\ntasks of personalization, popularity, and sustainability to spe-\ncialized LLM agents, Collab-Rec achieves richer, more bal-\nanced recommendations compared to single-agent pipelines.\n‚Ä¢ Multi-Round Negotiation: Agents iteratively propose and\nrefine city candidates under the guidance of a non-LLM mod-\nerator, which penalizes repeated or hallucinated suggestions.\nThis process fosters iterative compromise and significantly\nbroadens recommendation diversity.\n‚Ä¢ Scoring & Moderation for Bias Mitigation: A custom\nscoring function that integrates agent success (ùëüaùëñ,t), relia-\nbility (ùëëaùëñ,t), and hallucination penalty (‚Ñéaùëñ,t) helps curb the\npopularity bias often embedded in LLMs.\n‚Ä¢ Empirical Evaluation: Using synthetic and real-world travel\nqueries, we show that Collab-Rec yields systematically\nhigher relevance and diversity than single-round or single-\nagent baselines, thus promising a more equitable and eco-\nconscious travel recommender system.\nIn the remainder of this paper, we describe our system design\n(Section 2), experimental setup (Section 3), and evaluation results\n(Section 4), and conclude with potential future directions in Sec-\ntion 5.\n2\nAgentic Recommendation Framework\nGiven a complex user query Q, specialized agents (e.g., Popular-\nity, Sustainability, Constraints) handle subtasks reflecting different\nstakeholders in a multi-stakeholder tourism recommendation sce-\nnario. In each iteration, agents propose city candidates based on\ntheir criteria. A moderator module (see Figure 2) evaluates and\nintegrates these proposals using feedback, scoring metrics, and\nexternal knowledge, refining the collective recommendation until\ntermination criteria are met.\n2.1\nPreliminaries & System Goal\nProblem Setup. We consider a multi-agent recommendation sys-\ntem that generates city trip recommendations based on user queries\nand preferences. A user query Q is an input in natural language\nthat includes the user‚Äôs preferences and requirements for a city trip\nrecommendation. It also includes a set of structured filters denoted\nby F = {ùëì1, ùëì2, . . . , ùëìùëö} (e.g., budget, month, interests, etc.), where\neach filter f denotes an explicit constraint on the city attributes.\nAfter receiving the query, through multi-agent negotiation, the\nCollab-REC\nConference‚Äô17, July 2017, Washington, DC, USA\nUser Query (Q) : ‚ÄúEuropean cities with low popularity, great walkability, and high or medium season in September, with attractions like \nmuseums, historical sites, and cultural events.‚Äù\nTo align with the user‚Äôs \npreference for low-popularity‚Ä¶ \nwe replaced Amsterdam, \nLondon, and Paris with three \nstrong low-popularity \npicks‚ÄîCluj-Napoca, Sibiu, and \nLviv ‚Ä¶\nWe replaced three that were \neither overly crowded or less \nwalkable (Amsterdam, \nLondon, Arkhangelsk) with \nPorto, Bologna and \nCluj-Napoca. \nWe kept seven cities from the \ncurrent list that offer strong \nmuseum, history & cultural \nprogramming in September \nand added three lesser-known \ngems‚ÄîBrno, Bologna, and \nPorto\nPersonalization\nCollective Offer \n–§T: \n[Porto, Brno, \nBologna, \nCluj-Napoca, \nPrague‚Ä¶]\nCollective Offer \n–§1:\n[Paris, Aalborg, \nPrague, Vienna, \nLondon‚Ä¶]\nInitial candidates for low \npopularity ..\nInitial candidates for great \nwalkability ..\nInitial candidates for Arts & \nEntertainment in \nSeptember ..\nRound 1\nRound 2 ‚Ä¶ T\nCandidate \nGeneration\nAgent Prompt & Feedback\nUser Input\n‚óèUser Query\n‚óèUser Preferences\nFeedback\n‚ÄúCongrats! More than half of \nyour previous \nrecommendations were \nrelevant‚Ä¶ Warning! You \nrejected five cities in the \nprevious round. This violates \nthe instruction ‚Ä¶‚Äù\nExamples\n‚úÖ GOOD EXAMPLE\n‚ùå BAD EXAMPLE\nRound Context\n‚óèPrevious Recommendation\n‚óèCurrent Collective Offer\n‚óèOther Candidate Options\nM\nO\nD\nE\nR\nA\nT\nO\nR\nExternal\nKB\nSustainability\nPopularity\nPersonalization\nSustainability\nPopularity\nCollab-REC\nFigure 1: Overview of the Collab-Rec workflow to generate city trip recommendations using multiple LLM agents. The non-LLM\nModerator evaluates and combines the agent proposals, iterating through multiple rounds to refine the final recommendation\nset, which is then communicated to the user.\nsystem generates a ranked list of candidate cities Laùëñ,t that satisfy\nthe user preferences and constraints, from a catalog of all candidate\ncities C.\nNotation. Given a query ùëûwith filters F , our recommendation\nsystem uses multiple LLM-based agents and a non-LLM moderator\nin a multi-round interaction process. We denote rounds by ùë°=\n1, . . . ,ùëá, agents by ùëéùëñ‚ààA, and cities by ùëê‚ààC. The candidate list\ngenerated by agent ùëéùëñat round ùë°is denoted by Laùëñ,t.\nSystem Goal. The goal of the Collab-Rec framework is to select\nan ordered list of cities Œ¶ùëáat the final round T that maximizes the\ncumulative evaluation score ùë†(c, t):\nŒ¶ùëá= arg max\nùêøùëá\n|ùêøùëá|=ùëò\nh√ç\nùëê‚ààùêøùëáùë†(ùëê,ùëá)\ni\n,\n(1)\nwhere ùêøùëáranges over all possible city combinations of size ùëò,\nand ùë†(ùëê,ùëá) denotes the cumulative evaluation score of city ùëêat\nround ùëá. We define ùë†(ùëê,ùëá) as a combination of the hallucination\npenalty ‚Ñéaùëñ,t, agent success score ùëüaùëñ,t, and reliability score ùëëaùëñ,t.\nEach component is further described in Section 2.4.\n2.2\nArchitecture & Components\n2.2.1\nRecommender Agents. Each agent operates on a natural lan-\nguage query, a specified filter to focus on, the current collective\noffer, and a set of previously rejected candidates. Inspired by the\nmulti-stakeholder perspective in TRS [2], we instantiate three dis-\ntinct agents, each representing a key stakeholder group. Each agent\nproduces a recommendation list Laùëñ,t of candidate cities:\nFigure 2: Overview of the Collab-Rec Moderator core to gen-\nerate city trip recommendations using multiple LLM agents.\nThe moderator orchestrates the multi-round negotiation pro-\ncess, evaluates agent proposals, and aggregates them into a\nfinal recommendation list.\n(1) ùëé1: Item Popularity Agent ‚Äî aims to promote less popular\nitems by considering general popularity preferences inferred\nConference‚Äô17, July 2017, Washington, DC, USA\nBanerjee et al.\nfrom the query, thus mitigating popularity bias and item\nunfairness.\n(2) ùëé2: Personalization Agent ‚Äî focuses on user-specified prefer-\nences and travel filters (consumer-centric) such as budget,\npreferred month, and interest categories.\n(3) ùëé3: Sustainability Agent ‚Äî prioritizes sustainable travel rec-\nommendations, considering factors such as air quality in-\ndex (AQI), seasonality, and walkability. If no explicit sus-\ntainability preferences are provided, this agent defaults to\nrecommending the most sustainable cities available, which\nfocuses on the environment or society stakeholder as identi-\nfied in [2].\n2.2.2\nModerator Core. As seen in Figure 2 the moderator compo-\nnent, denoted as M, governs the interaction between agents and\norchestrates the multi-round negotiation process. It is a non-LLM\ndecision module responsible for the following tasks: detecting hal-\nlucinations, computing evaluation scores, and aggregating candidate\nlists into a final recommendation.\nAt each round t, the moderator receives the candidate lists Laùëñ,t\nfrom all agents, evaluates each city using the scoring function ùë†(ùëê,ùë°)\n(Equation 2), and constructs the Collective Offer ùúôt by selecting the\ntop-ùëòranked cities. Cities not accepted in previous rounds form\nthe Collective Rejection set ùúô‚Ä≤\nt. This updated context is passed back\nto the agents to guide the next round of recommendations.\nThese states are logged at each round, along with agent-specific\nsuccess and reliability metrics, enabling longitudinal analysis of ne-\ngotiation dynamics and agent behavior. Additionally, it has access\nto an external knowledge base (KB), which it leverages to ground\nagent responses and compute evaluation scores with factual con-\nsistency.\n2.3\nInteraction Protocol\nOur approach follows a multi-round interaction process in which\nthree agents, each representing a distinct stakeholder perspective,\ncollaborate iteratively to reach a consensus that maximizes overall\nrelevance. Each interaction loop consists of the following compo-\nnents:\n2.3.1\nAgent Instruction. Collab-Rec starts by prompting each\nagent to generate an initial top-ùëòrecommendation list based on the\nuser query Q and a set of travel-related filters F such as city popu-\nlarity, sustainability preferences, and user travel preferences. Each\nagent tailors its recommendations to the stakeholders it represents\n‚Äî popularity (item-provider-centric), sustainability (society-centric),\nor personalization (consumer-centric).\nIn each subsequent iteration, agents receive the current Collective\nOffer ùúôt from the moderator M and are instructed to revise their\ncandidate lists accordingly. Inspired by the Voting by Alternating\nOffers and Vetoes (VAOV) protocol used by Erlich et al. [11], we\npermit the agents to replace up to three items and must justify any\nchanges with supporting reasoning. We use in-context learning\nwith few-shot prompting during the iteration phase with good\nand bad examples of recommendations, tailored to each agent‚Äôs\nrespective preferences. The prompt provided to each agent at a\nround t consists of its own previous recommendation, the Collective\nOffer generated at the end of round t‚àí1, and specific feedback about\nits behavior intended to provide constructive criticism about the\nagent‚Äôs performance, similar to the strategy used by Wan et al. [35].\nThis feedback is generated based on (a) how many of the candidates\npreviously recommended by the agent are present in the Collective\nOffer and (b) the number of replacements.\n2.3.2\nHallucination Identification. Previous research has shown\nthat LLMs can run the risk of fabricating out-of-catalog items, lead-\ning to faulty recommendations [18]. To mitigate this, we incorporate\na grounding mechanism into the moderation process. The moder-\nator has access to a finite knowledge base (KB) of 200 European\ncities, each annotated with relevant metadata, used to ground agent\nresponses. Any candidate city proposed by an agent that is not\npresent in the KB or has already been rejected in a previous round\nis flagged as a hallucinated or non-grounded response. During\nthis phase, the moderator iteratively checks each candidate in the\nagent‚Äôs list Laùëñ,t for validity. If a hallucinated or previously rejected\ncity is found, the agent is prompted to substitute it with a valid\nalternative. This ensures that we maintain a consistent number\nof candidates across rounds, which is crucial for the negotiation\nprocess. To avoid infinite feedback loops, a maximum number of\niterations is enforced.\nIn our prototype implementation, this hallucination identifica-\ntion loop is executed only once per round to limit API usage and\ncomputational cost. If the agent continues to return to hallucinated\ncities after the first correction attempt, it is penalized during the\nevaluation phase (Section 2.4). However, our framework supports a\nconfigurable number of hallucination correction cycles to ensure\nall candidates ultimately conform to the query constraints.\n2.3.3\nGenerating Collective Offer. We define the Collective Offer\n(ùúôt) as a ranked list of cities that will be presented to each agent\nby the moderator in the next round of iterations ùë°+ 1. This list\nserves as a shared negotiation baseline for the specific round and\nreflects the most promising candidates according to the moderator‚Äôs\nevaluation. The collective offer is obtained by applying min-max\nnormalization [29] to the evaluation scores (explained in Section 2.4)\nof all candidate cities in the catalog C. The moderator then selects\nthe top-ùëòhighest-scoring cities, which constitute the collective\nrecommendation set returned to the agents for the next round of\nrefinement.\n2.3.4\nAggregation of Rejections. In this phase, we identify newly\nrejected cities by comparing each agent‚Äôs candidate list with the\nprevious collective offer. A city added to the Collective Rejection\n(ùúô‚Ä≤\nt) is excluded from future recommendations by both the agents\nand the moderator. We explore two rejection, or voting strategies\n(we use the terms \"rejection strategy\" and \"voting strategy\" inter-\nchangeably in the paper): Majority rejection (M), where a city\nis discarded if at least two agents omit it in their revised lists; and\nAggressive rejection, (A), where omission by even a single agent\nleads to rejection.\n2.4\nScoring Functions & Decision Rules\nOur framework relies on a set of scoring functions and decision\nrules implemented by the moderator to guide the multi-agent rec-\nommendation process. Specifically, the moderator evaluates each\nagent‚Äôs candidate list along three key dimensions ‚Äî groundedness\nCollab-REC\nConference‚Äô17, July 2017, Washington, DC, USA\nwith respect to the query filters (agent success), agent reliability,\nand hallucination rate. These evaluation criteria are detailed in Sec-\ntion 2.4.1, while Section 2.4.2 outlines the termination conditions\nand additional operational considerations of the framework.\n2.4.1\nGrounding & Assessment. In each round, the moderator eval-\nuates the agents and their recommended candidates across three\nkey dimensions ‚Äî Agent Success, Agent Reliability, and Hallucination\nRate.\nAgent Success. (ùëüaùëñ,t ‚àà[0, 1]) quantifies how well the agent‚Äôs\nrecommendations align with its assigned filters. It is calculated as\nthe average proportion of filters matched per candidate, based on\nthe filters specific to that agent.\nAgent Reliability. (ùëëaùëñ,t ‚àà[0, 1]) measures the consistency of\nan agent‚Äôs recommendations by quantifying changes in candidate\nrankings between two consecutive rounds, t ‚àí1 and t. A high-\nreliability score indicates that an agent‚Äôs recommendations remain\nstable over time.\nWe compute the reliability score ùëëaùëñ,t using three key compo-\nnents: (i) the cumulative change in rank positions for candidates\nappearing in both rounds, (ii) a drop penalty (ùúá1) for candidates\nthat were dropped between rounds, and (iii) an added penalty (ùúá2)\nfor newly introduced candidates. The drop penalty ùúá1 is set to the\nlength of the candidate list, while the add penalty ùúá2 is computed\nbased on the minimum rank deviation between the city‚Äôs position\nin the moderator‚Äôs Collective Offer and its position in the current\ncandidate list, capped by ùúá1. Specifically, ùúá2 is set to the minimum\nof the absolute rank difference and the base drop penalty, thereby\nassigning a lower penalty for cities selected from the collective\noffer. However, if a city is newly introduced by the agent and was\nnot present in the previous Collective Offer, it is penalized with\nthe maximum value, ùúá1, to discourage hallucinated or ungrounded\nadditions.\nHallucination Rate. (‚Ñéaùëñ,t ‚àà[‚àí1, 0]) While the Hallucination\nIdentification stage (Section 2.3.2) provides an initial check and asks\nthe agent to replace candidates that are either (i) out-of-catalog or\n(ii) rejected, the LLMs can still fail to obey. In order to account for\nthis scenario and penalize an agent that continues to hallucinate\neven beyond the initial check, we introduce the Hallucination Rate,\nor ‚Ñéaùëñ,t, as a penalty during the assessment phase. We define ‚Ñéaùëñ,t\nas the negated hit rate between the agent‚Äôs candidate list Laùëñ,t and\nthe available cities (C \\ ùúô‚Ä≤\nt) in the catalog.\nEvaluation Score. We compute the evaluation score (Equation 2),\nùë†(c, t), for each recommended city c for round t as the sum of the\nagent success (ùëüaùëñ,t) and agent reliability (ùëëaùëñ,t) negated by agent\nhallucination (‚Ñéaùëñ,t) for the current round added to the evaluation\nscore from the previous round t ‚àí1.\nùë†(c, t) = ùë†(c, t ‚àí1) +\n‚àëÔ∏Å\naùëñ‚ààA\n\u0012\n1\nùëüùëéùëõùëò(caùëñ) ¬∑ (‚àí‚Ñéaùëñ,t + ùëüaùëñ,t + ùëëaùëñ,t)\n\u0013\n(2)\nWe consider the reciprocal rank of the city in the agent‚Äôs candi-\ndate list to ensure that higher-ranked cities contribute more to the\nevaluation score as a way to prioritize more relevant candidates.\nThe new collective offer, ùúôt for round t, is the top-ùëòcities, ranked\naccording to their corresponding normalized evaluation scores.\n2.4.2\nTermination Criteria & Complexities. The termination crite-\nria for agent interactions are defined in two ways. First, we intro-\nduce a metric-based condition termed Moderator Success, computed\nanalogously to Agent Success (Section 2.4) but evaluated over the\nCollective Offer with respect to all travel filters, rather than only\nthe filters relevant to a specific agent. If the moderator success score\nreaches its maximum value of 1 or achieves an improvement of ùúè%\nover the score at round 0, the process is terminated via early stop-\nping. However, since this ideal score may not always be attainable,\nwe enforce a maximum of T interaction rounds to ensure termi-\nnation and avoid potential infinite loops. Additionally, we enforce\na minimum number of conversation rounds (set empirically at 5\nrounds) to ensure interaction between agents and avoid premature\ntermination.\n3\nExperiments\n3.1\nSetup\n3.1.1\nDataset. To evaluate Collab-Rec, we use a stratified sample\nof 45 queries from the SynthTRIPS dataset [3], a synthetic dataset\nconsisting of over 4000 queries comprising diverse consumer and\nsustainability preferences. These queries are broad, covering sim-\nple queries to more complex and specific requests generated to\nsimulate end-users interacting with a tourism recommender sys-\ntem. We specifically select queries across three popularity levels\n(low, medium, and high) and three complexity tiers (medium, hard,\nand sustainable). We randomly sample 5 queries for each of these 9\n(popularity, complexity) combinations, with the resulting 45 queries\nreflecting tasks such as ‚ÄúPlan a budget-friendly 3-day trip to a less\ncrowded coastal city in Europe‚Äù or ‚ÄúSuggest a moderately priced\nmetropolis known for art galleries,‚Äù each containing explicit filters\n(e.g., budget, month) and implicit constraints (e.g., local culture,\nsustainability). Overall, this yields a balanced set of user prompts\nwith realistic constraints (e.g., budget, travel dates, sustainability\nconcerns) while controlling computational overhead. Notably, Syn-\nthTRIPS queries stem from LLMs themselves, but we exclude those\ngenerated by Gemini (one of our tested LLMs) to avoid any overfit-\nting or bias in evaluating our approach.\n3.1.2\nExternal Knowledge Base. To validate agent outputs and de-\ntect hallucinations, Collab-Rec leverages the SynthTRIPS knowl-\nedge base (KB) [3], containing 200 European cities. Each city has\nattributes relevant to popularity, budget, seasonality, and sustainabil-\nity, among others. During each negotiation round, the moderator\nuses this KB to:\n(1) Compute Agent Success (ùëüaùëñ,t) by matching filters against the\nmetadata of the city,\n(2) Identify Hallucinations if an agent recommends a city not found\nin the KB or already rejected in a prior round.\n3.2\nExperimental Settings\n3.2.1\nImplementation Details. We focus primarily on the Multi-\nAgent Multi-Iteration (MAMI) setup, running it on all 45 queries.\nThe three specialized agents (Popularity, Sustainability, Personal-\nization) each use the same LLM backbone for fairness. Negotiation\nConference‚Äô17, July 2017, Washington, DC, USA\nBanerjee et al.\nproceeds up to T = 10 rounds (unless early-stopped). In each round\nùë°:\n‚Ä¢ Each agent proposes a top-ùëòlist of cities (ùëò= 10), with newly\nintroduced or replaced items clearly justified.\n‚Ä¢ The moderator detects and attempts to correct any hallucinated\ncity by prompting the agent for a valid alternative.\n‚Ä¢ Final proposals are scored and combined into a Collective Offer,\nwhich is returned to all agents to guide the next round.\nInitialization. At round 0, we assign each agent the ideal starting\nvalues of ùëëaùëñ,t = 1, ‚Ñéaùëñ,t = 0, and no penalty from previous offers.\nIn practice, the first actual proposals from the agents are generated\nin round 1, at which point their real reliability and hallucination\nrates begin to diverge.\n3.2.2\nBaselines: Traditional non-LLM: TopPop and RandRec\nand LLM-based: SASI and MASI. To assess the impact of multi-\nround interaction, we compare MAMI against four simpler base-\nlines: two standard non-LLM approaches from the literature and\ntwo simplified variants of our own framework.\n‚Ä¢ RandRec (Random Recommender): A non-LLM method that\nignores user preferences and returns a reproducible random set\nof ùëò= 10 recommendations per query [24].\n‚Ä¢ TopPop (Top Popularity Recommender): A non-personalized\nheuristic that always recommends the most popular items, in-\ndependent of user preferences [8].\n‚Ä¢ SASI (Single-Agent Single-Iteration): A single LLM is prompted\nwith the entire query (including filters). It returns a ranked list\nof ùëò= 10 cities in one shot, without any negotiation.\n‚Ä¢ MASI (Multi-Agent Single-Iteration): All three agents pro-\nduce their initial ùëò= 10 proposals. The moderator fuses them\n(after a single check for hallucinations) into a final recommen-\ndation, with no iterative refinement.\n3.2.3\nModels. All experiments use two reasoning LLMs:\n(1) gpt-o4-mini [28]\n(2) gemini-2.5-flash [33]\nWe also tested non-reasoning variants (claude-3.5-sonnet, gemini-\n2.0-flash, deepseek-chat-v3) but found they consistently ignored\nfeedback and failed to adapt across rounds. Hence, we exclude\nthem from final reporting.\n3.3\nEvaluation Metrics\nWe measure performance from two perspectives:\n(1) Final Recommendation Quality\n‚Ä¢ Relevance. We capture how well the final Collective Offer\nmatches all user filters. Concretely, we define Moderator Suc-\ncess as an analog to Agent Success, but scored over all user\nconstraints in the final offer. A score of 1 indicates that every\nrecommended city fully matches the user filters.\n‚Ä¢ Diversity. To assess whether the system avoids over-concentrating\non top-tier tourist hubs, we compute the GINI Index [14]\n(lower = more evenly distributed) and Normalized Entropy [19]\n(higher = more variety) over the final recommended set of\ncities.\n(2) Agent Behavior (per round)\n‚Ä¢ Reliability (ùëëaùëñ,t) measures how much each agent‚Äôs candidate\nlist changes from one round to the next.\n‚Ä¢ Hallucination Rate (‚Ñéaùëñ,t) is a negative penalty in [‚àí1, 0] that\ntracks out-of-catalog or previously rejected cities that persist\ndespite the moderator‚Äôs warnings.\nSummary of Experimental Goals. Ultimately, building on Sec-\ntion 2, we seek to answer four key research questions:\nRQ1: Does the multi-agent, multi-iteration (MAMI) approach en-\nhance final recommendation quality compared to single-agent\n(SASI), single-round (MASI), or traditional non-LLM RecSys\nbaselines (RandRec and TopPop)?\nRQ2: Does MAMI help reduce popularity bias and increase cover-\nage of lesser-known destinations?\nRQ3: How do the specialized agents evolve internally across re-\npeated negotiation, in terms of reliability and hallucinations?\nRQ4: What time and cost overheads does MAMI introduce, and\nhow might these overheads be mitigated?\nIn the next Section 4, we evaluate the outcomes of these experi-\nments, discussing system-level impact (RQ1, RQ2) as well as agent\nbehavior (RQ3) and computational costs (RQ4).\n4\nResults & Discussions\nAt a high level, throughout the subsequent RQ analysis, we aim\nto investigate whether enabling multiple agents to negotiate over\nmultiple iterations (MAMI) yields tangible benefits compared to:\n‚Ä¢ Traditional Non-LLM RecSys baselines (RandRec, and Top-\nPop)\n‚Ä¢ Single-agent single-iteration (SASI), and\n‚Ä¢ Multi-agent single-iteration (MASI)\nWe evaluate our proposed multi-agent, multi-round negotiation\nsystem (MAMI) against these baselines across four key research\nquestions (RQs) on a set of 45 representative queries as elaborated\nin Section 3.1.1. We employ statistical significance testing with\nmultiple comparison tests across the distributions of results ob-\ntained from the queries to ensure robust analysis. For MAMI, we\nexamine the effect of varying early stopping thresholds‚Äî20% (M20),\n60% (M60), and None (MN, continuing for all T rounds) to evaluate\ntheir influence on negotiation dynamics and outcomes.\nRQ1. System-Level Impact\nFirst, we begin by analyzing RQ1: ‚ÄúDo Multiple Agents and Multiple\nRounds Improve Outcomes?‚Äù, where success is measured in terms\nof the overall effectiveness of the collective offer (i.e., how well\nthe combined recommendations meet user constraints and agent-\nspecific objectives).\nDominance & Negotiation Dynamics. Figure 3 shows each\nagent‚Äôs as well as the Collective Offer‚Äôs success score across ne-\ngotiation rounds, split into three query types: (a) Low popularity,\n(b) Medium popularity, and (c) High popularity. Here, an agent\nshows high success if it satisfies its own objectives (e.g. popularity,\nsustainability) whereas a high success for the collective implies that\nall the cities satisfy all stakeholder requirements.\nWe see that for high-popularity queries (panel c), the Popular-\nity agent tends to dominate early (blue lines climbing above 0.95\nby round 3). For example, if a user specifically asks about ‚ÄúParis‚Äù\nCollab-REC\nConference‚Äô17, July 2017, Washington, DC, USA\nor ‚ÄúRome,‚Äù the Popularity agent can easily fulfill the constraints us-\ning abundant travel data. Conversely, for low-popularity queries\n(panel a), we observe that the Popularity agent struggles (success\nscore often below 0.3 in the first few rounds), while the Sustainabil-\nity and Personalization agents maintain higher scores (‚àº0.7‚Äì0.8).\nThis dynamic suggests that multi-round negotiation allows each\nagent to ‚Äúshine‚Äù in scenarios where it is most relevant. Ultimately,\nthe Collective Offer (purple line) reflects a compromise of all three\nagents‚Äô proposals, typically converging around 0.7‚Äì0.8 after several\nrounds.\nBeyond these per-agent curves, Table 1 and Table 2 summarize\noverall system-level outcomes against the baselines:\n‚Ä¢ Table 1 shows final collective-offer success scores for two\ntraditional baselines (RandRec, TopPop) and three LLM-\nbased systems (SASI, MASI, MAMI). MAMI consistently\nscores highest (0.75‚Äì0.85), outperforming RandRec (0.59),\nTopPop (0.70), SASI (0.70‚Äì0.75), and MASI (0.65‚Äì0.75), em-\nphasizing not only the advantages of LLM-based recom-\nmenders compared to traditional non-LLM baselines, but\nalso the dominance of the agentic negotiation framework\nrelative to single-LLM or single-iteration systems.\n‚Ä¢ Table 2 shows the results of pairwise statistical significance\ntests (ANOVA with post-hoc Bonferroni correction). We see\nthat MAMI outperforms both SASI and MASI with ùëù-values\nunder 0.01, confirming that multiple agents plus multiple\nrounds lead to significantly better final recommendations.\nMeanwhile, there is no statistically significant difference be-\ntween SASI and MASI (corrected ùëù-value > 0.05), suggest-\ning that merely adding agents without iterative negotiation\nbrings only limited gains.\nFrom a practical perspective, these findings indicate that repeated\nrefinement across agents ‚Äîwhere each agent proposes, critiques,\nand updates its suggestions ‚Äî is key to generating higher-quality\ncity recommendations. For instance, in one sample query:\n‚ÄúFind me a mid-sized European city that‚Äôs child-friendly\nand not too expensive.‚Äù\nSASI often returns well-known but moderately priced capitals\n(e.g., Budapest). MASI introduces some variety but is still skewed\ntoward popular tourist centers. In contrast, the multi-agent multi-\nround (MAMI) negotiation yields final lists with additional mid-tier\ncities that are more aligned to the user‚Äôs constraints (e.g., Ghent,\nLi√®ge), demonstrating the benefits of iterative agent interplay.\nAnswer to RQ1. Multiple agents and multiple negotiation rounds\n(MAMI) outperform non-LLM, single-agent and single-round base-\nlines in terms of final success scores, as shown by Table 1 and signifi-\ncance tests in Table 2. The iterative interaction allows each agent to\nbetter address the user‚Äôs constraints and prevents any single agent\n(e.g., Popularity) from dominating unless truly appropriate.\nRQ2. The Impact of Negotiation on Popularity\nBias and Diversification\nWe now specifically focus on how well each approach (SASI, MASI,\nMAMI) balances popularity versus lesser-known destinations. While\nTable 1: Overall system performance (Moderator Success\n‚Üë) comparing non-LLM baselines (RR: RandRec, TP: Top-\nPop) with LLM-based approaches (SASI, MASI, M20/M60/MN:\nMAMI with 20%, 60%, and no early stopping). Bold values\ndenote significant differences to SA; bold blue denotes sig-\nnificant differences between SA and MA. Significance is com-\nputed using multiple comparison t-tests with Bonferroni\ncorrection ùõº= 0.017.\nNon-LLM\nbaselines\nLLM-based Approaches\nRR\nTP\nModel\nRejection\nStrategy\nSASI\nMASI\nM20\nM60\nMN\n0.59\n0.70\nGPT4\nA\n0.741\n0.707\n0.802\n0.807\n0.672\nM\n0.717\n0.811\n0.772\n0.672\nGemini\nA\n0.727\n0.693\n0.859\n0.843\n0.683\nM\n0.730\n0.783\n0.772\n0.685\nTable\n2:\nPairwise\nstatistical\ncomparison\nresults\nfor\ngemini-2.5-flash at ùúè\n= 20%. The corrected p-values are\nadjusted using Bonferroni correction ùõº= 0.017.\nGroup 1\nGroup 2\nStat.\np-value\nCorrected\np-value\nReject ùêª0\nMAMI\nMASI\n3.6661\n0.0004\n0.0013\nTrue\nMAMI\nSASI\n3.1637\n0.0021\n0.0064\nTrue\nMASI\nSASI\n-0.7555\n0.452\n1.0000\nFalse\nSection 4 established that multi-round negotiation improves over-\nall outcomes, here we examine which cities ultimately get recom-\nmended and whether agent interplay curbs the tendency to over-\nrely on famous locales.\nMitigating Popularity Bias. Figure 4 and Table 3 (GINI and\nEntropy metrics) reveal that:\n‚Ä¢ Non-LLM baselines (RR: RandRec, TP: TopPop) illustrate\ndistribution extremes: TopPop‚Äôs repeated recommendations\nproduce maximal entropy and minimal GINI (perfect unifor-\nmity), while RandRec‚Äôs variability lowers entropy and raises\nGINI through unequal city frequencies.\n‚Ä¢ SASI skews heavily towards well-known hubs such as Paris,\nBarcelona, or Berlin. For instance, across low-popularity queries,\nSASI re-suggests popular capitals in roughly 60% of its final\noutputs.\n‚Ä¢ MASI improves slightly but still exhibits notable concentra-\ntion on top-tier tourist cities (GINI around 0.44‚Äì0.50).\n‚Ä¢ MAMI shows the most diverse outcomes: GINI drops to\nas low as 0.28 (and normalized entropy rises above 0.80)\nwhen the moderator enforces iterative corrections. However,\nunlike TopPop, they maintain strong recommendation rele-\nvance, outperforming both baselines in effectiveness while\npreserving balanced popularity coverage. Concretely, MAMI\nfrequently surfaces smaller or mid-sized European destina-\ntions (e.g., Trento, Malaga, and Cluj-Napoca) that were almost\nnever mentioned in SASI‚Äôs final lists.\nConference‚Äô17, July 2017, Washington, DC, USA\nBanerjee et al.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n0.2\n0.4\n0.6\n0.8\nAgent Success Score\n(a) Low\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n0.2\n0.4\n0.6\n0.8\nAgent Success Score\n(b) Medium\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAgent Success Score\n(c) High\nFigure 3: Agent Dominance when split by the popularity levels of the queries. Sustainability and personalization agents tend\nto dominate for medium and low popularity queries, but the popularity agent takes a substantial lead for high popularity\nqueries, signaling a potential popularity bias inherent in pre-trained models. ‚Äî‚Äî (dotted line) represents the results from\ngemini-2.5-flash while ‚Äî (continuous line) represents the results from gpt-o4-mini .\nFor a practical example, suppose a user requests ‚Äúan affordable\ncoastal city in Europe, less crowded, with strong local culture.‚Äù Single-\nagent systems often default to major (cheaper) coastal spots like\nValencia or Split. However, in the multi-agent multi-iteration ne-\ngotiation setting, all three agents are able to reach consensus by\nround 3 or 4, so that the final recommendation set incorporates both\nrecognized cities and lesser-known coastal gems (e.g., Thessaloniki,\nVarna).\nAnswer to RQ2. Multi-agent negotiation demonstrably reduces\npopularity bias and boosts recommendation diversity. Successive rounds\nof agent interplay ensure popular cities do not automatically domi-\nnate when less mainstream destinations better match user constraints.\nMeasured by GINI & Entropy (Table 3), MAMI achieves significantly\nbroader coverage across popularity tiers, addressing a key concern in\ntravel recommender systems.\nTable 3: GINI Index and Normalized Entropy of final candi-\ndates across popularity. Bold values denote optimum values\nper model and LLM setting ‚Äî minimum for GINI (‚Üì) and max-\nimum for Entropy (‚Üë). Non-LLM baselines (RR: RandRec, TP:\nTopPop) are included for comparison.\nScoring\nNon-LLM\nbaselines\nModel\nRejection\nStrategy\nLLM-based Approaches\nRR\nTP\nSASI\nMASI\nM20\nM60\nMN\nGINI ‚Üì\n0.504\n0.34\nGPT4\nA\n0.548\n0.441\n0.329\n0.367\n0.367\nM\n0.505\n0.427\n0.447\n0.447\nGemini\nA\n0.553\n0.495\n0.287\n0.342\n0.342\nM\n0.490\n0.372\n0.372\n0.355\nEntropy ‚Üë\n0.865\n0.940\nGPT4\nA\n0.451\n0.634\n0.823\n0.732\n0.732\nM\n0.534\n0.692\n0.732\n0.732\nGemini\nA\n0.431\n0.548\n0.865\n0.761\n0.761\nM\n0.546\n0.764\n0.764\n0.782\nRQ3. Agent Reliability and Hallucinations\nHaving established the advantages of our proposed multi-agent,\nmulti-round setup (MAMI) ‚Äî notably in terms of improved per-\nsonalization and greater recommendation diversity, we now turn\nour attention to less-explored aspects of agentic recommender sys-\ntems. In particular, we seek to answer: How do specialized agents\nbehave over multiple negotiation rounds, especially with respect to\ntheir reliability and susceptibility to hallucination?\nReliability Trends. Figure 5 (figures (a) and (b)) compares the\nreliability score of each agent over multiple rounds, under both\nAggressive and Majority voting strategies. Recall that reliability\nindicates how consistently city proposals by an agent follow its\nown prior round, i.e., how stable its suggestions remain once it\nreceives feedback. We initialize the reliability of each agent at 1.0\n(round 0), then observe an immediate drop in round 1‚Äî- (red circle\nin Figure 5 top row) once negotiation begins and the collective\noffer by the moderator forces agents to reassess their candidates. In\nsubsequent rounds, reliability steadily increases because the agents\nconverge on stable, negotiation-driven recommendations. Majority\nvoting (right side) tends to yield higher final reliability (‚â≥0.8) than\nAggressive rejection, which is stricter and drives more frequent\nchanges in agent proposals.\nHallucination Rate. Figure 5 (figures (c) and (d)) tracks each hallu-\ncination rate by each agent ‚Äî the fraction of city proposals that are\ninvalid (not in the knowledge catalog) or incorrectly grounded. Al-\nthough the moderator attempts to correct such invalid suggestions,\nthe agents can still hallucinate. Overall, we see modest improve-\nments over the rounds: e.g., the hallucination rate for gpt-o4-mini\nunder Aggressive rejection drops from ‚àº0.25 in round 1 to ‚àº0.15\nin round 6. Meanwhile, the Majority approach usually shows lower\nhallucination overall, since it constrains the agents less harshly,\nmaking it easier for them to refine ‚Äî rather than replace ‚Äî their\ncandidate lists.\nFor example, when asked to recommend cultural city hidden\ngems, the Sustainability agent suggests Pozna≈Ñ. While this is a suit-\nable choice, it is not present in the item catalog. The moderator\npromptly flags it as invalid, prompting the agent to adhere better to\nthe instruction. In the next round, the Sustainability agent proposes\nKo≈°ice, a similarly sustainable city that is, however, included in the\ncontext. These feedback loops help prevent out-of-catalog recom-\nmendations while ensuring a comparable alternative is suggested.\nAnswer to RQ3. Agents become more reliable and gradually re-\nduce hallucinations across multiple negotiation rounds. The iterative\nmoderator feedback and scoring scheme effectively penalizes invalid\nproposals, guiding all agents toward more stable, factually valid cities.\nCollab-REC\nConference‚Äô17, July 2017, Washington, DC, USA\n(a) SASI\n(b) MASI\n(c) MAMI\nFigure 4: City Distributions when split by the popularity levels of the recommended cities for 50 randomly sampled cities.\nFor brevity, the x-axis represents the IATA codes of the respective cities. MAMI tends to provide lesser-known cities as a\nrecommendation when compared to SASI and MASI.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nAgent Reliability Score\nAgents\nPopularity\nPersonalization\nSustainability\n(a) Reliability: Aggressive\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nAgent Reliability Score\n(b) Reliability: Majority\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n?0.25\n?0.20\n?0.15\n?0.10\n?0.05\n0.00\nHallucination Score\nAgents\nPopularity\nPersonalization\nSustainability\n(c) Hallucination: Aggressive\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nRounds\n?0.12\n?0.10\n?0.08\n?0.06\n?0.04\n?0.02\n0.00\nHallucination Score\n(d) Hallucination: Majority\nFigure 5: Agent Behavior metrics showing the agents‚Äô reliability score and hallucination rate over multiple rounds. ‚Äî‚Äî (dotted\nline) represents the results from gemini-2.5-flash while ‚Äî (continuous line) represents the results from gpt-o4-mini .\n0 1 2 3 4 5 6 7 8 9\nRound Number\n50\n100\nAvg. Exec. Time (s)\nModel\nGemini2Point5Flash\nGPTo4Mini\nFigure 6: Average time taken for Collab-Rec for 10 rounds\nfor two models using Aggressive strategy.\nRQ4. Time & Cost Complexity of Multi-Agent\nNegotiation\nHaving analyzed the qualitative benefits of multi-agent negotiation,\nwe now turn to its practical implications. Specifically, in this RQ\nwe ask: RQ4: How does the multi-round, multi-agent negotiation\nprotocol (MAMI) affect inference time and token usage compared to\nsingle-round baselines?\nIncreased Overhead. Figure 6 shows the average time per round\nfor gpt-o4-mini and gemini-2.5-flash under Aggressive rejection.\nBy round 10, the system takes over 100 seconds per round for\neach query (totaling ‚àº1000 seconds per query), as each of the\nthree agents issues an updated set of proposals and the moderator\nprocesses them. Over 45 queries, MAMI consumes about 7.4 million\ntokens and 2700 API calls per model, nearly 60√ó the cost of SASI ‚Äî\nwhich calls a single agent in a single iteration.\nTrade-Off: Quality vs. Cost. MASI partially mitigates this\noverhead but lacks the iterative refinement that boosts relevance\nand diversity. Meanwhile, MAMI achieves superior recommenda-\ntion quality at the expense of lengthy run times and higher token\nusage. This underscores a practical tension in real-world deploy-\nment: iterative negotiation fosters better results but raises concerns\nover latency and carbon footprint. Methods like early stopping,\ncaching, or agent pruning (e.g., removing an agent once its score\nstabilizes) could alleviate these costs in future work.\nAnswer to RQ4. Multi-round approach by MAMI substantially\noutperforms single-round baselines at the cost of higher computational\noverhead. For large-scale or real-time systems, this trade-off may re-\nquire optimizations (e.g., early stopping or partial agent involvement)\nto balance quality with efficiency.\n5\nConclusion\nWe present Collab-Rec, a multi-agent LLM framework that bal-\nances personalization, sustainability, and popularity through iter-\native agent negotiation. Experiments show that Collab-Rec im-\nproves relevance and diversity over single-agent baselines while\nreducing hallucinations via grounded moderation.\nHowever, Collab-Rec has limitations: reliance on a fixed city\ncatalog limits adaptability, and iterative negotiation increases com-\nputational cost. Popularity bias can still persist when users request\nConference‚Äô17, July 2017, Washington, DC, USA\nBanerjee et al.\npopular destinations. Future work could explore extending the num-\nber of negotiation rounds to study longer-term convergence trends,\nas well as introducing sampling strategies to reduce the candidate\npool presented to agents. This may help lower hallucination rates by\nnarrowing the decision space, especially in high-complexity scenar-\nios. Overall, Collab-Rec demonstrates the promise of collaborative\nLLM agents for balanced recommendations.\nGenAI Usage Disclosure\nWe used ChatGPT (OpenAI) for code snippet suggestions during\nthe development of this work. We also used Grammarly to check\nfor grammar inconsistencies in the paper and to refine the text for\nbetter clarity. We have critically reviewed and revised all GenAI\noutputs to ensure that accuracy and originality are maintained, and\nwe accept full responsibility for the content presented in this draft.\nReferences\n[1] Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas,\nMaxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, Zico Kolter, Matt Fredrik-\nson, et al. 2024. Agentharm: A benchmark for measuring harmfulness of llm\nagents. arXiv preprint arXiv:2410.09024 (2024).\n[2] Ashmi Banerjee, Paromita Banik, and Wolfgang W√∂rndl. 2023. A review on indi-\nvidual and multistakeholder fairness in tourism recommender systems. Frontiers\nin big Data 6 (2023), 1168692.\n[3] Ashmi Banerjee, Adithi Satish, Fitri Nur Aisyah, Wolfgang W√∂rndl, and Yashar\nDeldjoo. 2025. SynthTRIPs: A Knowledge-Grounded Framework for Benchmark\nData Generation for Personalized Tourism Recommenders. (2025), 3743‚Äì3752.\ndoi:10.1145/3726302.3730321\n[4] Ashmi Banerjee, Adithi Satish, and Wolfgang W√∂rndl. 2024. Enhancing tourism\nrecommender systems for sustainable city trips using retrieval-augmented gener-\nation. In International Workshop on Recommender Systems for Sustainability and\nSocial Good. Springer, 19‚Äì34.\n[5] Federico Bianchi, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan\nJurafsky, and James Zou. 2024. How Well Can LLMs Negotiate? NegotiationArena\nPlatform and Analysis. In International Conference on Machine Learning. PMLR,\n3935‚Äì3951.\n[6] Justin Chen, Swarnadeep Saha, and Mohit Bansal. 2024. ReConcile: Round-\nTable Conference Improves Reasoning via Consensus among Diverse LLMs. In\nProceedings of the 62nd Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), Lun-Wei Ku, Andre Martins, and Vivek\nSrikumar (Eds.). Association for Computational Linguistics, Bangkok, Thailand,\n7066‚Äì7085. doi:10.18653/v1/2024.acl-long.381\n[7] Xi Chen, Mao Mao, Shuo Li, and Haotian Shangguan. 2025. Debate-Feedback: A\nMulti-Agent Framework for Efficient Legal Judgment Prediction. In Proceedings\nof the 2025 Conference of the Nations of the Americas Chapter of the Association\nfor Computational Linguistics: Human Language Technologies (Volume 2: Short\nPapers). 462‚Äì470.\n[8] Paolo Cremonesi, Franca Garzotto, Sara Negro, Alessandro Vittorio Papadopoulos,\nand Roberto Turrin. 2011. Looking for ‚Äúgood‚Äù recommendations: A comparative\nevaluation of recommender systems. In IFIP Conference on Human-Computer\nInteraction. Springer, 152‚Äì168.\n[9] Yashar Deldjoo, Nikhil Mehta, Maheswaran Sathiamoorthy, Shuai Zhang, Pablo\nCastells, and Julian McAuley. 2025. Toward Holistic Evaluation of Recommender\nSystems Powered by Generative Models. SIGIR‚Äô25 (2025).\n[10] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch.\n2023. Improving factuality and reasoning in language models through multiagent\ndebate. In Forty-first International Conference on Machine Learning.\n[11] Sefi Erlich, Noam Hazon, and Sarit Kraus. 2018. Negotiation strategies for agents\nwith ordinal preferences. arXiv preprint arXiv:1805.00913 (2018).\n[12] Jiabao Fang, Shen Gao, Pengjie Ren, Xiuying Chen, Suzan Verberne, and\nZhaochun Ren. 2024. A multi-agent conversational recommender system. arXiv\npreprint arXiv:2402.01135 (2024).\n[13] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei\nZhang. 2023. Chat-REC: Towards Interactive and Explainable LLMs-Augmented\nRecommender System. arXiv:2303.14524 [cs.IR]\n[14] Joseph L Gastwirth. 1972. The estimation of the Lorenz curve and Gini index.\nThe review of economics and statistics (1972), 306‚Äì316.\n[15] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V\nChawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language model based\nmulti-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680\n(2024).\n[16] Kung-Hsiang Huang, Akshara Prabhakar, Sidharth Dhawan, Yixin Mao, Huan\nWang, Silvio Savarese, Caiming Xiong, Philippe Laban, and Chien-Sheng Wu.\n2024. CRMArena: Understanding the Capacity of LLM Agents to Perform Pro-\nfessional CRM Tasks in Realistic Environments. arXiv preprint arXiv:2411.02305\n(2024).\n[17] Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun\nYoon, Rachit Pareek, and Michelle Gong. 2025. MATCHA: Can Multi-Agent\nCollaboration Build a Trustworthy Conversational Recommender? arXiv preprint\narXiv:2504.20094 (2025).\n[18] Chumeng Jiang, Jiayin Wang, Weizhi Ma, Charles LA Clarke, Shuai Wang, Chuhan\nWu, and Min Zhang. 2025. Beyond Utility: Evaluating LLM as Recommender. In\nProceedings of the ACM on Web Conference 2025. 3850‚Äì3862.\n[19] Lou Jost. 2006. Entropy and diversity. Oikos 113, 2 (2006), 363‚Äì375.\n[20] Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, and Yi Yang. 2024. A survey on LLM-based\nmulti-agent systems: workflow, infrastructure, and challenges. Vicinagearth 1, 1\n(2024), 9.\n[21] Binwen Liu, Jiexi Ge, and Jiamin Wang. 2025. Vaiage: A Multi-Agent Solution to\nPersonalized Travel Planning. arXiv preprint arXiv:2505.10922 (2025).\n[22] Yuhan Liu, Yuxuan Liu, Xiaoqing Zhang, Xiuying Chen, and Rui Yan. 2025.\nThe Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large\nLanguage Models Unmask Fake News. In Proceedings of the 48th International\nACM SIGIR Conference on Research and Development in Information Retrieval\n(Padua, Italy) (SIGIR ‚Äô25). Association for Computing Machinery, New York, NY,\nUSA, 504‚Äì514. doi:10.1145/3726302.3730092\n[23] Sebastian Lubos, Thi Ngoc Trang Tran, Alexander Felfernig, Seda Polat Erdeniz,\nand Viet-Man Le. 2024. Llm-generated explanations for recommender systems.\nIn Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation\nand Personalization. 276‚Äì285.\n[24] Elena-Ruxandra Lu≈£an and Costin BƒÉdicƒÉ. 2024. Literature Books Recommender\nSystem using Collaborative Filtering and Multi-Source Reviews. In 2024 19th\nConference on Computer Science and Intelligence Systems (FedCSIS). IEEE, 225‚Äì230.\n[25] Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, Qifan Wang, Si Zhang,\nRen Chen, Chris Leung, Jiajie Tang, and Jiebo Luo. 2024. LLM-Rec: Personalized\nRecommendation via Prompting Large Language Models. In Findings of the\nAssociation for Computational Linguistics: NAACL 2024. 583‚Äì612.\n[26] Reza Yousefi Maragheh and Yashar Deldjoo. 2025. The Future is Agentic: Defini-\ntions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems.\narXiv preprint arXiv:2507.02097 (2025).\n[27] Guangtao Nie, Rong Zhi, Xiaofan Yan, Yufan Du, Xiangyang Zhang, Jianwei Chen,\nMi Zhou, Hongshen Chen, Tianhao Li, Ziguang Cheng, Sulong Xu, and Jinghe\nHu. 2024. A Hybrid Multi-Agent Conversational Recommender System with LLM\nand Search Engine in E-commerce. In Proceedings of the 18th ACM Conference\non Recommender Systems (Bari, Italy) (RecSys ‚Äô24). Association for Computing\nMachinery, New York, NY, USA, 745‚Äì747. doi:10.1145/3640457.3688061\n[28] OpenAI.\n2025.\nOpenAI\no3\nand\no4-mini\nSystem\nCard.\n(2025).\nhttps://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-\nand-o4-mini-system-card.pdf\n[29] SGOPAL Patro and Kishore Kumar Sahu. 2015. Normalization: A preprocessing\nstage. arXiv preprint arXiv:1503.06462 (2015).\n[30] Qiyao Peng, Hongtao Liu, Hua Huang, Qing Yang, and Minglai Shao. 2025.\nA survey on llm-powered agents for recommender systems. arXiv preprint\narXiv:2502.10050 (2025).\n[31] Shahnewaz Karim Sakib and Anindya Bijoy Das. 2024. Challenging fairness: A\ncomprehensive exploration of bias in llm-based recommendations. In 2024 IEEE\nInternational Conference on Big Data (BigData). IEEE, 1585‚Äì1592.\n[32] Robin Staab, Mark Vero, Mislav Balunoviƒá, and Martin Vechev. 2023. Beyond\nmemorization: Violating privacy via inference with large language models. arXiv\npreprint arXiv:2310.07298 (2023).\n[33] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui\nYu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican,\net al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805 (2023).\n[34] Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry\nO‚ÄôSullivan, and Hoang D Nguyen. 2025. Multi-agent collaboration mechanisms:\nA survey of llms. arXiv preprint arXiv:2501.06322 (2025).\n[35] David Wan, Justin Chen, Elias Stengel-Eskin, and Mohit Bansal. 2025. MAMM-\nRefine: A Recipe for Improving Faithfulness in Generation with Multi-Agent\nCollaboration. In Proceedings of the 2025 Conference of the Nations of the Ameri-\ncas Chapter of the Association for Computational Linguistics: Human Language\nTechnologies (Volume 1: Long Papers). 9882‚Äì9901.\n[36] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah\nCho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023. Rec-\nmind: Large language model powered agent for recommendation. arXiv preprint\narXiv:2308.14296 (2023).\n[37] Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, and Min Zhang. 2024.\nMACRec: A Multi-Agent Collaboration Framework for Recommendation (SIGIR\n‚Äô24). Association for Computing Machinery, New York, NY, USA, 2760‚Äì2764.\ndoi:10.1145/3626772.3657669\nCollab-REC\nConference‚Äô17, July 2017, Washington, DC, USA\n[38] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu,\nLi Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. 2023. Autogen: En-\nabling next-gen llm applications via multi-agent conversation. arXiv preprint\narXiv:2308.08155 (2023).\n[39] Zengqing Wu and Takayuki Ito. 2025. The hidden strength of disagreement:\nUnraveling the consensus-diversity tradeoff in adaptive multi-agent systems.\narXiv preprint arXiv:2502.16565 (2025).\n[40] Zengqing Wu, Run Peng, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Inhyuk\nKwon, Makoto Onizuka, Shaojie Tang, and Chuan Xiao. 2024. Shall we team\nup: Exploring spontaneous cooperation of competing llm agents. arXiv preprint\narXiv:2402.12327 (2024).\n[41] Fan Yang, Zheng Chen, Ziyan Jiang, Eunah Cho, Xiaojiang Huang, and Yanbin\nLu. 2023. Palr: Personalization aware llms for recommendation. arXiv preprint\narXiv:2305.07622 (2023).\n[42] Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun Zhao, Roy Bar-Haim, Arman\nCohan, and Michal Shmueli-Scheuer. 2025. Survey on Evaluation of LLM-based\nAgents. arXiv preprint arXiv:2503.16416 (2025).\n[43] Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin\nZhao, Leyu Lin, and Ji-Rong Wen. 2024. AgentCF: Collaborative Learning with\nAutonomous Language Agents for Recommender Systems. In Proceedings of the\nACM Web Conference 2024 (Singapore, Singapore) (WWW ‚Äô24). Association for\nComputing Machinery, New York, NY, USA, 3679‚Äì3689. doi:10.1145/3589334.\n3645537\n[44] Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, and Shumin\nDeng. 2024. Exploring Collaboration Mechanisms for LLM Agents: A Social\nPsychology View. In Proceedings of the 62nd Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers). 14544‚Äì14607.\n",
    "content": "# Interpretation of the Paper \"Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism\"\n\n---\n\n## I. Core Content and Main Contributions of the Paper\n\n### Core Content\n\nThis paper introduces **Collab-Rec**, a multi-agent framework based on large language models (LLMs), designed to balance three key objectives in tourism recommendations: personalization, popularity, and sustainability. Traditional recommendation systems often favor popular attractions, leading to overtourism and homogenized recommendations. Collab-Rec addresses these issues by employing three specialized LLM agents ‚Äî the **Personalization Agent**, **Popularity Agent**, and **Sustainability Agent** ‚Äî each offering recommendations from different perspectives. These recommendations are then refined through a multi-round negotiation and optimization process led by a non-LLM **Moderator**, ultimately generating more balanced and diverse travel suggestions.\n\n### Main Contributions\n\n1. **Multi-Stakeholder Agent Design**: By assigning the goals of personalization, popularity, and sustainability to three separate LLM agents, the system produces richer and more balanced recommendations compared to single-agent systems.\n2. **Multi-Round Negotiation Mechanism**: A multi-round negotiation mechanism guided by a non-LLM Moderator allows agents to propose and refine candidate city recommendations in each round, while penalizing repetitive or fabricated suggestions to enhance diversity.\n3. **Scoring and Moderation Mechanism**: A comprehensive evaluation function is designed, incorporating agent success rate, reliability, and hallucination penalties, effectively mitigating the popularity bias commonly found in LLMs.\n4. **Empirical Evaluation**: Experiments on both synthetic and real-world tourism query datasets demonstrate that Collab-Rec outperforms single-round or single-agent baseline methods in terms of recommendation relevance and diversity.\n\n---\n\n## II. Breakthroughs and Innovations in the Paper\n\n### 1. **Innovation in Multi-Agent Collaborative Architecture**\n\nUnlike traditional single-model recommendation systems, Collab-Rec adopts a collaborative multi-agent architecture. Each agent focuses on a specific objective ‚Äî personalization, popularity, or sustainability ‚Äî and through a multi-round negotiation process, they collectively arrive at a consensus, achieving a form of \"collective intelligence\" in recommendations.\n\n### 2. **Dynamic Moderation and Penalty Mechanism**\n\nA non-LLM **Moderator** module is introduced to detect hallucinations, calculate scores, integrate recommendations, and provide feedback and penalties to agents based on historical performance in each round, preventing any single objective (e.g., popularity) from dominating the results.\n\n### 3. **Multi-Dimensional Evaluation Metric System**\n\nA comprehensive scoring mechanism incorporating success rate, reliability, and hallucination rate is designed, ensuring that recommendations not only meet user preferences but also consider sustainability and diversity.\n\n### 4. **Empirical Validation of Effectiveness**\n\nExperiments comparing Collab-Rec with traditional systems (e.g., TopPop, RandRec) and single-round LLM systems (e.g., SASI, MASI) show that Collab-Rec significantly outperforms baseline methods in terms of recommendation diversity (measured by GINI index and normalized entropy) and relevance (Moderator Success).\n\n---\n\n## III. Entrepreneurial Project Ideas Based on the Paper\n\n### 1. **\"Sustainable Travel Recommendation Platform\"**\n\n**Project Focus**: Provide personalized travel recommendations for eco-conscious travelers who want to avoid overcrowded tourist spots.\n\n**Technical Implementation**: Adopt the Collab-Rec architecture, with agents focusing on user preferences, destination popularity, and sustainability metrics (e.g., carbon emissions, seasonality, walkability).\n\n**Business Model**:\n- **B2C**: Offer personalized travel advice to individual travelers.\n- **B2B**: Partner with eco-friendly travel agencies and green hotels to provide recommendation engine APIs.\n- **Data Services**: Deliver destination sustainability analysis reports to governments or tourism authorities.\n\n---\n\n### 2. **\"City Tourism Balance Recommendation System\"**\n\n**Project Focus**: Help municipal tourism authorities alleviate the \"overtourism\" problem by recommending alternative travel destinations.\n\n**Technical Implementation**:\n- Use the Popularity Agent to identify popular cities.\n- Deploy the Sustainability Agent to suggest eco-friendly alternatives.\n- Let the Personalization Agent generate interest-based alternatives.\n- The Moderator coordinates the multi-objective recommendations to meet traveler needs while reducing pressure on popular cities.\n\n**Business Model**:\n- Partner with local governments to provide \"touristÂàÜÊµÅ recommendation systems\".\n- Embed recommendation modules into city tourism websites to enhance user experience.\n- Offer tourism data insights to help cities optimize tourism policies.\n\n---\n\n### 3. **\"Smart Travel Planning Assistant\"**\n\n**Project Focus**: Provide users with one-stop travel planning services, including itinerary planning, hotel recommendations, and transportation advice.\n\n**Technical Implementation**:\n- Multi-agent collaboration to generate recommendation lists.\n- The Moderator optimizes recommendations through multi-round dialogue, adjusting dynamically based on user feedback.\n- Integrate external knowledge bases (e.g., weather, transportation, attraction opening hours) to improve recommendation accuracy.\n\n**Business Model**:\n- **SaaS Model**: Provide APIs for travel apps or websites.\n- **Personalized Subscription Service**: Offer tailored travel advice based on user needs.\n- **Partnerships with airlines and hotels** for integrated recommendation and booking.\n\n---\n\n### 4. **\"AI-Powered Tourism Content Creation Platform\"**\n\n**Project Focus**: Offer AI-assisted travel content generation tools for travel bloggers and content creators.\n\n**Technical Implementation**:\n- Generate diverse travel routes using the Collab-Rec framework.\n- Use LLMs to create personalized travel copy, guides, and video scripts.\n- The Moderator ensures content diversity and originality.\n\n**Business Model**:\n- Subscription-based content creation tools.\n- Custom content generation for travel influencers.\n- Tourism brand content marketing solutions.\n\n---\n\n## IV. Conclusion\n\nThe Collab-Rec paper introduces an innovative multi-agent recommendation framework that addresses the issues of popularity bias and recommendation homogenization in traditional tourism recommendation systems. Its multi-objective coordination mechanism, dynamic feedback system, and multi-round negotiation approach offer new insights for building smarter and more sustainable recommendation systems. Based on this framework, various entrepreneurial projects can be developed across travel recommendations, urban governance, and content creation, offering broad commercial potential.",
    "github": "",
    "hf": ""
}