{
    "id": "2510.02572",
    "title": "Geospatial Machine Learning Libraries",
    "summary": "This paper reviews the development of geographic spatial machine learning (GeoML) libraries, analyzes their core functionalities and ecosystems, and introduces several popular GeoML libraries and their applications in data preprocessing, spatiotemporal connections, and benchmark testing.",
    "abstract": "Recent advances in machine learning have been supported by the emergence of domain-specific software libraries, enabling streamlined workflows and increased reproducibility. For geospatial machine learning (GeoML), the availability of Earth observation data has outpaced the development of domain libraries to handle its unique challenges, such as varying spatial resolutions, spectral properties, temporal cadence, data coverage, coordinate systems, and file formats. This chapter presents a comprehensive overview of GeoML libraries, analyzing their evolution, core functionalities, and the current ecosystem. It also introduces popular GeoML libraries such as TorchGeo, eo-learn, and Raster Vision, detailing their architecture, supported data types, and integration with ML frameworks. Additionally, it discusses common methodologies for data preprocessing, spatial--temporal joins, benchmarking, and the use of pretrained models. Through a case study in crop type mapping, it demonstrates practical applications of these tools. Best practices in software design, licensing, and testing are highlighted, along with open challenges and future directions, particularly the rise of foundation models and the need for governance in open-source geospatial software. Our aim is to guide practitioners, developers, and researchers in navigating and contributing to the rapidly evolving GeoML landscape.",
    "category1": "Application Implementation",
    "category2": "Agriculture",
    "category3": "Non-Agent",
    "authors": "Adam J. Stewart,Caleb Robinson,Arindam Banerjee",
    "subjects": [
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
    ],
    "comments": "Comments:Book chapter",
    "keypoint": "The availability of Earth observation data has outpaced the development of domain-specific geospatial machine learning (GeoML) libraries.\nGeoML libraries aim to address unique challenges such as varying spatial resolutions, spectral properties, temporal cadence, data coverage, coordinate systems, and file formats.\nTorchGeo, eo-learn, and Raster Vision are highlighted as popular GeoML libraries with distinct architectures and integrations with ML frameworks.\nGeoML libraries provide core functionalities including data loaders, preprocessing tools, spatial–temporal joins, benchmarking support, and pretrained models.\nA case study on crop type mapping demonstrates practical applications of GeoML tools and workflows.\nBest practices in software design, licensing, testing, and continuous integration are critical for robust and reproducible GeoML libraries.\nThe ecosystem remains fragmented with limited support for temporal modeling, sensor fusion, and distributed inference over large datasets.\nFoundation models are emerging as a key trend in GeoML, enabling transfer learning and reducing dependency on labeled data.\nThere is a growing need for governance in open-source geospatial software to ensure sustainability and community-driven development.\nComponent-based, modular libraries like TorchGeo are fostering interoperability and reuse across the GeoML ecosystem.\nPretrained models and foundation model embeddings are increasingly available in libraries like TorchGeo to accelerate model development.\nStandardized dataset loaders and adherence to train/validation/test splits improve reproducibility in GeoML research.\nSpatial and temporal joins are essential operations in GeoML workflows, requiring proper handling of coordinate reference systems and missing data.\nEfficient file formats such as cloud-optimized GeoTIFFs, Zarr, and Parquet enhance I/O performance in large-scale GeoML pipelines.\nDistribution through package managers like PyPI and Conda Forge improves accessibility and adoption of GeoML libraries.\nPermissive licenses like MIT and Apache-2.0 dominate active GeoML libraries, promoting broader use compared to copyleft licenses.\nContinuous integration, high test coverage, and automated documentation are key indicators of library stability and long-term viability.\nReproducibility in GeoML is challenged by stochasticity in data, models, and optimization processes across platforms and accelerators.\nFuture directions include unified foundation models for land, ocean, and atmosphere, and increased focus on ease of use through low-code interfaces.\nIndependent governance models and software foundations (e.g., OSGeo, AI Alliance) are supporting the maturation of major GeoML projects.",
    "date": "2025-10-07",
    "paper": "Geospatial Machine Learning Libraries\nAdam J. Stewart,1,2 Caleb Robinson,3 and Arindam Banerjee4\n1Chair of Data Science in Earth Observation, Technical University of Munich\n2Munich Center for Machine Learning\n3AI for Good Research Lab, Microsoft\n4Siebel School of Computing and Data Science, University of Illinois Urbana-Champaign\nAbstract\nRecent advances in machine learning have been supported by the emergence of domain-specific software\nlibraries, enabling streamlined workflows and increased reproducibility. For geospatial machine learning\n(GeoML), the availability of Earth observation data has outpaced the development of domain libraries\nto handle its unique challenges, such as varying spatial resolutions, spectral properties, temporal cadence,\ndata coverage, coordinate systems, and file formats. This chapter presents a comprehensive overview\nof GeoML libraries, analyzing their evolution, core functionalities, and the current ecosystem. It also\nintroduces popular GeoML libraries such as TorchGeo, eo-learn, and Raster Vision, detailing their archi-\ntecture, supported data types, and integration with ML frameworks. Additionally, it discusses common\nmethodologies for data preprocessing, spatial–temporal joins, benchmarking, and the use of pretrained\nmodels. Through a case study in crop type mapping, it demonstrates practical applications of these tools.\nBest practices in software design, licensing, and testing are highlighted, along with open challenges and\nfuture directions, particularly the rise of foundation models and the need for governance in open-source\ngeospatial software. Our aim is to guide practitioners, developers, and researchers in navigating and\ncontributing to the rapidly evolving GeoML landscape.\nKeywords: Geospatial, Machine Learning, Software Libraries, Open Source\n1.\nIntroduction\nMachine learning (ML) software libraries have played a foundational role in both shaping ML re-\nsearch and the commoditization of ML models. Libraries such as scikit-learn (Pedregosa et al. 2011),\nTensorFlow (Abadi et al. 2016), and PyTorch (Paszke et al. 2019) incorporate best practices, pro-\nvide composable APIs, and abstract low-level engineering complexity, allowing researchers and\npractitioners to focus on experimentation, implementation of higher-level features, and conceptual\ndevelopment. A well designed software library provides a platform that users can build upon to\npursue their agendas. As a result, the accessibility and maturity of ML tooling are tightly coupled\nwith research progress.\nBeyond general-purpose frameworks, domain-specific libraries further lower the barriers to re-\nsearch in particular subfields. These libraries often provide data loaders, evaluation metrics, pre-\ntrained models, and architecture templates specific to that domain. For example, the torchvision\nlibrary (Marcel and Rodriguez 2010) simplifies experimentation in computer vision by including\nstandard datasets (e.g., CIFAR (Krizhevsky, Hinton, et al. 2009), ImageNet (Deng et al. 2009)),\ndata augmentation routines, and reference implementations of neural network architectures. In\nnatural language processing (NLP), the Hugging Face ecosystem has standardized tokenization,\nmodel configuration, and inference across transformer-based architectures (Wolf et al. 2019), en-\nabling large-scale evaluation and pretraining. Similar domain-specific tooling ecosystems exist in\nreinforcement learning (e.g., OpenAI Gym (Brockman et al. 2016)), speech (e.g., torchaudio\n(Yang et al. 2022)), and time series (e.g., GluonTS (Alexandrov et al. 2020)), all of which have\nsubstantially influenced research agendas and benchmarks.\nIn contrast, the development of libraries tailored to geospatial machine learning (GeoML) has\nlagged behind. This gap is notable given the increasing volume and accessibility of satellite and\narXiv:2510.02572v1  [cs.LG]  2 Oct 2025\n2\nAdam J. Stewart et al.\naerial imagery from public and commercial platforms. Remotely-sensed data support a wide range\nof applications — including land cover mapping (Karra et al. 2021), agricultural monitoring (Mulla\n2013), disaster response (Van Westen 2013), and climate modeling (Rolnick et al. 2022) — but present\na set of challenges not typically encountered in standard ML workflows. As presented in Chapter 1,\nEarth observation images vary in spatial resolution (from millimeters to tens of kilometers per pixel),\nspectral characteristics (e.g., 3-band RGB imagery vs. 13-band multispectral Sentinel-2 imagery vs.\n242-band hyperspectral imagery), and temporal cadence (every five minutes from the NASA GOES\nsatellites, to on-demand tasking for commercial high-resolution satellites, to every 16 days for Land-\nsat 9). Further complications include non-uniform data coverage over the Earth, cloud occlusion,\ndiffering coordinate reference systems (CRS), and file formats optimized for spatial indexing rather\nthan machine learning (Rolf et al. 2024). These characteristics require preprocessing steps such as\nreprojection, resampling, and cloud masking, none of which are directly supported by conventional\nML data pipelines. As a result, integrating geospatial data into an ML workflow typically requires\nmanual interfacing with specialized libraries such as GDAL (GDAL/OGR contributors 2022), cre-\nating substantial friction between data access and model development.\nDespite these challenges, recent years have seen progress toward standardizing workflows for\nGeoML through the development of libraries explicitly designed for geospatial data in machine\nlearning contexts. TorchGeo (A. J. Stewart et al. 2024), for example, builds on PyTorch to provide\ndataset abstractions, spatial sampling utilities, and support for georeferenced imagery and vector data.\nOther libraries, such as eo-learn (Aleksandrov et al. 2018) and Raster Vision (Azavea/Element 84\nand Cheetham 2017), offer higher-level frameworks for remote sensing tasks, including land cover\nclassification, semantic segmentation, and change detection. These libraries attempt to bridge the\ngap between geospatial data infrastructure and modern ML tooling, offering primitives for common\noperations such as patch extraction, label alignment, and tiling. However, the ecosystem remains\nfragmented, with limited support for tasks such as temporal modeling, sensor fusion, or distributed\ninference over petabyte-scale datasets. Moreover, unlike domains such as vision and language mod-\neling, GeoML currently lacks a unifying toolkit that combines data curation, model training, and\ndeployment into an integrated framework, though considerable progress has been made in recent\nyears. While the current chapter primarily focuses on Python libraries as much of the active devel-\nopment, GeoML developments in other languages such as R have similar or related issues.\n2.\nMethodology\nBy definition, GeoML libraries must support two core tasks: processing geospatial data, and inte-\ngrating it into machine learning workflows. Their functionality spans input/output (I/O) opera-\ntions, internal data representations, and dataset handling.\nMost GeoML libraries rely on the Geospatial Data Abstraction Library (GDAL) either directly\nor indirectly to support I/O operations. GDAL provides a consistent API for interacting with a wide\nrange of raster and vector data formats — as of September 2025, it includes 155 raster drivers and\n83 vector drivers, covering formats such as GeoTIFF, Zarr, HDF5, NetCDF, Esri Shapefile, and\nGeoPackage. In Python, libraries like rasterio (Gillies et al. 2013) and fiona (Gillies et al. 2024)\nwrap GDAL’s API and provide an additional layer of abstraction and additional features (e.g., vec-\ntorization, rasterization, and fine-grained management of environment variables to control GDAL\nbehavior). In R, terra (Hijmans et al. 2018) and sf (Pebesma 2018) provide similar support for raster\nand vector operations at a higher level of abstraction. Even higher-levels of abstraction exist through\nlibraries such as xarray (Hoyer and Joseph 2017), rioxarray (Snow et al. 2019), and geopandas\n(Jordahl et al. 2013), which provide array- or dataframe-based abstractions that retain coordinate\nreference system (CRS) metadata and spatial transforms. Some geospatial file formats can also be ac-\ncessed through alternative backends. h5py (Collette et al. 2008), zarr (Miles et al. 2015), and tifffile\n(Gohlke 2018) all provide direct interfaces for HDF5, Zarr, and TIFF files, respectively. Similarly,\n3\nGeoJSON files can be read using any standard JSON parsers, although geospatial-aware libraries\n(like fiona) ensure proper CRS interpretation and coordinate handling. A key feature throughout\nall GeoML libraries is how they ensure that the geospatial metadata of inputs are taken into ac-\ncount — any corresponding outputs will need this information in order to be georeferenced for\ndownstream analysis. Machine learning libraries that do not support this require users to (a) have\nknowledge of how geospatial metadata works and (b) develop ad-hoc methods for propagating\ngeospatial metadata, both of which can easily allow for bugs to be introduced.\nAnother key feature of GeoML libraries is how spatial and temporal data are represented within\nthe library. Spatial and temporal joins, in particular, are common operations for setting up Ge-\noML experiments. For example, training a model to predict whether land is cropland or not from\na time series of satellite imagery observations over the planting season of that area requires several\nkey steps. First, representing a time series of multispectral satellite imagery over the same location\nrequires a temporal join with corresponding decisions. Does the library itself allow for the temporal\njoin to be performed? How will missing observations be handled and how will the time dimension\nbe represented (densely in 4D, sparsely with pointers to 3D tensors)? How are layers with differing\ncoordinate reference systems and spatial resolutions handled? Second, a spatial join between the\nresulting imagery stack and a known cropland mask is necessary in order to create labeled examples\nthat can be fed into a machine learning pipeline. If there are many different cropland masks, or\nsatellite imagery layers, then a spatial index will be needed to ensure that intersections between the\nlayers can be computed quickly. Further, the spatial join must also take different coordinate refer-\nence systems and/or spatial resolutions into account — some layers will likely need to be reprojected\nand resampled in an appropriate manner before further analysis can be done. The cropland masks\ncould also be in a vector format and need to be rasterized or otherwise transformed into a format\nthat can be used directly in modeling.\nGeoML libraries also differ in how they support benchmark datasets. The GeoML community\nhas proposed a growing set of benchmark datasets intended to facilitate algorithmic comparison\nand standardized evaluation on a wide variety of tasks. These datasets typically pair remotely-\nsensed imagery with structured labels, such as land cover classifications (Robinson et al. 2019), object\nboundaries (Kerner et al. 2025), or change detection masks (Chen and Shi 2020). Unlike domains\nsuch as computer vision or NLP, geospatial benchmark datasets often lack standardized data loaders\nor preprocessing routines. As a result, researchers are frequently required to write custom scripts\nfor parsing, tiling, and aligning data. This introduces inconsistencies and hinders reproducibility.\nGeoML libraries can substantially reduce this friction by implementing standardized, reusable data\nloaders for popular benchmarks. Features that distinguish high-quality dataset support include:\n• adherence to published train/validation/test splits;\n• support for user-defined or random splits, including spatial stratification;\n• compatibility with PyTorch or TensorFlow Dataset abstractions, enabling seamless integration\ninto training pipelines;\n• additional utilities such as on-the-fly reprojection, resampling, normalization, augmentation, or\nclass remapping; and\n• built-in visualization tools for inspecting inputs, labels, and predictions.\nTaken together, these capabilities define the core functionality and value of a GeoML library.\nBy abstracting the geospatial data pipeline from raw file access and metadata handling to dataset\nconstruction and integration with ML training loops, these libraries allow researchers and prac-\ntitioners to focus on model development rather than infrastructure. However, the design choices\nmade at each stage, such as metadata preservation, spatial joining logic, temporal indexing strategies,\nand dataset standardization, directly affect model reproducibility, comparability, and deployment.\nIn the remainder of the chapter we highlight the history of GeoML libraries, break down existing\n4\nAdam J. Stewart et al.\n“state-of-the-art” libraries along the dimensions we describe here, expand on our example of crop-\nland mapping, and finally discuss best practices for GeoML library development from a software\nengineering standpoint.\n3.\nState of the Art and Current Developments\nBefore jumping in to the current state of GeoML library development, it helps to first understand\nhow we got there.\n3.1\nA Brief History\nThe development of GeoML software libraries has evolved alongside the rise of machine learning\nin computer vision. Beginning in the early-2000s, researchers began repurposing general-purpose\nmachine learning frameworks to work with the unique formats and challenges of satellite and aerial\nimagery. Over time, this ad hoc adaptation gave way to a more intentional, ecosystem-wide effort\nto build specialized tools for Earth observation data.\n2016 2017 2018 2019 2020 2021 2022 2023 2024 2025\nSPy\nOTB\nDeepOSM\nHyperspectral\nDeepNetsForEO\nSITS\nRaster Vision\nDeepHyperX\nPyinterpolate\nOTBTF\neo-learn\nRoboSat\nspopt\nDELTA\nTorchSat\nSolaris\nAIDE\nAiTLAS\nDeepForest\nML4Floods\nTorchGeo\ngeo-bench\ntorchrs\nMyria3D\nPaddleRS\nGeoTorchAI\nRaster4ML\nsrai\nMoonshine\nsamgeo\ngeodl\nGeoAI\nscikit-eo\nTerraTorch\nGeoDeep\nGeoTessera\nActive\nInactive\nFigure 1. Timeline of GeoML library development. Libraries that are under active development (defined as a new commit\nwithin the last year) are shown in black. Inactive libraries are shown in red. SPy and OTB development stretches back\nto 2001 and 2006, respectively, and are truncated to focus on more recent developments. Bars denote earliest and most\nrecent commit (as of September 2025).\nOne of the earliest known GeoML libraries, SPy (Spectral Python), began development in 2001\nwith simple iterative clustering methods for hyperspectral imagery, later adding k-means clustering\n5\nand perceptron classifiers (Boggs et al. 2001). The library predates most modern ML frameworks,\nand all methods are implemented from scratch in NumPy (Harris et al. 2020). SPy has successfully\nsurvived several transitions (Python 2 →3, CVS →SVN →Git) and is still maintained to this day.\nOTB (Orfeo ToolBox) is another popular software library for processing optical, multispectral, and\nradar imagery (Grizonnet et al. 2017). Initial development began in 2006 by the French national\nspace agency (CNES) as part of the Orfeo Program, targeting high resolution imagery from the\nOrfeo constellation (Pléiades and COSMO-Skymed). OTB offered early support for support vector\nmachines (SVMs) via LibSVM (Chang and Lin 2011) and later added support for gradient boosted\ndecision trees, k-nearest neighbors (k-NNs), and multilayer perceptrons (MLPs) from OpenCV\n(Bradski, Kaehler, et al. 2000) and k-means and random forests from the Shark machine learning\nlibrary (Krause et al. 2009). OTB itself is written in C++, with a command-line interface, Python\nbindings, and an official QGIS plugin.\nThe earliest known geospatial deep learning libraries began development in 2016. TrailBe-\nhind introduced DeepOSM (Johnson et al. 2016), which built on top of the now-defunct TFLearn\n(Damien et al. 2016) and supported automatic downloading and preprocessing of labeled imagery for\nroad network detection using OpenStreetMap (OSM) (OpenStreetMap contributors 2017). Hyper-\nspectral was developed by researchers at IIT Kharagpur, with early TensorFlow-based experiments\nwith MLPs and CNNs on hyperspectral imagery (Santara et al. 2016). Later that year, ONERA and\nIRISA released DeepNetsForEO (Audebert, Saux, and Lefèvre 2017), initially built on Caffe (Jia\net al. 2014) and later ported to PyTorch. Notably, it was the first library to offer pretrained models\non multispectral remote sensing imagery. All three libraries were discontinued within a few years\nof release. They were never packaged for PyPI or other standard software registries, and instead\nrequired knowledge of Git and Docker for installation. Nonetheless, they established foundational\nideas — especially the importance of pipelines for data handling — that would influence the next\ngeneration of GeoML libraries.\nIn 2017, the first broadly adopted, formally maintained geospatial deep learning libraries were\nintroduced. In the R ecosystem, SITS (Satellite Image Time Series) was launched (Simoes et al. 2021).\nSITS is a library developed by e-sensing with a focus on time series analysis and data cube construc-\ntion from providers such as AWS, the Microsoft Planetary Computer, and Copernicus Data Space.\nBuilt on R bindings to libtorch, SITS emphasizes accessibility, with formal documentation, CRAN\n(and more recently PyPI) packaging, and a free online book (Camara et al. 2024). One day after\nthe initial commit of SITS, in the Python ecosystem, Azavea started work on Raster Vision (Aza-\nvea/Element 84 and Cheetham 2017). Raster Vision is a modular framework for training and de-\nploying deep learning models on arbitrary raster datasets. Initially built on TensorFlow, it migrated\nto PyTorch in 2019. The authors of DeepNetsForEO returned with DeepHyperX, a library for\nhyperspectral classification using scikit-learn and PyTorch (Audebert, Le Saux, and Lefèvre 2019).\nHowever, its development fractured across multiple forks on GitLab and GitHub and was later\nabandoned.\nFour influential libraries followed in 2018. Pyinterpolate was introduced by Dataverse Labs,\nwith support for several geostatistical interpolation techniques and learning-based Kriging methods\n(Moliński et al. 2018). OTBTF was created as a TensorFlow and Keras plugin for Orfeo ToolBox\nand provides both Python and C++ APIs, but is only distributed through Docker due to its com-\npilation requirements (Cresson 2018). Sentinel Hub released eo-learn, a scikit-learn-compatible\npipeline that offers strong integration with Sentinel Hub products and showed the possibility of\ncloud native workflows (Aleksandrov et al. 2018). Mapbox released RoboSat, built on PyTorch and\ntorchvision, which offered a command-line interface for data preparation, training, and postpro-\ncessing (Hofmann, Kowshik, et al. 2018). RoboSat was eventually discontinued and briefly revived\nas RoboSat.pink, then Neat-EO.pink, before being abandoned again in 2020.\nIn 2019, the ecosystem diversified with several new projects. The Python Spatial Analysis Li-\n6\nAdam J. Stewart et al.\nbrary (PySAL) introduced spopt, providing several spatial optimization techniques including clus-\ntering methods from scikit-learn (X. Feng et al. 2022). NASA released DELTA, a TensorFlow-based\ntoolkit for large-image tiling and semantic segmentation (Coltin et al. 2019). The TorchSat project\nattempted to adapt torchvision to the geospatial domain (Wang 2019). CosmiQ Works launched\nSolaris, a PyTorch framework for object detection (Weir et al. 2019). Finally, Microsoft’s AI for\nEarth team created AIDE (Kellenberger, Tuia, and Morris 2020), a modular web-based annotation\ninterface with Detectron2 (Y. Wu et al. 2019) integration. While each offered novel features, none\nof these libraries besides spopt were maintained beyond 2022.\nThe COVID-19 pandemic brought a slowdown in 2020. Only one major library, AiTLAS,\nwas released that year (Dimitrovski, Kitanovski, Panov, et al. 2023). Developed by Bias Variance\nLabs, it built on PyTorch, scikit-learn, and eo-learn to support common tasks like classification and\nsemantic segmentation using curated datasets. It also attempted the first large-scale benchmarking\nof more than 500 deep learning models on 22 EO classification datasets with its AiTLAS Benchmark\nArena (Dimitrovski, Kitanovski, Kocev, et al. 2023).\nIn 2021, GeoML software development entered a new phase of stability and community-driven\ngrowth. The Weecology group at the University of Florida released DeepForest, targeting object\ndetection of tree crowns in RGB drone imagery with pretrained torchvision models (Weinstein et\nal. 2020). Trillium Technologies launched ML4Floods, an end-to-end PyTorch pipeline for flood\nextent estimation (Mateo-Garcia et al. 2021). Microsoft’s AI for Good Lab and the University of\nIllinois Urbana-Champaign introduced TorchGeo, a PyTorch-native library combining the re-\nproducibility of torchvision-style datasets with raster/vector data handling capabilities similar to\nRaster Vision (A. J. Stewart et al. 2024). A similar project, torchrs was launched in parallel and\nwas subsequently merged into TorchGeo (Corley 2021). Other major 2021 releases included Ser-\nviceNow’s GEO-Bench, a foundation model benchmarking suite with 20 built-in datasets (many\ncurated using TorchGeo) (Lacoste et al. 2023), and IGNF’s Myria3D, uniquely focused on aerial\nLiDAR segmentation (Gaydon 2022).\nBy contrast, most libraries launched in 2022 were eventually abandoned. Baidu’s PaddleRS\n(PaddlePaddle Authors 2022) built on the PaddlePaddle deep learning framework (Ma et al. 2019),\nmaking it the first Chinese-developed GeoML library to gain traction. Wherobots released GeoTorch,\nlater renamed GeoTorchAI (Chowdhury and Sarwat 2022), offering scalable spatial indexing with\nApache Sedona (Yu et al. 2015), but the project was discontinued in favor of TorchGeo. Raster4ML,\ndesigned for agricultural research, provided over 350 spectral indices and scikit-learn compatibility\n(Bhadra 2023). Finally, Kraina AI released srai (Spatial Representations for Artificial Intelligence),\na library providing pre-computed embeddings and spatial data visualization and processing tools\n(Gramacki et al. 2023). Among these libraries, only srai is still maintained to this day.\nA new wave of tools emerged in 2023. Moonshine focused on hosting pretrained semantic\nsegmentation models but was abandoned (Harada 2023). Open Geospatial Solutions launched both\nsamgeo (Wu and Osco 2023), a GUI wrapper for Meta’s Segment Anything Model (SAM) (Kirillov\net al. 2023), and GeoAI (Q. Wu et al. 2023), a general-purpose toolkit for satellite, LiDAR, and\nvector data built atop TorchGeo and scikit-learn. Geodl, another R library built on top of the torch\nand terra packages, brought 2D convolutional neural networks to the R GeoML ecosystem for the\nfirst time (Maxwell et al. 2024). Scikit-eo also debuted, offering another scikit-learn interface for\nEO tasks (Tarazona et al. 2024).\nIn 2024, IBM released TerraTorch, a toolkit for fine-tuning foundation models, built on Torch-\nGeo (Gomes et al. 2025). Together with GEO-Bench and GeoAI, TerraTorch represents a second\ngeneration of GeoML libraries —– those that complement instead of compete with core infrastruc-\nture by extending existing GeoML libraries like TorchGeo.\nLaunched in 2025, UAV4GEO’s GeoDeep is focused on providing a lightweight solution for\nobject detection and semantic segmentation, with dependencies only on onnxruntime and rasterio\n7\nTable 1. Features available in popular GeoML libraries (as of September 2025). While the majority of libraries provide gen-\neral purpose data loaders and models, only a handful provide curated dataset-specific data loaders or pre-trained model\nweights.\nFeature Count\nFeature Support\nLibrary\nML Backend\nDatasets\nWeights\nCLI\nGUI\nReprojection\nSTAC\nTime Series\nTorchGeo\nPyTorch\n127\n120\nyes\nno\nyes\nno\npartial\nOTB\nLibSVM,\nOpenCV, Shark\n0\n0\nyes\nyes\nyes\nno\nno\nTerraTorch\nPyTorch\n27\n1\nyes\nno\nyes\nno\npartial\nDeepForest\nPyTorch,\nTensorFlow*\n0\n4\nno\nno\nno\nno\nno\nRaster Vision\nPyTorch,\nTensorFlow*\n0\n6\nyes\nno\nyes\nyes\npartial\nsamgeo\nPyTorch\n0\n0\nno\nyes\nyes\nno\nno\nspopt\nscikit-learn\n0\n0\nno\nno\nyes\nno\nno\nSITS\nR Torch\n22\n0\nno\nno\nyes\nyes\nyes\nSPy\nnumpy\n3\n0\nno\nno\nno\nno\nno\nsrai\nPyTorch\n0\n0\nno\nno\nno\nno\nno\nML4Floods\nPyTorch\n0\n0\nno\nno\nyes\nno\npartial\nGEO-Bench\nPyTorch\n12\n0\nno\nno\nno\nno\nno\nscikit-eo\nscikit-learn,\nTensorFlow\n0\n0\nno\nno\nno\nno\npartial\nGeoAI\nPyTorch\n0\n6\nno\nno\nyes\nyes\nno\nMyria3D\nPyTorch\n0\n0\npartial\nno\nno\nno\nno\nGeoTessera\nscikit-learn\n0\n0\nyes\nno\nyes\nno\nno\nOTBTF\nTensorFlow\n0\n0\nyes\nno\nyes\nno\nno\nGeoDeep\nONNX\n0\n7\nyes\nno\nyes\nno\nno\n*Support was dropped in newer releases.\n(Toffanin et al. 2025). This library was inspired by and uses some code from Deepness (Aszkowski et\nal. 2023) and DeepForest. Cambridge’s GeoTessera is the first library to focus solely on embeddings,\nproviding easy access to learned representations from the Tessera foundation model (Z. Feng et\nal. 2025).\nThe evolution of GeoML software has mirrored broader trends in machine learning and open-\nsource development. While many early projects were short-lived, they introduced core abstractions\n— data tiling, preprocessing pipelines, pretrained weights — that persist in modern libraries. In re-\ncent years, the field has converged around modular, PyTorch-based tooling with strong community\nsupport, clearer maintenance practices, and increasing interoperability.\n3.2\nCurrent Landscape\nAs of September 2025, the current set of popular GeoML libraries under active development in-\nclude: TorchGeo, OTB, TerraTorch, DeepForest, Raster Vision, samgeo, spopt, SITS, SPy, srai,\nML4Floods, GEO-Bench, scikit-eo, GeoAI, Myria3D, GeoTessera, OTBTF, and GeoDeep. Ta-\nble 1 summarizes the machine learning backend (e.g., PyTorch, TensorFlow, scikit-learn), dataset/model\navailability, and any notable features such as a command-line interfaces (CLI), graphical user in-\nterfaces (GUI), support for automatic reprojection and resampling, SpatioTemporal Asset Catalogs\n(STAC), or time-series analysis for each of these libraries. Tables 2 and 3 display a number of metrics\n8\nAdam J. Stewart et al.\nTable 2. GitHub engagement statistics for popular GeoML libraries (as of September 2025). All statistics are reported by the\nGitHub API. Test coverage is manually calculated when not available via Codecov and may be higher than reported in the\ncase of failing tests.\nLibrary\nContributors\nForks\nWatchers\nStars\nIssues\nPRs\nCoverage\nLicense\nTorchGeo\n108\n473\n56\n3,663\n173\n2,339\n100%\nMIT\nOTB\n41\n121\n40\n375\n3\n24\n56%\nApache-2.0\nTerraTorch\n40\n101\n23\n601\n92\n634\n55%\nApache-2.0\nDeepForest\n35\n217\n17\n657\n96\n530\n86%\nMIT\nRaster Vision\n33\n393\n71\n2,163\n40\n1,465\n90%\nApache-2.0\nsamgeo\n24\n351\n59\n3,408\n33\n154\n13%\nMIT\nspopt\n23\n55\n12\n341\n30\n265\n77%\nBSD-3-Clause\nSITS\n17\n86\n27\n515\n26\n653\n91%\nGPL-2.0\nSPy\n15\n146\n35\n636\n25\n38\n69%\nMIT\nsrai\n15\n27\n12\n316\n104\n280\n92%\nApache-2.0\nML4Floods\n13\n42\n18\n170\n1\n73\n0%\nLGPL-3.0\nGEO-Bench\n13\n12\n12\n153\n8\n9\n51%\nApache-2.0\nscikit-eo\n8\n24\n6\n206\n4\n14\n32%\nApache-2.0\nGeoAI\n7\n202\n33\n1,587\n24\n174\n6%\nMIT\nMyria3D\n7\n31\n14\n259\n18\n79\n57%\nBSD-3-Clause\nGeoTessera\n6\n14\n4\n146\n11\n9\n15%\nISC\nOTBTF\n5\n39\n11\n166\n22\n19\n55%\nApache-2.0\nGeoDeep\n3\n24\n9\n326\n3\n3\n0%\nAGPL-3.0\nuseful for gauging the popularity and stability of each library.1 While the number of GitHub stars\nand PyPI downloads are useful for gauging popularity, the number of contributors and test cover-\nage are much more reliable for gauging the stability and long-term success of the library. Finally\nwe describe the abstractions in three popular libraries: TorchGeo, eo-learn, and Raster Vision. We\nalso assess the typical user base, limitations, and scope of each library.\n3.2.1\nTorchGeo\nTorchGeo is a PyTorch domain library designed to unite machine learning and remote sensing\nexperts under a single platform. It defines two broad classes of datasets: GeoDataset for uncurated\nraster and vector data files and NonGeoDataset for curated benchmark datasets.\nLike other libraries on this list, users can directly use GeoDataset and its subclasses, RasterDataset\nand VectorDataset, to load and process arbitrary raster and vector data. Each dataset consists of a\ngeopandas GeoDataFrame index, allowing different datasets to be intelligently composed based on\nspatiotemporal intersection or union. The resulting dataset can then be queried by a spatiotemporal\nslice, allowing users to quickly load small patches of imagery and masks from large collections of\nraster scenes. Reprojection and resampling are automatically handled by rasterio and fiona, and users\ncan specify which spectral bands they want to load. To ease spatiotemporal indexing, TorchGeo\ndefines a GeoSampler interface, allowing users to select various random (for training) or sequential\n(for inference) sampling strategies.\n1. All tables are maintained in perpetuity at https://torchgeo.rtfd.io/en/latest/user/alternatives.html. If any metrics are out\nof date, please open a pull request to update them.\n9\nTable 3. Download statistics for popular GeoML libraries (as of September 2025). Note that weekly download metrics may\nbe volatile. OTB and OTBTF are not distributed on any package index and therefore download statistics are not available.\nSITS includes both CRAN and PyPI downloads.\nPyPI/CRAN\nConda\nTotal\nLibrary\nLast Week\nLast Month\nAll Time\nAll Time\nAll Time\nTorchGeo\n69,430\n200,906\n845,353\n40,949\n886,302\nOTB\n0\n0\n0\n0\n0\nTerraTorch\n3,870\n29,514\n130,473\n0\n130,473\nDeepForest\n2,483\n6,526\n988,841\n97,503\n1,086,344\nRaster Vision\n4,666\n8,613\n221,409\n5,872\n227,281\nsamgeo\n2,319\n6,692\n274,609\n54,307\n328,916\nspopt\n13,289\n44,498\n1,122,138\n251,912\n1,374,050\nSITS\n477\n1,967\n22,502\n136,850\n159,352\nSPy\n17,720\n59,792\n1,445,738\n150,137\n1,595,875\nsrai\n661\n1,962\n51,103\n0\n51,103\nML4Floods\n90\n195\n10,254\n0\n10,254\nGEO-Bench\n609\n1,818\n58,756\n0\n58,756\nscikit-eo\n515\n598\n22,281\n0\n22,281\nGeoAI\n1,765\n7,277\n63,399\n16,747\n80,146\nMyria3D\n13\n33\n4,429\n0\n4,429\nGeoTessera\n348\n1,218\n3,725\n0\n3,725\nOTBTF\n0\n0\n0\n0\n0\nGeoDeep\n229\n920\n18,540\n0\n18,540\nTorchGeo also includes a number of curated ML-ready benchmark datasets designed to train\nand evaluate models for specialized tasks such as crop type mapping, biomass estimation, or disaster\nresponse. Each of these datasets provides an input image and an output target, such as a semantic\nsegmentation mask or object detection bounding box. In total, TorchGeo provides over 125 built-in\ngeospatial and benchmark datasets, more than all other libraries combined.\nAnother primary focus of TorchGeo is on providing pretrained foundation models capable of\nbeing finetuned for any task. TorchGeo provides over 120 such model weights, including models\npretrained on Landsat, NAIP, and Sentinel imagery and newer “sensor-agnostic” foundation models\nlike Scale-MAE (Reed et al. 2023), DOFA (Xiong et al. 2024), CROMA (Fuller, Millard, and Green\n2023), Panopticon (Waldmann et al. 2025), and Copernicus-FM (Wang et al. 2025).\nTorchGeo places a great deal of emphasis on documentation and testing, with 100% test cover-\nage on three Python versions, three platforms, and the minimum and maximum supported depen-\ndency versions. It also has more than double the number of contributors as any other library on this\nlist, demonstrating its widespread adoption by the community. Its component-based nature, pro-\nviding PyTorch-compatible datasets and models for the community, naturally allows other libraries\nlike TerraTorch and GeoAI to build on top of TorchGeo, extending its features and capabilities.\n3.2.2\neo-learn\neo-learn is a Python library that aims to bridge the gap between the remote sensing and data sci-\nence ecosystems. It is highly coupled with the commercial Sentinel Hub library and ecosystem, and\nenables users to build reusable workflows based around the EOPatch, EOTask, and EOWorkflow\nabstractions. An EOPatch contains all types of data for a given bounding box location — raster data\nwith time series support, vector data, and one-off masks like land cover information. EOTasks oper-\n10\nAdam J. Stewart et al.\nate on EOPatches and transform them, for example performing cloud masking, computing spectral\nindices, classical feature extraction pipelines, and/or classification. Finally, EOTasks are organized\ninto computational graphs that exchange patch objects and run in EOWorkflows, allowing for par-\nallelization and record keeping.\nFor data I/O, eo-learn relies on GDAL (typically through rasterio) for reading geospatial raster\ndata, and also uses OpenCV, pandas, SciPy, and Zarr under the hood. This means it can handle\ncommon raster formats and even work with large out-of-core datasets (Zarr provides chunked, on-\ndisk array storage). For vector data and geometric operations, eo-learn uses GeoPandas, enabling\nintegration of shapefiles or GeoJSON data for tasks like sampling points or computing zonal statis-\ntics. NumPy is used as the primary foundation for array transformations and manipulations within\ntasks.\nTime-series modeling is not explicitly provided as a specialized feature, although eo-learn can\ncertainly process time-indexed imagery (e.g., stacking time frames in an EOPatch object) — but\nit lacks specialized time-series ML models or temporal analysis tools out-of-the-box. eo-learn is\nbest suited for Earth observation practitioners and data scientists who need to preprocess satellite\nimagery and derive features for modeling. Its ease of integration with scikit-learn makes it ideal for\nprototyping land cover classifications or regressions on remote sensing data when deep learning is\nnot required.\n3.2.3\nRaster Vision\nRaster Vision is a Python library for training and deploying deep learning models with satellite\nimagery. It was originally developed by Azavea and has been maintained by Element 84 since\nFebruary of 2023. Similar to eo-learn, Raster Vision is built around the idea of data pipelines. The\ninput to a Raster Vision pipeline is imagery and labels over given areas of interest (AOIs) while the\noutput is a trained model formatted in a “bundle” for deployment. The pipeline steps include:\n1. Analyze - compute dataset-level statistics\n2. Chip - convert geospatial data into uniformly sized patches that can be input into a model in a\nbatched manner\n3. Train - train a machine learning model via a Learner abstraction (typically using a PyTorch\nbackend)\n4. Predict and Evaluate - run inference with a trained model over validation and test data and\ncompute performance metrics\n5. Bundle - Create a model bundle to be used in deployments\nRaster Vision creates abstractions for every step in the above pipeline.\nFor example, input\ndata is represented by source classes: RasterSource, with subclasses such as RasterioSource or\nXarraySource, VectorSource, and LabelSource. Different sources are combined into Scenes\n— collections of data over the same area of interest — and finally a PyTorch DataLoader-compatible\nGeoDataset object that can be used with various training pipelines (e.g., PyTorch Lightning).\n4.\nApplication Example\nIn order to demonstrate the power and potential of GeoML libraries, let us consider the follow-\ning example. A researcher has access to hundreds (or even thousands) of raster images and one or\nmore vector files containing polygon labels. They would like to train a model to perform semantic\nsegmentation, assigning a class label to every pixel in the image. Each raster and vector file in the\ndataset may have a different CRS or resolution, and may or may not have spatiotemporal overlap.\nThis example is representative of a broad class of tasks in remote sensing, and can apply to anything\nfrom building or road segmentation, to land use/land cover mapping, to deforestation and natural\ndisaster analysis.\n11\nFigure 2. A common use case for GeoML practitioners is joining raster data, such as satellite imagery (top left), with vector\ndata, such as crop masks (bottom left), then randomly sampling patches from the intersection of these datasets to use in\nmodeling pipelines (right).\nTo make this more concrete, let us say that the raster images are from Sentinel-2 (Drusch et\nal. 2012) and the vector files are from EuroCrops (Schneider et al. 2023) (see Figure 2). The goal\nis to perform crop type mapping, with each pixel being assigned to one of ∼200 crop classes. This\nrequires reprojection, rasterization, and chipping of each image and vector file into smaller image\npatches that can be passed through the model. For the model, we will use a simple U-Net (Ron-\nneberger, Fischer, and Brox 2015) architecture with a ResNet-50 (He et al. 2016) backbone.\nNow, let us see how this task can be solved with various levels of abstraction using TorchGeo.\nTorchGeo is available on PyPI and Conda Forge, and can easily be installed using:\n> pip install torchgeo\nTorchGeo is designed with the same API as other PyTorch domain libraries. The below code should\nlook familiar to anyone with experience using libraries like torchvision and PyTorch Lightning.\nThe following examples demonstrate three different levels of abstraction, each with their own pros\nand cons.2\n4.1\nPure PyTorch\nFor maximum control and customization, TorchGeo datasets, samplers, and pre-trained models can\nbe used directly. While the data loader setup is a bit custom, the rest of the training and evaluation\npipeline is identical to other PyTorch domain libraries.\n2. Maintained and well-tested notebooks for many of these application examples can be found at: https://torchgeo.rtfd.io/\nen/latest/tutorials/getting_started.html.\n12\nAdam J. Stewart et al.\nFirst, we import everything we will later require.\nimport segmentation_models_pytorch as smp\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchgeo.datasets import (\nEuroCrops, Sentinel2, random_grid_cell_assignment\n)\nfrom torchgeo.models import ResNet50_Weights\nfrom torchgeo.samplers import (\nGridGeoSampler, RandomGeoSampler\n)\nGiven a user-defined local directory or list of remote file paths, we next instantiate PyTorch Dataset\nobjects for Sentinel-2 and EuroCrops data. Given a spatiotemporal slice, this dataset is responsible\nfor loading the data at that time and location from disk. We then compute the spatiotemporal\nintersection of these datasets. All data is automatically reprojected to a shared CRS and rasterized\non the fly.\nsentinel2 = Sentinel2(paths='...')\neurocrops = EuroCrops(paths='...', download=True)\ndataset = sentinel2 & eurocrops\nNext, we overlay a 10 × 10 grid over the dataset. Each grid cell is randomly assigned to a train,\nvalidation, or test split using an 80:10:10 split. Note that TorchGeo has other geospatial splitting\nstrategies that may be more suitable for out-of-distribution evaluation.\ntrain_ds, val_ds, test_ds = random_grid_cell_assignment(\ndataset, [0.8, 0.1, 0.1], grid_size=10\n)\nNext, we instantiate PyTorch Sampler objects for each split. The sampler is responsible for telling\nthe dataset where and when to load data from. Here, we use random sampling at training time\nto maximize the diversity of the training data and grid-based sampling at evaluation time to avoid\noverlap or missing locations.\ntrain_sr = RandomGeoSampler(train_ds, size=224)\nval_sr = GridGeoSampler(val_ds, size=224, stride=224)\ntest_sr = GridGeoSampler(test_ds, size=224, stride=224)\nAll TorchGeo datasets and samplers are compatible with PyTorch’s built-in DataLoader class. Here,\nwe set the batch size and tell the data loader where it is allowed to sample from.\nbatch_size = 64\ntrain_dl = DataLoader(train_ds, batch_size, sampler=train_sr)\nval_dl = DataLoader(val_ds, batch_size, sampler=val_sr)\ntest_dl = DataLoader(test_ds, batch_size, sampler=test_sr)\nNext, we instantiate our model. TorchGeo comes with 120+ model weights pre-trained on SAR,\nRGB, MSI, and HSI remote sensing imagery. In this case, we use a model pre-trained on all 13\nbands of Sentinel-2 imagery using self-supervised learning (Wang et al. 2023).\nmodel = smp.Unet('resnet50', in_channels=13, classes=200)\nweights = ResNet50_Weights.SENTINEL2_ALL_DINO\nmodel.encoder.load_state_dict(weights.get_state_dict())\n13\nWe next transfer our model to the GPU. Note that this step may look different for NVIDIA, AMD,\nand Apple Silicon GPUs.\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nFor our loss function, we choose cross-entropy loss, which works well for multiclass classification\nand semantic segmentation tasks. For our optimizer, we choose stochastic gradient descent (SGD).\nUsers can and should experiment with fancier optimizers here.\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-2)\nWe define a train function containing the forward and backward pass of our model for a single\nepoch.\ndef train(dataloader):\nmodel.train()\ntotal_loss = 0\nfor batch in dataloader:\nx = batch['image'].to(device)\ny = batch['mask'].to(device)\n# Forward pass\ny_hat = model(x)\nloss = loss_fn(y_hat, y)\ntotal_loss += loss.item()\n# Backward pass\nloss.backward()\noptimizer.step()\noptimizer.zero_grad()\nprint(f'Loss: {total_loss:.2f}')\nWe define a similar evaluation function containing the forward pass of our model and compute the\noverall accuracy of a single epoch.\ndef evaluate(dataloader):\nmodel.eval()\ncorrect = 0\nwith torch.no_grad():\nfor batch in dataloader:\nx = batch['image'].to(device)\ny = batch['label'].to(device)\n# Forward pass\ny_hat = model(x)\ny_hat_hard = y_hat.argmax(1) == y\ncorrect += y_hat_hard.sum().item()\ncorrect /= len(dataloader.dataset)\nprint(f'Accuracy: {correct:.0%\n14\nAdam J. Stewart et al.\nFinally, we combine everything and train and evaluate our model over 100 epochs. Validation\naccuracy can be used for early stopping and for hyperparameter tuning. Once an optimal set of\nhyperparameters is found, we report the final test accuracy.\nfor epoch in range(100):\nprint(f'Epoch: {epoch}')\ntrain(train_dataloader)\nevaluate(val_dataloader)\nevaluate(test_dataloader)\n4.2\nPyTorch Lightning\nWhile the above code has the most flexibility and can be easily customized to add preprocessing or\ndata augmentation, it can be daunting for many users. Beginners are likely to make mistakes when\ncomputing accuracy metrics, while experts may require a lot of code duplication if they want to,\nfor example, evaluate several model architectures on dozens of different datasets. To simplify the\ntraining and evaluation pipeline, TorchGeo offers PyTorch Lightning (Falcon and The PyTorch\nLightning team 2019) integration. PyTorch Lightning introduces two ideas: data modules, col-\nlections of train/val/test datasets and the transforms applied to them, and modules, reusable recipes\nfor tasks like classification, regression, or semantic segmentation. TorchGeo provides built-in data\nmodules for many datasets and modules for:\n• Classification (binary, multiclass, multilabel)\n• Regression (imagewise, pixelwise)\n• Semantic Segmentation (binary, multiclass, multilabel)\n• Change Detection (binary, multiclass, multilabel)\n• Object Detection\n• Instance Segmentation\n• Self-Supervised Learning (BYOL (Grill et al. 2020), MoCo (He et al. 2020), SimCLR (Chen\net al. 2020))\nThe following code can be easily extended to support TensorBoard logging (Lee et al. 2015), early\nstopping, and model checkpointing, and implements all of the steps from the previous section with\nsignificantly fewer lines of code.\nfrom lightning.pytorch import Trainer\nfrom torchgeo.datamodules import Sentinel2EuroCropsDataModule\nfrom torchgeo.models import ResNet50_Weights\nfrom torchgeo.trainers import SemanticSegmentationTask\nmodel = SemanticSegmentationTask(\nmodel='unet',\nbackbone='resnet50',\nweights=ResNet50_Weights.SENTINEL2_ALL_DINO,\nin_channels=13,\nnum_classes=200,\nlr=1e-2,\n)\ndatamodule = Sentinel2EuroCropsDataModule(\nsentinel2_paths='...',\neurocrops_paths='...',\n15\nbatch_size=64,\npatch_size=224,\n)\ntrainer = Trainer(max_epochs=100)\ntrainer.fit(model=model, datamodule=datamodule)\ntrainer.test(model=model, datamodule=datamodule)\n4.3\nCommand Line\nIn the research community, easy experimentation and reproducibility are paramount. TorchGeo\noffers a command-line interface based on LightningCLI, with support for command-line, YAML,\nand JSON configuration. The following YAML file can be used to reproduce an experiment from a\npaper without writing a single line of code.\nmodel:\nclass_path: SemanticSegmentationTask\ninit_args:\nmodel: 'unet'\nbackbone: 'resnet50'\nweights: 'ResNet50_Weights.SENTINEL2_ALL_DINO'\nin_channels: 13\nnum_classes: 200\nlr: 1e-2\ndata:\nclass_path: Sentinel2EuroCropsDataModule\ninit_args:\nbatch_size: 64\npatch_size: 224\ndict_kwargs:\nsentinel2_path: '...'\neurocrops_path: '...'\nOnce TorchGeo is installed, the user simply needs to run commands like fit or test to train and\nevaluate their model.\n> torchgeo fit --config config.yaml\n> torchgeo test --config config.yaml --ckpt_path=...\n5.\nBest Practices and Open Issues\nWith so many successful or abandoned GeoML libraries over the years, there is a wealth of in-\nformation on best practices to follow (and also what to avoid). Despite significant progress towards\nforming a consensus on code and data hosting repositories, there are still many open issues for future\ngenerations to tackle.\n5.1\nFile Formats\nOne of the primary purposes of GeoML libraries is to load and preprocess data. Thus, choosing the\nright file format is critical to achieve efficient I/O and keep the GPU busy. While GeoML libraries\nthemselves are often agnostic to file format and support a wide range of file types, users of GeoML\nlibraries can drastically improve the speed of training and inference by choosing the right file type.\nFor uncurated raster and vector data layers, GeoTIFF and ESRI Shapefile have long been stan-\ndard. In particular, so-called “cloud optimized GeoTIFFs” (COGs) support fast and efficient win-\ndowed reading, allowing tools like TorchGeo to load small image patches without reading the entire\n16\nAdam J. Stewart et al.\nfile from disk. Preprocessing, including manual reprojection, target aligned pixels (TAP), and com-\npression, can all improve I/O performance (A. J. Stewart et al. 2024).\nFor curated ML-ready benchmark datasets, geospatial metadata is often unnecessary or absent.\nTypical file formats include PNG and JPEG, with newer file formats like Parquet and Zarr becoming\nmore common for larger datasets. Language- or software-specific file formats like PyTorch’s .pth,\nNumPy’s .npy, or Python’s pickle should be avoided to ensure cross-language support.\nLarge-scale datasets commonly used for self-supervised learning and foundation model pretrain-\ning require their own careful consideration. Datasets such as SSL4EO (Wang et al. 2023; A. Stewart\net al. 2023), SatlasPretrain (Bastani et al. 2023), and CopernicusPretrain (Wang et al. 2025) consist of\nanywhere from millions to billions of files, easily enough to overwhelm all but the largest compute\nclusters. Modern formats like WebDataset (Breuel et al. 2019) and LitData (Chaton and Lightning\nAI 2023) offer support for sharding and streaming data, avoiding inode and storage limits.\n5.2\nDistribution\nGitHub is the primary hosting platform for GeoML libraries, with every single library on the list\nbeing developed or mirrored on GitHub. While many geospatial software packages are still hosted\non private servers like OSGeo and bug reports are filed through TRAC, GitHub has long been\npopular within the ML community. Having a single shared platform for everything from version\ncontrol to continuous integration to bug reporting makes it easier for potential users to find your\nsoftware and potential contributors to improve your software.\nWhile GitHub can be used for release distribution, the vast majority of successful GeoML li-\nbraries are distributed through language-specific servers like PyPI (Python), CRAN (R), or Conda-\nForge (Python/R). In fact, most of the abandoned GeoML libraries on our list either never had stable\nreleases, or were only distributed through git clone or docker pull. In the Python ecosystem,\npre-compiled binaries (bdists) such as wheels are critical for ease of installation, especially on Win-\ndows.\nGeoML datasets and pre-trained model weights can be found on a variety of platforms, with\npersonal Google Drive, OneDrive, and Baidu Drive being common. However, these platforms\nshould be avoided for serious scientific advances, as it is too easy to accidentally delete the wrong\nfile or directory. Instead, dedicated data hosting platforms like Zenodo or Hugging Face should be\nused instead. While AWS S3 buckets and Source Cooperative repositories are useful for extremely\nlarge datasets, they lack stable download URLs and checksumming capabilities required to ensure\nreproducibility.\n5.3\nLicensing\nOne of the most important considerations for developers and users of GeoML software is the license\nunder which it is distributed. Often overlooked by researchers, the license allows the owner of the IP\n(copyright, trademark, and/or patent) to explicitly grant certain permissions, with certain limitations,\nsubject to certain conditions. For example, the popular MIT license grants the user permission to\nredistribute and modify the software, including commercial and private use, limiting liability and\nwarranty of the developer, under the condition that the user preserves the license and copyright\nnotice. In this sense, licenses protect both the users and contributors.\nThere are two broad families of licenses: permissive and copyleft. Permissive licenses like MIT\nand Apache-2.0 are generally more relaxed, with the only condition that the license must be pre-\nserved. Copyleft licenses like the GNU Public License (GPL), on the other hand, impose strict\nconstraints on users such that any code bundled with the software must be released under the same\nlicense. Copyleft licenses are generally incompatible with industry, limiting adoption by many\ncommunities. With the exception of SITS, ML4Floods, and GeoDeep, every single GeoML library\nunder active development is released under a permissive license (see Table 2), reflecting the broader\n17\nPython and ML communities. SITS, like R itself, is licensed under GPL, restricting its use primarily\nto academic settings.\nWhile software licenses can technically be used for data and models, many of the clauses in these\nlicenses are not applicable to data or models. Instead, the Creative Commons family of licenses is\nmore common, including CC0 (public domain), CC-BY (Attribution), CC-BY-SA (Attribution-\nShareAlike), and CC-BY-NC (Attribution-NonCommercial). Responsible AI Licenses (RAIL) are\nanother family of licenses tailored specifically for the AI community, with subcategories for Data,\nApps, Models, and Source code. However, it is worth noting that CC-BY-NC and OpenRAIL are\nnot considered to be open source licenses, as they restrict certain usage.\nThe important thing for both code and data is to choose a license3 and stick with it. In particular,\ndatasets without licenses are unfortunately pervasive and challenging for GeoML libraries. While\nrarely enforced, it is technically illegal to even download let alone use or redistribute data without\na license.\n5.4\nContinuous Integration\nA good software library is not complete without continuous integration (CI), suites of checks and tests\nto ensure software quality that typically run on every commit, branch, pull request, and release.\nGitHub Actions is currently the dominant CI platform for free, public libraries, replacing Travis CI\nand CircleCI which dominated before its release.\nCI can and should consist of a variety of different types of testing. The most obvious is unit test-\ning, designed to ensure that individual functions and classes behave as they are designed to. Testing\nframeworks, including pytest for Python and testthat for R, handle the heavy lifting, allowing one\nto quickly add test cases (expected output given a certain input). Many libraries also run integration\ntests on release branches, ensuring that functions and classes can be integrated into a larger frame-\nwork. Test coverage is particularly important as it ensures that the majority of the library is touched\nby unit tests. Test coverage can be reported by services including Codecov and Coveralls. Software\nlibraries with less than 80% test coverage are generally not recommended for production use and\nshould be considered unstable.\nEven more important than unit testing is documentation. Tools like Sphinx can be used to\nbuild and test the documentation, and documentation hosting sites like ReadTheDocs provide CI\nsupport, allowing developers to see the documentation generated by each pull request. Sphinx can\nalso automatically generate API documentation from function and class docstrings, allowing you to\neasily maintain high-quality documentation.\nDynamically typed languages like Python can also benefit from type hints. Tools like mypy,\npytype, pyright, pyre, and ty can be used to enforce strict static typing, preventing a number of bugs\ncaused by bad typing practices. Tools like Sphinx can even use these type hints when generating\nAPI documentation. Similarly, tools like flake8, isort, black, and ruff can be used to enforce style\nguides, resulting in well-formatted code. While these may not seem important for single-author\nprojects, they become critical for maintaining projects with hundreds of contributors.\n5.5\nOpen Issues\nTesting and reproducibility (Heil et al. 2021) remain the biggest challenges faced by GeoML libraries\nat the moment. While many actively maintained GeoML libraries have over 90% test coverage (see\nTable 2), the majority fall far below, with some having no testing at all. A lack of tests puts these\nprojects at risk of both bugs (unexpected or incorrect behavior) and regressions (when a fixed bug\nresurfaces later). In addition, tests can ensure software stability, warning developers of unintentional\nbackwards-incompatible changes and allowing them to mitigate or document the change before\nmaking a release.\n3. https://choosealicense.com/\n18\nAdam J. Stewart et al.\nTest coverage itself is not the only important metric. Just because a line of code can be exe-\ncuted without raising an error does not mean it produces a desirable result. Machine learning is\ninherently stochastic, with non-determinism originating from the data (cross validation split, data\naugmentation, random shuffling), the model (initial weights, dropout layers), and the optimiza-\ntion process (SGD, momentum, learning rate scheduler). While setting a random seed can alleviate\nsome of these sources of non-determinism, reproducibility is not guaranteed across software ver-\nsions, platforms, and accelerators (CPU, GPU, TPU). This makes testing challenging for developers\nand perfect reproducibility practically impossible for users.\nAs datasets and models continue to grow in size, computational performance becomes increas-\ningly important. Maximizing I/O and data transfer speeds, especially for parallel filesystems and\non distributed compute, remains an important challenge. Libraries like Kornia (Riba et al. 2020)\naddress some of these challenges by implementing data augmentations directly in PyTorch or Rust,\nproviding significant speedups over pure Python implementations. It may be possible to achieve\nsimilar speedups for reprojection and resampling, often the biggest bottlenecks for geospatial data\nprocessing, by implementing these operations in PyTorch or CUDA and performing them on the\nGPU.\n6.\nFuture Implications\nWith increased interest in and funding for geospatial intelligence by industry, the future of GeoML\nlibraries looks promising. Below, we list our own predictions for what the next five years will look\nlike.\n6.1\nFoundation Models to Embeddings\nFoundation models (Bommasani et al. 2021) — large, task-agnostic deep learning models pretrained\non massive amounts of data — have dominated the last few years of research. We expect this dom-\ninance to continue, especially in the geospatial domain where scientists so often deal with limited\nlabeled data. While most current research focuses on EO foundation models for SAR and MSI satel-\nlite imagery, we expect foundation models to expand to a greater number of modalities, including\nHSI, UAV, and LiDAR data.\nWe also anticipate the development of unified foundation models for the land surface, ocean, and\natmosphere (Zhu et al. 2024). This is especially important in the area of weather and climate mod-\neling, where these processes are all interconnected and cannot be individually modeled. Application\ndomains like air pollution and nowcasting provide new challenges for GeoML libraries, forcing the\nincorporation of real-time point data in unstructured graphs instead of curated raster data.\nThe recent release of a number of high-profile foundation model embeddings, including Ma-\njor TOM (Czerkawski, Kluczek, Bojanowski, et al. 2024) and AlphaEarth Foundations (Brown et\nal. 2025), raises the question: are GeoML libraries still necessary? Deep learning can be very com-\nputationally demanding and requires technical expertise that many users lack, while pre-computed\nglobal embeddings allow users to run simple linear probing layers or k-NN models directly on\nfoundation model outputs. However, GeoML libraries are still necessary to generate new embed-\ndings, and foundation model fine-tuning still offers higher performance. Conversely, embeddings\nhave opened the door for a new type of GeoML library, like GeoTessera, which ease the use of\nlarge-scale embeddings.\n6.2\nGrowing Focus on Reuse and Ease of Use\nThe majority of the history of GeoML libraries has seen a “reinvention of the wheel”, with new li-\nbraries introducing clever ideas and solutions for common challenges without reusing older libraries.\nThis is especially true for pipeline-based libraries like Raster Vision and eo-learn, which are easy to\nuse but difficult to build on top of. The introduction of component-based libraries like TorchGeo\n19\nhas changed this, with libraries like GEO-Bench, TerraTorch, and GeoAI supplementing instead\nof replacing TorchGeo.\nFoundation models and embeddings have shown us that ease of use is often more important than\naccuracy. We expect further abstractions on top of component-based libraries providing low-code\nor no-code solutions for GIS domain experts. A handful of machine learning plugins already exist for\nArcGIS and QGIS, but lack the power and features of existing GeoML libraries. Vision–language\nfoundation models like DOFA-CLIP (Xiong et al. 2025) present an interesting opportunity for\nzero-shot learning, in which the user can ask the model to perform a task using natural language.\n6.3\nIndependent Governance and Software Foundations\nHowever, successful software is often made by multiple people working together on behalf of a\ncompany or research institution. This incubation process provides the necessary funding and ad-\nvertising needed for the project to take off. After gaining popularity, successful software can quickly\noutgrow the organization that created it. Once this happens, independent governance is required to\nallow the project to continue to grow. Examples of this include PyTorch (developed by Meta) and\nTensorFlow/Keras/JAX (developed by Google), which are now governed by independent teams of\nmaintainers.\nSeveral GeoML libraries have graduated beyond this incubation status and achieved open and\nindependent governance. OTB gained independence from CNES and announced its new open\ngovernance model in March of 2015. PySAL has always been independent and adopted a formal\ngovernance structure in February of 2019. TorchGeo gained independence from Microsoft in Au-\ngust of 2025 and now holds monthly Technical Steering Committee meetings open to the public.\nAll three of these libraries have cultivated successful open source ecosystems, with further GeoML\nlibraries extending their capabilities: OTB (OTBTF), PySAL (spopt), and TorchGeo (GEO-Bench,\nGeoAI, TerraTorch).\nAn interesting question is what role software foundations should play in this incubation pro-\ncess. Many geospatial and ML software foundations exist, including the Open Source Geospatial\nFoundation (OSGeo), the PyTorch Foundation, the Linux Foundation AI & Data, and the AI Al-\nliance. OTB and TorchGeo already belong to OSGeo, while TerraTorch recently joined the AI\nAlliance. These foundations provide advertising, financial support, and legal support for a variety of\nsoftware projects, promoting collaboration between member projects. These software foundations\ncould provide a neutral home for many such GeoML libraries.\nAcknowledgments\nThe authors would like to thank the contributors to and maintainers of all GeoML software for their\ntireless efforts in building much-needed software infrastructure for this domain. In particular, we\nwould like to thank Nicolas Audebert (author of DeepNetsForEO and DeepHyperX) and Gilberto\nCamara (author of SITS) for sharing their knowledge about the early history of GeoML software.\nWe would also like to thank Robin Cole and Eduardo Lacerda for maintaining listings of all major\nGeoML libraries throughout recent years. The work was supported in part by the National Science\nFoundation (NSF) through awards IIS 21-31335, OAC 21-30835, DBI 20-21898, as well as a C3.ai\nresearch award.\nReferences\nAbadi, Martín, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat,\nGeoffrey Irving, Michael Isard, et al. 2016. TensorFlow: a system for large-scale machine learning. In 12th usenix\nsymposium on operating systems design and implementation (osdi 16), 265–283.\nAleksandrov, Matej, et al. 2018. Eo-learn: Earth observation processing framework for machine learning in Python. https://github.\ncom/sentinel-hub/eo-learn.\n20\nAdam J. Stewart et al.\nAlexandrov, Alexander, Konstantinos Benidis, Michael Bohlke-Schneider, Valentin Flunkert, Jan Gasthaus, Tim Januschowski,\nDanielle C Maddix, Syama Rangapuram, David Salinas, Jasper Schulz, et al. 2020. GluonTS: probabilistic and neural\ntime series modeling in Python. Journal of Machine Learning Research 21 (116): 1–6.\nAszkowski, Przemysław, Bartosz Ptak, Marek Kraft, Dominik Pieczyński, and Paweł Drapikowski. 2023. Deepness: deep\nneural remote sensing plugin for QGIS. SoftwareX 23:101495. ISSN: 2352-7110. https://doi.org/https://doi.org/10.\n1016/j.softx.2023.101495. https://www.sciencedirect.com/science/article/pii/S2352711023001917.\nAudebert, N., B. Le Saux, and S. Lefèvre. 2019. Deep learning for classification of hyperspectral data: a comparative review.\nIEEE Geoscience and Remote Sensing Magazine 7, no. 2 (June): 159–173. ISSN: 2373-7468. https://doi.org/10.1109/\nMGRS.2019.2912563.\nAudebert, Nicolas, Bertrand Le Saux, and Sébastien Lefèvre. 2017. Beyond RGB: very high resolution urban remote sensing\nwith multimodal deep networks. ISPRS Journal of Photogrammetry and Remote Sensing, ISSN: 0924-2716. https://doi.org/\nhttps://doi.org/10.1016/j.isprsjprs.2017.11.011.\nAzavea/Element 84 and Robert Cheetham. 2017. Raster Vision: An open source library and framework for deep learning on satellite\nand aerial imagery (2017-2023). https://github.com/azavea/raster-vision.\nBastani, Favyen, Piper Wolters, Ritwik Gupta, Joe Ferdinando, and Aniruddha Kembhavi. 2023. SatlasPretrain: a large-scale\ndataset for remote sensing image understanding. In Proceedings of the ieee/cvf international conference on computer vision,\n16772–16782.\nBhadra, Sourav. 2023. Raster4ML: a geospatial raster processing library for machine learning. https://github.com/souravbhadra/\nraster4ml.\nBoggs, Thomas, et al. 2001. Spectral Python (SPy): Python module for hyperspectral image processing. https : / / github . com /\nspectralpython/spectral.\nBommasani, Rishi, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jean-\nnette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv\npreprint arXiv:2108.07258.\nBradski, Gary, Adrian Kaehler, et al. 2000. OpenCV. Dr. Dobb’s Journal of Software Tools 3 (2).\nBreuel, Thomas, et al. 2019. WebDataset: a high-performance Python-based I/O system for large (and small) deep learning problems,\nwith strong support for PyTorch. https://github.com/webdataset/webdataset.\nBrockman, Greg, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba.\n2016. OpenAI Gym. arXiv preprint arXiv:1606.01540.\nBrown, Christopher F, Michal R Kazmierski, Valerie J Pasquarella, William J Rucklidge, Masha Samsikova, Chenhui Zhang,\nEvan Shelhamer, Estefania Lahera, Olivia Wiles, Simon Ilyushchenko, et al. 2025. AlphaEarth Foundations: an em-\nbedding field model for accurate and efficient global mapping from sparse label data. arXiv preprint arXiv:2507.22291.\nCamara, Gilberto, Rolf Simoes, Felipe Souza, Felipe Carlos, Charlotte Pelletier, Pedro R. Andrade, Karine Ferreira, and\nGilberto Queiroz. 2024. SITS - satellite image time series analysis on Earth observation data cubes. National Institute for\nSpace Research (INPE), Brazil.\nChang, Chih-Chung, and Chih-Jen Lin. 2011. LIBSVM: a library for support vector machines. ACM transactions on intelligent\nsystems and technology (TIST) 2 (3): 1–27.\nChaton, Thomas, and Lightning AI. 2023. LitData: transform datasets at scale. optimize datasets for fast ai model training. https:\n//github.com/Lightning-AI/litdata.\nChen, Hao, and Zhenwei Shi. 2020. A spatial-temporal attention-based method and a new dataset for remote sensing image\nchange detection. Remote Sensing 12 (10): 1662.\nChen, Ting, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learn-\ning of visual representations. In International conference on machine learning, 1597–1607. PmLR.\nChowdhury, Kanchan, and Mohamed Sarwat. 2022. GeoTorch: a spatiotemporal deep learning framework. In Sigspatial ’22.\nSeattle, Washington: Association for Computing Machinery. ISBN: 9781450395298. https://doi.org/10.1145/3557915.\n3561036. https://doi.org/10.1145/3557915.3561036.\nCollette, Andrew, et al. 2008. HDF5 for Python – the h5py package is a Pythonic interface to the HDF5 binary data format.\nhttps://github.com/h5py/h5py.\nColtin, Brian, et al. 2019. DELTA: deep learning for satellite imagery. https://github.com/nasa/delta.\n21\nCorley, Isaac. 2021. Torchrs: PyTorch implementation of popular datasets and models in remote sensing. https : / / github . com /\nisaaccorley/torchrs.\nCresson, Rémi. 2018. A framework for remote sensing images processing using deep learning techniques. IEEE Geoscience\nand Remote Sensing Letters 16 (1): 25–29.\nCzerkawski, Mikolaj, Marcin Kluczek, JÄ Bojanowski, et al. 2024. Global and dense embeddings of Earth: Major TOM\nfloating in the latent space. arXiv preprint arXiv:2412.05600.\nDamien, Aymeric, et al. 2016. TFLearn: deep learning library featuring a higher-level API for TensorFlow. https://github.com/\ntflearn/tflearn.\nDeng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. ImageNet: a large-scale hierarchical image\ndatabase. In 2009 ieee conference on computer vision and pattern recognition, 248–255. IEEE.\nDimitrovski, Ivica, Ivan Kitanovski, Dragi Kocev, and Nikola Simidjievski. 2023. Current trends in deep learning for Earth\nobservation: an open-source benchmark arena for image classification. ISPRS Journal of Photogrammetry and Remote\nSensing 197:18–35. ISSN: 0924-2716.\nDimitrovski, Ivica, Ivan Kitanovski, Panče Panov, Ana Kostovska, Nikola Simidjievski, and Dragi Kocev. 2023. AiTLAS:\nartificial intelligence toolbox for Earth observation. Remote Sensing 15 (9). ISSN: 2072-4292. https://doi.org/10.3390/\nrs15092343.\nDrusch, Matthias, Ugo Del Bello, Séverine Carlier, Olivier Colin, Viviana Fernandez, Ferran Gascon, Bernhard Hoersch, et\nal. 2012. Sentinel-2: ESA’s optical high-resolution mission for GMES operational services. Remote Sensing of Environment\n120:25–36. https://doi.org/10.1016/j.rse.2011.11.026.\nFalcon, William, and The PyTorch Lightning team. 2019. PyTorch Lightning. https://github.com/Lightning-AI/lightning.\nFeng, Xin, Germano Barcelos, James D. Gaboardi, Elijah Knaap, Ran Wei, Levi J. Wolf, Qunshan Zhao, and Sergio J. Rey.\n2022. Spopt: a Python package for solving spatial optimization problems in PySAL. Journal of Open Source Software 7\n(74): 3330. https://doi.org/10.21105/joss.03330. https://doi.org/10.21105/joss.03330.\nFeng, Zhengpeng, Clement Atzberger, Sadiq Jaffer, Jovana Knezevic, Silja Sormunen, Robin Young, Madeline C Lisaius, et\nal. 2025. TESSERA: temporal embeddings of surface spectra for Earth representation and analysis. arXiv: 2506.20380 [cs.LG].\nhttps://arxiv.org/abs/2506.20380.\nFuller, Anthony, Koreen Millard, and James Green. 2023. CROMA: remote sensing representations with contrastive radar-\noptical masked autoencoders. Advances in Neural Information Processing Systems 36:5506–5538.\nGaydon, Charles. 2022. Myria3D: deep learning for the semantic segmentation of aerial lidar point clouds. https://github.com/\nIGNF/myria3d.\nGDAL/OGR contributors. 2022. GDAL/OGR geospatial data abstraction software library. Open Source Geospatial Foundation.\nhttps://doi.org/10.5281/zenodo.5884351. https://gdal.org.\nGillies, Sean, et al. 2013. Rasterio: geospatial raster I/O for Python programmers. https://github.com/rasterio/rasterio.\nGillies, Sean, René Buffat, Joshua Arnott, Mike W. Taves, Kevin Wurster, Alan D. Snow, Micah Cochran, Elliott Sales de\nAndrade, and Matthew Perry. 2024. Fiona. V. 1.10.0, September. https://github.com/Toblerity/Fiona.\nGohlke, Christoph. 2018. Tifffile: read and write TIFF files. https://github.com/cgohlke/tifffile.\nGomes, Carlos, Benedikt Blumenstiel, Joao Lucas de Sousa Almeida, Pedro Henrique de Oliveira, Paolo Fraccaro, Francesc\nMarti Escofet, Daniela Szwarcman, Naomi Simumba, Romeo Kienzler, and Bianca Zadrozny. 2025. TerraTorch: the\ngeospatial foundation models toolkit. arXiv preprint arXiv:2503.20563.\nGramacki, Piotr, Kacper Leśniara, Kamil Raczycki, Szymon Woźniak, Marcin Przymus, and Piotr Szymański. 2023. SRAI:\ntowards standardization of geospatial AI. In Proceedings of the 6th acm sigspatial international workshop on ai for geographic\nknowledge discovery. Association for Computing Machinery, November. https://dl.acm.org/doi/10.1145/3615886.\n3627740.\nGrill, Jean-Bastien, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch,\nBernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. 2020. Bootstrap your own latent-a new\napproach to self-supervised learning. Advances in Neural Information Processing Systems 33:21271–21284.\nGrizonnet, Manuel, Julien Michel, Victor Poughon, Jordi Inglada, Mickaël Savinaud, and Rémi Cresson. 2017. Orfeo Tool-\nBox: open source processing of remote sensing images. Open Geospatial Data, Software and Standards 2 (1): 15.\n22\nAdam J. Stewart et al.\nHarada, Nate. 2023. Moonshine: pretrained remote sensing models for the rest of us. https://github.com/moonshinelabs- ai/\nmoonshine.\nHarris, Charles R., K. Jarrod Millman, Stéfan J van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser,\net al. 2020. Array programming with NumPy. Nature 585:357–362. https://doi.org/10.1038/s41586-020-2649-2.\nHe, Kaiming, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momentum contrast for unsupervised visual\nrepresentation learning. In Proceedings of the ieee/cvf conference on computer vision and pattern recognition, 9729–9738.\nHe, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceed-\nings of the ieee conference on computer vision and pattern recognition, 770–778.\nHeil, Benjamin J, Michael M Hoffman, Florian Markowetz, Su-In Lee, Casey S Greene, and Stephanie C Hicks. 2021.\nReproducibility standards for machine learning in the life sciences. Nature Methods 18 (10): 1132–1135.\nHijmans, Robert J., Márcia Barbosa, Roger Bivand, Andrew Brown, Michael Chirico, Emanuele Cordano, Krzysztof Dyba,\nEdzer Pebesma, Barry Rowlingson, and Michael D. Sumner. 2018. Terra: R package for spatial data handling. https :\n//doi.org/10.32614/CRAN.package.terra.\nHofmann, Daniel J., Bhargav Kowshik, et al. 2018. RoboSat: generic ecosystem for feature extraction from aerial and satellite imagery.\nhttps://github.com/mapbox/robosat.\nHoyer, Stephan, and Hamman Joseph. 2017. Xarray: N-D labeled arrays and datasets in Python. Journal of Open Research\nSoftware 5, no. 1 (April). https://doi.org/10.5334/jors.148.\nJia, Yangqing, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and\nTrevor Darrell. 2014. Caffe: convolutional architecture for fast feature embedding. In Proceedings of the 22nd acm inter-\nnational conference on multimedia, 675–678.\nJohnson, Andrew L., et al. 2016. DeepOSM: train a deep learning net with OpenStreetMap features and satellite imagery. https:\n//github.com/trailbehind/DeepOSM.\nJordahl, Kelsey, et al. 2013. GeoPandas: Python tools for geographic data. https://github.com/geopandas/geopandas.\nKarra, Krishna, Caitlin Kontgis, Zoe Statman-Weil, Joseph C Mazzariello, Mark Mathis, and Steven P Brumby. 2021. Global\nland use/land cover with Sentinel 2 and deep learning. In 2021 ieee international geoscience and remote sensing symposium\nigarss, 4704–4707. Brussels, Belgium: IEEE.\nKellenberger, Benjamin, Devis Tuia, and Dan Morris. 2020. AIDE: accelerating image-based ecological surveys with inter-\nactive machine learning. Methods in Ecology and Evolution 11 (12): 1716–1727.\nKerner, Hannah, Snehal Chaudhari, Aninda Ghosh, Caleb Robinson, Adeel Ahmad, Eddie Choi, Nathan Jacobs, Chris\nHolmes, Matthias Mohr, Rahul Dodhia, et al. 2025. Fields of the world: a machine learning benchmark dataset for\nglobal agricultural field boundary segmentation. In Proceedings of the aaai conference on artificial intelligence, 39:28151–\n28159.\nKirillov, Alexander, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead,\nAlexander C Berg, Wan-Yen Lo, et al. 2023. Segment anything. In Proceedings of the ieee/cvf international conference on\ncomputer vision, 4015–4026.\nKrause, Oswin, et al. 2009. The Shark machine learning library. https://github.com/Shark-ML/Shark.\nKrizhevsky, Alex, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. Master’s thesis, Uni-\nversity of Toronto.\nLacoste, Alexandre, Nils Lehmann, Pau Rodriguez, Evan Sherwin, Hannah Kerner, Björn Lütjens, Jeremy Irvin, David Dao,\nHamed Alemohammad, Alexandre Drouin, et al. 2023. GEO-Bench: toward foundation models for Earth monitoring.\nAdvances in Neural Information Processing Systems 36:51080–51093.\nLee, Stephan, et al. 2015. TensorBoard: TensorFlow’s visualization toolkit. https://github.com/tensorflow/tensorboard.\nMa, Yanjun, Dianhai Yu, Tian Wu, and Haifeng Wang. 2019. PaddlePaddle: an open-source deep learning platform from\nindustrial practice. Frontiers of Data and Computing 1 (1): 105–115.\nMarcel, Sébastien, and Yann Rodriguez. 2010. Torchvision the machine-vision package of torch. In Proceedings of the 18th\nacm international conference on multimedia, 1485–1488.\n23\nMateo-Garcia, Gonzalo, Joshua Veitch-Michaelis, Lewis Smith, Silviu Vlad Oprea, Guy Schumann, Yarin Gal, Atılım Güneş\nBaydin, and Dietmar Backes. 2021. Towards global flood mapping onboard low cost satellites with machine learning.\nScientific Reports 11, no. 1 (March): 7249. ISSN: 2045-2322, accessed April 1, 2021. https://doi.org/10.1038/s41598-\n021-86650-z.\nMaxwell, Aaron E, Sarah Farhadpour, Srinjoy Das, and Yalin Yang. 2024. Geodl: an R package for geospatial deep learning\nsemantic segmentation using torch and terra. PloS one 19 (12): e0315127.\nMiles, Alistair, et al. 2015. Zarr: an implementation of chunked, compressed, N-dimensional arrays for Python. https://github.com/\nzarr-developers/zarr-python.\nMoliński, Szymon, et al. 2018. Pyinterpolate: Kriging | Poisson Kriging | variogram analysis. https://github.com/DataverseLabs/\npyinterpolate.\nMulla, David J. 2013. Twenty five years of remote sensing in precision agriculture: key advances and remaining knowledge\ngaps. Special Issue: Sensing Technologies for Sustainable Agriculture, Biosystems Engineering 114 (4): 358–371. ISSN:\n1537-5110. https://doi.org/10.1016/j.biosystemseng.2012.08.009.\nOpenStreetMap contributors. 2017. OpenStreetMap. https://www.openstreetmap.org.\nPaddlePaddle Authors. 2022. PaddleRS, awesome remote sensing toolkit based on PaddlePaddle. https://github.com/PaddlePaddle/\nPaddleRS.\nPaszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019.\nPyTorch: an imperative style, high-performance deep learning library. In Advances in neural information processing sys-\ntems, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, vol. 32. Curran\nAssociates, Inc. https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-\nPaper.pdf.\nPebesma, Edzer. 2018. Simple Features for R: standardized support for spatial vector data. The R Journal 10 (1): 439–446.\nhttps://doi.org/10.32614/RJ-2018-009. https://doi.org/10.32614/RJ-2018-009.\nPedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blon-\ndel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: machine learning in Python. Journal of\nMachine Learning Research 12:2825–2830.\nReed, Colorado J, Ritwik Gupta, Shufan Li, Sarah Brockman, Christopher Funk, Brian Clipp, Kurt Keutzer, Salvatore\nCandido, Matt Uyttendaele, and Trevor Darrell. 2023. Scale-MAE: a scale-aware masked autoencoder for multiscale\ngeospatial representation learning. In Proceedings of the ieee/cvf international conference on computer vision, 4088–4099.\nRiba, E., D. Mishkin, D. Ponsa, E. Rublee, and G. Bradski. 2020. Kornia: an open source differentiable computer vision\nlibrary for PyTorch. In Winter conference on applications of computer vision. https://arxiv.org/pdf/1910.02190.pdf.\nRobinson, Caleb, Le Hou, Kolya Malkin, Rachel Soobitsky, Jacob Czawlytko, Bistra Dilkina, and Nebojsa Jojic. 2019. Large\nscale high-resolution land cover mapping with multi-resolution data. In Proceedings of the ieee/cvf conference on computer\nvision and pattern recognition, 12726–12735.\nRolf, Esther, Konstantin Klemmer, Caleb Robinson, and Hannah Kerner. 2024. Position: mission critical–satellite data is a\ndistinct modality in machine learning. In Forty-first international conference on machine learning.\nRolnick, David, Priya L Donti, Lynn H Kaack, Kelly Kochanski, Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross,\nNikola Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, et al. 2022. Tackling climate change with machine\nlearning. ACM Computing Surveys (CSUR) 55 (2): 1–96.\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. U-Net: convolutional networks for biomedical image segmen-\ntation. In Medical image computing and computer-assisted intervention–miccai 2015, 234–241. Springer.\nSantara, Anirban, Ankit Singh, Pranoot Hatwar, Kaustubh Mani, and Pabitra Mitra. 2016. Hyperspectral: deep learning for\nland-cover classification in hyperspectral images. https://github.com/KGPML/Hyperspectral.\nSchneider, Maja, Tobias Schelte, Felix Schmitz, and Marco Körner. 2023. EuroCrops: the largest harmonized open crop\ndataset across the European Union. Scientific Data 10 (1): 612.\nSimoes, Rolf, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R Andrade, Lorena Santos, Alexandre Carvalho, and\nKarine Ferreira. 2021. Satellite image time series analysis for big Earth observation data. Remote Sensing 13 (13): 2428.\nSnow, Alan D., et al. 2019. Rioxarray: geospatial xarray extension powered by rasterio. https://github.com/corteva/rioxarray.\n24\nAdam J. Stewart et al.\nStewart, Adam, Nils Lehmann, Isaac Corley, Yi Wang, Yi-Chia Chang, Nassim Ait Ali Braham, Shradha Sehgal, Caleb\nRobinson, and Arindam Banerjee. 2023. SSL4EO-L: datasets and foundation models for Landsat imagery. Advances in\nNeural Information Processing Systems 36:59787–59807.\nStewart, Adam J., Caleb Robinson, Isaac A. Corley, Anthony Ortiz, Juan M. Lavista Ferres, and Arindam Banerjee. 2024.\nTorchGeo: deep learning with geospatial data. ACM Transactions on Spatial Algorithms and Systems (December). https:\n//doi.org/10.1145/3707459. https://doi.org/10.1145/3707459.\nTarazona, Yonatan, Fernando Benitez-Paez, Jakub Nowosad, Fabian Drenkhan, and Martín E Timaná. 2024. Scikit-eo: a\nPython package for remote sensing data analysis. Journal of Open Source Software 9 (99): 6692.\nToffanin, Piero, et al. 2025. GeoDeep: free and open source library for AI object detection and semantic segmentation in geospatial\nrasters. https://github.com/uav4geo/GeoDeep.\nVan Westen, Cees J. 2013. Remote sensing and GIS for natural hazards assessment and disaster risk management. Treatise on\nGeomorphology 3:259–298.\nWaldmann, Leonard, Ando Shah, Yi Wang, Nils Lehmann, Adam J Stewart, Zhitong Xiong, Xiao Xiang Zhu, Stefan Bauer,\nand John Chuang. 2025. Panopticon: advancing any-sensor foundation models for Earth observation. arXiv preprint\narXiv:2503.10845.\nWang, Shuai. 2019. TorchSat: an open-source deep learning framework for satellite imagery analysis based on PyTorch. https://github.\ncom/sshuair/torchsat.\nWang, Yi, Nassim Ait Ali Braham, Zhitong Xiong, Chenying Liu, Conrad M Albrecht, and Xiao Xiang Zhu. 2023.\nSSL4EO-S12: a large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation. IEEE\nGeoscience and Remote Sensing Magazine 11 (3): 98–106.\nWang, Yi, Zhitong Xiong, Chenying Liu, Adam J Stewart, Thomas Dujardin, Nikolaos Ioannis Bountos, Angelos Zavras,\nFranziska Gerken, Ioannis Papoutsis, Laura Leal-Taixé, et al. 2025. Towards a unified Copernicus foundation model\nfor Earth vision. arXiv preprint arXiv:2503.11849.\nWeinstein, Ben G, Sergio Marconi, Mélaine Aubry-Kientz, Gregoire Vincent, Henry Senyondo, and Ethan P White. 2020.\nDeepForest: a Python package for RGB deep learning tree crown delineation. Methods in Ecology and Evolution 11 (12):\n1743–1751.\nWeir, Nick, et al. 2019. Solaris: CosmiQ Works geospatial machine learning analysis toolkit. https://github.com/CosmiQ/solaris.\nWolf, Thomas, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault,\nRémi Louf, Morgan Funtowicz, et al. 2019. HuggingFace’s transformers: state-of-the-art natural language processing.\narXiv preprint arXiv:1910.03771.\nWu, Qiusheng, et al. 2023. GeoAI: artificial intelligence for geospatial data. https://github.com/opengeos/geoai.\nWu, Qiusheng, and Lucas Prado Osco. 2023. Samgeo: a Python package for segmenting geospatial data with the Segment\nAnything Model (SAM). Journal of Open Source Software 8, no. 89 (September): 5663. https://doi.org/10.21105/joss.\n05663. https://joss.theoj.org/papers/10.21105/joss.05663.\nWu, Yuxin, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick. 2019. Detectron2. https://github.com/\nfacebookresearch/detectron2.\nXiong, Zhitong, Yi Wang, Weikang Yu, Adam J Stewart, Jie Zhao, Nils Lehmann, Thomas Dujardin, Zhenghang Yuan,\nPedram Ghamisi, and Xiao Xiang Zhu. 2025. DOFA-CLIP: multimodal vision-language foundation models for Earth\nobservation. arXiv preprint arXiv:2503.06312.\nXiong, Zhitong, Yi Wang, Fahong Zhang, Adam J Stewart, Joëlle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le\nSaux, Gustau Camps-Valls, and Xiao Xiang Zhu. 2024. Neural plasticity-inspired multimodal foundation model for\nEarth observation. arXiv preprint arXiv:2403.15356.\nYang, Yao-Yuan, Moto Hira, Zhaoheng Ni, Artyom Astafurov, Caroline Chen, Christian Puhrsch, David Pollack, Dmitriy\nGenzel, Donny Greenberg, Edward Z Yang, et al. 2022. Torchaudio: building blocks for audio and speech processing.\nIn Icassp 2022-2022 ieee international conference on acoustics, speech and signal processing (icassp), 6982–6986. IEEE.\nYu, Jia, et al. 2015. Apache Sedona: a cluster computing framework for processing large-scale geospatial data. https://github.com/\napache/sedona.\nZhu, Xiao Xiang, Zhitong Xiong, Yi Wang, Adam J Stewart, Konrad Heidler, Yuanyuan Wang, Zhenghang Yuan, Thomas\nDujardin, Qingsong Xu, and Yilei Shi. 2024. On the foundations of Earth and climate foundation models. arXiv preprint\narXiv:2405.04285.\n",
    "content": "```markdown\n# Interpreting the Paper \"Geospatial Machine Learning Libraries\"\n\n## 1. Core Content and Key Contributions\n\nThis paper provides a systematic review and analysis of the **development, current state, and future directions of geospatial machine learning (GeoML) software libraries**, aiming to serve as a comprehensive guide for researchers, developers, and practitioners.\n\n### Core Content:\n- **Problem Context**: Despite the growing abundance of remote sensing data (e.g., satellite imagery), its unique characteristics—such as multi-resolution, multi-spectral, temporal nature, coordinate systems, and file formats—make traditional machine learning tools difficult to apply directly.\n- **Historical Evolution**: Traces the development of over 30 GeoML libraries since 2001, from early tools like SPy and OTB to recent frameworks such as TorchGeo, eo-learn, and Raster Vision.\n- **Technical Analysis**: In-depth examination of core functionalities in mainstream GeoML libraries, including data I/O, spatiotemporal alignment, preprocessing, sampling strategies, and model integration.\n- **Case Study Demonstration**: Uses \"crop type classification\" as an example to illustrate end-to-end modeling with TorchGeo across three abstraction levels: pure PyTorch, PyTorch Lightning, and command-line interface.\n- **Best Practices**: Summarizes lessons learned in areas such as file format selection, distribution methods, open-source licensing, continuous integration (CI), and test coverage.\n- **Future Outlook**: Predicts trends toward foundation models, embeddings, low-code/no-code tools, and independently governed projects.\n\n### Key Contributions:\n1. **First Systematic Survey**: Offers the most comprehensive ecosystem map of GeoML libraries to date, filling a critical gap in authoritative reviews for this domain.\n2. **Standardized Evaluation Framework**: Compares libraries using structured tables covering functionality support, GitHub activity, download statistics, and test coverage—enabling informed tool selection.\n3. **Practical Insights Synthesized**: Draws actionable best practices from real-world project successes and failures, emphasizing **reproducibility, robust testing, and community governance**.\n4. **Catalyzing Industry Consensus**: Advocates for building unified, modular, composable GeoML infrastructure to avoid redundant efforts (\"reinventing the wheel\").\n\n---\n\n## 2. Breakthroughs and Innovations\n\n### (1) Proposing “Component-Based Architecture” as the Next-Gen GeoML Standard\nThe paper argues that many past GeoML libraries adopted monolithic or pipeline-based designs (e.g., Raster Vision, eo-learn)—easy to use but hard to extend. In contrast, **TorchGeo represents a new paradigm: component-driven, composable design**. It focuses solely on high-quality abstractions for datasets, samplers, and pre-trained models, enabling higher-level tools (like TerraTorch or GeoAI) to build atop it. This \"Lego-like\" architecture significantly enhances ecosystem synergy.\n\n> ✅ Innovation Significance: Shifts GeoML from isolated silos to collaborative ecosystem building.\n\n### (2) Identifying How “Foundation Models + Embeddings” Are Reshaping GeoML Workflows\nThe paper observes that large-scale pre-trained models like Scale-MAE, DOFA, and Copernicus-FM are reducing the need for training from scratch. The emergence of libraries like **GeoTessera, which provide ready-to-use embeddings**, suggests that many future tasks may only require simple linear probing or k-nearest neighbors.\n\n> ✅ Innovation Significance: Redefines who needs deep learning expertise, lowering AI accessibility barriers.\n\n### (3) Emphasizing “Governance Independence” as Key to Long-Term Success\nThe authors highlight that successful open-source projects must eventually transition from institutional control to open governance. Examples include **OTB, PySAL, and TorchGeo**, all of which have achieved independence through affiliations with foundations like OSGeo or the AI Alliance, ensuring long-term sustainability.\n\n> ✅ Innovation Significance: Moves beyond technology to examine organizational evolution paths for open-source projects.\n\n### (4) Empirically Driven Methodology\nUnlike purely theoretical surveys, this work uses real-world metrics—GitHub stars/forks/contributors, PyPI downloads, test coverage—for quantitative analysis. It also derives best practices by analyzing failed projects (e.g., lack of stable releases often leads to project abandonment).\n\n> ✅ Innovation Significance: Grounds conclusions in data, enhancing credibility and practical relevance.\n\n---\n\n## 3. Promising Startup Ideas (Based on the Paper)\n\nHere are five commercially viable startup opportunities inspired by technological gaps and emerging trends identified in the paper:\n\n### 🚀 Startup Idea 1: GeoML Model Hub — A Marketplace Platform for Geospatial AI Models\n\n**Inspiration**: Hugging Face’s success + references to GEO-Bench and pre-trained weights in TorchGeo.\n\n**Pain Point**: GeoML models are currently scattered across GitHub repos and personal drives, lacking standardized discovery, benchmarking, and deployment mechanisms.\n\n**Solution**:\n- Build a **domain-specific model hub for geospatial AI**, similar to [HuggingFace](https://huggingface.co/), supporting upload/download, fine-tuning, and inference APIs.\n- Integrate automated benchmarking suites (using GEO-Bench) with public leaderboards.\n- Support ONNX/TorchScript conversion for one-click deployment to edge devices (drones, agricultural robots).\n\n**Business Model**:\n- Free open-source core + paid enterprise deployments\n- Pay-per-call API usage\n- Revenue sharing with cloud providers via plugins (AWS/Azure/GCP)\n\n---\n\n### 🧩 Startup Idea 2: No-Code GeoAI Builder for GIS Professionals\n\n**Inspiration**: Section 6.2 on \"Low-code/No-code solutions\" + limitations of existing QGIS/ArcGIS plugins.\n\n**Pain Point**: Many GIS experts understand remote sensing but lack coding skills, making advanced tools like TorchGeo inaccessible.\n\n**Solution**:\n- Develop **QGIS/ArcGIS plugins with drag-and-drop interfaces**:\n  - Connect to data sources (STAC/Sentinel Hub)\n  - Automatically align and tile spatiotemporal data\n  - Select and fine-tune pre-trained models\n  - Visualize and export results\n- Backend powered by TorchGeo or PyTorch Lightning to ensure performance and reproducibility.\n\n**Target Customers**:\n- Agricultural companies (crop monitoring)\n- Urban planning institutes (land use change detection)\n- Environmental NGOs (deforestation tracking)\n\n**Advantage**: Enables non-programmers to leverage cutting-edge AI capabilities effortlessly.\n\n---\n\n### ☁️ Startup Idea 3: Cloud-Native GeoML Pipeline Engine\n\n**Inspiration**: EOWorkflow concept from eo-learn + demand for distributed computing at scale.\n\n**Pain Point**: Existing tools struggle with petabyte-scale remote sensing data and lack cross-cloud orchestration capabilities.\n\n**Solution**:\n- Build a **cloud-native GeoML pipeline engine** featuring:\n  - Auto-scaling for distributed data tiling and feature extraction\n  - Integration with Dask/Ray for large-scale training\n  - Seamless stitching of multi-source data (Landsat + Sentinel + Planet)\n  - Automatic publishing of outputs as WMS/WMTS services\n- Define workflows via YAML configuration files compatible with TorchGeo Dataset API.\n\n**Differentiator**: More specialized than Airflow, more scalable than eo-learn.\n\n**Use Cases**: National natural resource monitoring, global carbon sink estimation.\n\n---\n\n### 🌍 Startup Idea 4: Global Embedding as a Service (GEaaS)\n\n**Inspiration**: Emergence of global embedding models like Major TOM and AlphaEarth Foundations.\n\n**Pain Point**: Running billion-parameter models is prohibitively expensive for small and medium organizations.\n\n**Solution**:\n- Launch a **“Global Earth Embeddings as a Service” product**:\n  - Regularly updated global, multimodal embedding layers (optical/SAR/weather)\n  - API access to retrieve vector representations for any latitude/longitude\n  - Provide templates for downstream tasks (classification, regression, anomaly detection)\n- Analogous to Google Maps API—but returns AI-ready semantic vectors instead of maps.\n\n**Value Proposition**: “You don’t need to train big models—just know how to ask.”\n\n**Potential Clients**:\n- Insurance underwriting (natural disaster risk modeling)\n- Commodity futures (crop yield forecasting)\n- Logistics optimization (terrain passability assessment)\n\n---\n\n### 🔐 Startup Idea 5: GeoML Compliance & Provenance Audit Platform\n\n**Inspiration**: The paper’s emphasis on licensing, reproducibility, and data provenance.\n\n**Pain Point**: When AI-generated maps inform decisions (e.g., environmental enforcement), full auditability is essential.\n\n**Solution**:\n- Build a **compliance management platform for GeoML projects**:\n  - Automatically detect license conflicts in dependencies (e.g., GPL vs commercial use)\n  - Log data sources, model versions, hyperparameters (enhanced MLflow-style tracking)\n  - Generate CITATION.cff files compliant with academic publishing standards\n  - Offer “one-click experiment reproduction” with environment snapshots (Docker/Git)\n\n**Applications**:\n- Government procurement vetting for AI services\n- Academic paper submission support\n- Third-party verification for ESG reporting\n\n**Barrier to Entry**: Requires deep integration with Git, Docker, STAC, and metadata standards.\n\n---\n```\n\n> 💡 **Summary Recommendation**: The most promising ideas to pursue first are **\"No-Code GeoAI Builder\"** and **\"Model Hub\"**, due to clear market demand, well-defined technical pathways, and strong open-source foundations. In the long term, **\"Global Embedding as a Service\"** has the potential to become foundational infrastructure for geospatial AI.",
    "github": "",
    "hf": ""
}