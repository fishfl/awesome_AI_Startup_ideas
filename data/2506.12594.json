{
    "id": "2506.12594",
    "title": "A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications",
    "summary": "This paper summarizes the latest advancements of over 80 deep study systems (AI-powered applications) that have emerged since 2023, and proposes a new hierarchical classification method to categorize these systems.",
    "abstract": "This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through comprehensive examination, we propose a novel hierarchical taxonomy that categorizes systems according to four fundamental technical dimensions: foundation models and reasoning engines, tool utilization and environmental interaction, task planning and execution control, and knowledge synthesis and output generation. We explore the architectural patterns, implementation approaches, and domain-specific adaptations that characterize these systems across academic, scientific, business, and educational applications. Our analysis reveals both the significant capabilities of current implementations and the technical and ethical challenges they present regarding information accuracy, privacy, intellectual property, and accessibility. The survey concludes by identifying promising research directions in advanced reasoning architectures, multimodal integration, domain specialization, human-AI collaboration, and ecosystem standardization that will likely shape the future evolution of this transformative technology. By providing a comprehensive framework for understanding Deep Research systems, this survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical development of more capable, responsible, and accessible research technologies. The paper resources can be viewed atthis https URL.",
    "category1": "Algorithms and Models",
    "category2": "",
    "category3": "Non-Agent",
    "authors": "Renjun Xu,Jingwen Peng",
    "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
    ],
    "comments": "Comments:95 pages, 11 figures",
    "keypoint": "- Deep Research systems integrate AI technologies for automating and enhancing research processes through three core dimensions: intelligent knowledge discovery, end-to-end workflow automation, and collaborative intelligence enhancement.\n- The evolution of Deep Research systems includes three stages: origin and early exploration (2023 - February 2025), technological breakthrough and competitive rivalry (February - March 2025), and ecosystem expansion and multi-modal integration (March 2025 - Present).\n- Architectural patterns for implementing Deep Research capabilities include monolithic, pipeline-based, multi-agent, and hybrid approaches.\n- Commercial systems like OpenAI/DeepResearch and Gemini/DeepResearch demonstrate strong performance on benchmarks such as HLE and GAIA, while open-source alternatives show varied but respectable results.\n- Key technical challenges in Deep Research systems include hallucination detection, uncertainty communication, privacy protection, intellectual property respect, and accessibility.\n- Future research directions focus on advanced reasoning architectures, multimodal integration, domain-specific optimization, human-AI collaboration, and ecosystem standardization.\n- Application areas of Deep Research systems include academic research, scientific discovery, business intelligence, financial analysis, education, and personal knowledge management.\n- Evaluation methodologies for Deep Research systems involve functional and non-functional metrics, cross-domain benchmarks, and emerging interactive evaluation approaches.\n- Ethical considerations in Deep Research development encompass information accuracy, privacy protection, intellectual property respect, and ensuring accessibility across diverse user groups.",
    "date": "2025-06-18",
    "paper": "A Comprehensive Survey of Deep Research: Systems, Methodologies, and\nApplications\nRENJUN XU∗and JINGWEN PENG, Zhejiang University, China\nThis survey examines the rapidly evolving field of Deep Research systems—AI-powered applications that automate\ncomplex research workflows through the integration of large language models, advanced information retrieval, and\nautonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that\nhave emerged since 2023, including OpenAI/DeepResearch, Gemini/DeepResearch, Perplexity/DeepResearch, and\nnumerous open-source alternatives. Through comprehensive examination, we propose a novel hierarchical taxonomy\nthat categorizes systems according to four fundamental technical dimensions: foundation models and reasoning\nengines, tool utilization and environmental interaction, task planning and execution control, and knowledge synthesis\nand output generation. We explore the architectural patterns, implementation approaches, and domain-specific\nadaptations that characterize these systems across academic, scientific, business, and educational applications. Our\nanalysis reveals both the significant capabilities of current implementations and the technical and ethical challenges\nthey present regarding information accuracy, privacy, intellectual property, and accessibility. The survey concludes\nby identifying promising research directions in advanced reasoning architectures, multimodal integration, domain\nspecialization, human-AI collaboration, and ecosystem standardization that will likely shape the future evolution of\nthis transformative technology. By providing a comprehensive framework for understanding Deep Research systems,\nthis survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical\ndevelopment of more capable, responsible, and accessible research technologies. The paper resources can be viewed at\nhttps://github.com/scienceaix/deepresearch.\nCCS Concepts: • Computing methodologies →Artificial intelligence; Natural language processing; • Computer systems\norganization →Embedded and cyber-physical systems; • Information systems →Information retrieval; • Human-centered\ncomputing →Collaborative and social computing.\nAdditional Key Words and Phrases: Deep Research, Large Language Models, Autonomous Agents, AI Systems,\nResearch Automation, Information Retrieval, Knowledge Synthesis, Human-AI Collaboration, Multi-Agent Systems,\nTool-Using Agents\n∗Corresponding author: rux@zju.edu.cn\nAuthors’ Contact Information: Renjun Xu; Jingwen Peng, Zhejiang University, China.\n1\narXiv:2506.12594v1  [cs.AI]  14 Jun 2025\n2\nXu et al.\nContents\nAbstract\n1\nContents\n2\n1\nIntroduction\n4\n1.1\nDefinition and Scope of Deep Research\n4\n1.2\nHistorical Context and Technical Evolution\n5\n1.3\nSignificance and Practical Implications\n6\n1.4\nResearch Questions and Contribution of this Survey\n7\n2\nThe Evolution and Technical Framework of Deep Research\n7\n2.1\nFoundation Models and Reasoning Engines: Evolution and Advances\n7\n2.2\nTool Utilization and Environmental Interaction: Evolution and Advances\n10\n2.3\nTask Planning and Execution Control: Evolution and Advances\n11\n2.4\nKnowledge Synthesis and Output Generation: Evolution and Advances\n13\n3\nComparative Analysis and Evaluation of Deep Research Systems\n14\n3.1\nCross-Dimensional Technical Comparison\n14\n3.2\nApplication-Based System Suitability Analysis\n16\n3.3\nPerformance Metrics and Benchmarking\n18\n4\nImplementation Technologies and Challenges\n21\n4.1\nArchitectural Implementation Patterns\n21\n4.2\nInfrastructure and Computational Optimization\n27\n4.3\nSystem Integration and Interoperability\n29\n4.4\nTechnical Challenges and Solutions\n33\n5\nEvaluation Methodologies and Benchmarks\n35\n5.1\nFunctional Evaluation Frameworks\n35\n5.2\nNon-Functional Evaluation Metrics\n37\n5.3\nCross-Domain Evaluation Benchmarks\n39\n5.4\nEmerging Evaluation Approaches\n41\n5.5\nComparative Evaluation Methodology\n42\n6\nApplications and Use Cases\n44\n6.1\nAcademic Research Applications\n44\n6.2\nScientific Discovery Applications\n46\n6.3\nBusiness Intelligence Applications\n49\n6.4\nFinancial Analysis Applications\n51\n6.5\nEducational Applications\n52\n6.6\nPersonal Knowledge Management Applications\n54\n7\nEthical Considerations and Limitations\n56\n7.1\nInformation Accuracy and Hallucination Concerns\n56\n7.2\nPrivacy and Data Security\n59\n7.3\nSource Attribution and Intellectual Property\n61\n7.4\nAccessibility and Digital Divide\n63\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n3\n8\nFuture Research Directions\n64\n8.1\nAdvanced Reasoning Architectures\n64\n8.2\nMulti-Modal Deep Research\n68\n8.3\nDomain-Specific Optimization\n70\n8.4\nHuman-AI Collaboration and Standardization\n72\n9\nConclusion\n76\n9.1\nKey Findings and Contributions\n76\n9.2\nLimitations and Outlook\n78\n9.3\nBroader Implications\n79\n9.4\nFinal Thoughts\n80\nReferences\n81\n4\nXu et al.\n1\nIntroduction\nRapid advancement of artificial intelligence has precipitated a paradigm shift in how knowledge is discovered,\nvalidated, and utilized across academic and industrial domains. Traditional research methodologies, reliant\non manual literature reviews, experimental design, and data analysis, are increasingly supplemented—and\nin some cases supplanted—by intelligent systems capable of automating end-to-end research workflows. This\nevolution has given rise to a novel domain we term “Deep Research”, which signifies the convergence of large\nlanguage models (LLMs), advanced information retrieval systems, and automated reasoning frameworks to\nredefine the boundaries of scholarly inquiry and practical problem-solving.\n1.1\nDefinition and Scope of Deep Research\nDeep Research refers to the systematic application of AI technologies to automate and enhance research\nprocesses through three core dimensions:\n(1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern\nrecognition across heterogeneous data sources\n(2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and\nresult interpretation into unified AI-driven pipelines\n(3) Collaborative Intelligence Enhancement: Facilitating human-AI collaboration through natural lan-\nguage interfaces, visualizations, and dynamic knowledge representation\nTo clearly delineate the boundaries of Deep Research, we distinguish it from adjacent AI systems as\nfollows:\n∙Differentiating from General AI Assistants: While general AI assistants like ChatGPT can answer\nresearch questions, they lack the autonomous workflow capabilities, specialized research tools, and\nend-to-end research orchestration that define Deep Research systems. Recent surveys have highlighted\nthis crucial distinction between specialized research systems and general AI capabilities [73, 76],\nwith particular emphasis on how domain-specific tools fundamentally transform research workflows\ncompared to general-purpose assistants [213, 318].\n∙Differentiating from Single-Function Research Tools: Specialized tools like citation managers, liter-\nature search engines, or statistical analysis packages address isolated research functions but lack\nthe integrated reasoning and cross-functional orchestration of Deep Research systems. Tools like\nscispace [242] and You.com [313] represent earlier attempts at research assistance but lack the\nend-to-end capabilities that define true Deep Research systems.\n∙Differentiating from Pure LLM Applications: Applications that simply wrap LLMs with research-\noriented prompts lack the environmental interaction, tool integration, and workflow automation\ncapabilities that characterize true Deep Research systems.\nThis survey specifically examines systems that exhibit at least two of the three core dimensions, with\na focus on those incorporating large language models as their foundational reasoning engine. Our scope\nencompasses commercial offerings such as OpenAI/DeepResearch [197], Google’s Gemini/DeepResearch\n[89], and Perplexity/DeepResearch [209], alongside open-source implementations including dzhng/deep-\nresearch [321], HKUDS/Auto-Deep-Research [112], and numerous others detailed in subsequent sections. We\nexclude purely bibliometric tools or single-stage automation systems lacking integrated cognitive capabilities,\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n5\nsuch as research assistance tools like Elicit [74], ResearchRabbit [228], Consensus [63], or citation tools\nlike Scite [243]. Additional specialized tools like STORM [278], which focuses on scientific text retrieval and\norganization, are valuable but lack the end-to-end deep research capabilities central to our survey scope.\n1.2\nHistorical Context and Technical Evolution\nThe trajectory of Deep Research can be mapped through three evolutionary stages that reflect both\ntechnological advancements and implementation approaches:\n1.2.1\nOrigin and Early Exploration (2023 - February 2025). It should be noted that workflow automation\nframeworks like n8n [183], QwenLM/Qwen-Agent [224], etc. had already been in existence long before the\nboom of deep research. Their early establishment demonstrated the pre-existing groundwork in related\ntechnological domains, highlighting that the development landscape was not solely shaped by the emergence\nof deep research, but had a more diverse and earlier-rooted origin. The concept of Deep Research emerged\nfrom the shift of AI assistants towards intelligent agents. In December 2024, Google Gemini pioneered\nthis functionality with its initial Deep Research implementation, focusing on basic multi-step reasoning\nand knowledge integration [60]. This phase laid the groundwork for subsequent advancements, setting the\nstage for more sophisticated AI-driven research tools. Many of these advances built upon earlier workflow\nautomation tools like n8n [183] and agent frameworks such as AutoGPT [250] and BabyAGI [311] that had\nalready established foundations for autonomous task execution. Other early contributions to this ecosystem\ninclude cline2024 [61], which pioneered integrated research workflows, and open_operator [36], which\ndeveloped foundational browser automation capabilities essential for web-based research.\n1.2.2\nTechnological Breakthrough and Competitive Rivalry (February - March 2025). The rise of DeepSeek’s\nopen-source models [68] revolutionized the market with efficient reasoning and cost-effective solutions. In\nFebruary 2025, OpenAI’s release of Deep Research, marked a significant leap forward [197]. Powered by the o3\nmodel, it demonstrated advanced capabilities such as autonomous research planning, cross-domain analysis,\nand high-quality report generation, achieving accuracy rates exceeding previous benchmarks in complex tasks.\nConcurrently, Perplexity launched its free-to-use Deep Research in February 2025 [209], emphasizing rapid\nresponse and accessibility to capture the mass market. Open-source projects such as nickscamara/open-deep-\nresearch [42], mshumer/OpenDeepResearcher [249], btahir_open_deep_research [37], and GPT-researcher\n[16] emerged as community-driven alternatives to commercial platforms. The ecosystem continued to expand\nwith lightweight implementations like Automated-AI-Web-Researcher-Ollama [267], designed for local\nexecution with limited resources, and modular frameworks such as Langchain-AI/Open_deep_research\n[131] that provided composable components for custom research workflows.\n1.2.3\nEcosystem Expansion and Multi-modal Integration (March 2025 - Present). The third stage is character-\nized by the maturation of a diverse ecosystem. Open-source projects like Jina-AI/node-DeepResearch [121]\nenable localized deployment and customization, while commercial closed-source versions from OpenAI and\nGoogle continue to push boundaries with multi-modal support and multi-agent collaboration capabilities.\nThe integration of advanced search technologies and report generation frameworks further enhances the tool’s\nutility across academic research, financial analysis, and other fields. Meanwhile, platforms like Manus [164]\nand AutoGLM-Research [330], MGX [171], and Devin [62] are incorporating advanced AI research capabilities\n6\nXu et al.\nto enhance their services. Concurrently, Anthropic launched Claude/Research [13] in April 2025, introducing\nagentic search capabilities that systematically explore multiple angles of queries and deliver comprehensive\nanswers with verifiable citations. Agent frameworks such as OpenManus [193], Camel-AI/OWL [43], and TARS\n[39] further expand the ecosystem with specialized capabilities and domain-specific optimizations.\nEvolution Timeline of Deep Research Systems (2024-2025)\n(2023 - February 2025)\nEarly prototypes and foundational approaches\n(February - March 2025)\nCommercial releases and competitive rivalry\n(March 2025 - Present)\nMulti-modal integration and diverse applications\nGoogle Gemini\nDeep Research\nDec 2024\nOpenAI\nDeep Research\nFeb 2025\nManus\nMar 2025\nPerplexity\nDeep Research\nFeb 2025\nAutoGLM-Research\nMar 2025\nQwenLM/\nQwen-Agent\nApr 2024\nn8n\n2023\nmshumer/\nOpenDeepResearcher\nFeb 2025\nnickscamara/\nopen-deep-research\nFeb 2025\nCamel-AI/OWL\nMar 2025\nTARS\nMar 2025\nOpenManus\nMar 2025\nDeepSeek\nModel\nJan 2025\nJina AI/\nnode-Deep Research\nFeb 2025\nCommercial Systems\nOpen-source Systems\nOrigin and Early Exploration\nTechnological Breakthrough\nEcosystem Expansion\nFig. 1. Evolution Timeline of Deep Research Systems\n1.3\nSignificance and Practical Implications\nDeep Research demonstrates transformative potential across multiple domains:\n(1) Academic Innovation: Accelerating hypothesis validation through automated literature synthesis\n(e.g., HotpotQA [307] performance benchmarks) and enabling researchers to explore broader inter-\ndisciplinary connections that might otherwise remain undiscovered. The transformative potential of\nDeep Research extends beyond individual applications to fundamentally reshape scientific discovery\nprocesses. As Sourati and Evans [256] argue, human-aware artificial intelligence can significantly\naccelerate science by augmenting researchers’ capabilities while adapting to their conceptual frame-\nworks and methodological approaches. This human-AI synergy represents a fundamental shift from\ntraditional automation toward collaborative intelligence that respects and enhances human scientific\nintuition. Complementary work by Khalili and Bouchachia [128] further demonstrates how systematic\napproaches to building science discovery machines can transform hypothesis generation, experimental\ndesign, and theory refinement through integrated AI-driven research workflows.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n7\n(2) Enterprise Transformation: Enabling data-driven decision-making at scale through systems like\nAgent-RL/ReSearch [2] and smolagents/open_deep_research [115] that can analyze market trends,\ncompetitive landscapes, and strategic opportunities with unprecedented depth and efficiency.\n(3) Democratization of Knowledge: Reducing barriers to entry through open-source implementations like\ngrapeot/deep_research_agent [263] and OpenManus [193], making sophisticated research capabilities\naccessible to individuals and organizations regardless of technical expertise or resource constraints.\n1.4\nResearch Questions and Contribution of this Survey\nThis survey addresses three fundamental questions:\n(1) How do architectural choices (system architecture, implementation approach, functional capabilities)\nimpact Deep Research effectiveness?\n(2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow\norchestration across the spectrum of Deep Research implementations?\n(3) How do existing systems balance performance, usability, and ethical considerations, and what\npatterns emerge from comparing approaches like those of n8n [183] and OpenAI/AgentsSDK [199]?\nOur contributions manifest in three dimensions:\n(1) Methodological: Proposing a novel taxonomy categorizing systems by their technical architecture,\nfrom foundation models to knowledge synthesis capabilities\n(2) Analytical: Conducting comparative analysis of representative systems across evaluation metrics,\nhighlighting the strengths and limitations of different approaches\n(3) Practical: Identifying key challenges and formulating a roadmap for future development, with specific\nattention to emerging architectures and integration opportunities\nThe remainder of this paper follows a structured exploration beginning with conceptual frameworks\n(Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies\n(Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations\n(Section 8), and future directions (Section 9).\n2\nThe Evolution and Technical Framework of Deep Research\nThis section presents a comprehensive technical taxonomy for understanding Deep Research systems,\norganized around four fundamental technological capabilities that define these systems. For each capabil-\nity, we examine the evolutionary trajectory and technical innovations while highlighting representative\nimplementations that exemplify each approach.\n2.1\nFoundation Models and Reasoning Engines: Evolution and Advances\nThe foundation of Deep Research systems lies in their underlying AI models and reasoning capabilities,\nwhich have evolved from general-purpose language models to specialized research-oriented architectures.\n2.1.1\nFrom General-Purpose LLMs to Specialized Research Models. The progression from general LLMs to\nresearch-specialized models represents a fundamental shift in deep research capabilities:\n8\nXu et al.\nHierarchical Technical Framework of Deep Research Systems\nDeep\nResearch\nFoundation Models and\nReasoning Engines\n• General-purpose to specialized models\n• Context handling and memory\n• Chain-of-thought reasoning\n• Tree-of-thought architectures\nTool Utilization and\nEnvironmental Interaction\n• Web navigation and interaction\n• Content processing technologies\n• API integration patterns\n• Domain-specific tool usage\nTask Planning and\nExecution Control\n• Research task decomposition\n• Hierarchical planning methods\n• Autonomous execution monitoring\n• Multi-agent collaboration\nKnowledge Synthesis and\nOutput Generation\n• Information evaluation\n• Source verification\n• Structured report generation\n• Interactive presentation\nGeneral LLMs\n(GPT-4, Gemini)\nSpecialized\n(o3, DeepSeek-R1)\nWeb Interaction\n(Nanobrowser)\nAPI Integration\n(n8n, Manus)\nPlanning\n(OpenAI SDK)\nExecution\n(Agent-RL)\nEvaluation\n(grapeot)\nGeneration\n(mshumer)\nFig. 2. Hierarchical Technical Framework of Deep Research Systems\nTechnical Evolution Trajectory. Early implementations relied on general-purpose LLMs with minimal\ntask-specific optimization. Current systems feature models specifically enhanced for research tasks through\narchitectural modifications, specialized training corpora, and fine-tuning regimes focused on analytical and\nreasoning capabilities. The transition from models like GPT-4 to OpenAI’s o3 demonstrates significant\nimprovements in abstraction, multi-step reasoning, and knowledge integration capabilities essential for\ncomplex research tasks [198, 200].\nRepresentative Systems. OpenAI/DeepResearch [197] exemplifies this evolution with its o3-based model\noptimized specifically for web browsing and data analysis. The system leverages chain-of-thought and tree-of-\nthought reasoning techniques to navigate complex information landscapes. Google’s Gemini/DeepResearch\n[60] similarly employs Gemini 2.5 Pro with enhanced reasoning capabilities and a million-token context\nwindow to process extensive information. These approaches build upon foundational work in reasoning\nenhancement techniques like chain-of-thought prompting [291], self-consistency [287], and human preference\nalignment [205] that have been adapted specifically for research-intensive tasks. In the open-source domain,\nAutoGLM-Research [330] demonstrates how specialized training regimes can optimize existing models like\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n9\nChatGLM for research-intensive tasks, achieving significant performance gains through targeted enhancements\nto reasoning components.\n2.1.2\nContext Understanding and Memory Mechanisms. The ability to process, retain, and utilize extensive\ncontextual information represents a crucial advancement in Deep Research systems:\nTechnical Evolution Trajectory. Early systems struggled with limited context windows, hampering their\nability to synthesize information from multiple sources. Contemporary implementations employ sophisticated\nmemory management techniques including episodic buffers, hierarchical compression, and attention-based\nretrieval mechanisms that extend effective context far beyond model limitations. The million-token context\nwindows of models like Grok 3 [299] and Gemini 2.5 Pro [60], along with the context optimization in\nOpenAI’s o3 model [195], have dramatically expanded the information processing capabilities of these\nsystems. Advanced systems now distinguish between working memory (active reasoning context) and\nlong-term memory (knowledge repository), allowing for more human-like research processes.\nRepresentative Systems. Perplexity/DeepResearch [209] has pioneered efficient context processing by\nleveraging DeepSeek-R1’s capabilities while implementing proprietary mechanisms for structured information\nmanagement. The system can analyze hundreds of sources while maintaining coherent reasoning threads.\nSimilarly, Camel-AI/OWL [43] employs an innovative open-weight approach to memory management, allowing\nfor dynamic allocation of attention resources based on information relevance and task requirements. Both\nsystems demonstrate how effective memory architectures can significantly enhance research performance\neven with comparable base model capabilities.\n2.1.3\nEnhancements in Reasoning Capabilities. Advanced reasoning mechanisms distinguish modern Deep\nResearch systems from conventional LLM applications:\nTechnical Evolution Trajectory. Early implementations relied primarily on zero-shot or few-shot prompting\nfor reasoning tasks. Current systems integrate explicit reasoning frameworks including chain-of-thought,\ntree-of-thought, and graph-based reasoning architectures. Recent work by Lang et al. [132] demonstrates how\ndebate-driven reasoning can facilitate weak-to-strong generalization, enabling more robust performance on\ncomplex research tasks through structured argumentative processes. These approaches implement reasoning\npatterns that more closely mirror human scientific discourse, with explicit representation of alternative\nviewpoints and structured evaluation of competing hypotheses. Advanced implementations like OpenAI’s\no3 incorporate self-critique, uncertainty estimation, and recursive reasoning refinement [198, 200]. This\nevolution enables increasingly sophisticated forms of evidence evaluation, hypothesis testing, and knowledge\nsynthesis essential for high-quality research outputs.\nRepresentative Systems. QwenLM/Qwen-Agent [224] exemplifies advanced reasoning capabilities through its\nspecialized toolkit integration and modular reasoning framework. The system employs a multi-stage reasoning\nprocess with explicit planning, information gathering, analysis, and synthesis phases optimized for research\nworkflows. Similar capabilities are evident in smolagents/open_deep_research [115], which implements a\nflexible reasoning architecture that can adapt to different research domains and methodologies. Systems like\nCycleResearcher [294] demonstrate how integrating automated review processes into research workflows can\nenhance accuracy through structured feedback loops. These approaches implement explicit verification steps\n10\nXu et al.\nthat identify potential errors and inconsistencies before generating final research outputs. The application of\nAI to complex domains like mathematics further illustrates this progress, where models are increasingly\nviewed from a cognitive science perspective to enhance their reasoning abilities [320], achieving notable\nmilestones such as silver-medal standards in solving International Mathematical Olympiad problems [7].\nThese systems highlight how reasoning enhancements can dramatically improve research quality even without\nrequiring the largest or most computationally intensive base models.\n2.2\nTool Utilization and Environmental Interaction: Evolution and Advances\nDeep Research systems must effectively interact with external environments to gather and process information,\nrepresenting a fundamental capability beyond core language model functions[144].\n2.2.1\nWeb Interaction Technology Development. The ability to navigate and extract information from the\nweb represents a foundational capability for deep research:\nTechnical Evolution Trajectory. Initial implementations relied on simple API-based search queries with\nlimited interaction capabilities. Current systems employ sophisticated web navigation including dynamic\ncontent handling, authentication management, and interactive element manipulation. Advanced implementa-\ntions feature semantic understanding of web structures, allowing for adaptive information extraction and\nmulti-page navigation flows. This evolution has dramatically expanded access to web-based information\nsources and the ability to extract insights from complex web environments.\nRepresentative Systems. Nanobrowser [184] represents a purpose-built browser environment designed\nspecifically for AI agent use, offering optimized rendering and interaction capabilities for research tasks.\nIt enables fine-grained control of web navigation while maintaining security and performance. Similarly,\nAutoGLM [330] demonstrates sophisticated GUI interaction capabilities across both web and mobile interfaces,\nallowing it to access information through interfaces designed for human use. These systems showcase how\nspecialized web interaction technologies can significantly expand the information gathering capabilities of\nDeep Research systems.\n2.2.2\nContent Processing Technology Advancements. Beyond basic navigation, the ability to process diverse\ncontent formats is crucial for comprehensive research:\nTechnical Evolution Trajectory. Early systems were limited primarily to text extraction from HTML\nsources. Modern implementations support multi-modal content processing including structured data tables,\nembedded visualizations, PDF documents, and interactive applications. Advanced systems like those built\non OpenAI’s o3 can extract semantic structure from unstructured content, identify key information from\ndiverse formats, and integrate insights across modalities [201]. This evolution has dramatically expanded the\nrange of information sources that can be incorporated into research processes.\nRepresentative Systems. The dzhng/deep-research [321] project exemplifies advanced content processing\nthrough its specialized modules for different document types and formats. It implements custom extraction\nlogic for academic papers, technical documentation, and structured data sources. Similarly, nickscamara/\nopen-deep-research [42] features sophisticated content normalization pipelines that transform diverse\nformats into consistent knowledge representations suitable for analysis. Both systems demonstrate how\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n11\nspecialized content processing can significantly enhance the quality and comprehensiveness of research\noutputs.\n2.2.3\nSpecialized Tool Integration Progress. Integration with domain-specific tools extends Deep Research\ncapabilities beyond general information processing:\nTechnical Evolution Trajectory. Initial systems relied on general-purpose web search and basic API\nintegrations. The integration of diverse tools has been dramatically advanced by frameworks like ToolLLM\n[222], which enables large language models to master over 16,000 real-world APIs, significantly expanding\nthe interaction capabilities of research systems. Similarly, AssistGPT [82] demonstrates how general multi-\nmodal assistants can plan, execute, inspect, and learn across diverse environments, creating unified research\nexperiences that seamlessly incorporate varied information sources and interaction modalities. LLaVA-Plus\n[152] further extends these capabilities through explicit tool learning mechanisms, enabling research assistants\nto adaptively incorporate specialized tools within multimodal workflows. Current implementations feature\ncomplex toolchains including specialized databases, analytical frameworks, and domain-specific services.\nAdvanced systems dynamically select and orchestrate tools based on research requirements, effectively\ncomposing custom research workflows from available capabilities. Some implementations like those leveraging\nOpenAI’s Codex [194] can even generate custom code to process research data or implement analytical models\non demand, further extending analytical capabilities. This evolution has enabled increasingly sophisticated\nanalysis and domain-specific research applications.\nRepresentative Systems. Manus [164] exemplifies sophisticated tool orchestration through its extensive API\nintegration framework and tool selection mechanisms. The system can incorporate domain-specific research\ntools and services into unified workflows, significantly expanding its analytical capabilities. Similarly, n8n\n[183] provides a flexible workflow automation platform that can be configured for research tasks, allowing for\nintegration with specialized data sources and analytical services. Steward extends web interaction capabilities\nby implementing natural language-driven navigation and operation across websites, overcoming scalability\nlimitations of traditional automation frameworks while maintaining low operational costs [261]. These\nsystems highlight how tool integration can extend Deep Research capabilities into specialized domains and\ncomplex analytical workflows.\n2.3\nTask Planning and Execution Control: Evolution and Advances\nEffective research requires sophisticated planning and execution mechanisms to coordinate complex, multi-\nstage workflows.\n2.3.1\nResearch Task Planning Development. The ability to decompose research objectives into manageable\ntasks represents a fundamental advancement:\nTechnical Evolution Trajectory. Early approaches employed simple task decomposition with linear ex-\necution flows, similar to those found in early agent frameworks like MetaGPT [111] and AgentGPT [230].\nModern systems implement hierarchical planning with dynamic refinement based on intermediate results and\ndiscoveries. Advanced planning approaches increasingly incorporate structured exploration methodologies\nto navigate complex solution spaces efficiently. AIDE [120] demonstrates how tree search algorithms can\n12\nXu et al.\neffectively explore the space of potential code solutions for machine learning engineering, trading computa-\ntional resources for enhanced performance through strategic reuse and refinement of promising pathways.\nAdvanced implementations incorporate resource-aware planning, considering time constraints, computational\nlimitations, and information availability. However, incorporating AI tools for tasks like automated code\nreview has been observed to increase pull request closure durations despite benefits, as evidenced in studies\nsuch as Cihan et al. [59], highlighting the critical need to account for temporal impacts in such resource-aware\nsystems. This evolution has enabled increasingly sophisticated research strategies adaptive to both task\nrequirements and available resources.\nRepresentative Systems. The OpenAI/AgentsSDK [199] provides a comprehensive framework for research\ntask planning, with explicit support for goal decomposition, execution tracking, and adaptive refinement.\nIt enables the development of applications with sophisticated planning capabilities for research workflows.\nSimilarly, Flowith/OracleMode [77] implements specialized planning mechanisms optimized for research\ntasks, with particular emphasis on information quality assessment and source prioritization. These systems\ndemonstrate how advanced planning capabilities can significantly improve research efficiency and effectiveness.\n2.3.2\nAutonomous Execution and Monitoring Advances. Reliable execution of research plans requires sophisti-\ncated control and monitoring mechanisms:\nTechnical Evolution Trajectory. Initial systems employed basic sequential execution with limited error\nhandling. Current implementations feature concurrent execution paths, comprehensive monitoring, and\ndynamic response to execution challenges. Advanced systems implement self-supervision with explicit success\ncriteria, failure detection, and autonomous recovery strategies. This evolution has dramatically improved\nthe reliability and autonomy of Deep Research systems across complex tasks.\nRepresentative Systems. Agent-RL/ReSearch [2] exemplifies advanced execution control through its rein-\nforcement learning-based approach to research execution. The system learns effective execution strategies\nfrom experience, continuously improving its ability to navigate complex research workflows. Its adaptive exe-\ncution mechanisms can recover from failures and adjust strategies based on intermediate results, highlighting\nhow sophisticated control mechanisms can enhance research reliability and effectiveness.\n2.3.3\nMulti-Agent Collaboration Framework Development. Complex research often benefits from specialized\nagent roles and collaborative approaches:\nTechnical Evolution Trajectory. Early systems relied on monolithic agents with undifferentiated capa-\nbilities. Modern implementations employ specialized agent roles with explicit coordination mechanisms\nand information sharing protocols. Advanced systems feature dynamic role allocation, consensus-building\nmechanisms, and sophisticated conflict resolution strategies. This evolution has enabled increasingly complex\ncollaborative research workflows and improved performance on challenging tasks[49]. For instance, frame-\nworks employing multi-agent debate have been shown to improve evaluation consistency [48], while research\ninto generative AI voting demonstrates resilience to model biases in collective decision-making [162].\nRepresentative Systems. The smolagents/open_deep_research [115] framework demonstrates effective\nmulti-agent collaboration through its modular agent architecture and explicit coordination mechanisms. It\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n13\nenables the composition of specialized research teams with complementary capabilities and shared objectives.\nSimilarly, TARS [39] implements a sophisticated agent collaboration framework within its desktop environment,\nallowing multiple specialized agents to contribute to unified research workflows. These systems highlight\nhow multi-agent approaches can enhance research capabilities through specialization and collaboration.\n2.4\nKnowledge Synthesis and Output Generation: Evolution and Advances\nThe ultimate value of Deep Research systems lies in their ability to synthesize disparate information into\ncoherent, actionable insights.\n2.4.1\nInformation Evaluation Technology Development. Critical assessment of information quality represents\na crucial capability for reliable research:\nTechnical Evolution Trajectory. Early systems relied primarily on source reputation heuristics with limited\ncontent-based assessment. Modern implementations employ sophisticated evaluation frameworks considering\nsource characteristics, content features, and consistency with established knowledge. Advanced systems\nimplement explicit uncertainty modeling, contradiction detection, and evidential reasoning approaches. This\nevolution has dramatically improved the reliability and trustworthiness of research outputs. Advances in\nknowledge retrieval based on generative AI enhance the ability to source and verify information [306].\nRepresentative Systems. The grapeot/deep_research_agent [263] implements sophisticated information\nevaluation mechanisms with explicit quality scoring for diverse source types. It can assess information\nreliability based on both intrinsic content features and extrinsic source characteristics, enabling more\ndiscerning information utilization. These capabilities highlight how advanced evaluation mechanisms can\nsignificantly enhance research quality and reliability.\n2.4.2\nReport Generation Technology Advances. Effective communication of research findings requires sophis-\nticated content organization and presentation:\nTechnical Evolution Trajectory. Initial systems produced simple text summaries with limited structure or\ncoherence. Current implementations generate comprehensive reports with hierarchical organization, evidence\nintegration, and coherent argumentation. Advanced systems produce adaptive outputs tailored to audience\nexpertise, information needs, and presentation contexts. This evolution has dramatically improved the\nusability and impact of Deep Research outputs.\nRepresentative Systems. The mshumer/OpenDeepResearcher [249] project exemplifies advanced report\ngeneration through its structured output framework and evidence integration mechanisms. It produces\ncomprehensive research reports with explicit attribution, structured arguments, and integrated supporting\nevidence. These capabilities demonstrate how sophisticated report generation can enhance the utility and\ntrustworthiness of Deep Research outputs. Additionally, the MegaWika dataset [22] offers a large-scale\nmultilingual resource consisting of millions of articles and referenced sources, enabling collaborative AI\nreport generation.\n2.4.3\nInteractive Presentation Technology Development. Beyond static reports, interactive result exploration\nenhances insight discovery and utilization:\n14\nXu et al.\nTechnical Evolution Trajectory. Early systems produced fixed textual outputs with minimal user interaction.\nModern implementations support dynamic exploration including drill-down capabilities, source verification,\nand alternative viewpoint examination. Advanced systems enable collaborative refinement through iterative\nfeedback incorporation and adaptive response to user queries. This evolution has dramatically enhanced the\nutility and flexibility of Deep Research interfaces.\nRepresentative Systems. HKUDS/Auto-Deep-Research [112] implements sophisticated interactive presenta-\ntion capabilities, allowing users to explore research findings through dynamic interfaces, examine supporting\nevidence, and refine analysis through iterative interaction. These features highlight how interactive presen-\ntation technologies can enhance the utility and accessibility of Deep Research outputs, facilitating more\neffective knowledge transfer and utilization.\nThis technical framework provides a comprehensive foundation for understanding the capabilities and\nevolution of Deep Research systems. The subsequent sections will build on this framework to analyze\nimplementation approaches, evaluate system performance, and explore applications across diverse domains.\n3\nComparative Analysis and Evaluation of Deep Research Systems\nBuilding upon the technical framework established in Section 2, this section provides a comprehensive\ncomparative analysis of existing Deep Research systems across multiple dimensions. We examine how different\nimplementations balance technical capabilities, application suitability, and performance characteristics to\naddress diverse research needs.\n3.1\nCross-Dimensional Technical Comparison\nDeep Research systems demonstrate varying strengths across the four key technical dimensions identified\nin our framework. This section analyzes how different implementations balance these capabilities and the\nresulting performance implications.\n3.1.1\nFoundation Model and Reasoning Efficiency Comparison. The underlying reasoning capabilities of Deep\nResearch systems significantly impact their overall effectiveness:\nTable 1. Comparison of Foundation Model Characteristics\nSystem\nBase Model\nContext Length\nReasoning Approach\nOpenAI/DeepResearch [197]\no3\nmay up to 200k tokens [195]\nMulti-step reasoning\nGemini/DeepResearch [60]\nGemini 2.5 Pro\n1M tokens [167]\nChain-of-thought\nPerplexity/DeepResearch [209]\nDeepSeek-R1\n128K tokens [210]\nIterative reasoning\nGrok3Beta [299]\nGrok 3\n1M tokens [299]\nChain-of-thought\nAutoGLM-Research [330]\nChatGLM\nDOM\nStep-by-step planning\nDOM: Depends On the Model\nCommercial systems from OpenAI and Google leverage proprietary models with extensive context windows\nand sophisticated reasoning mechanisms, enabling them to process larger volumes of information with greater\ncoherence. OpenAI’s o3 model demonstrates particular strength in complex reasoning tasks, while Gemini 2.5\nPro excels in information integration across diverse sources. In contrast, Perplexity/DeepResearch achieves\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n15\ncompetitive performance with the open-source DeepSeek-R1 model through optimized implementation and\nfocused use cases.\nOpen-source implementations like Camel-AI/OWL [43] and QwenLM/Qwen-Agent [224] demonstrate that\neffective deep research capabilities can be achieved with more accessible models through specialized opti-\nmization. The open-weight approach of Camel-AI/OWL [43] enables flexible deployment across computing\nenvironments, while QwenLM/Qwen-Agent [224] leverages modular reasoning to compensate for more limited\nbase model capabilities.\n3.1.2\nTool Integration and Environmental Adaptability Comparison. The ability to interact with diverse\ninformation environments varies significantly across implementations:\nTable 2. Environmental Interaction Capabilities of Deep Research Systems\nSystem\nWeb Interaction\nAPI Integration\nDocument Processing\nGUI Navigation\nNanobrowser [184]\nHeadless browsing, JavaScript execution, dynamic content rendering\nREST API connectors\nBasic HTML parsing\nNot implemented\nAutoGLM [330]\nFull browser automation, form interaction\nRESTful and GraphQL support\nPDF, Office formats, JSON\nElement identification, click/input automation\ndzhng/deep-research [321]\nMulti-page navigation, cookie handling\nOAuth authentication support\nAcademic paper extraction, table parsing\nNot implemented\nManus [164]\nJavaScript rendering, session management\n150+ service integrations, webhook support\nPDF with layout preservation, CSV processing\nBasic element interaction\nn8n [183]\nLimited, via HTTP requests\n200+ integration nodes, custom webhook endpoints\nCSV/XML processing\nNot implemented\nTARS [39]\nViewport management, scroll handling\nREST/SOAP support\nStandard formats processing\nDesktop application control, UI element recognition\nNote: Capabilities documented based on system repositories, technical documentation, and published demonstrations as of April 2025.\nSpecialized tools like Nanobrowser [184] excel in web interaction capabilities, providing sophisticated\nnavigation and content extraction optimized for research workflows. Systems like dzhng/deep-research\n[321] and nickscamara/open-deep-research [42] complement these capabilities with advanced document\nprocessing features that can extract structured information from diverse formats.\nComprehensive platforms like Manus [164] and AutoGLM [330] offer broader environmental interaction\ncapabilities, balancing web browsing, API integration, and document processing. These systems can adapt\nto diverse research scenarios but may not match the specialized performance of more focused tools in\nspecific domains. The workflow automation capabilities of n8n [183] provide exceptional flexibility for API\nintegration but offer more limited direct interaction with web and document environments.\n3.1.3\nTask Planning and Execution Stability Comparison. Effective research requires reliable task planning\nand execution capabilities:\nTable 3. Planning and Execution Capabilities of Deep Research Systems\nSystem\nTask Planning Mechanisms\nError Handling Features\nCollaboration Infrastructure\nOpenAI/AgentsSDK [199]\nHierarchical task decomposition, goal-oriented planning\nAutomated retry logic, exception handling\nSupervisor-worker architecture\nFlowith/OracleMode [77]\nConstraint-based planning, information quality prioritization\nCheckpoint-based recovery\nLimited role-based workflow\nAgent-RL/ReSearch [2]\nReinforcement learning planning, adaptive task ordering\nProgressive fallback strategies, state restoration\nStandard agent messaging protocol\nsmolagents/open_deep_research [115]\nTask queue management, priority-based scheduling\nBasic retry mechanisms\nMulti-agent configuration, specialized role definitions\nTARS [39]\nProcess template architecture, event-driven coordination\nState persistence, interruption handling\nTeam-based agent organization, shared memory\ngrapeot/deep_research_agent [263]\nLinear task execution, sequential processing\nTimeout handling\nSingle-agent architecture\nNote: Capabilities documented based on system repositories, technical documentation, and published implementations as of April 2025.\nThe OpenAI/AgentsSDK [199] demonstrates sophisticated planning capabilities with hierarchical task\ndecomposition and adaptive execution, enabling complex research workflows with reliable completion rates.\nSimilarly, Flowith/OracleMode [77] offers advanced planning mechanisms optimized for research tasks,\nthough with more limited error recovery capabilities.\n16\nXu et al.\nAgent-RL/ReSearch [2] employs reinforcement learning techniques to develop robust execution strategies,\nenabling exceptional error recovery capabilities that can adapt to unexpected challenges during research work-\nflows. In contrast, smolagents/open_deep_research [115] and TARS [39] focus on multi-agent collaboration,\ndistributing complex tasks across specialized agents to enhance overall research effectiveness.\nSimpler implementations like grapeot/deep_research_agent [263] offer more limited planning and\nexecution capabilities but may provide sufficient reliability for less complex research tasks, demonstrating\nthe range of complexity available across the ecosystem.\n3.1.4\nKnowledge Synthesis and Output Quality Comparison. The ability to synthesize findings into coherent,\nreliable outputs varies significantly:\nTable 4. Knowledge Synthesis Capabilities of Deep Research Systems\nSystem\nSource Evaluation Mechanisms\nOutput Structuring\nUser Interaction Features\nOpenAI/DeepResearch [197]\nSource corroboration, authority ranking algorithms\nHierarchical report generation, section organization\nQuery clarification dialogue, result expansion\nPerplexity/DeepResearch [209]\nSource diversity metrics, publication date filtering\nCitation-based organization, inline attribution\nSource exploration interface, follow-up questioning\nmshumer/OpenDeepResearcher [249]\nPublication venue filtering, citation count tracking\nTemplate-based document generation, section templating\nMinimal interaction, batch processing focus\nHKUDS/Auto-Deep-Research [112]\nBasic source categorization, recency filtering\nStandard academic format, heading organization\nInteractive result exploration, citation navigation\ngrapeot/deep_research_agent [263]\nEvidence classification algorithms, contradictory claim detection\nMinimal formatting, raw data presentation\nCommand-line interface, non-interactive\nOpenManus [193]\nSource type categorization, basic metadata filtering\nMarkdown formatting, hierarchy-based organization\nBasic query refinement, result browsing\nNote: Capabilities documented based on system repositories, technical documentation, and published implementations as of April 2025.\nCommercial platforms like OpenAI/DeepResearch [197] and Perplexity/DeepResearch [209] demonstrate\nsophisticated information evaluation capabilities, effectively assessing source credibility and content reliability\nto produce high-quality syntheses. OpenAI’s implementation excels in report structure and organization,\nwhile Perplexity offers particularly strong citation practices for source attribution and verification.\nOpen-source implementations like mshumer/OpenDeepResearcher [249] focus on report structure and\norganization, producing well-formatted outputs that effectively communicate research findings. HKUDS/Auto-\nDeep-Research [112] emphasizes interactive exploration, allowing users to examine evidence and refine\nanalyses through iterative interaction. Specialized tools like grapeot/deep_research_agent [263] prioritize\ninformation evaluation over presentation, focusing on reliable content assessment rather than sophisticated\noutput formatting.\n3.2\nApplication-Based System Suitability Analysis\nBeyond technical capabilities, Deep Research systems demonstrate varying suitability for different application\ncontexts. This section examines how system characteristics align with key application domains.\n3.2.1\nAcademic Research Scenario Adaptability Assessment. Academic research requires particular empha-\nsis on comprehensive literature review, methodological rigor, and citation quality. Systems like OpenAI/\nDeepResearch [197] excel in this domain through their ability to access academic databases, comprehensively\nanalyze research methodologies, and generate properly formatted citations. Other specialized academic\nresearch tools like PaperQA [80] and Scite [243] offer complementary capabilities focused specifically on\nscientific literature processing, while Google’s NotebookLm [95] provides structured knowledge workspaces\nfor academic exploration.\nOpenAI/DeepResearch [197] demonstrates exceptional suitability for academic research through its com-\nprehensive literature coverage, methodological rigor, and high-quality citation practices. The system can\neffectively navigate academic databases, understand research methodologies, and produce well-structured\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n17\nTable 5. Academic Research Application Features of Deep Research Systems\nSystem\nAcademic Database Integration\nMethodology Analysis Features\nCitation Management\nOpenAI/DeepResearch [197]\nArXiv, IEEE Xplore, PubMed, Google Scholar\nStatistical method identification, study design classification\nIEEE, APA, MLA, Chicago format support\nPerplexity/DeepResearch [209]\nArXiv, PubMed, JSTOR, ACM Digital Library\nExperimental design analysis, sample size assessment\nAutomated citation generation, DOI resolution\ndzhng/deep-research [321]\nArXiv, Semantic Scholar, limited database access\nBasic methodology extraction\nBibTeX export, standard format support\nCamel-AI/OWL [43]\nCustom corpus integration, specialized domain databases\nResearch design pattern recognition, methodology comparison\nDomain-specific citation formatting\nmshumer/OpenDeepResearcher [249]\nOpen access databases, PDF repository processing\nMethodology summary extraction\nStandard citation format generation\nHKUDS/Auto-Deep-Research [112]\nUniversity library integration, institutional repository access\nResearch approach categorization\nReference management, bibliography generation\nNote: Features documented based on system repositories, technical documentation, and published use cases as of April 2025.\nliterature reviews with appropriate attribution. Perplexity/DeepResearch [209] offers similarly strong\nperformance for literature coverage and citation quality, though with somewhat less methodological sophisti-\ncation.\nOpen-source alternatives like Camel-AI/OWL [43] provide competitive capabilities for specific academic\ndomains, particular strength in methodological understanding for specific domains. Systems like dzhng/deep-\nresearch [321], mshumer/OpenDeepResearcher [249], and HKUDS/Auto-Deep-Research [112] offer moderate\ncapabilities across all dimensions, making them suitable for less demanding academic research applications\nor preliminary literature exploration.\n3.2.2\nEnterprise Decision-Making Scenario Adaptability Assessment. Business intelligence and strategic\ndecision-making emphasize information currency, analytical depth, and actionable insights:\nTable 6. Enterprise Decision-Making Application Features of Deep Research Systems\nSystem\nMarket Information Sources\nAnalytical Frameworks\nDecision Support Features\nGemini/DeepResearch [60]\nNews API integration, SEC filings access, market data feeds\nCompetitor analysis templates, trend detection algorithms\nExecutive summary generation, recommendation formatting\nManus [164]\nFinancial data integrations, news aggregation, industry reports\nMarket sizing frameworks, SWOT analysis templates\nStrategic options presentation, decision matrix generation\nn8n [183]\nCRM integration, marketing platform connectivity, custom data sources\nCustom analytics workflow creation, data pipeline automation\nDashboard generation, notification systems\nAgent-RL/ReSearch [2]\nConfigurable information source adapters, custom data inputs\nPattern recognition algorithms, causal analysis frameworks\nScenario planning tools, impact assessment matrices\nFlowith/OracleMode [77]\nReal-time data feeds, specialized industry sources\nIndustry-specific analytical templates, framework application\nStrategic briefing generation, insight prioritization\nTARS [39]\nEnterprise system integration, desktop application data access\nBasic analytical template application\nStandardized reporting, data visualization\nNote: Features documented based on system repositories, technical documentation, and published use cases as of April 2025.\nGemini/DeepResearch [60] demonstrates exceptional suitability for enterprise decision-making through its\nstrong information currency, analytical capabilities, and actionable output formats. The system effectively\nnavigates business information sources, analyzes market trends, and produces insights directly relevant to\ndecision processes. Manus [164] offers similarly strong performance for information acquisition and analysis,\nthough with somewhat less emphasis on actionable recommendation formatting. Microsoft Copilot [173]\nempowers organizations with powerful generative AI, enterprise-grade security and privacy, and is trusted\nby companies around the world. Similarly, the Adobe Experience Platform AI Assistant [181] employs\nknowledge graph-enhanced retrieval-augmented generation to accurately respond over private enterprise\ndocuments, significantly enhancing response relevance while maintaining provenance tracking.\nWorkflow automation platforms like n8n [183] provide particular strengths in information currency\nand actionability through their integration with enterprise data sources and business intelligence tools.\nResearch-focused systems like Agent-RL/ReSearch [2] and Flowith/OracleMode [77] offer competitive an-\nalytical capabilities but may require additional processing to translate findings into actionable business\nrecommendations.\n3.2.3\nPersonal Knowledge Management Adaptability Assessment. Individual knowledge management empha-\nsizes accessibility, personalization, and integration with existing workflows:\n18\nXu et al.\nTable 7. Personal Knowledge Management Features of Deep Research Systems\nSystem\nUser Interface Design\nCustomization Options\nExisting Tool Integration\nPerplexity/DeepResearch [209]\nWeb-based interface, mobile application support\nTopic preference settings, information filtering options\nBrowser extension, sharing functionality\nnickscamara/open-deep-research [42]\nCommand-line interface, web interface option\nModular configuration, source priority adjustment\nLocal file system integration, note-taking exports\nOpenManus [193]\nDesktop application, local web interface\nTemplate customization, workflow configuration\nNote application exports, knowledge base connections\nNanobrowser [184]\nProgrammatic interface, developer-focused API\nFull configuration access, component-level customization\nBrowser automation framework compatibility\nsmolagents/open_deep_research [115]\nTechnical interface, Python library integration\nArchitecture-level customization, agent behavior configuration\nPython ecosystem integration, custom adapter support\nJina-AI/node-DeepResearch [121]\nNode.js integration, API-driven interface\nComponent-level configuration, pipeline customization\nNode.js application ecosystem, JavaScript framework support\nNote: Features documented based on system repositories, technical documentation, and published implementations as of April 2025.\nPerplexity/DeepResearch [209] offers strong accessibility for personal knowledge management through\nits consumer-friendly interface and free access tier, though with more limited personalization capabilities.\nOpen-source implementations like nickscamara/open-deep-research [42] and OpenManus [193] provide\ngreater personalization possibilities through local deployment and customization, enabling adaptation to\nindividual information management preferences.\nInfrastructure tools like Nanobrowser [184] and Jina-AI/node-DeepResearch [121] offer particular strengths\nin workflow integration, allowing seamless incorporation into existing personal knowledge management\nsystems and processes. More complex frameworks like smolagents/open_deep_research [115] provide\nsophisticated capabilities but may present accessibility challenges for non-technical users.\n3.3\nPerformance Metrics and Benchmarking\nBeyond qualitative comparisons, quantitative performance metrics provide objective assessment of Deep\nResearch capabilities across systems.\n3.3.1\nQuantitative Evaluation Metrics. Standard benchmarks enable comparative evaluation of core research\ncapabilities:\nTable 8. Performance on Standard Evaluation Benchmarks\nSystem\nHLE Score* [212]\nMMLU** Score [33]\nHotpotQA Score [307]\nGAIA Score(pass@1)*** [172]\nOpenAI/DeepResearch [197]\n26.6%\n-\n-\n67.36%\nGemini-2.5 [60, 293]\n18.8%\n-\n-\n-\nGemini-2.0-Flash [89, 93]\n-\n77.9%\n-\n-\nPerplexity/DeepResearch [209]\n21.1%\n-\n-\n-\nGrok3Beta [299]\n-\n79.9%\n-\n-\nManus [164]\n-\n-\n-\n86.5%\nAgent-RL/ReSearch [2]\n-\n-\n37.51%\n-\n*Humanity’s Last Exam: Tests frontier research capabilities\n**Massive Multitask Language Understanding: Tests general knowledge\n***GAIA Score(pass@1): Average score\nOpenAI/DeepResearch [30, 123, 197] demonstrates leading performance across various benchmark cate-\ngories, particularly excelling in Humanity’s Last Exam (HLE) [212] hich measures advanced research and\nreasoning capabilities. Gemini/DeepResearch [60] shows comparable performance. According to the intro-\nduction of Google Deep Research with Gemini 2.5 Pro Experimental [60, 126], the new model demonstrated\nsuperior user preference over OpenAI/DeepResearch across four key metrics: instruction following (60.6% vs.\n39.4%), Comprehensiveness (76.9% vs. 23.1%), Completeness (73.3% vs. 26.7%), and Writing quality (58.2%\nvs. 41.8%). These results suggest Gemini 2.5 Pro’s enhanced capability in synthesizing structured, high-fidelity\nresearch outputs. This capability is further amplified in fullstack applications, where the integration of Gemini\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n19\nTable 9. Documented Performance Metrics from Deep Research Systems\nSystem\nBenchmark\nReported Score\nEvaluation Context\nSource\nOpenAI/DeepResearch\nHLE\n26.6%\nHumanity’s Last Exam\n[197]\nOpenAI/DeepResearch\nGAIA (pass@1)\n67.36%\nGeneral AI assistant tasks\n[197]\nPerplexity/DeepResearch\nHLE\n21.1%\nHumanity’s Last Exam\n[209]\nPerplexity/DeepResearch\nSimpleQA\n93.9%\nFactual question answering\n[209]\nGrok3Beta\nMMLU\n92.7%\nMultitask language understanding\n[299]\nManus\nGAIA (pass@1)\n86.5%\nGeneral AI assistant tasks\n[164]\nAgent-RL/ReSearch\nHotpotQA\n37.51%\nMulti-hop question answering\n[2]\nAutoGLM\nWebArena-Lite\n55.2% (59.1% retry)\nWeb navigation tasks\n[330]\nAutoGLM\nOpenTable\n96.2%\nRestaurant booking tasks\n[330]\nNote: Scores reflect performance on specific benchmarks as reported in cited publications. Direct comparison requires consideration of\nevaluation methodologies and task specifications.\nmodels with frameworks like LangGraph facilitates research-augmented conversational AI for comprehen-\nsive query handling, as demonstrated in Google-Gemini/Gemini-Fullstack-Langgraph-Quickstart [94].\nPerplexity/DeepResearch [209] achieves competitive results despite utilizing the open-source DeepSeek-R1\nmodel, highlighting the importance of implementation quality beyond raw model capabilities.\nOpen-source implementations show progressively lower benchmark scores, though many still achieve\nrespectable performance suitable for practical applications. Systems like AutoGLM-Research [330], HKUDS/\nAuto-Deep-Research [112], and Camel-AI/OWL [43] demonstrate that effective research capabilities can be\nachieved with more accessible models and frameworks, though with some performance trade-offs compared\nto leading commercial implementations.\nRecent benchmark development has expanded evaluation to more specialized aspects of research assis-\ntance. The AAAR-1.0 benchmark [157] specifically evaluates AI’s potential to assist research through 150\nmulti-domain tasks designed to test both retrieval and reasoning capabilities. Domain-specific approaches\ninclude DSBench [122], which evaluates data science agent capabilities across 20 real-world tasks[182, 283],\nSciCode [268] for scientific code generation, MASSW [323] for scientific workflow assistance, and MMSci [147]\nfor multimodal scientific understanding across graduate-level materials. ScienceQA[160] offers a comprehen-\nsive multimodal science benchmark with chain-of-thought explanations for evaluating reasoning capabilities.\nDomain-specific benchmarks like TPBench [58] for theoretical physics and AAAR-1.0 [157] for research\nassistance capabilities offer additional targeted evaluation approaches for specialized research applications.\nMulti-domain code generation benchmark like DomainCodeBench[328] is designed to systematically assess\nlarge language models across 12 software application domains and 15 programming languages. Interactive\nevaluation frameworks like LatEval [114] specifically assess systems’ capabilities in handling incomplete\ninformation through lateral thinking puzzles, providing insight into research abilities under uncertainty and\nambiguity. Complementary approaches like Mask-DPO [100] focus on generalizable fine-grained factuality\nalignment, addressing a critical requirement for reliable research outputs. Domain-specific benchmarks such\nas GMAI-MMBench [51] provide comprehensive multimodal evaluation frameworks specifically designed for\nmedical AI applications, while AutoBench [52] offers automated evaluation of scientific discovery capabilities,\nproviding standardized assessment of core research functions. Other broad evaluation frameworks including\nHELM [149], BIG-bench [88], and AGIEval [331], provide complementary assessment dimensions. Specialized\n20\nXu et al.\nmultimodal benchmarks like INQUIRE [279] extend this landscape to ecological challenges, rigorously\nevaluating expert-level text-to-image retrieval tasks critical for accelerating biodiversity research.\nTable 10. Specialized Deep Research Benchmarks\nBenchmark\nFocus Area\nEvaluation Approach\nKey Metrics\nAAAR-1.0 [157]\nResearch assistance\n150 multi-domain tasks\nRetrieval and reasoning capability\nDSBench [122]\nData science\n20 real-world tasks\nEnd-to-end completion rate\nSciCode [268]\nScientific coding\nCurated by scientists\nCode quality, task completion\nMASSW [323]\nScientific workflows\nBenchmarking tasks\nWorkflow orchestration quality\nMMSci [147]\nMultimodal science\nGraduate-level questions\nCross-modal understanding\nTPBench [58]\nTheoretical physics\nPhysics reasoning\nProblem-solving accuracy\nNote: These benchmarks represent domain-specific evaluation frameworks for specialized research capabilities.\n3.3.2\nQualitative Assessment Frameworks. Beyond numeric benchmarks, qualitative evaluation provides\ninsight into practical effectiveness:\nTable 11. Documented Output Characteristics of Deep Research Systems\nSystem\nContent Organization\nInformation Diversity\nVerification Features\nNovel Connection Mechanisms\nOpenAI/DeepResearch [197]\nHierarchical structure with 5+ sections, executive summaries\nCross-domain source integration (reported in [197])\nStatement-level citation linking, contradiction flagging\nCross-domain connection identification\nGemini/DeepResearch [60]\nMulti-level heading organization, standardized formatting\nMulti-perspective source inclusion (documented in [60])\nSource credibility metrics, confidence indicators\nThematic pattern identification\nPerplexity/DeepResearch [209]\nProgressive information disclosure, expandable sections\nReal-time source aggregation across platforms\nDirect quote attribution, inline source linking\nTimeline-based relationship mapping\nmshumer/OpenDeepResearcher [249]\nTemplate-based document structure, consistent formatting\nTopic-based categorization of sources\nBasic citation framework, reference listing\nTopic cluster visualization\ngrapeot/deep_research_agent [263]\nMinimal formatting, content-focused presentation\nSource type categorization, domain tracking\nSource credibility scoring system based on metadata\nNot implemented per repository documentation\nAgent-RL/ReSearch [2]\nAdaptive content organization based on information types\nExploratory search patterns documented in repository\nContradiction detection algorithms\nPattern-based insight generation documented in [2]\nNote: Characteristics documented based on system technical documentation, published demonstrations, repository analysis, and official\ndescriptions as of April 2025. Specific feature implementations may vary across system versions.\nCommercial systems generally demonstrate stronger qualitative performance, particularly in output\ncoherence and factual accuracy. OpenAI/DeepResearch [197] produces exceptionally well-structured reports\nwith reliable factual content, while also achieving moderate innovation in connecting disparate sources.\nGemini/DeepResearch [60] shows similar strengths in coherence and accuracy, with slightly less emphasis\non novel insights.\nSome open-source implementations show particular strengths in specific dimensions. Agent-RL/ReSearch\n[2] achieves notable performance in insight novelty through its exploration-focused approach, while grapeot/\ndeep_research_agent [263] demonstrates strong factual accuracy through its emphasis on information\nverification. These specialized capabilities highlight the diversity of approaches within the Deep Research\necosystem.\n3.3.3\nEfficiency and Resource Utilization Metrics. Practical deployment considerations include computational\nrequirements and operational efficiency:\nCommercial cloud-based services offer optimized performance with moderate response times, though\nwith dependency on external infrastructure and associated costs. Perplexity/DeepResearch [209] achieves\nparticularly strong efficiency metrics, with relatively quick response times and high token efficiency despite\nits competitive output quality.\nOpen-source implementations present greater variability in efficiency metrics. Systems like AutoGLM-\nResearch [330] and QwenLM/Qwen-Agent [224] require substantial computational resources but can be\ndeployed in local environments, offering greater control and potential cost savings for high-volume usage.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n21\nTable 12. Efficiency and Resource Utilization\nSystem\nResponse Time*\nCompute Requirements\nToken Efficiency**\nOpenAI/DeepResearch [197]\n5-30 min\nCloud-only\nHigh (detailed, citation-rich)\nPerplexity/DeepResearch [209]\n2m59s\nCloud-only\n-\nGrok3Beta [299]\n-\nCloud-only\n-\nNanobrowser [184]\n-\nUser-defined via LLM API key\n-\nn8n [183]\n-\nSelf-hosted or cloud-based; scalable\n-\n*Typical response time for moderately complex research tasks\n**Efficiency of token utilization relative to output quality\nLighter-weight implementations like nickscamara/open-deep-research [42] can operate with more limited\nresources but typically demonstrate longer response times and lower token efficiency.\nThis comparative analysis highlights the diversity of approaches and capabilities across the Deep Research\necosystem. While commercial implementations currently demonstrate leading performance on standard\nbenchmarks, open-source alternatives offer competitive capabilities in specific domains and use cases, with\nparticular advantages in customization, control, and potential cost efficiency for specialized applications.\nThe subsequent sections will build on this analysis to examine implementation technologies, evaluation\nmethodologies, and application domains in greater detail.\n4\nImplementation Technologies and Challenges\nThe practical realization of Deep Research systems involves numerous technical challenges spanning in-\nfrastructure design, system integration, and safeguard implementation. This section examines the key\nimplementation technologies that enable effective Deep Research capabilities and the challenges that must\nbe addressed for reliable, efficient operation.\n4.1\nArchitectural Implementation Patterns\nThe diverse systems analyzed in this survey reveal several distinct architectural patterns that represent\ndifferent approaches to implementing Deep Research capabilities. This section examines four fundamental\narchitectural patterns: monolithic, pipeline-based, multi-agent, and hybrid implementations. For each pattern,\nwe analyze the underlying structural principles, component interactions, information flow mechanisms, and\nrepresentative systems.\n4.1.1\nMonolithic Architecture Pattern. Monolithic implementations integrate all Deep Research capabilities\nwithin a unified architectural framework centered around a core reasoning engine. As illustrated in Figure 4,\nthese systems employ a centralized control mechanism with direct integration of specialized modules.\nThe defining characteristics of this architecture include:\n∙Centralized Control Flow: All operations route through a primary reasoning engine that maintains\nglobal state and execution context\n∙Tightly Coupled Integration: Specialized modules (web browsing, document processing, etc.) are\ndirectly integrated with the central controller\n∙Shared Memory Architecture: Information state is maintained in a centralized memory system\naccessible to all components\n22\nXu et al.\nImplementation Architecture of Deep Research Systems\nFoundation Model\n(LLM Reasoning Engine)\no3, Gemini, DeepSeek-R1\nWeb Crawling\n(Dynamic Discovery)\nNanobrowser, AutoGLM\nAPI Integration\n(Structured Data)\nn8n, Manus\nDocument Analysis\n(Content Processing)\ndzhng/deep-research\nSpecialized Tools\n(Domain-Specific)\nCamel-AI/OWL\nTask Planning\n(Decomposition Scheduling)\nOpenAI Agents SDK, Flowith\nExecution Control\n(Monitoring Recovery)\nAgent-RL/ReSearch, TARS\nInformation Evaluation\n(Quality Assessment)\ngrapeot/deep_research_agent\nReport Generation\n(Structured Output)\nmshumer/OpenDeepResearcher\nInteractive Presentation\n(User Exploration)\nHKUDS/Auto-Deep-Research\nMemory System\n(Context Management)\nMulti-Agent System\n(Distributed Reasoning)\nsmolagents/\nopen_deep_research\nUser Interface\nFoundation Model\nInformation Retrieval\nOrchestration\nKnowledge Synthesis\nCore Systems\nFig. 3. Implementation Architecture of Deep Research Systems\n∙Sequential Reasoning Processes: Operations typically follow a structured sequence defined by the\ncentral controller\nThis architectural pattern offers strong coherence and reasoning consistency through its unified control\nstructure. However, it presents challenges for extensibility and can struggle with parallelization of com-\nplex operations. Representative implementations include OpenAI/DeepResearch [197] and grapeot/deep_\nresearch_agent [263], which demonstrate how this architecture enables coherent reasoning across diverse\ninformation sources while maintaining implementation simplicity.\n4.1.2\nPipeline-Based Architecture Pattern. Pipeline architectures implement Deep Research capabilities\nthrough a sequence of specialized processing stages connected through well-defined interfaces. As shown in\nFigure 5, these systems decompose research workflows into discrete processing components with explicit\ndata transformations between stages.\nThe key characteristics of pipeline implementations include:\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n23\nMonolithic Deep Research Architecture\nFoundation Model\n(Centralized Reasoning Engine)\nShared Memory System\nWeb Browsing\nModule\nAPI Integration\nModule\nDocument\nProcessor\nKnowledge\nSynthesizer\nUser Interface\nResearch Output\nKey Features:\n• Centralized control flow\n• Tightly coupled components\n• Unified shared memory\n• Sequential reasoning processes\nRepresentative Systems:\n• OpenAI/Deep Research\n• grapeot/deep_research_agent\nFig. 4. Monolithic Deep Research Architecture\n∙Sequential Component Organization: Research tasks flow through a predefined sequence of specialized\nprocessing modules\n∙Standardized Interfaces: Clear data transformation specifications between pipeline stages enable\nmodular component replacement\n∙Staged Processing Logic: Each component implements a specific transformation, with minimal\ndependence on global state\n∙Configurable Workflow Paths: Advanced implementations enable conditional routing between alter-\nnative processing paths based on intermediary results\nPipeline architectures excel in workflow customization and component reusability but may struggle\nwith complex reasoning tasks requiring iterative refinement across components. Systems like n8n [183]\nand dzhng/deep-research [321] exemplify this approach, demonstrating how explicit workflow sequencing\nenables sophisticated research automation through composition of specialized components.\n4.1.3\nMulti-Agent Architecture Pattern. Multi-agent architectures implement Deep Research capabilities\nthrough ecosystems of specialized autonomous agents coordinated through explicit communication protocols.\nFigure 6 illustrates how these systems distribute research functionality across collaborating agents with\ndifferentiated roles and responsibilities.\n24\nXu et al.\nPipeline-Based Deep Research Architecture\nQuery Processing\nStage 1\nInformation\nRetrieval Stage 2\nContent Analysis\nStage 3\nOutput\nStage 4\nIntent Classifier\nQuery Expander\nWeb Search Manager\nDatabase Connector\nDocument Fetcher\nContent Extractor\nFact Verificator\nKnowledge Integrator\nReport\nVisual\nStandardized Data Transformation Interface\nConditional Routing Control\nKey Features:\n• Sequential component organization\n• Standardized interfaces\n• Component reusability\nRepresentative Systems:\n• n8n\n• dzhng/deep-research\nFig. 5. Pipeline-Based Deep Research Architecture\nThe defining elements of multi-agent implementations include:\n∙Distributed Functional Decomposition: Research capabilities are distributed across specialized agents\nwith defined roles (searcher, analyst, critic, etc.)\n∙Explicit Coordination Mechanisms: Standardized message passing and task delegation protocols\nenable inter-agent collaboration\n∙Autonomous Decision Logic: Individual agents maintain independent reasoning capabilities within\ntheir designated domains\n∙Dynamic Task Allocation: Advanced implementations employ flexible task assignment based on agent\ncapabilities and current workload\nMulti-agent architectures excel in complex research tasks requiring diverse specialized capabilities and\nparallel processing. Their distributed nature enables exceptional scaling for complex research workflows but\nintroduces challenges in maintaining overall coherence and consistent reasoning across agents. Representative\nimplementations include smolagents/open_deep_research [115] and TARS [39], which demonstrate how\nmulti-agent coordination enables sophisticated research workflows through specialized agent collaboration.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n25\nMulti-Agent Deep Research Architecture\nAgent Coordination Layer\nStandardized Message Bus\nSearch Agent\n(Information Retrieval)\nAnalyst Agent\n(Data Processing)\nCritic Agent\n(Verification)\nWriter Agent\n(Content Generation)\nWeb Crawler\nAPI Client\nParser\nAnalytics\nFact Check\nValidator\nTemplate\nFormatter\nSearch Memory\nAnalysis Memory\nVerification Memory\nContent Memory\nShared Knowledge Repository\nKey Features:\n• Distributed functional decomposition\n• Explicit coordination mechanisms\n• Autonomous specialized agents\nRepresentative Systems:\n• smolagents/open_deep_research\n• TARS\nFig. 6. Multi-Agent Deep Research Architecture\n4.1.4\nHybrid Architecture Pattern. Hybrid architectures combine elements from multiple architectural\npatterns to balance their respective advantages within unified implementations. As shown in Figure 7, these\nsystems employ strategic integration of architectural approaches to address specific research requirements.\nKey characteristics of hybrid implementations include:\n∙Tiered Architectural Organization: Different architectural patterns are employed at different system\nlevels based on functional requirements\n∙Domain-Specific Optimization: Architectural approaches are selected based on domain-specific pro-\ncessing requirements\n∙Flexible Integration Mechanisms: Standardized interfaces enable communication between components\nemploying different architectural patterns\n∙Adaptive Execution Frameworks: Control mechanisms dynamically adjust processing approaches\nbased on task characteristics\nHybrid architectures offer exceptional flexibility and optimization opportunities but introduce implemen-\ntation complexity and potential integration challenges. Systems like Perplexity/DeepResearch [209] and\nCamel-AI/OWL [43] exemplify this approach, combining centralized reasoning with distributed information\n26\nXu et al.\nHybrid Deep Research Architecture\nAdaptive Orchestration Layer\nMonolithic Core\n(Centralized Reasoning)\nDomain: Complex Reasoning\nPipeline Sub-system\n(Sequential Processing)\nDomain: Data Transformation\nMulti-Agent Sub-system\n(Distributed Collaboration)\nDomain: Parallel Information Gathering\nFoundation Model\nUnified Memory\nContent Extractor\nData Transform Pipeline\nSearch Agents\nMessage Bus\nUnified Integration Layer\nExternal Tools, APIs, and Data Sources\nDomain Adaptation\nKey Features:\n• Domain-specific optimization\n• Tiered architectural organization\n• Flexible integration mechanisms\n• Adaptive execution\nRepresentative Systems: Perplexity/Deep Research, camel-ai/owl\nFig. 7. Hybrid Deep Research Architecture\ngathering and specialized processing pipelines to achieve sophisticated research capabilities with balanced\nperformance characteristics.\n4.1.5\nEmerging Agent Framework Ecosystems. Beyond the core architectural patterns described above, the\nDeep Research ecosystem has been significantly enhanced by specialized agent frameworks that provide\nstandardized components for agent development. Emerging systems incorporate specialized agent frameworks\n[54, 142, 301] that structure reasoning in ways particularly suited to complex research tasks requiring both\ndepth and breadth of analysis. As detailed in comprehensive analyses of agent frameworks [133, 304], these\nsystems offer varying approaches to agent orchestration, execution control, and reasoning orchestration.\nKey frameworks include LangGraph [134], which provides graph-based control flow for language model\napplications, enabling complex reasoning patterns through explicit state management and transition logic.\nGoogle’s Agent Development Kit (ADK) [91] offers a comprehensive framework for agent development with\nstandardized interfaces for tool integration, planning, and execution monitoring. CrewAI [64] implements an\nagent collaboration framework designed specifically for multi-specialist workflows, enabling role-based task\ndistribution with explicit coordination mechanisms. More experimental frameworks like Agno [3] explore\nagentic autonomy through self-improvement and meta-reasoning capabilities.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n27\nThe TapeAgents framework [19] provides a particularly comprehensive approach to agent development\nand optimization, with explicit support for iterative refinement through systematic recording and analysis\nof agent behavior. These frameworks collectively demonstrate an ongoing shift toward standardized agent\ncomponents that enhance development efficiency while enabling more complex reasoning and execution\npatterns.\n4.1.6\nArchitectural Pattern Comparison. Table 13 provides a comparative analysis of these architectural\npatterns across key performance dimensions:\nTable 13. Architectural Pattern Characteristics in Deep Research Systems\nCharacteristic\nMonolithic\nPipeline\nMulti-Agent\nHybrid\nControl Structure\nCentralized\nSequential\nDistributed\nMixed\nComponent Coupling\nTight\nLoose\nModerate\nVariable\nFailure Propagation\nSystem-wide\nStage-limited\nAgent-isolated\nComponent-dependent\nDevelopment Complexity\nMinimal\nModerate\nSubstantial\nMaximal\nDeployment Flexibility\nLimited\nModerate\nModerate\nHigh\nRepresentative Systems\ngrapeot/deep_research_agent\nn8n, dzhng/deep-research\nsmolagents, TARS\nPerplexity, Camel-AI/OWL\nNote: Characteristics based on architectural analysis of surveyed systems. Quantitative performance comparison requires standardized\nbenchmarking across identical tasks and environments.\nEach architectural pattern presents distinct advantages and limitations that influence its suitability for\nspecific Deep Research applications. Monolithic architectures excel in reasoning coherence and implemen-\ntation simplicity, making them appropriate for focused research applications with well-defined workflows.\nPipeline architectures offer exceptional extensibility and component reusability, enabling customized research\nworkflows through modular composition. Multi-agent architectures provide superior parallelization and fault\ntolerance, supporting complex research tasks requiring diverse specialized capabilities. Hybrid architectures\nbalance these characteristics through strategic integration, offering flexible optimization for diverse research\nrequirements.\nThe architectural pattern selection significantly influences system capabilities, performance characteristics,\nand application suitability. As the Deep Research ecosystem continues to evolve, we anticipate further\narchitectural innovation combining elements from these foundational patterns to address emerging application\nrequirements and technical capabilities.\n4.2\nInfrastructure and Computational Optimization\nDeep Research systems require sophisticated infrastructure to support their complex reasoning and informa-\ntion processing capabilities.\n4.2.1\nDistributed Reasoning Architectures. Effective reasoning across expansive information landscapes\nrequires specialized architectural approaches. Frameworks like AutoChain [78] and AutoGen [298] have\npioneered distributed agent paradigms that can be applied to research workflows. Advanced systems\nemploy distributed reasoning architectures that decompose complex queries into parallel processing paths.\nOpenAI/DeepResearch [197] implements a hierarchical reasoning framework that distributes analytical tasks\nacross multiple execution threads while maintaining coherent central coordination.\nImplementation approaches increasingly leverage specialized frameworks for efficient LLM serving, in-\ncluding LightLLM [177], Ollama [192], VLLM [281], and Web-LLM [176] for browser-based deployment.\n28\nXu et al.\nThese frameworks enable more efficient utilization of computational resources, particularly important for\nresource-intensive research workflows requiring extensive model inference. Such optimizations are especially\ncritical for open-source implementations operating with more constrained computational resources compared\nto commercial cloud-based alternatives.\nParallel Reasoning Pathways. Advanced systems employ distributed reasoning architectures that decom-\npose complex queries into parallel processing paths. OpenAI/DeepResearch [197] implements a hierarchical\nreasoning framework that distributes analytical tasks across multiple execution threads while maintaining\ncoherent central coordination. Similar approaches are evident in Gemini/DeepResearch [60], which leverages\nGoogle’s distributed computing infrastructure to parallelize information analysis while preserving reasoning\nconsistency.\nOpen-source implementations like HKUDS/Auto-Deep-Research [112] and Agent-RL/ReSearch [2] demon-\nstrate more accessible distributed reasoning approaches, utilizing task decomposition and asynchronous\nprocessing to enhance performance within more constrained computational environments. These systems\nshow that effective parallelization can be achieved even without the extensive infrastructure of commercial\nplatforms.\nMemory and State Management. Distributed reasoning introduces significant challenges in memory coher-\nence and state management. Commercial systems implement sophisticated state synchronization mechanisms\nthat maintain consistent reasoning contexts across distributed components. OpenAI’s implementation utilizes\na hierarchical memory architecture with explicit coordination protocols [200], while Google’s approach\nleverages its existing distributed computing frameworks adapted for reasoning workflows.\nOpen-source alternatives like Camel-AI/OWL [43] employ simplified but effective memory management\napproaches, including centralized knowledge repositories with controlled access patterns. These implementa-\ntions demonstrate pragmatic solutions to state management challenges within more constrained technical\nenvironments.\n4.2.2\nParallel Search and Information Retrieval. Information acquisition represents a primary bottleneck in\nDeep Research performance:\nConcurrent Query Execution. Advanced systems implement sophisticated parallel search infrastructures\nto accelerate information gathering. Perplexity/DeepResearch [209] employs a multi-threaded search\narchitecture that dispatches dozens of concurrent queries across different information sources, significantly\naccelerating the research process. Similar capabilities are evident in dzhng/deep-research [321], which\nimplements a specialized scheduler for concurrent web queries with adaptive rate limiting to avoid service\nrestrictions.\nInfrastructure tools like Nanobrowser [184] provide optimized platforms for parallel browsing operations,\nenabling multiple concurrent page loads with shared resource management. These specialized components en-\nhance the information gathering capabilities of integrated systems like Manus [164] and Flowith/OracleMode\n[77], which leverage concurrent browsing to accelerate their research workflows.\nQuery Coordination and Deduplication. Effective parallel search requires sophisticated coordination to\navoid redundancy and ensure comprehensive coverage. Commercial systems implement advanced query\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n29\nplanning that dynamically adapts to intermediate results, adjusting search strategies based on discovered\ninformation. OpenAI’s implementation includes explicit deduplication mechanisms that identify and con-\nsolidate redundant sources, while Perplexity employs source diversification techniques to ensure broad\ncoverage.\nOpen-source tools like nickscamara/open-deep-research [42] implement pragmatic approaches to query\ncoordination, including simple but effective caching mechanisms and result fingerprinting to avoid redundant\nprocessing. These techniques demonstrate that effective coordination can be achieved with relatively\nstraightforward implementation approaches.\n4.2.3\nResource Allocation and Efficiency Optimization. Computational efficiency significantly impacts both\nperformance and operational economics:\nAdaptive Resource Allocation. Advanced systems implement dynamic resource allocation based on task\ncharacteristics and complexity. Gemini/DeepResearch [60] employs sophisticated workload prediction to\nprovision computational resources adaptively, allocating additional capacity for more complex research\ntasks. Similar approaches are emerging in open-source implementations like QwenLM/Qwen-Agent [224], which\nincorporates task complexity estimation to guide resource allocation decisions.\nProgressive Processing Strategies. Efficiency-focused implementations employ progressive processing ap-\nproaches that incrementally refine results based on available information. Perplexity/DeepResearch [209]\nutilizes a staged analysis approach that provides preliminary findings quickly while continuing deeper analysis\nin the background. This strategy enhances perceived responsiveness while ensuring comprehensive results\nfor complex queries.\nOpen-source alternatives like mshumer/OpenDeepResearcher [249] implement simpler but effective pro-\ngressive strategies, including early result previews and incremental report generation. These approaches\ndemonstrate pragmatic solutions to efficiency challenges without requiring sophisticated infrastructure.\n4.3\nSystem Integration and Interoperability\nDeep Research systems must effectively coordinate diverse components and external services to deliver\ncomprehensive capabilities.\n4.3.1\nAPI Design and Standardization. Consistent interfaces enable modular development and component\ninteroperability:\nComponent Interface Standardization. Current Deep Research implementations employ largely incom-\npatible architectures and interfaces. Future research could build upon emerging standardization efforts\nlike Anthropic’s Model Context Protocol (MCP) [12] and Google’s Agent2Agent Protocol (A2A) [90, 92]\nto establish truly universal component interfaces. MCP provides a structured framework for model-tool\ninteraction, enabling consistent integration patterns across diverse LLM applications, while A2A focuses\non standardized agent-to-agent communication to facilitate multi-agent systems. These complementary\napproaches could form the foundation for comprehensive standardization enabling modular development\n30\nXu et al.\nand interchangeable components across implementations. Early steps in this direction appear in frame-\nworks like OpenAI/AgentsSDK [199], which provides standardized agent definitions, but more comprehensive\nstandardization would require broader industry adoption of common protocols.\nWorkflow Automation. Several workflow automation platforms like Dify [259], Coze [38], and Flowise\n[5] have emerged as low-code environments for building LLM-powered applications, potentially offering\nstandardized frameworks for Deep Research components. Advanced workflow orchestration platforms\nincluding Temporal [265], Restate [229], and Orkes [203] provide robust infrastructure for complex, stateful\nworkflows with explicit support for long-running processes and reliability patterns crucial for sophisticated\nresearch applications. Implementation approaches might include defining standard message passing protocols\nbetween research components, establishing common data structures for research tasks and results, developing\ncompatibility layers between competing standards, extending existing protocols with research-specific\ninteraction patterns, and establishing common evaluation frameworks for component interoperability. These\nadvances could accelerate ecosystem development by enabling specialized components from diverse developers\nto work seamlessly within unified frameworks, significantly enhancing the pace of innovation through\ncomponentization and reuse.\nExternal Service Integration. Access to specialized external services significantly enhances research capa-\nbilities. Advanced retrieval frameworks like LlamaIndex [235] provide standardized interfaces for retrieval\naugmentation, enabling consistent integration patterns across diverse information sources and document\nformats. Systems like n8n [183] excel in external service integration through their comprehensive connector\nlibrary and standardized authentication mechanisms. This capability enables access to specialized information\nsources and analytical services that extend beyond basic web search.\nOpen-source frameworks like Jina-AI/node-DeepResearch [121] implement simplified but effective API\nintegration patterns, providing standardized wrappers for common services while maintaining extensibility\nfor custom integrations. These approaches balance standardization with flexibility for diverse research\nrequirements.\n4.3.2\nTool Integration Frameworks. Effective orchestration of diverse tools enhances overall system capabili-\nties:\nTool Selection and Composition. Advanced systems implement sophisticated tool selection based on\ntask requirements and information context. Manus [164] features an adaptive tool selection framework\nthat identifies appropriate tools for specific research subtasks, dynamically composing workflows based on\navailable capabilities. Similar approaches are emerging in open-source implementations like grapeot/deep_\nresearch_agent [263], which includes basic tool selection heuristics based on task classification.\nTool Execution Monitoring. Reliable tool usage requires effective execution monitoring and error handling.\nCommercial systems implement sophisticated monitoring frameworks that track tool execution, detect\nfailures, and implement recovery strategies. OpenAI’s implementation includes explicit success criteria\nverification and fallback mechanisms for tool failures, ensuring reliable operation even with unreliable\nexternal components.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n31\nOpen implementations like Agent-RL/ReSearch [2] demonstrate more accessible monitoring approaches,\nincluding simplified execution tracking and basic retry mechanisms for common failure modes. These imple-\nmentations show that effective monitoring can be achieved with relatively straightforward implementation\nstrategies.\nRecent advances in agent collaboration frameworks [145, 221] highlight significant challenges in agent\ncoordination [46], particularly for complex research tasks requiring diverse, specialized capabilities working\nin concert toward unified research objectives.\n4.3.3\nCross-Platform Compatibility. Deployment flexibility requires careful attention to environmental de-\npendencies:\nPlatform Abstraction Layers. Cross-platform implementations employ abstraction layers to isolate core\nlogic from environmental dependencies. TARS [39] implements a sophisticated abstraction architecture that\nseparates its core reasoning framework from platform-specific integration components, enabling deployment\nacross diverse environments. Similar approaches are evident in Nanobrowser [184], which provides consistent\nbrowsing capabilities across different operating systems.\nContainerization and Deployment Standardization. Modern implementations leverage containerization to\nensure consistent deployment across environments. OpenManus [193] provides explicit container configurations\nthat encapsulate all dependencies, enabling reliable deployment across diverse infrastructures. Similar\napproaches are employed by AutoGLM-Research [330], which provides standardized deployment configurations\nfor different environments. Alongside containerization, modern cloud platforms such as Vercel [280] offer\nstreamlined, standardized deployment workflows for the web-based interfaces of many research applications.\n4.3.4\nResearch-Oriented Coding Assistance Integration. The integration of AI-powered coding assistants\nrepresents an increasingly important dimension of Deep Research system capabilities, particularly for\ncomputational research workflows requiring custom analysis scripts, data processing pipelines[108], and\nresearch automation tools.\nCoding Assistant Integration Patterns. Modern research workflows increasingly depend on custom code\ndevelopment for data analysis, visualization, and automation tasks. AI coding assistants have emerged as\ncrucial tools for enhancing researcher productivity in these computational aspects. The landscape of coding\nassistance tools demonstrates varying approaches to integration with research workflows, from IDE-native\ncompletion systems to conversational code generation interfaces. Systems like GitHub Copilot [20, 86] provide\nseamless integration within development environments, enabling context-aware code completion for research\nscripts and analysis workflows. Complementary approaches like ChatGPT-based code generation [309] offer\nconversational interfaces that can translate research requirements into executable implementations. More\nspecialized frameworks like AutoDev [275], DSPy[257], and Pydantic-AI[216] enable end-to-end automated\ndevelopment workflows particularly suited for research prototype generation and experimental tool creation.\nAdditionally, tools like Bolt [32] allow researchers to create web applications directly from text descriptions,\nhandling the coding process while they focus on their vision. Evolutionary coding agents like AlphaEvolve [190]\nfurther enhance capabilities by iteratively optimizing algorithms using autonomous pipelines of LLMs and\nevolutionary feedback mechanisms. Recent research explores the synergy between generative AI and software\n32\nXu et al.\nengineering, leveraging techniques like zero-shot prompting to enhance coding assistants and streamline\ndevelopment processes [41]. However, research has revealed limitations in these assistants’ capabilities, such\nas ambiguous beliefs regarding research claims and a lack of credible evidence to support their responses\n[35]. A large-scale survey demonstrates that developers frequently decline initial suggestions, citing unmet\nfunctional or non-functional requirements and challenges in controlling the tool to generate desired outputs\n[148]. User resistance behaviors documented in such surveys highlight the need for comprehensive adoption\nstrategies, including providing active support during initial use, clearly communicating system capabilities,\nand adhering to predefined collaboration rules to mitigate low acceptance rates[252]. This underscores the\nneed for adaptive hint systems, which can provide personalized support for bug finding and fixing by tailoring\nto user understanding levels and program representations to improve accuracy in debugging tasks [226].\nPioneering studies employ physiological measurements such as EEG and eye tracking to quantify developers’\ncognitive load during AI-assisted programming tasks, addressing critical gaps in understanding actual usage\npatterns and productivity impacts [106]. Furthermore, tools like CodeScribe address challenges in AI-driven\ncode translation for scientific computing by combining prompt engineering with user supervision to automate\nconversion processes while ensuring correctness [69]. Similarly, CodeCompose’s multi-line suggestion feature\ndeployed at Meta demonstrates substantial productivity improvements, saving 17% of keystrokes through\noptimized latency solutions despite initial usability challenges [72]. Moreover, for debugging tasks, ChatDBG\n[139] enhances debugging capabilities by enabling programmers to engage in collaborative dialogues for root\ncause analysis and bug resolution, leveraging LLMs to provide domain-specific reasoning. Intelligent QA\nassistants are also being developed to streamline bug resolution processes [308], and grey literature reviews\nindicate a growing trend in AI-assisted test automation [231]. Additionally, benchmarks like CodeMMLU [163]\nevaluate code understanding and reasoning across diverse tasks, revealing significant comprehension gaps in\ncurrent models despite advanced generative capabilities. Empirical evaluations of ACATs through controlled\ndevelopment scenarios demonstrate nuanced variations in acceptance patterns, modification reasons, and\neffectiveness based on task characteristics and user expertise [260]. Generative AI tools significantly enhance\ndeveloper productivity by accelerating learning processes and altering collaborative team workflows through\nreduced repetitive tasks, fundamentally transforming development paradigms [277]. To realize the vision of\nnext-generation AI coding assistants, it is crucial to address integration gaps and establish robust design\nprinciples such as setting clear usage expectations and employing extendable backend architectures [186].\nTable 14. Qualitative Assessment of AI Coding Assistants for Research Applications\nSystem\nDocumented Capabilities\nIntegration Approach\nEvaluation Evidence\nResearch-Specific Features\nGitHub Copilot [86, 319]\nCode completion, documentation\nIDE-native integration\nUser study on practices [319]\nLimited domain specialization\nAmazon CodeWhisperer [175]\nSecurity-focused suggestions\nAWS ecosystem integration\nComparative evaluation [309]\nCloud research workflows\nChatGPT Code [309]\nConversational code generation\nAPI-based interaction\nCode quality assessment [309]\nNatural language specification\nCursor [65]\nContext-aware completion\nCodebase integration\nNo published evaluation\nRepository-level understanding\nCodeium [206]\nMulti-language support\nEditor extensions\nComparative benchmark [206]\nAnalysis workflow support\nAutoDev [275]\nAutomated development\nTask automation pipeline\nEmpirical evaluation [275]\nEnd-to-end implementation\nGPT-Pilot [217]\nProject scaffolding\nGuided development process\nRepository demonstrations\nResearch prototype generation\nNote: Capabilities and evaluations based on published studies and documented features. Comparative performance requires standardized\nevaluation across identical tasks.\nThe diversity of coding assistance approaches highlights the importance of integration flexibility within\nDeep Research systems. While some implementations benefit from tightly integrated coding assistance\nthat understands research context, others require more flexible interfaces that can accommodate diverse\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n33\ndevelopment workflows and programming paradigms. This integration dimension becomes particularly\ncrucial as research increasingly requires custom computational tools and analysis pipelines that extend\nbeyond pre-existing software packages[75, 244, 295]. Recent work by Chen et al. [53] demonstrates that\nproactive programming assistants, which automatically provide suggestions to enhance productivity and\nuser experience, represent a key advancement in this domain. Additionally, ChatDev [220] exemplifies how\nlinguistic communication serves as a unifying bridge for multi-agent collaboration in software development,\nstreamlining the entire lifecycle from design to testing. Moreover, research on integrating AI assistants in\nAgile meetings reveals critical links to team collaboration dynamics and provides roadmaps for facilitating\ntheir adoption in development contexts [40]. As demonstrated by Talissa Dreossi[70], this hybrid approach\nbridges the gap between the high performance of deep learning models and the transparency of symbolic\nreasoning, advancing AI by providing interpretable and trustworthy applications.\nResearch Workflow Code Generation. Advanced coding assistants specifically optimized for research\ncontexts demonstrate particular value in translating research methodologies into executable implementations.\nSystems like GPT-Pilot [217] enable guided development of complete research applications, while domain-\nspecific tools can generate analysis scripts aligned with particular research methodologies or data types.\nThese capabilities enhance research efficiency by reducing the technical barriers between research design and\ncomputational implementation.\nImplementation patterns typically involve integration with research data management systems, version\ncontrol workflows, and collaborative development environments that support reproducible research practices.\nThe effectiveness of such integration depends significantly on the coding assistant’s understanding of research-\nspecific requirements including documentation standards, reproducibility considerations, and domain-specific\nlibraries and frameworks commonly used in particular research fields[124].\n4.4\nTechnical Challenges and Solutions\nDeep Research systems face numerous technical challenges that must be addressed for reliable, trustworthy\noperation.\n4.4.1\nHallucination Control and Factual Consistency. Maintaining factual accuracy represents a fundamental\nchallenge for LLM-based research systems:\nSource Grounding Techniques. Advanced implementations employ explicit source grounding to enhance\nfactual reliability. Perplexity/DeepResearch [209] implements strict attribution requirements that link all\ngenerated content to specific sources, reducing unsupported assertions. Similar approaches are evident in\nOpenAI/DeepResearch [197], which maintains explicit provenance tracking throughout the reasoning process.\nOpen-source implementations like grapeot/deep_research_agent [263] demonstrate more accessible\ngrounding approaches, including simple but effective citation tracking and verification mechanisms. These\ntechniques show that meaningful improvements in factual reliability can be achieved with straightforward\nimplementation strategies.\nContradiction Detection and Resolution. Effective research requires identification and resolution of contra-\ndictory information. Commercial systems implement sophisticated contradiction detection mechanisms that\nidentify inconsistencies between sources and implement resolution strategies [296]. Gemini/DeepResearch\n34\nXu et al.\n[60] includes explicit uncertainty modeling and conflicting evidence presentation, enhancing transparency\nwhen definitive conclusions cannot be reached.\nOpen implementations like HKUDS/Auto-Deep-Research [112] employ simpler but useful contradiction iden-\ntification approaches, flagging potential inconsistencies for user review. These implementations demonstrate\nthat even basic contradiction handling can significantly enhance research reliability.\n4.4.2\nPrivacy Protection and Security Design. Research systems must safeguard sensitive information and\nprotect against potential misuse:\nQuery and Result Isolation. Secure implementations employ strict isolation between user queries to\nprevent information leakage. Commercial platforms implement sophisticated tenant isolation that ensures\ncomplete separation between different users’ research activities. Similar concerns motivate open-source\nimplementations like OpenManus [193], which enables local deployment for sensitive research applications.\nSource Data Protection. Responsible implementation requires careful handling of source information.\nSystems like Flowith/OracleMode [77] implement controlled data access patterns that respect source restric-\ntions including authentication requirements and access limitations. These approaches enhance compliance\nwith source terms of service while ensuring comprehensive information access. Recent advancements include\nbenchmarking frameworks such as CI-Bench [56], which evaluates how well systems adhere to contextual\nnorms and privacy expectations.\n4.4.3\nExplainability and Transparency. The scientific context places particularly stringent requirements on\nexplanation quality. Mengaldo [170] argues that transparent explanation is not merely a feature but a\nfundamental requirement for scientific applications, emphasizing that black-box approaches fundamentally\ncontradict scientific methodology’s requirement for transparent reasoning and reproducible results. This\nperspective suggests that explanation capabilities may require different standards in scientific Deep Research\napplications compared to general AI systems. Trustworthy research systems must provide insight into their\nreasoning processes and sources:\nReasoning Trail Documentation. Advanced implementations maintain explicit documentation of the\nreasoning process. OpenAI/DeepResearch [197] includes comprehensive reasoning traces that expose the\nanalytical steps leading to specific conclusions. Similar capabilities are emerging in open-source alternatives\nlike mshumer/OpenDeepResearcher [249], which includes basic reasoning documentation to enhance result\ninterpretability.\nSource Attribution and Verification. Transparent systems provide clear attribution for all information\nand enable verification. Perplexity/DeepResearch [209] implements comprehensive citation practices with\nexplicit links to original sources, enabling direct verification of all claims. Similar approaches are employed\nby dzhng/deep-research [321], which maintains rigorous source tracking throughout the research process.\nThese implementation technologies and challenges highlight the complex engineering considerations\ninvolved in creating effective Deep Research systems. While commercial platforms benefit from extensive\ninfrastructure and specialized components, open-source implementations demonstrate that effective research\ncapabilities can be achieved through pragmatic approaches to the same fundamental challenges. The diversity\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n35\nof implementation strategies across the ecosystem reflects different priorities in balancing capability, efficiency,\nreliability, and accessibility.\n5\nEvaluation Methodologies and Benchmarks\nRigorous evaluation of Deep Research systems presents unique challenges due to their complex capabilities\nand diverse application contexts. This section examines established frameworks for assessment, identifies\nemerging evaluation standards, and analyzes the strengths and limitations of current approaches.\nMulti-dimensional Evaluation Framework for Deep Research Systems\nDeep Research\nEvaluation\nComprehensive Assessment\nFunctional Evaluation\nTask Completion\nWebArena\nMobileArena\nInformation Retrieval\nPrecision/Recall\nTREC benchmarks\nNon-Functional Evaluation\nPerformance\nResponse time\nResource utilization\nReliability\nError rates\nStability metrics\nCross-Domain Evaluation\nAcademic Research\nLitReview benchmark\nMethodEval\nBusiness Intelligence\nMarketInsight\nFinEval\nEmerging Evaluation\nInteractive Evaluation\nMulti-turn assessment\nFeedback incorporation\nMultimodal Research\nCross-modal integration\nVisual information\nHuman Assessment\nExpert evaluation\nUser experience studies\nSUS scores, interviews\nBenchmark Assessment\nStandardized tests\nMMLU, HLE, HotpotQA, GAIA\nComparative scoring\nFig. 8. Multi-dimensional Evaluation Framework for Deep Research Systems\n5.1\nFunctional Evaluation Frameworks\nFunctional evaluation assesses core capabilities essential to effective research performance.\n5.1.1\nTask Completion Capability Assessment. The ability to successfully complete research tasks represents\na fundamental evaluation dimension:\nTask Success Rate Metrics. Quantitative assessment of task completion provides objective performance\nmeasures. Standardized evaluation suites like WebArena [332] measure successful completion of web-based\n36\nXu et al.\nresearch tasks. For instance, AutoGLM [330] achieves a 55.2% success rate on VAB-WebArena-Lite (improving\nto 59.1% on a second attempt) and 96.2% on OpenTable evaluation tasks. Similarly, benchmarks like\nMobileArena evaluate successful completion of mobile interface tasks, where AutoGLM [330] demonstrates a\n36.2% success rate on AndroidLab and 89.7% on common tasks in popular Chinese apps [153]. Domain-\nspecific benchmarks, such as AutoPenBench for generative agents in penetration testing [85], provide further\ntargeted assessments. These benchmarks provide meaningful comparative metrics, though with limitations\nin representing real-world research complexity.\nThese benchmarks provide meaningful comparative metrics, though with limitations in representing real-\nworld research complexity. Perplexity/DeepResearch [209] explicitly highlights this distinction, noting that\nwhile benchmark performance provides comparative indicators, practical effectiveness depends significantly\non task characteristics and domain specifics.\nMulti-Attempt Resolution Rates. Effective research often involves iterative refinement with multiple\nattempts. Advanced evaluation frameworks incorporate multi-attempt metrics that assess system resilience\nand adaptability. AutoGLM [154] demonstrates significant performance improvement with second attempts\n(55.2% to 59.1% on WebArena-Lite), highlighting the importance of error recovery and adaptive strategies\nin practical research contexts.\nOpen-source frameworks like Agent-RL/ReSearch [2] explicitly emphasize iterative improvement through\nreinforcement learning approaches, demonstrating how evaluation methods that consider adaptability provide\nmore comprehensive assessment than single-attempt metrics alone.\n5.1.2\nInformation Retrieval Quality Evaluation. Effective information gathering forms the foundation of\nsuccessful research:\nSearch Effectiveness Metrics. Information retrieval quality significantly impacts overall research per-\nformance. Evaluation frameworks employ metrics including precision (relevance of retrieved informa-\ntion), recall (comprehensiveness of coverage), and F1 scores (balanced measure of both). Systems like\nPerplexity/DeepResearch [209] demonstrate particular strength in recall metrics, effectively identifying\ncomprehensive information across diverse sources.\nSpecialized information retrieval benchmarks like TREC [214] provide standardized assessment of search\neffectiveness. However, to the best of our knowledge, there is no specific evidence that the Deep Research\nsystems from OpenAI, Google, Perplexity, or any of the open-source projects listed in this survey have\nbeen formally evaluated on TREC benchmarks [214] . This limitation motivates domain-specific evaluation\napproaches that better reflect particular research requirements.\nSource Diversity Assessment. Comprehensive research requires balanced information from diverse per-\nspectives and sources. Advanced evaluation frameworks incorporate explicit diversity metrics that assess the\nbreadth of source utilization. Commercial systems like Gemini/DeepResearch [60] emphasize source diversity\nas a key performance indicator, while open implementations like dzhng/deep-research [321] incorporate\nspecific mechanisms to ensure balanced source consideration.\nEmerging evaluation approaches include explicit source spectra analysis that examines distribution\nacross domains, perspectives, and publication types. These methods provide more nuanced assessment of\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n37\ninformation gathering quality beyond simple relevance metrics, addressing concerns about potential bias in\nautomated research processes.\n5.1.3\nKnowledge Synthesis Accuracy Assessment. Transforming information into accurate, coherent insights\nrepresents a crucial capability:\nFactual Consistency Metrics. Reliable research requires accurate synthesis without introducing errors\nor misrepresentations. Evaluation frameworks employ fact verification techniques that compare generated\ncontent against source materials, identifying potential inaccuracies or unsupported claims. Systems like\ngrapeot/deep_research_agent [263] emphasize factual verification through explicit source linking, enabling\ndirect accuracy assessment. Benchmark suites like TruthfulQA [151] assess the truthfulness of language models\nunder challenging conditions. While specific accuracy figures for OpenAI/DeepResearch [197] and Perplexity/\nDeepResearch [209] on TruthfulQA [151] are not publicly available, these systems have demonstrated notable\nperformance on other rigorous benchmarks. For instance, OpenAI/DeepResearch [197] achieved a 26.6%\naccuracy [197] on Humanity’s Last Exam (HLE) [212]. Similarly, Perplexity/DeepResearch [209] attained a\n21.1% accuracy [209] on the same benchmark. The development of unified, fine-grained, and multi-dimensional\nevaluation frameworks for summarization further advances the ability to assess the quality of synthesized\ncontent from LLMs [137]. These metrics provide standardized comparison points, though with recognized\nlimitations in representing the complexity of real-world research synthesis.\nLogical Coherence Assessment. Effective research requires logically sound integration of information into\ncoherent analyses. Sophisticated evaluation approaches employ reasoning validity assessment that examines\nlogical structures and inference patterns in research outputs. This dimension proves particularly challenging\nfor automated assessment, often requiring expert human evaluation for reliable scoring.\nCommercial systems like OpenAI/DeepResearch [197] and Gemini/DeepResearch [60] emphasize logical\ncoherence in their evaluation frameworks, while open-source alternatives like mshumer/OpenDeepResearcher\n[249] incorporate simplified but useful logical consistency checks. These approaches highlight the importance\nof sound reasoning in effective research outputs beyond simple factual accuracy.\n5.2\nNon-Functional Evaluation Metrics\nBeyond core functionality, practical effectiveness depends on operational characteristics that impact usability\nand deployment.\n5.2.1\nPerformance and Efficiency Metrics. Operational efficiency significantly impacts practical utility:\nResponse Time Profiling. Timeliness represents a crucial dimension of research effectiveness. Evaluation\nframeworks incorporate response time metrics that measure completion duration across standardized tasks.\nCommercial systems demonstrate varying performance characteristics, with Perplexity/DeepResearch [209]\nachieving relatively quick response times (2-5 minutes for moderate tasks) while OpenAI/DeepResearch [197]\ntypically requires longer processing (5-10 minutes) for similar complexity.\nOpen-source implementations generally demonstrate longer response times, though with significant\nvariation based on implementation approaches and deployment environments. Systems like nickscamara/\n38\nXu et al.\nopen-deep-research [42] emphasize accessibility over performance optimization, while QwenLM/Qwen-Agent\n[224] incorporates specific optimizations to enhance response times within resource constraints.\nResource Utilization Assessment. Computational efficiency enables broader deployment and accessibility.\nComprehensive evaluation includes resource profiling that measures memory consumption, computational\nrequirements, and energy utilization across standardized workloads. Specialized benchmarks like Minerva\nassess programmable memory capabilities of language models, offering insights into their efficiency in\nhandling long-context information [300]. Commercial cloud-based systems obscure some of these metrics due\nto their managed infrastructure, though with operational costs providing indirect resource indicators. Open\nimplementations like Camel-AI/OWL [43] and AutoGLM-Research [330] provide more transparent resource\nprofiles, enabling direct assessment of deployment requirements and operational economics. These metrics\nhighlight significant variation in efficiency across the ecosystem, with implications for practical deployment\nscenarios and accessibility.\n5.2.2\nReliability and Stability Metrics. Consistent performance under diverse conditions ensures practical\nusability:\nError Rate Analysis. Reliability under challenging conditions significantly impacts user trust and adoption.\nRobust evaluation frameworks incorporate error rate metrics that measure failure frequency across diverse\nscenarios. Commercial systems generally demonstrate lower error rates compared to open-source alternatives,\nthough with remaining challenges in complex or novel research contexts.\nSpecialized reliability testing employs adversarial scenarios designed to trigger failure modes, providing\ninsight into system robustness. Systems like OpenAI/DeepResearch [197] and Agent-RL/ReSearch [2] incor-\nporate explicit error recovery mechanisms that enhance reliability under challenging conditions, highlighting\nthe importance of resilience in practical research applications.\nLong-Term Stability Assessment. Consistent performance over extended operation provides crucial deploy-\nment confidence. Comprehensive evaluation includes stability metrics that measure performance consistency\nacross extended sessions and repeated executions. This dimension proves particularly relevant for open-source\nimplementations that must operate in diverse deployment environments with varying infrastructure stability.\nSystems like Flowith/OracleMode [77] and TARS [39] emphasize operational stability through robust\nerror handling and recovery mechanisms, enabling reliable performance in production environments. These\ncapabilities highlight the importance of engineering quality beyond core algorithmic performance in practical\nresearch applications.\n5.2.3\nUser Experience and Usability Metrics. Effective interaction significantly impacts practical utility:\nInterface Usability Assessment. Intuitive interfaces enhance accessibility and effective utilization. Usability\nevaluation frameworks employ standardized usability metrics including System Usability Scale (SUS) [140]\nscores and task completion time measurements. Commercial systems typically demonstrate stronger usability\ncharacteristics, with Perplexity/DeepResearch [209] particularly emphasizing intuitive interaction for non-\ntechnical users. Open-source alternatives show greater variability, with implementations like HKUDS/Auto-\nDeep-Research [112] incorporating specific interface enhancements to improve accessibility.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n39\nUser studies provide more nuanced usability assessment beyond standardized metrics. Evaluations\nof systems like Manus [164] and Flowith/OracleMode [77] incorporate explicit user feedback to identify\ninteraction challenges and improvement opportunities. These approaches highlight the importance of human-\ncentered design in practical research applications beyond technical performance. Similarly, frameworks such\nas AdaptoML-UX [87] enable HCI researchers to employ automated ML pipelines without specialized expertise,\nfacilitating robust model development and customization.\nLearning Curve Assessment. Approachability for new users significantly impacts adoption and effective\nutilization. Comprehensive evaluation includes learning curve metrics that measure time-to-proficiency\nacross user segments with varying technical backgrounds. Commercial systems generally demonstrate gentler\nlearning curves, with Perplexity/DeepResearch [209] explicitly designed for accessibility to non-technical\nusers.\nOpen implementations show greater variability, with systems like n8n [183] requiring more technical\nexpertise for effective deployment and utilization. More accessible alternatives like nickscamara/open-\ndeep-research [42] incorporate simplified interfaces designed for broader accessibility, highlighting diverse\napproaches to the accessibility-sophistication balance across the ecosystem.\n5.3\nCross-Domain Evaluation Benchmarks\nStandardized benchmarks enable objective comparison across systems and domains.\n5.3.1\nAcademic Research Task Benchmarks. Specialized benchmarks assess capabilities relevant to scholarly\nresearch:\nLiterature Review Benchmarks. Comprehensive literature synthesis represents a fundamental academic\nresearch task requiring sophisticated information retrieval, critical analysis, and synthesis capabilities. To\nthe best of our knowledge, no benchmark suite is specifically designed to evaluate systems’ ability to identify\nrelevant literature, synthesize key findings, and highlight research gaps across scientific domains. We propose\nleveraging existing high-quality literature reviews published in Nature Reviews journals as gold standards.\nCitation networks from academic knowledge graphs—such as Microsoft Academic Graph, Semantic Scholar\nAcademic Graph, and Open Academic Graph—could provide complementary evaluation data by measuring\na system’s ability to traverse citation relationships and identify seminal works[1, 31].\nWhile direct literature review benchmarks remain underdeveloped, several indirect benchmarks offer\ninsight into related capabilities. OpenAI/DeepResearch [197] demonstrates leading performance, achieving\n26.6% accuracy on Humanity’s Last Exam (HLE) [212] and averaging 72.57% on the GAIA benchmark\n[172], reflecting strong performance in complex reasoning tasks essential for literature synthesis. Similarly,\nPerplexity/DeepResearch [209] achieves 21.1% accuracy on HLE [212] and 93.9% on SimpleQA [290],\nindicating robust factual retrieval capabilities.\nThese benchmarks include challenging cases requiring integration across multiple disciplines, identification\nof methodological limitations, and disambiguation of conflicting findings—all crucial for effective literature\nreview. Such tasks demonstrate the importance of sophisticated reasoning capabilities beyond simple\ninformation retrieval. While specific performance metrics for systems like Camel-AI/OWL [43] are not publicly\n40\nXu et al.\navailable, their specialized academic optimization suggests potential effectiveness in handling complex\nsynthesis tasks.\nMethodology Evaluation Benchmarks. Critical assessment of research methodology requires sophisticated\nanalytical capabilities. To the best of our knowledge, no benchmark is specifically designed for quantitative\nmethodology assessment of strengths and limitations. A comprehensive methodology evaluation benchmark\nwould need to assess a system’s ability to identify flaws in research design, statistical approaches, sampling\nmethods, and interpretive limitations across diverse disciplines. An effective benchmark might incorporate\nmulti-layered evaluation criteria including: reproducibility assessment, identification of confounding variables,\nappropriate statistical power analysis, and proper handling of uncertainty. Future benchmarks could utilize\nexpert-annotated corpora of research papers with methodological strengths and weaknesses clearly marked,\ncreating a gold standard against which systems’ analytical capabilities can be measured while minimizing\nbias through diverse evaluation metrics that reflect methodological best practices across different fields of\ninquiry.\nBeyond standard benchmarks, case study evaluations of complete AI scientist systems provide valuable\ninsights into current capabilities. Beel et al. [24] conduct a detailed assessment of Sakana’s AI Scientist\nfor autonomous research, examining whether current implementations represent genuine progress toward\n“Artificial Research Intelligence” or remain limited in fundamental ways, highlighting the gap between current\nbenchmarks and comprehensive research capability evaluation.\n5.3.2\nBusiness Analysis Task Benchmarks. Standardized evaluation for business intelligence applications:\nMarket Analysis Benchmarks. Strategic decision support necessitates a comprehensive understanding\nof market dynamics. Advanced AI systems, such as OpenAI/DeepResearch [197], are designed to analyze\ncompetitive landscapes, identify market trends, and generate strategic recommendations based on diverse\nbusiness information. OpenAI/DeepResearch has demonstrated significant capabilities in handling complex,\nmulti-domain data analysis tasks, providing detailed insights and personalized recommendations. Similarly,\nGoogle’s Gemini/DeepResearch [60] offers robust performance in processing extensive datasets, delivering\nconcise and factual reports efficiently.\nThese benchmarks include challenging scenarios requiring integration of quantitative financial data with\nqualitative market dynamics and regulatory considerations. Such tasks highlight the importance of both\nanalytical depth and domain knowledge, with systems like Manus [164] demonstrating strong performance\nthrough specialized business intelligence capabilities.\nFinancial Analysis Benchmarks. Economic assessment requires sophisticated quantitative reasoning\ncombined with contextual understanding of market dynamics. The FinEval benchmark [103] provides a\nstandardized framework for measuring systems’ capabilities in analyzing financial statements, evaluating\ninvestment opportunities, and assessing economic risk factors across diverse scenarios. To our knowledge, no\nDeep Research projects have yet published official FinEval benchmark results, though several commercial\ndemonstrations suggest strong performance in this domain. OpenAI/DeepResearch [197] has demonstrated\nparticular strength in quantitative financial analysis through its ability to process complex numerical\ndata while incorporating relevant market context. Meanwhile, open-source implementations show more\nvariable performance, though specialized systems like n8n [183] achieve competitive results through strategic\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n41\nintegration with financial data sources and analytical tools. These patterns highlight the critical importance\nof domain-specific integrations and data accessibility in financial analysis applications, extending beyond\ncore language model capabilities to create truly effective analytical systems.\n5.3.3\nGeneral Knowledge Management Benchmarks. Broad applicability assessment across general research\ndomains:\nFactual Research Benchmarks. Accurate information gathering forms the foundation of effective research.\nThe SimpleQA benchmark [290] evaluates language models’ ability to answer short, fact-seeking questions\nwith a single, indisputable answer. Perplexity/DeepResearch [209] demonstrates exceptional performance\non this benchmark, achieving an accuracy of 93.9% [209]. OpenAI’s Deep Research tool, integrated into\nChatGPT, offers comprehensive research capabilities, though specific accuracy metrics on SimpleQA [290] are\nnot publicly disclosed [197]. Similarly, Google’s Gemini/DeepResearch provides robust information synthesis\nfeatures, but detailed performance data on SimpleQA [290] is not available.\nThese metrics provide useful baseline performance indicators, though with recognized limitations in repre-\nsenting more complex research workflows. Comparative evaluation highlights the importance of information\nquality beyond simple factual recall, with sophisticated systems demonstrating more nuanced performance\nprofiles across complex tasks.\nHumanities and Social Sciences Benchmarks. Comprehensive evaluation requires assessment beyond STEM\ndomains. The MMLU benchmark [33] evaluates systems’ performance across humanities and social science\nresearch tasks, including historical analysis, ethical evaluation, and social trend identification. Performance\nshows greater variability compared to STEM-focused tasks, with generally lower accuracy across all systems\nwhile maintaining similar relative performance patterns. These benchmarks highlight remaining challenges\nin domains requiring nuanced contextual understanding and interpretive reasoning. Commercial systems\nmaintain performance leads, though with open alternatives like smolagents/open_deep_research [115]\ndemonstrating competitive capabilities in specific humanities domains through specialized component design.\n5.4\nEmerging Evaluation Approaches\nBeyond established benchmarks, novel evaluation methods address unique aspects of Deep Research perfor-\nmance.\nInteractive Evaluation Frameworks. Traditional static benchmarks often fail to capture the dynamic and\ninteractive nature of real-world research workflows. To address this gap, interactive evaluation frameworks\nhave been developed to assess AI systems’ abilities to iteratively refine research strategies through multiple\ninteraction rounds. Notably, QuestBench [141] is a novel benchmark which specifically assesses an AI system’s\nability to identify missing information and ask appropriate clarification questions, a crucial skill for real-world\nresearch scenarios where problems are often underspecified. To the best of our knowledge, no deep research\nsystem invested in this survey has yet been publicly evaluated using QuestBench. Nonetheless, these systems\nhave demonstrated strong performance in other interactive evaluations, highlighting their effectiveness in\nsupporting iterative research processes.\n42\nXu et al.\nMultimodal Research Evaluation. Comprehensive research increasingly involves diverse content modalities.\nAdvanced evaluation frameworks incorporate multimodal assessment that measures systems’ ability to\nintegrate information across text, images, data visualizations, and structured content. Commercial systems\ngenerally demonstrate stronger multimodal capabilities, with Gemini/DeepResearch [60] particularly excelling\nin image-inclusive research tasks.\nOpen implementations show emerging multimodal capabilities, with systems like Jina-AI/node-DeepResearch\n[121] incorporating specific components for multimodal content processing. These approaches highlight\nthe growing importance of cross-modal integration in practical research applications beyond text-centric\nevaluation.\nEthical and Bias Assessment. Responsible research requires careful attention to ethical considerations\nand potential biases. Comprehensive evaluation increasingly incorporates explicit assessment of ethical\nawareness, bias detection, and fairness in information processing. Commercial systems implement sophis-\nticated safeguards, with OpenAI/DeepResearch [197] incorporating explicit ethical guidelines and bias\nmitigation strategies. Open implementations show varied approaches to these considerations, with systems\nlike grapeot/deep_research_agent [263] emphasizing transparency in source selection and attribution.\nThese evaluation dimensions highlight the importance of responsibility beyond technical performance,\naddressing growing concerns about potential amplification of existing information biases through automated\nresearch systems. Ongoing development of standardized ethical evaluation frameworks represents an active\narea of research with significant implications for system design and deployment.\nThe diverse evaluation approaches outlined in this section highlight both the complexity of comprehensive\nassessment and the ongoing evolution of evaluation methodologies alongside system capabilities. While\nstandard benchmarks provide useful comparative metrics, practical effectiveness depends on alignment\nbetween system capabilities, evaluation criteria, and specific application requirements. This alignment\nrepresents a key consideration for both system developers and adopters seeking to integrate Deep Research\ncapabilities into practical workflows.\n5.5\nComparative Evaluation Methodology\nTo ensure systematic and consistent evaluation across diverse Deep Research systems, we have developed a\ncomprehensive evaluation framework. This section outlines our methodological approach, evaluation criteria\nselection, and application consistency across systems.\n5.5.1\nSystems Selection Criteria. Our evaluation encompasses various Deep Research systems selected based\non the following criteria:\n∙Functional Completeness: Systems must implement at least two of the three core dimensions of Deep\nResearch as defined in Section 1.1\n∙Public Documentation: Sufficient technical documentation must be available to enable meaningful\nanalysis\n∙Active Development: Systems must have demonstrated active development or usage within the past\n12 months\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n43\n∙Representational Balance: Selection ensures balanced representation of commercial, open-source,\ngeneral-purpose, and domain-specialized implementations\n5.5.2\nEvaluation Dimensions and Metrics Application. Our evaluation employs a consistent set of dimensions\nacross all systems, though the specific benchmarks within each dimension vary based on system focus and\navailable performance data. Table 15 presents the evaluation coverage across representative systems.\nTable 15. Evaluation Metrics Application Across Systems\nSystem\nFunctional\nPerformance\nEfficiency\nDomain-Specific\nUsability\nBenchmarks\nMetrics\nMetrics\nBenchmarks\nAssessment\nOpenAI/DeepResearch\nHLE, GAIA\nFactual accuracy\nResponse time\nAcademic citation\nUser interface\nGemini/DeepResearch\nMMLU\nOutput coherence\nCloud compute\nMarket analysis\nMobile support\nPerplexity/DeepResearch\nHLE, SimpleQA\nSource diversity\nResponse time\nLegal search\nMulti-device\nGrok3Beta\nMMLU\nSource verification\nCloud efficiency\nFinancial analysis\nVoice interface\nManus\nGAIA\nCross-domain\nAPI latency\nBusiness analysis\nDashboard\nAgent-RL/ReSearch\nHotpotQA\nPlanning efficiency\nLocal compute\nScientific research\nCLI interface\nAutoGLM-Research\nWebArena\nGUI navigation\nMobile efficiency\nDomain adaptation\nAccessibility\nn8n\nWorkflow\nAPI integration\nSelf-hosted\nEnterprise workflow\nNo-code design\n5.5.3\nData Collection Methods. Our evaluation data comes from four primary sources:\n(1) Published Benchmarks: Performance metrics reported in peer-reviewed literature or official system\ndocumentation\n(2) Technical Documentation Analysis: Capabilities and limitations outlined in official documentation,\nAPIs, and technical specifications\n(3) Repository Examination: Analysis of open-source code repositories for architectural patterns and\nimplementation approaches\n(4) Experimental Verification: Where inconsistencies exist, we conducted direct testing of publicly\navailable systems to verify capabilities\nWhen benchmark results are unavailable for specific systems, we indicate this gap explicitly rather than\nextrapolating performance. This approach ensures transparency regarding the limits of our comparative\nanalysis while maintaining the integrity of available evaluation data.\n5.5.4\nCross-System Comparison Challenges. Several methodological challenges exist in comparing Deep\nResearch systems:\n∙Benchmark Diversity: Different systems emphasize different benchmarks based on their focus areas\n∙Implementation Transparency: Commercial systems often provide limited details about internal\narchitectures\n∙Rapid Evolution: Systems undergo frequent updates, potentially rendering specific benchmark results\nobsolete\n∙Domain Specialization: Domain-specific systems excel on targeted benchmarks but may perform\npoorly on general evaluations\n44\nXu et al.\nWe address these challenges through qualitative architectural analysis alongside quantitative benchmarks,\nenabling meaningful comparison despite data limitations. Section 3.3 presents the resulting comparative anal-\nysis, highlighting both performance differentials and the limitations of direct comparison across heterogeneous\nimplementations.\n6\nApplications and Use Cases\nThe technical capabilities of Deep Research systems enable transformative applications across diverse\ndomains. This section examines implementation patterns, domain-specific adaptations, and representative\nuse cases that demonstrate the practical impact of these technologies.\nDeep Research Application Domains and Use Cases\nDeep Research\nSystems\nAcademic Research\nLiterature Review Synthesis\nOpenAI DR, Perplexity DR\nHypothesis Generation\nCamel-AI/OWL\nInterdisciplinary Research\nsmolagents/open_deep_research\nScientific Discovery\nData Analysis Patterns\nn8n, Gemini DR\nExperiment Design\nAgent-RL/ReSearch\nScientific Literature Integration\njina-ai/node-DeepResearch\nEducational Applications\nLearning Support, Content Development\nHKUDS/Auto-Deep-Research\nFinancial Analysis\nInvestment Research, Risk Assessment\nPerplexity DR, OpenAI DR\nBusiness Intelligence\nMarket Research\nGemini DR, n8n\nStrategic Decision Support\nManus, OpenAI DR\nPersonal Knowledge\nInformation Organization\nPerplexity DR, nickscamara\nPersonal Learning\nOpenManus\nDecision Support\nGemini DR, Agent-RL/ReSearch\nApplication Domains\nDomain\nUse Case\nFig. 9. Deep Research Application Domains and Use Cases\n6.1\nAcademic Research Applications\nDeep Research systems offer significant enhancements to scholarly research workflows.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n45\n6.1.1\nLiterature Review and Synthesis. Comprehensive literature analysis forms the foundation of effective\nresearch:\nSystematic Review Automation. Deep Research systems demonstrate particular effectiveness for system-\natic literature reviews requiring exhaustive coverage of existing research. Systems like Google’s Gemini/\nDeepResearch [60] can efficiently analyze thousands of research papers, a capability that has significant\nimplications for fields like biomedicine where the volume of literature makes comprehensive manual re-\nview increasingly challenging [289]. OpenAI/DeepResearch [197] has been successfully deployed for medical\nresearch reviews, analyzing thousands of publications to identify intervention efficacy patterns with sig-\nnificantly reduced human effort compared to traditional methods. Similar capabilities are evident in\nPerplexity/DeepResearch [209] and Gemini/DeepResearch [60], which enables rapid synthesis of research\nfindings across disciplinary boundaries. Generative AI frameworks integrating retrieval-augmented generation\nfurther automate systematic reviews by expanding user queries to retrieve relevant scholarly articles and\nreduce time and resource burdens [234].\nOpen-source implementations like dzhng/deep-research [321] have found adoption in academic settings\nwhere local deployment and customization are prioritized. Specialized scientific implementations like AI-\nResearcher [109] extend these capabilities with domain-specific optimizations for academic literature\nprocessing and analysis. These systems enable literature review automation with greater control over search\nscope and synthesis methods, particularly valuable for specialized research domains with unique requirements.\nImplementation patterns typically involve customization of search strategies, source weightings, and output\nformats to align with disciplinary conventions.\nResearch Gap Identification. Beyond simple synthesis, advanced systems effectively identify unexplored\nareas and research opportunities. Gemini/DeepResearch [60] has demonstrated this capability in inter-\ndisciplinary contexts, identifying connection opportunities between distinct research domains that might\notherwise remain undiscovered. This application leverages the system’s ability to process extensive literature\nacross fields while identifying patterns and absences in existing research coverage.\nOpen implementations like HKUDS/Auto-Deep-Research [112] incorporate specific mechanisms for gap\nanalysis, including explicit detection of methodological limitations and underexplored variables across\nresearch corpora. These capabilities highlight the potential for automated systems to not only synthesize\nexisting knowledge but actively contribute to research direction through systematic gap identification.\n6.1.2\nHypothesis Generation and Testing. AI-assisted hypothesis development enhances research creativity\nand validation:\nHypothesis Formulation Support. Deep Research systems effectively generate testable hypotheses based\non existing literature and theoretical frameworks. OpenAI/DeepResearch [197] provides explicit hypothesis\ngeneration capabilities, identifying potential causal relationships and testable predictions derived from\nliterature synthesis. These features enable researchers to explore broader possibility spaces than might be\npractical through manual review alone.\nSpecialized frameworks like Camel-AI/OWL [43] implement domain-specific hypothesis generation for\nscientific applications, incorporating field-specific constraints and validation criteria. These approaches\nhighlight how domain adaptation enhances the practical utility of hypothesis generation capabilities beyond\n46\nXu et al.\ngeneric formulation. Implementation patterns typically involve iterative refinement with researcher feedback\nto align generated hypotheses with specific research objectives.\nPreliminary Validation Assessment. Advanced systems support hypothesis validation through evidence\nassessment and methodological planning. Gemini/DeepResearch [60] enables preliminary hypothesis testing\nthrough automated data source identification, statistical power analysis, and potential confound identification.\nThese capabilities streamline the transition from hypothesis formulation to empirical testing, reducing manual\neffort in research design.\nOpen implementations like Agent-RL/ReSearch [2] incorporate specific validation planning components,\nguiding researchers through experimental design considerations based on hypothesis characteristics. These\napproaches demonstrate how Deep Research capabilities extend beyond information gathering to actively\nsupport the complete research workflow from conception through validation planning.\n6.1.3\nInterdisciplinary Research Support. Cross-domain integration represents a particular strength of auto-\nmated research systems:\nCross-Domain Knowledge Translation. Deep Research systems effectively bridge terminological and\nconceptual gaps between disciplines. Perplexity/DeepResearch [209] demonstrates this capability through\nexplicit concept mapping between fields, enabling researchers from diverse backgrounds to explore unfamiliar\ndomains with reduced onboarding barriers. This application leverages the system’s broad knowledge base to\nidentify conceptual parallels across disciplinary boundaries.\nOpen frameworks like smolagents/open_deep_research [115] implement specialized agents for disciplinary\ntranslation, with explicit focus on terminological mapping and concept alignment. These approaches highlight\nhow multi-agent architectures can effectively address the challenges of interdisciplinary communication\nthrough specialized component design[117].\nMethodology Transfer Facilitation. Advanced systems enable effective adaptation of research methods\nacross domains. OpenAI/DeepResearch [197] supports methodology transfer through explicit identification\nof adaptation requirements and implementation guidance when applying techniques from one field to\nanother. This capability accelerates methodological innovation by facilitating cross-pollination between\nresearch traditions. Implementation patterns typically involve specialized methodological components like\nthose in QwenLM/Qwen-Agent [224], which incorporates explicit methodology modeling to identify transfer\nopportunities and adaptation requirements. This is particularly relevant in fields like engineering, where AI\nis beginning to impact established design procedures for complex dynamical systems [67]. These approaches\ndemonstrate how Deep Research systems can actively contribute to methodological innovation beyond simple\ninformation retrieval and synthesis.\n6.2\nScientific Discovery Applications\nDeep Research technologies enable enhanced scientific investigation across disciplines.\n6.2.1\nData Analysis and Pattern Recognition. Automated analysis enhances insight extraction from complex\nscientific data:\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n47\nLarge-Scale Data Synthesis. Deep Research systems effectively integrate findings across extensive datasets\nto identify broader patterns. Gemini/DeepResearch [60] has been applied to climate science research,\nsynthesizing findings across hundreds of climate models and observational datasets to identify consistent\npatterns and outliers. This application leverages the system’s ability to process and integrate diverse\ndata formats while maintaining analytical coherence. Open implementations like n8n [183] enable similar\ncapabilities through workflow automation that coordinates specialized analytical tools across complex data\nprocessing pipelines. Furthermore, SqlCompose [161] enhances analytical workflows by automating SQL\nauthoring to reduce syntax barriers and improve efficiency in large-scale data operations, as demonstrated\nthrough enterprise deployment and user feedback. Systems like DataInquirer quantitatively measure workflow\npatterns and task execution consistency, revealing significant variations across practitioners while also\nassessing AI tool impacts on aligning novice approaches with expert practices [325]. AI assistants specifically\ndesigned for data wrangling tasks can provide semi-automated support in transforming and cleaning data\nthrough interactive recommendations, thereby enhancing workflow efficiency [211]. Other systems assist\ndomain experts in making sense of multi-modal personal tracking data through visualization and human-\nin-the-loop LLM agents [143]. Additionally, no-code machine-readable documentation frameworks support\nresponsible dataset evaluation by facilitating quality assessment and accuracy verification during large-scale\ndata synthesis [233]. These approaches demonstrate how tool integration capabilities extend analytical\nreach beyond the core language model’s native capabilities, particularly valuable for quantitative scientific\napplications.\nAnomaly Detection and Investigation. Advanced systems effectively identify unexpected patterns and\nfacilitate targeted investigation. OpenAI/DeepResearch [197] demonstrates this capability in pharmacological\ncontexts, identifying unexpected drug interaction patterns across clinical literature and proposing mechanistic\nexplanations for further investigation. This application combines pattern recognition with explanatory\nhypothesis generation to enhance scientific discovery.\nSpecialized tools like grapeot/deep_research_agent [263] implement focused anomaly detection capa-\nbilities, with particular emphasis on statistical outlier identification and contextual explanation. These\napproaches highlight how targeted optimization can enhance specific scientific workflows beyond general-\npurpose research capabilities[125].\n6.2.2\nExperiment Design and Simulation. AI assistance enhances experimental planning and virtual testing:\nExperimental Protocol Optimization. Deep Research systems support experimental design through com-\nprehensive protocol development and optimization. Gemini/DeepResearch [60] provides explicit protocol\ngeneration capabilities, incorporating existing methodological best practices while identifying potential\nconfounds and control strategies. These features streamline experimental planning while enhancing method-\nological rigor.\nOpen implementations like Agent-RL/ReSearch [2] incorporate specialized experimental design compo-\nnents with particular emphasis on statistical power optimization and confound control. These approaches\ndemonstrate how focused optimization can enhance specific scientific workflows through specialized compo-\nnent design targeting critical research phases.\n48\nXu et al.\nDespite these capabilities, significant gaps remain between current systems and truly autonomous scientific\ndiscovery. Yu et al. [314] identify critical missing elements in current AI research systems, particularly\nhighlighting limitations in open-ended exploration, creative hypothesis generation, and experimental design\noptimization that constrain their effectiveness in leading scientific discovery processes.\nTheoretical Model Testing. Advanced systems enable accelerated testing of theoretical models through\nsimulation and virtual experimentation. OpenAI/DeepResearch [197] supports this application through\nintegration with computational modeling tools, enabling rapid assessment of theoretical predictions against\nexisting evidence. This capability accelerates theory refinement by identifying empirical constraints and\nvalidation opportunities more efficiently than manual methods.\nImplementation patterns typically involve specialized tool integration like that found in Manus [164],\nwhich provides sophisticated orchestration of computational modeling and simulation tools within research\nworkflows. Systems like AgentLaboratory [237] further enhance these capabilities through specialized\nexperimental design components that generate statistically rigorous protocols based on research objectives\nand methodological best practices. These approaches highlight how tool integration capabilities significantly\nenhance scientific applications beyond the language model’s native capabilities.\n6.2.3\nScientific Literature Integration. Comprehensive knowledge integration enhances scientific understand-\ning:\nCross-Modal Scientific Content Analysis. Deep Research systems effectively integrate information across\ntext, data, and visualizations prevalent in scientific literature. Gemini/DeepResearch [60] demonstrates\nparticular strength in this application, extracting and synthesizing information from scientific figures, tables,\nand text into cohesive analyses. This capability enables more comprehensive literature utilization than\ntext-only approaches.\nOpen implementations like Jina-AI/node-DeepResearch [121] incorporate specialized components for\nmultimodal scientific content processing, enabling similar capabilities in customizable frameworks. These\napproaches highlight the growing importance of multimodal processing in scientific applications, reflecting\nthe diverse information formats prevalent in scientific communication.\nConflicting Evidence Resolution. Advanced systems help navigate contradictory findings common in\nscientific literature. Perplexity/DeepResearch [209] provides explicit conflict identification and resolution\nguidance, identifying methodological differences, contextual factors, and potential reconciliation approaches\nwhen faced with contradictory evidence. This capability enhances scientific understanding by providing\nstructured approaches to evidence integration rather than simple aggregation.\nImplementation patterns typically involve sophisticated evidence modeling like that found in HKUDS/Auto-\nDeep-Research [112], which implements explicit evidence weighting and confidence estimation mechanisms.\nThese approaches demonstrate how specialized components for scientific evidence handling enhance the\npractical utility of Deep Research systems in complex scientific contexts.\n6.2.4\nAutonomous Scientific Discovery. Fully autonomous research systems represent an emerging direction\nthat extends current Deep Research capabilities toward greater autonomy. Recent work in this area includes\nthe AI Scientist system [159] that implements an automated discovery loop with hypothesis generation,\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n49\nexperimentation, and theory revision capacities. Similarly, the Dolphin system [316] demonstrates how\nclosed-loop auto-research can integrate thinking, practice, and feedback mechanisms to implement systematic\nscientific discovery processes.\nThis evolution toward more autonomous operation represents a significant advancement beyond tradi-\ntional tool-based approaches, enabling continuous research cycles with minimal human intervention while\nmaintaining scientific rigor through structured validation processes. Systems like CycleResearcher [294]\nfurther enhance this approach by incorporating automated peer review mechanisms [150] that improve\noutput quality through systematic feedback loops mimicking scientific review processes.\nPractical implementation of these concepts appears in systems like AgentLaboratory [240], which demon-\nstrates how LLM agents can function as effective research assistants within structured laboratory environ-\nments. Complementing these approaches, the concept of self-maintainability (SeM) addresses critical gaps in\nlaboratory automation by enabling systems to autonomously adapt to disturbances and maintain operational\nreadiness [191]. In addition, strategies such as BOLAA [156] orchestrate multiple specialized agents by\nemploying a controller to manage communication among them, enhancing the resolution of complex tasks.\nMoreover, Automated Capability Discovery (ACD) [158] automates the evaluation of foundation models by\ndesignating one model as a scientist to propose open-ended tasks that systematically uncover unexpected\ncapabilities and failures. Similarly, SeqMate [178] utilizes large language models to automate RNA sequencing\ndata preparation and analysis, enabling user-friendly one-click analytics and report generation for biologists.\nThe FutureHouse Platform [253] broadens accessibility by delivering the first publicly available superintelli-\ngent AI agents for scientific discovery through web interfaces and APIs. These implementations highlight\nboth the significant potential and current limitations of autonomous scientific discovery systems, suggesting\nan evolutionary path toward increasingly capable research automation while maintaining appropriate human\noversight and validation.\n6.3\nBusiness Intelligence Applications\nDeep Research technologies enable enhanced strategic decision support in commercial contexts.\n6.3.1\nMarket Research and Competitive Analysis. Comprehensive market understanding supports strategic\nplanning:\nCompetitor Landscape Mapping. Deep Research systems effectively synthesize comprehensive competitive\nintelligence across diverse sources. Gemini/DeepResearch [60] enables detailed competitor analysis across\nfinancial disclosures, product announcements, market reception, and strategic positioning to identify com-\npetitive dynamics and market opportunities. This application leverages the system’s ability to integrate\ninformation across public and specialized business sources with current market context.\nOpen implementations like n8n [183] support similar capabilities through workflow automation that\nintegrates specialized business intelligence data sources. These approaches demonstrate how effective tool\nintegration can create sophisticated business intelligence applications by coordinating specialized components\nwithin consistent analytical frameworks.\nEmerging Trend Identification. Advanced systems effectively identify early-stage market trends and poten-\ntial disruptions. OpenAI/DeepResearch [197] demonstrates this capability through temporal pattern analysis\n50\nXu et al.\nacross industry publications, startup activity, and technology development indicators. This application\ncombines historical pattern recognition with current signal detection to anticipate market evolution with\ngreater lead time than manual methods alone.\nImplementation patterns typically involve specialized analytical components like those in Flowith/\nOracleMode [77], which incorporates explicit trend modeling and weak signal amplification techniques.\nThese approaches highlight how specialized optimization enhances business intelligence applications through\ncomponents targeting specific analytical requirements.\n6.3.2\nStrategic Decision Support. AI-enhanced analysis informs high-stakes business decisions:\nInvestment Opportunity Assessment. Deep Research systems support investment analysis through com-\nprehensive opportunity evaluation. Perplexity/DeepResearch [209] enables detailed investment analysis\nincorporating financial metrics, market positioning, competitive dynamics, and growth indicators within\nunified analytical frameworks. This application integrates quantitative financial assessment with qualitative\nmarket understanding to support more comprehensive investment evaluation.\nOpen frameworks like mshumer/OpenDeepResearcher [249] implement investment analysis components\nwith particular emphasis on structured evaluation frameworks and comprehensive source integration. These\napproaches demonstrate how domain-specific optimization enhances practical utility for specialized business\napplications beyond generic research capabilities.\nRisk Factor Identification. Advanced systems support risk management through comprehensive threat\nidentification and assessment. Gemini/DeepResearch [60] provides explicit risk analysis capabilities, identi-\nfying potential threats across regulatory, competitive, technological, and market dimensions with associated\nimpact and likelihood estimation. These features enable more comprehensive risk management than might\nbe practical through manual analysis alone.\nImplementation patterns typically involve specialized risk modeling components like those found in Manus\n[164], which incorporates explicit risk categorization and prioritization mechanisms. These approaches\nhighlight how targeted optimization enhances specific business workflows through specialized components\naddressing critical decision support requirements.\n6.3.3\nBusiness Process Optimization. Research-driven insights enhance operational effectiveness:\nBest Practice Identification. Deep Research systems effectively synthesize operational best practices across\nindustries and applications. OpenAI/DeepResearch [197] enables comprehensive process benchmarking against\nindustry standards and innovative approaches from adjacent sectors, identifying optimization opportunities\nthat might otherwise remain undiscovered. This application leverages the system’s broad knowledge base to\nfacilitate cross-industry learning and adaptation.\nOpen implementations like TARS [39] support similar capabilities through workflow analysis and recommen-\ndation components designed for business process optimization. These approaches demonstrate how domain\nadaptation enhances practical utility for specific business applications beyond general research capabilities.\nImplementation Planning Support. Advanced systems support process change through comprehensive\nimplementation guidance. Gemini/DeepResearch [60] provides detailed implementation planning incorporat-\ning change management considerations, resource requirements, and risk mitigation strategies derived from\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n51\nsimilar initiatives across industries. This capability accelerates organizational learning by leveraging broader\nimplementation experience than typically available within single organizations.\nImplementation patterns typically involve specialized planning components like those in QwenLM/Qwen-\nAgent [224], HuggingGPT[246], XAgent[202], Mastra[168],Letta[138] and SemanticKernel[174] which incor-\nporates explicit process modeling and change management frameworks. These approaches highlight how\ntargeted optimization enhances specific business workflows through specialized components addressing\ncritical implementation challenges.\n6.4\nFinancial Analysis Applications\nDeep Research technologies enable enhanced financial assessment and decision support.\n6.4.1\nInvestment Research and Due Diligence. AI-enhanced analysis supports investment decisions across\nasset classes:\nComprehensive Asset Evaluation. Deep Research systems enable detailed asset analysis across financial and\ncontextual dimensions. Perplexity/DeepResearch [209] supports investment research through integration of\nfinancial metrics, market positioning, competitive dynamics, and growth indicators within unified analytical\nframeworks. This application enhances investment decision quality through more comprehensive information\nintegration than typically practical through manual methods alone.\nOpen implementations like n8n [183] enable similar capabilities through workflow automation that\nintegrates specialized financial data sources and analytical tools. These approaches demonstrate how effective\ntool orchestration creates sophisticated financial applications by coordinating specialized components within\nconsistent analytical frameworks.\nManagement Quality Assessment. Advanced systems support leadership evaluation through comprehensive\nbackground analysis. OpenAI/DeepResearch [197] enables detailed management assessment incorporating\nhistorical performance, leadership approach, strategic consistency, and reputation across diverse sources. This\ncapability enhances investment evaluation by providing deeper leadership insights than typically available\nthrough standard financial analysis.\nImplementation patterns typically involve specialized entity analysis components like those found in\nManus [164], which incorporates explicit leadership evaluation frameworks. These approaches highlight how\ntargeted optimization enhances specific financial workflows through specialized components addressing\ncritical evaluation dimensions.\n6.4.2\nFinancial Trend Analysis. Pattern recognition across financial data informs strategic positioning:\nMulti-Factor Trend Identification. Deep Research systems effectively identify complex patterns across\nfinancial indicators and contextual factors. Gemini/DeepResearch [60] demonstrates this capability through\nintegrated analysis of market metrics, macroeconomic indicators, sector-specific factors, and relevant external\ntrends. This application enhances trend identification through more comprehensive factor integration than\ntypically practical through manual analysis alone.\nOpen frameworks like grapeot/deep_research_agent [263] implement specialized trend analysis compo-\nnents with particular emphasis on statistical pattern detection and causal factor identification. However,\n52\nXu et al.\nresearch indicates that the effectiveness of such AI systems may be limited in tasks requiring deep domain\nunderstanding, as their generated outputs can exhibit redundancy or inaccuracies [254]. These approaches\ndemonstrate how domain-specific optimization enhances practical utility for specialized financial applications\nbeyond generic analytical capabilities.\nScenario Development and Testing. Advanced systems support financial planning through structured\nscenario analysis. OpenAI/DeepResearch [197] enables detailed scenario development incorporating varied\nassumptions, historical precedents, and system dependencies with coherent projection across financial\nimpacts. This capability enhances strategic planning by facilitating more comprehensive scenario exploration\nthan typically practical through manual methods.\nImplementation patterns typically involve specialized scenario modeling components like those in\nAgent-RL/ReSearch [2], which incorporates explicit dependency modeling and consistency verification\nmechanisms. These approaches highlight how targeted optimization enhances specific financial workflows\nthrough specialized components addressing critical planning requirements.\n6.4.3\nRisk Assessment and Modeling. Comprehensive risk analysis informs financial decisions:\nMulti-Dimensional Risk Analysis. Deep Research systems enable integrated risk assessment across diverse\nrisk categories. Perplexity/DeepResearch [209] supports comprehensive risk evaluation incorporating\nmarket, credit, operational, regulatory, and systemic risk factors within unified analytical frameworks.\nThis application enhances risk management through more comprehensive factor integration than typically\npractical through compartmentalized analysis.\nOpen implementations like nickscamara/open-deep-research [42] implement risk analysis components\nwith particular emphasis on integrated factor assessment and interaction modeling. These approaches\ndemonstrate how domain adaptation enhances practical utility for specific financial applications beyond\ngeneral analytical capabilities. Evaluations such as RedCode-Exec[101] show that agents are less likely to\nreject executing technically buggy code, indicating high risks, which highlights the need for stringent safety\nevaluations for diverse code agents.\nStress Testing and Resilience Assessment. Advanced systems support financial stability through so-\nphisticated stress scenario analysis. Gemini/DeepResearch [60] provides detailed stress testing capabilities\nincorporating historical crisis patterns, theoretical risk models, and system dependency analysis to identify\npotential vulnerabilities. These features enable more comprehensive resilience assessment than might be\npractical through standardized stress testing alone.\nImplementation patterns typically involve specialized stress modeling components like those found in\nFlowith/OracleMode [77], which incorporates explicit extreme scenario generation and impact propagation\nmechanisms. These approaches highlight how targeted optimization enhances specific financial workflows\nthrough specialized components addressing critical stability assessment requirements.\n6.5\nEducational Applications\nDeep Research technologies enable enhanced learning and knowledge development. Educational approaches\nto research automation have shown particular promise in scientific education [236] and data science peda-\ngogy [274], with systems like DS-Agent automating machine learning workflows through case-based reasoning\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n53\nto reduce learners’ technical barriers [102], highlighting the dual role of these systems in both conducting\nresearch and developing research capabilities in human learners. Smart AI reading assistants are also being\ndeveloped to enhance reading comprehension through interactive support [266]. However, adoption challenges\nremain significant in educational contexts, where user resistance and ineffective system utilization can impede\nlearning progress, requiring strategies such as active support during initial use and clear communication\nof system capabilities [252]. Specifically in data science education, learners encounter challenges similar\nto those faced by data scientists when interacting with conversational AI systems, such as difficulties in\nformulating prompts for complex tasks and adapting generated code to local environments [57]. Structured\nempirical evaluations of LLMs for data science tasks, such as the work by Nathalia Nascimento et al. [185],\ndemonstrate their effectiveness in coding challenges and provide guidance for model selection in educational\ntools.\n6.5.1\nPersonalized Learning Support. AI-enhanced research supports individualized educational experiences:\nAdaptive Learning Path Development. Deep Research systems effectively generate customized learning\npathways based on individual interests and knowledge gaps. OpenAI/DeepResearch [197] enables detailed\nlearning plan development incorporating knowledge structure mapping, prerequisite relationships, and diverse\nlearning resources tailored to individual learning styles and objectives. This application enhances educational\neffectiveness through more personalized learning journeys than typically available through standardized\ncurricula.\nOpen implementations like OpenManus [193] implement personalized learning components with particular\nemphasis on interest-driven exploration and adaptive difficulty adjustment. These approaches demonstrate\nhow educational adaptation enhances practical utility beyond general research capabilities.\nComprehensive Question Answering. Advanced systems provide detailed explanations tailored to learner\ncontext and prior knowledge. Perplexity/DeepResearch [209] demonstrates this capability through multi-\nlevel explanations that adjust detail and terminology based on learner background, providing conceptual\nscaffolding appropriate to individual knowledge levels. This capability enhances learning effectiveness by\nproviding precisely targeted explanations rather than generic responses.\nImplementation patterns typically involve specialized educational components like those in HKUDS/\nAuto-Deep-Research [112], which incorporates explicit knowledge modeling and explanation generation\nmechanisms. These approaches highlight how targeted optimization enhances educational applications\nthrough specialized components addressing critical learning support requirements.\n6.5.2\nEducational Content Development. Research-driven content creation enhances learning materials:\nCurriculum Development Support. Deep Research systems effectively synthesize educational best practices\nand domain knowledge into coherent curricula. Gemini/DeepResearch [60] enables comprehensive curriculum\ndevelopment incorporating learning science principles, domain structure mapping, and diverse resource\nintegration. This application enhances educational design through more comprehensive knowledge integration\nthan typically practical for individual educators.\nOpen frameworks like smolagents/open_deep_research [115] implement curriculum development compo-\nnents with particular emphasis on learning progression modeling and resource alignment. These approaches\n54\nXu et al.\ndemonstrate how specialized adaptation enhances practical utility for educational applications beyond\ngeneric content generation.\nMulti-Modal Learning Material Creation. Advanced systems generate diverse educational content formats\ntailored to learning objectives. OpenAI/DeepResearch [197] supports creation of integrated learning materials\nincorporating explanatory text, conceptual visualizations, practical examples, and assessment activities\naligned with specific learning outcomes. This capability enhances educational effectiveness through more\ncomprehensive content development than typically practical through manual methods alone.\nImplementation patterns typically involve specialized content generation components like those in\nQwenLM/Qwen-Agent [224], which incorporates explicit learning objective modeling and multi-format content\ngeneration. These approaches highlight how targeted optimization enhances educational applications through\nspecialized components addressing diverse learning modalities.\n6.5.3\nAcademic Research Training. AI-assisted research skill development supports scholarly advancement:\nResearch Methodology Instruction. Deep Research systems effectively teach research methods through\nguided practice and feedback. Perplexity/DeepResearch [209] provides explicit methodology training,\ndemonstrating effective research processes while explaining rationale and providing structured feedback on\nlearner attempts. This application enhances research skill development through more interactive guidance\nthan typically available through traditional instruction.\nOpen implementations like Jina-AI/node-DeepResearch [121] support similar capabilities through re-\nsearch practice environments with explicit guidance and feedback mechanisms. These approaches demonstrate\nhow educational adaptation enhances practical utility for research training beyond simple information provi-\nsion.\nCritical Evaluation Skill Development. Maintaining critical thinking skills while leveraging AI research\nassistance presents unique educational challenges. Drosos et al. [71] demonstrate that carefully designed\n“provocations” can help restore critical thinking in AI-assisted knowledge work, suggesting important\neducational approaches for developing research skills that complement rather than rely entirely on AI\ncapabilities. Advanced systems support critical thinking through guided source evaluation and analytical\npractice. OpenAI/DeepResearch [197] enables critical evaluation training, demonstrating source assessment,\nevidence weighing, and analytical reasoning while guiding learners through similar processes. This capability\nenhances critical thinking development through structured practice with sophisticated feedback.\nImplementation patterns typically involve specialized educational components like those in grapeot/\ndeep_research_agent [263], which incorporates explicit critical thinking modeling and guided practice\nmechanisms. These approaches highlight how targeted optimization enhances educational applications\nthrough specialized components addressing crucial scholarly skill development.\n6.6\nPersonal Knowledge Management Applications\nDeep Research technologies enable enhanced individual information organization and utilization.\n6.6.1\nInformation Organization and Curation. AI-enhanced systems support personal knowledge development:\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n55\nPersonalized Knowledge Base Development. Deep Research systems effectively organize diverse information\ninto coherent personal knowledge structures. Perplexity/DeepResearch [209] supports knowledge base\ndevelopment through automated information organization, connection identification, and gap highlighting\ntailored to individual interests and objectives. This application enhances personal knowledge management\nthrough more sophisticated organization than typically practical through manual methods alone.\nOpen implementations like nickscamara/open-deep-research [42] implement knowledge organization\ncomponents with particular emphasis on personalized taxonomy development and relationship mapping.\nThese approaches demonstrate how individual adaptation enhances practical utility for personal applications\nbeyond generic information management.\nContent Summarization and Abstraction. Advanced systems transform complex information into accessi-\nble personal knowledge. OpenAI/DeepResearch [197] provides multi-level content abstraction capabilities,\ngenerating overview summaries, detailed analyses, and conceptual maps from complex source materials\ntailored to individual comprehension preferences. This capability enhances information accessibility by\nproviding precisely targeted representations rather than generic summaries.\nImplementation patterns typically involve specialized content processing components like those in\nNanobrowser [184], which incorporates explicit knowledge distillation and representation generation mecha-\nnisms. These approaches highlight how targeted optimization enhances personal knowledge applications\nthrough specialized components addressing individual information processing needs.\n6.6.2\nPersonal Learning and Development. Research-driven insights support individual growth:\nInterest-Driven Exploration. Deep Research systems effectively support curiosity-driven learning through\nguided exploration. Gemini/DeepResearch [60] enables interest-based knowledge discovery, identifying\nconnections, extensions, and practical applications related to individual curiosities. This application enhances\npersonal learning through more sophisticated guidance than typically available through standard search\nalone.\nOpen frameworks like OpenManus [193] implement exploration components with particular emphasis on\ninterest mapping and discovery facilitation. These approaches demonstrate how personalization enhances\npractical utility for individual learning beyond generic information retrieval.\nSkill Development Planning. Advanced systems support personal growth through comprehensive develop-\nment guidance. Perplexity/DeepResearch [209] provides detailed skill development planning, incorporating\nlearning resource identification, progression mapping, and practice guidance tailored to individual objectives\nand constraints. This capability enhances personal development through more comprehensive planning\nsupport than typically available through generic guidance.\nImplementation patterns typically involve specialized planning components like those in TARS [39], which\nincorporates explicit skill modeling and development path generation. These approaches highlight how\ntargeted optimization enhances personal growth applications through specialized components addressing\nindividual development needs.\n6.6.3\nDecision Support for Individual Users. Research-enhanced decision making improves personal outcomes:\n56\nXu et al.\nComplex Decision Analysis. Deep Research systems effectively support personal decisions through com-\nprehensive option evaluation. OpenAI/DeepResearch [197] enables detailed decision analysis, incorporating\nmultiple criteria, preference weighting, and consequence projection tailored to individual values and con-\nstraints. This application enhances decision quality through more sophisticated analysis than typically\npractical through manual methods alone.\nOpen implementations like Agent-RL/ReSearch [2] implement decision support components with par-\nticular emphasis on preference elicitation and consequence modeling. These approaches demonstrate how\npersonalization enhances practical utility for individual decision making beyond generic information provision.\nLife Planning and Optimization. Advanced systems support long-term planning through integrated life\ndomain analysis. Gemini/DeepResearch [60] provides comprehensive life planning support, integrating career,\nfinancial, health, and personal considerations within coherent planning frameworks tailored to individual\nvalues and objectives. This capability enhances life optimization through more integrated planning than\ntypically achievable through domain-specific approaches alone.\nImplementation patterns typically involve specialized planning components like those in Flowith/\nOracleMode [77], which incorporates explicit value modeling and multi-domain integration mechanisms.\nThese approaches highlight how targeted optimization enhances personal planning applications through\nspecialized components addressing holistic life considerations.\nThe diverse applications outlined in this section demonstrate the broad practical impact of Deep Research\ntechnologies across domains. While specific implementation approaches vary across commercial and open-\nsource ecosystems, common patterns emerge in domain adaptation, specialized component design, and\nintegration with existing workflows. These patterns highlight how technical capabilities translate into\npractical value through thoughtful application design aligned with domain-specific requirements and user\nneeds.\n7\nEthical Considerations and Limitations\nThe integration of Deep Research systems into knowledge workflows introduces significant ethical considera-\ntions and technical limitations that must be addressed for responsible deployment. This section examines\nkey challenges across four fundamental dimensions (see Figure 10): information integrity, privacy protection,\nsource attribution and intellectual property, and accessibility.\n7.1\nInformation Accuracy and Hallucination Concerns\nDeep Research systems face fundamental challenges in maintaining factual reliability despite their sophisti-\ncated capabilities.\n7.1.1\nFactual Verification Mechanisms. Recent studies have highlighted significant challenges in reliable\nuncertainty communication [55], with particular concerns for research contexts where uncertainty boundaries\nmay be unclear or contested. Some researchers have raised concerns about excessive reliance on AI-generated\ncontent in scholarly writing [27, 45, 104, 119, 146, 207, 282, 286, 324, 335], particularly when verification\nmechanisms are inadequate or bypassed. These limitations are further complicated by tendencies toward\nmisleading responses in conversation [113], presenting particular challenges for interactive research workflows\nwhere iterative refinement may inadvertently amplify initial inaccuracies. AI support systems designed for\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n57\nEthical Dimensions of Deep Research Systems\nResponsible Deep\nResearch Development\nBalancing Capability, Safety, Equity\nInformation Accuracy and Hallucination\nFactual Verification\nSource validation\nOpenAI DR, Perplexity DR\nHallucination Detection\nGrounding requirements\nGemini DR, grapeot\nQuality Control\nConfidence estimation, feedback\nPrivacy and Data Security\nUser Data Protection\nQuery isolation\nOpenAI DR, Gemini DR\nSensitive Information\nPII management\nPerplexity DR, TARS\nCompliance Frameworks\nRegional and local deployment\nSource Attribution and IP Issues\nCitation Generation\nAcademic formats\nOpenAI DR, Perplexity DR\nCopyright Considerations\nFair use boundaries\njina-ai, mshumer\nIntellectual Attribution\nSource transparency, licensing\nAccessibility and Digital Divide\nTechnology Access\nResource requirements\nCamel-AI/OWL\nUser Expertise\nTechnical knowledge\nOpenManus\nInclusive Design\nMultilingual, disability accommodation\nKey Ethical Considerations\nFig. 10. Ethical Dimensions of Deep Research Systems\nevidence-based expository writing tasks, such as literature reviews, offer frameworks to enhance verification\nthrough structured sensemaking over source documents [247]. Addressing these challenges requires technical\nadvancements in uncertainty representation, improvements in decision workflow design[107] and interface\ndesign improvements that effectively communicate confidence boundaries to research users[270].\nEnsuring information accuracy requires explicit verification strategies:\nSource Verification Approaches. Leading implementations incorporate explicit source validation mecha-\nnisms to enhance factual reliability. OpenAI/DeepResearch [197] implements multi-level verification that\nconfirms information across multiple independent sources before incorporation into research outputs, with\ndetailed guidelines outlined in their system documentation [196]. Similarly, Perplexity/DeepResearch [209]\nimplements automated fact-checking that independently verifies key claims against trusted reference sources\nbefore inclusion in final reports.\nOpen-source alternatives demonstrate varied approaches to verification. Systems like grapeot/deep_\nresearch_agent [263] emphasize explicit citation mechanisms that maintain direct links between claims\n58\nXu et al.\nand sources, enabling straightforward verification. More sophisticated implementations like HKUDS/Auto-\nDeep-Research [112] incorporate specialized verification modules that assess source credibility and content\nconsistency before information utilization.\nHallucination Detection and Prevention. Mitigating fabricated information represents a crucial challenge\nfor LLM-based research systems. Commercial implementations employ advanced hallucination reduction\ntechniques including strict grounding requirements and consistency verification. Gemini/DeepResearch [60]\nimplements explicit uncertainty modeling that distinguishes between confirmed information and speculative\nextensions, enhancing transparency when definitive answers cannot be provided. Emerging paradigms\nlike those proposed by Silver and Sutton [251] suggest a fundamental shift toward experience-driven\nlearning, potentially transforming how research systems acquire and refine capabilities through interaction\nwith information environments. Such approaches could enable more human-like research development\nthrough continuous improvement based on research experiences rather than static training alone, and could\nfundamentally mitigate hallucinations.\nOpen implementations demonstrate pragmatic approaches to hallucination reduction within more con-\nstrained technical environments. Systems like Agent-RL/ReSearch [2] employ preventative strategies including\nexplicit sourcing requirements and conservative synthesis guidelines that prioritize factual reliability over\ncomprehensive coverage. Complementary approaches like Mask-DPO [100] focus on generalizable fine-grained\nfactuality alignment, addressing a critical requirement for reliable research outputs. Recent work from\nthe GAIR NLP team on DeepResearcher [81] has advanced these capabilities through integrated neural\nverification and knowledge graph alignment techniques that significantly enhance factual reliability. These\napproaches highlight diverse strategies for addressing a fundamental challenge that impacts all LLM-based\nresearch systems.\n7.1.2\nUncertainty Communication Approaches. Transparent uncertainty representation enhances result inter-\npretation and appropriate utilization:\nConfidence Estimation Methods. Advanced systems implement explicit confidence assessment for research\nfindings and recommendations. OpenAI/DeepResearch [197] incorporates graduated confidence scoring that\nreflects evidence quality, consistency across sources, and reasoning reliability. This capability enhances result\ninterpretation by clearly distinguishing between well-supported conclusions and more speculative findings.\nOpen-source implementations demonstrate simplified but effective confidence communication approaches.\nSystems like mshumer/OpenDeepResearcher [249] incorporate basic confidence indicators that signal infor-\nmation reliability through explicit markers in research outputs. These approaches highlight the importance\nof transparent uncertainty communication regardless of implementation sophistication.\nEvidence Qualification Standards. Responsible systems clearly communicate limitations and contextual\nfactors affecting result interpretation. Commercial implementations like Perplexity/DeepResearch [209]\nincorporate explicit evidence qualification that highlights contextual limitations, conflicting viewpoints, and\ntemporal constraints affecting research findings. This practice enhances appropriate utilization by providing\nnecessary context for result interpretation.\nOpen-source alternatives demonstrate varied approaches to evidence qualification. Systems like dzhng/\ndeep-research [321] implement explicit limitation statements that identify key constraints affecting research\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n59\nreliability. More sophisticated implementations like Camel-AI/OWL [43] incorporate structured evidence\nmodels that represent both supporting and contradicting information within unified frameworks.\n7.1.3\nQuality Control Frameworks. Systematic approaches to quality assurance enhance overall reliability:\nPre-Release Verification Standards. Leading implementations employ comprehensive validation processes\nbefore result delivery. Gemini Deep Research implements structured quality verification including automated\nconsistency checking, source validation, and reasoning verification before providing research outputs. These\npractices enhance overall reliability through systematic error identification and correction.\nOpen-source implementations demonstrate more varied quality control approaches. Systems like nickscamara/\nopen-deep-research [42] incorporate simplified validation processes focusing on critical reliability factors\nincluding source verification and logical consistency. These approaches highlight how even basic quality\ncontrol mechanisms can significantly enhance research reliability.\nFeedback Integration Systems. Continuous improvement requires effective incorporation of accuracy\nfeedback. As Deep Research systems advance toward greater autonomy, broader safety considerations\nbecome increasingly important. Bengio et al. [26] highlight potential risks from superintelligent agents and\npropose approaches like “Scientist AI” that balance capability with safer development paths, emphasizing the\nimportance of integrated safety mechanisms in advanced research systems. Commercial systems implement\nsophisticated feedback integration including explicit accuracy reporting channels and systematic error pattern\nanalysis. OpenAI/DeepResearch [197] includes dedicated correction mechanisms that incorporate verified\naccuracy feedback into system improvements, creating virtuous improvement cycles.\nOpen implementations demonstrate more community-oriented feedback approaches. Systems like smolagents/\nopen_deep_research [115] incorporate collaborative improvement frameworks that enable distributed error\nidentification and correction through community contributions. These approaches highlight diverse strategies\nfor enhancing reliability through user engagement across implementation contexts.\n7.2\nPrivacy and Data Security\nResearch systems must carefully protect sensitive information throughout the research process.\n7.2.1\nUser Data Protection Mechanisms. Safeguarding user information requires comprehensive protection\nstrategies:\nQuery Isolation Practices. Leading implementations employ strict isolation between user research sessions.\nCommercial systems like OpenAI/DeepResearch [197] and Gemini/DeepResearch [60] implement compre-\nhensive tenant isolation that prevents information leakage between distinct users or organizations. These\npractices are particularly crucial for sensitive research applications in corporate or governmental contexts.\nOpen-source implementations demonstrate varied isolation approaches depending on deployment models.\nSystems designed for local deployment like OpenManus [193] enable complete isolation within organizational\nboundaries, enhancing privacy for sensitive applications. Cloud-dependent implementations typically in-\ncorporate more limited isolation mechanisms, highlighting deployment considerations for privacy-sensitive\napplications.\nData Minimization Strategies. Responsible systems limit sensitive data collection and retention. Commercial\nimplementations increasingly emphasize data minimization, collecting only information necessary for service\n60\nXu et al.\nprovision and applying appropriate retention limitations. These practices enhance privacy protection by\nreducing potential exposure of sensitive information through either security incidents or authorized access.\nOpen implementations demonstrate diverse approaches to data management. Systems like Nanobrowser\n[184] enable complete local control of browsing data, preventing external exposure of research activities.\nInfrastructure frameworks like Jina-AI/node-DeepResearch [121] provide flexible configuration options that\nenable deployment-specific privacy controls aligned with organizational requirements.\n7.2.2\nSensitive Information Handling. Special safeguards are required for particularly sensitive content\ncategories:\nPersonal Identifier Management. Advanced systems implement specific protections for personally identifiable\ninformation. Commercial implementations like Perplexity/DeepResearch [209] incorporate automatic\ndetection and redaction of personal identifiers from research outputs unless specifically relevant to research\nobjectives. These practices prevent inadvertent exposure of personal information through research activities.\nOpen implementations demonstrate more varied approaches to identifier management. Systems like TARS\n[39] incorporate basic identifier detection focused on common patterns like email addresses and phone\nnumbers. More sophisticated implementations like QwenLM/Qwen-Agent [224] provide configurable sensitivity\ncontrols that enable context-appropriate protection aligned with specific deployment requirements.\nProtected Category Safeguards. Responsible systems implement enhanced protections for specially regulated\ninformation categories. Commercial implementations increasingly incorporate specialized handling for\ninformation categories including health data, financial records, and other regulated content types. These\npractices enhance compliance with domain-specific regulatory requirements governing sensitive information.\nOpen-source alternatives demonstrate more varied regulatory alignment. Systems like n8n [183] provide\nspecialized workflow components for handling regulated data categories, enabling compliance-oriented\nimplementations in sensitive domains. These approaches highlight how specialized components can address\ndomain-specific regulatory requirements within flexible implementation frameworks.\n7.2.3\nCompliance with Regulatory Frameworks. Adherence to applicable regulations ensures legally appropri-\nate operation:\nJurisdictional Compliance Adaptation. Advanced systems implement regionally appropriate operational\nstandards. Commercial implementations increasingly incorporate jurisdiction-specific adaptations that align\nwith regional privacy regulations including GDPR, CCPA, and other frameworks. These practices enhance\nlegal compliance across diverse deployment environments with varying regulatory requirements.\nOpen implementations demonstrate more deployment-dependent compliance approaches. Systems designed\nfor flexible deployment like Flowith/OracleMode [77] provide configurable privacy controls that enable\nadaptation to specific regulatory environments. These approaches highlight the importance of adaptable\nprivacy frameworks that can address diverse compliance requirements across implementation contexts.\nTransparency and Control Mechanisms. Responsible systems provide appropriate visibility and user\nauthority over information processing. Emerging regulatory frameworks are increasingly focusing on AI\nagents with autonomous capabilities. Osogami [204] proposes that regulation of autonomous AI systems\nshould specifically consider action sequence patterns rather than individual actions in isolation, which has\nparticular implications for Deep Research systems that execute complex multi-step research workflows.\nCommercial implementations increasingly emphasize transparency through explicit processing disclosures\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n61\nand user control mechanisms aligned with regulatory requirements. These practices enhance both regulatory\ncompliance and user trust through appropriate information governance.\nOpen-source alternatives demonstrate varied transparency approaches. Systems like HKUDS/Auto-Deep-\nResearch [112] provide detailed logging of information access and processing activities, enabling appropriate\noversight and verification. These approaches highlight how transparent operation can enhance both compliance\nand trust across implementation contexts.\n7.3\nSource Attribution and Intellectual Property\nProper acknowledgment of information sources and respect for intellectual property rights are essential for\nethical information utilization.\n7.3.1\nCitation Generation and Verification. Accurate source attribution requires reliable citation mechanisms:\nAutomated Citation Systems. Advanced implementations incorporate sophisticated citation generation\nfor research outputs. Commercial systems like OpenAI/DeepResearch [197] and Perplexity/DeepResearch\n[209] implement automatic citation generation in standard academic formats, enhancing attribution quality\nand consistency. These capabilities support appropriate source acknowledgment without manual effort.\nOpen implementations demonstrate varied citation approaches. Systems like mshumer/OpenDeepResearcher\n[249] incorporate basic citation generation focused on fundamental bibliographic information. More sophisti-\ncated alternatives like dzhng/deep-research [321] provide enhanced citation capabilities including format\ncustomization and citation verification against reference databases.\nCitation Completeness Verification. Responsible systems ensure comprehensive attribution for all utilized\ninformation. Commercial implementations increasingly incorporate citation coverage verification that identi-\nfies unsupported claims requiring additional attribution. These practices enhance attribution reliability by\nensuring all significant claims maintain appropriate source connections.\nOpen-source alternatives demonstrate pragmatic approaches to attribution verification. Systems like\ngrapeot/deep_research_agent [263] implement explicit source-claim mapping that maintains clear relation-\nships between information and origins. These approaches highlight the importance of systematic attribution\nregardless of implementation sophistication.\n7.3.2\nIntellectual Attribution Challenges. Special attribution considerations apply to complex intellectual\ncontributions:\nIdea Attribution Practices. Research systems must appropriately acknowledge conceptual contributions\nbeyond factual information. Commercial implementations increasingly emphasize concept-level attribution\nthat acknowledges intellectual frameworks and theoretical approaches beyond simple facts. These practices\nenhance ethical information utilization by appropriately recognizing intellectual contributions.\nOpen implementations demonstrate varied idea attribution approaches. Systems like Camel-AI/OWL [43]\nincorporate explicit concept attribution that identifies theoretical frameworks and analytical approaches\nutilized in research outputs. These approaches highlight the importance of comprehensive attribution beyond\nbasic factual sources.\nSynthesized Knowledge Attribution. Attribution becomes particularly challenging for insights synthesized\nacross multiple sources. Advanced systems implement specialized attribution approaches for synthetic insights\n62\nXu et al.\nthat acknowledge multiple contributing sources while clearly identifying novel connections. These practices\nenhance attribution accuracy for the increasingly common scenario of cross-source synthesis.\nOpen-source alternatives demonstrate pragmatic approaches to synthesis attribution. Systems like Agent-\nRL/ReSearch [2] implement explicit synthesis markers that distinguish between directly sourced information\nand system-generated connections. These approaches highlight the importance of transparent derivation\neven when direct attribution becomes challenging.\n7.3.3\nCopyright and Fair Use Considerations. Research activities interact with copyright protections in\nmultiple dimensions:\nFair Use Evaluation Mechanisms. Research systems must navigate appropriate utilization of copyrighted\nmaterials. Commercial implementations increasingly incorporate fair use evaluation that considers purpose,\nnature, amount, and market impact when utilizing copyrighted content. These practices enhance legal\ncompliance while enabling appropriate information utilization for legitimate research purposes.\nOpen implementations demonstrate varied copyright approaches. Systems like Jina-AI/node-DeepResearch\n[121] incorporate basic copyright acknowledgment focusing on proper attribution, while more sophisticated al-\nternatives like Manus [164] provide enhanced copyright handling including content transformation assessment\nand restricted access mechanisms for sensitive materials.\nContent Licensing Compliance. Responsible systems respect diverse license terms applicable to utilized\ncontent. Advanced implementations increasingly incorporate license-aware processing that adapts information\nutilization based on specific terms governing particular sources. These practices enhance compliance with\nvaried license requirements across the information ecosystem.\nOpen implementations demonstrate more standardized licensing approaches. Systems like grapeot/deep_\nresearch_agent [263] incorporate simplified license categorization focusing on common frameworks including\ncreative commons and commercial restrictions. These approaches highlight pragmatic strategies for license\nnavigation within resource constraints.\n7.3.4\nOutput Intellectual Property Frameworks. Clear rights management for research outputs enhances\ndownstream utilization:\nOutput License Assignment. Complex questions arise regarding intellectual property in research outputs.\nCommercial systems increasingly implement explicit license assignment for generated content, clarifying\nintellectual property status for downstream utilization. These practices enhance transparency regarding\nusage rights for research outputs created through automated systems.\nOpen-source alternatives demonstrate varied approaches to output rights. Systems like OpenManus [193]\nincorporate explicit license designation for research outputs aligned with organizational policies and source\nrestrictions. These approaches highlight the importance of clear intellectual property frameworks regardless\nof implementation context.\nDerivative Work Management. Research systems must address whether outputs constitute derivative\nworks of source materials. Commercial systems increasingly implement derivative assessment frameworks\nthat evaluate the nature and extent of source transformation in research outputs. These practices enhance\nappropriate categorization for downstream utilization aligned with source licenses.\nOpen-source alternatives demonstrate varied derivation approaches. Systems such as QwenLM/Qwen-Agent\n[224] incorporate a basic transformation assessment focusing on content reorganization and analytical\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n63\naddition. These approaches highlight the importance of thoughtful derivative consideration regardless of\nimplementation sophistication.\n7.4\nAccessibility and Digital Divide\nEquitable access to research capabilities requires addressing systematic barriers.\n7.4.1\nTechnology Access Disparities. Recent work has highlighted both adoption barriers and opportunities\nfor making Deep Research systems more accessible. Bianchini et al. [29] and Tonghe Zhuang et al. [334]\nidentify specific organizational and individual factors affecting AI adoption in scientific research contexts,\nwith implications for Deep Research deployment. Accessibility-focused approaches like those presented by\nMowar et al. [179] demonstrate how AI coding assistants can be specifically designed to support accessible\ndevelopment practices, suggesting parallel opportunities for accessibility-centered Deep Research systems.\nExtending this, systems such as ResearchAgent [18] showcase how AI can lower barriers to scientific\ninnovation by enabling iterative refinement of research ideas through collaborative feedback mechanisms,\nthus democratizing access to complex ideation processes.\nResource requirements create potential exclusion for various user segments:\nComputational Requirement Considerations. Resource-intensive systems may exclude users without sub-\nstantial computing access. Commercial cloud-based implementations address this challenge through shared\ninfrastructure that reduces local requirements, though with associated cost barriers. Open-source alternatives\ndemonstrate varied resource profiles, with systems like Camel-AI/OWL [43] emphasizing efficiency to enable\nbroader deployment on limited hardware.\nCost Barrier Mitigation. Financial requirements create systematic access disparities across socioeco-\nnomic dimensions. Commercial implementations demonstrate varied pricing approaches, with systems like\nPerplexity/DeepResearch [209] offering limited free access alongside premium tiers. Open-source alter-\nnatives like HKUDS/Auto-Deep-Research [112] and nickscamara/open-deep-research [42] eliminate direct\ncost barriers while potentially introducing technical hurdles.\n7.4.2\nUser Expertise Requirements. Technical complexity creates additional access barriers beyond resource\nconsiderations:\nTechnical Expertise Dependencies. Complex system deployment and operation may exclude users without\nspecialized knowledge. Commercial implementations address this challenge through managed services that\neliminate deployment complexity, though with reduced customization flexibility. Open-source alternatives\ndemonstrate varied usability profiles, with systems like OpenManus [193] emphasizing simplified deployment\nto enhance accessibility despite local operation.\nDomain Knowledge Prerequisites. Effective research still requires contextual understanding for appropriate\nutilization. Both commercial and open-source implementations increasingly incorporate domain guidance\nthat assists users with limited background knowledge in specific research areas. These capabilities enhance\naccessibility by reducing domain expertise barriers to effective research utilization.\n7.4.3\nInclusivity and Universal Design Approaches. Deliberate inclusive design can address systematic access\nbarriers:\n64\nXu et al.\nLinguistic and Cultural Inclusivity. Language limitations create significant barriers for non-dominant\nlanguage communities. Commercial implementations increasingly offer multilingual capabilities, though with\npersistent quality disparities across languages. Open-source alternatives demonstrate varied language support,\nwith systems like Flowith/OracleMode [77] emphasizing extensible design that enables community-driven\nlanguage expansion beyond dominant languages.\nDisability Accommodation Approaches. Accessible design ensures appropriate access for users with diverse\nabilities. Commercial implementations increasingly incorporate accessibility features including screen reader\ncompatibility, keyboard navigation, and alternative format generation. Open-source alternatives demonstrate\nmore varied accessibility profiles, highlighting an area for continued community development to ensure\nequitable access across implementation contexts.\nThe ethical considerations explored in this section highlight the complex responsibilities associated with\nDeep Research technologies beyond technical performance. While current implementations demonstrate\nvarying approaches to these challenges across commercial and open-source ecosystems, consistent patterns\nemerge in the importance of factual verification, attribution quality, privacy protection, intellectual property\nrespect, and accessible design. Addressing these considerations represents a critical priority for responsible\ndevelopment and deployment of these increasingly influential research technologies.\n8\nFuture Research Directions\nThe rapidly evolving field of Deep Research presents numerous opportunities for technical advancement\nand application expansion. Recent work by Zheng et al. [329] proposes scaling deep research capabilities\nvia reinforcement learning in real-world environments, while Wu et al. [297] explore enhancing reasoning\ncapabilities of LLMs with tools specifically for deep research applications. The comprehensive framework for\nbuilding effective agents outlined by Anthropic [11] provides additional design principles that could inform\nfuture Deep Research systems. This section examines promising research directions (illustrated in Figure 11)\nthat could significantly enhance capabilities, address current limitations, and expand practical impact across\ndomains, focusing on four key areas: advanced reasoning architectures, multimodal integration, domain\nspecialization, and human-AI collaboration with standardization.\n8.1\nAdvanced Reasoning Architectures\nEnhanced reasoning capabilities represent a fundamental advancement opportunity for next-generation\nsystems.\n8.1.1\nContext Window Optimization and Management. The information-intensive nature of deep research\ntasks presents fundamental challenges for context window utilization:\nInformation Compression and Prioritization. Current systems struggle with context window exhaustion when\nprocessing extensive research materials. Future architectures could incorporate sophisticated compression\nmechanisms that maintain semantic content while reducing token consumption. Early steps in this direction\nappear in systems like OpenAI/DeepResearch [197], which implements basic summarization for lengthy\nsources. Recent work on academic paper review systems demonstrates how hierarchical processing of\nextended research content can maintain coherence while managing context limitations [333]. Semantic\nnavigation techniques offer complementary approaches by enabling efficient exploration of problem-solution\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n65\nResearch Directions for Deep Research Systems\nFuture of\nDeep Research\nAdvanced Reasoning Architectures\nMulti-Modal Deep Research\nDomain-Specific Optimization\nHuman-AI Collaboration Standards\nHybrid Symbolic-Neural Approaches\nNeuro-symbolic integration, knowledge graphs\nCausal Reasoning Enhancement\nCausal inference, intervention modeling\nUncertainty Representation\nMulti-dimensional uncertainty, Bayesian reasoning\nScientific Domain Adaptation\nField-specific models, scientific workflow integration\nLegal Regulatory Specialization\nLegal reasoning, regulatory compliance\nMedical Healthcare Research\nClinical evidence synthesis, personalization\nInteractive Research Workflows\nQuery refinement, exploration interfaces\nFramework Standardization\nCommon APIs, research protocols, interoperability\nJoint Knowledge Creation\nCollaborative writing, mixed-initiative research\nVisual Information Integration\nScientific imagery, visual evidence analysis\nMultimodal Source Analysis\nVideo content, audio content processing\nCross-Modal Reasoning\nConsistency verification, multimodal explanations\nFig. 11. Research Directions for Deep Research Systems\nspaces within constrained domains, optimizing context usage through input filtering while enhancing\ngeneration quality [238]. More advanced approaches could develop adaptive compression that preserves\ncrucial details while condencing secondary information based on query relevance.\nImplementation opportunities include developing hierarchical summarization techniques that maintain\nmulti-level representations of sources, implementing information relevance scoring that prioritizes context\nallocation to critical content, and designing dynamic context management that continuously optimizes\nwindow utilization throughout research workflows. These advances could significantly enhance information\nprocessing capabilities without requiring proportional increases in context length.\nExternal Memory Architectures. Beyond compression, architectural innovations could fundamentally\ntransform context window utilization. Future systems could implement sophisticated external memory\n66\nXu et al.\nframeworks that maintain rich information representations outside the primary context window, accessing\nthem through efficient retrieval mechanisms when needed. Systems like Camel-AI/OWL [43] demonstrate\nearly steps with basic retrieval-augmented generation, but more comprehensive approaches could enable\neffectively unlimited knowledge integration.\nResearch directions include developing differentiable retrieval mechanisms that seamlessly integrate\nexternal knowledge within reasoning flows, implementing structured memory hierarchies that organize\ninformation for efficient access, and designing memory-aware reasoning processes that explicitly consider\ninformation availability when planning analytical approaches. These architectures could fundamentally\naddress context limitations while enhancing reasoning transparency and reliability.\n8.1.2\nHybrid Symbolic-Neural Approaches. Integration of complementary reasoning paradigms offers signifi-\ncant potential:\nNeuro-Symbolic Integration. Current Deep Research systems rely primarily on neural approaches with\nlimited explicit reasoning structures. Future systems could integrate symbolic reasoning components that pro-\nvide formal logical capabilities alongside neural flexibility, enhancing both reliability and explainability. Early\nexamples of this direction appear in systems like Camel-AI/OWL [43], which incorporates structured knowledge\nrepresentation within primarily neural architectures. Future research could develop more sophisticated\nintegration approaches that leverage the complementary strengths of both paradigms.\nImplementation approaches might include explicit logical verification layers that validate neural-generated\nreasoning, hybrid architectures that select appropriate reasoning mechanisms based on task characteristics,\nor integrated systems that translate between symbolic and neural representations as needed throughout\ncomplex workflows. These approaches could address current challenges in reliability and consistency while\nmaintaining the flexibility and generalization capabilities of neural foundations.\nAdvanced Knowledge Graph Integration. While current systems already incorporate basic knowledge graph\ncapabilities, future approaches could implement more sophisticated integration with dynamic, contextually-\naware knowledge structures. Beyond the entity relationship modeling seen in systems like HKUDS/Auto-Deep-\nResearch [112], next-generation implementations could enable bidirectional updates where research findings\nautomatically refine and expand knowledge graphs while simultaneously leveraging them for reasoning. Such\napproaches could incorporate uncertainty representation within graph structures, probabilistic reasoning\nacross knowledge networks, and adaptive abstraction hierarchies that transform between detailed and\nhigh-level conceptual representations based on reasoning requirements. Research opportunities include\ndeveloping dynamic knowledge graph construction techniques that automatically build and refine structured\nrepresentations from unstructured sources, implementing graph-aware attention mechanisms that incorporate\nrelationship structures into neural reasoning, and designing hybrid querying approaches that combine graph\ntraversal with neural generation. These advances could enhance precision for complex reasoning tasks\nrequiring structured relationship understanding.\n8.1.3\nCausal Reasoning Enhancement. Moving beyond correlation to causal understanding represents a\ncrucial capability advancement:\nCausal Inference Mechanisms. Current systems excel at identifying correlations but struggle with robust\ncausal analysis. Future research could develop specialized causal reasoning components that systematically\nidentify potential causal relationships, evaluate evidence quality, and assess alternative explanations. Recent\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n67\nwork in healthcare research by Schuemie et al. [241] demonstrates the challenges of establishing confident\nobservational findings, highlighting the need for more sophisticated causal reasoning in research systems.\nEarly steps in this direction appear in systems like OpenAI/DeepResearch [197], which incorporates basic\ncausal language in relationship descriptions. Other research explores the use of AI to assist in mining\ncausality, for instance, by searching for instrumental variables in economic analysis [105]. More sophisticated\napproaches could enable reliable causal analysis across domains. Implementation opportunities include\ndeveloping causal graph construction techniques that explicitly model intervention effects and counterfactuals,\nimplementing causal uncertainty quantification that represents confidence in causal assertions, and designing\nspecialized prompt structures that guide causal reasoning through structured analytical patterns. These\nadvances could enhance research quality for domains where causal understanding is particularly crucial,\nincluding medicine, social sciences, and policy analysis.\nIntervention Modeling Techniques. Advanced causal understanding requires sophisticated intervention and\ncounterfactual reasoning capabilities. Future systems could incorporate explicit intervention modeling that\nsimulates potential actions and outcomes based on causal understanding, enhancing both explanatory and\npredictive capabilities. Early examples of this direction appear in systems like Agent-RL/ReSearch [2], which\nimplements basic intervention simulation within reinforcement learning frameworks. More comprehensive\napproaches could enable sophisticated what-if analysis across domains.\nResearch directions include developing counterfactual generation techniques that systematically explore\nalternative scenarios based on causal models, implementing intervention optimization algorithms that\nidentify high-leverage action opportunities, and designing domain-specific intervention templates that embed\nfield-specific causal knowledge for common analysis patterns. These advances could enhance practical utility\nfor decision support applications requiring sophisticated action planning and outcome prediction.\n8.1.4\nUncertainty Representation and Reasoning. Sophisticated uncertainty handling enhances both accuracy\nand trustworthiness:\nMulti-Dimensional Uncertainty Modeling. Current systems employ relatively simplistic uncertainty represen-\ntations that inadequately capture different uncertainty types. Future research could develop multi-dimensional\nuncertainty frameworks that separately represent epistemic uncertainty (knowledge limitations), aleatoric\nuncertainty (inherent randomness), and model uncertainty (representation limitations). Early steps in\nthis direction appear in systems like Perplexity/DeepResearch [209], which distinguishes between source\nuncertainty and integration uncertainty. More comprehensive approaches could enable more nuanced and\nreliable uncertainty communication.\nImplementation opportunities include developing uncertainty propagation mechanisms that track distinct\nuncertainty types throughout reasoning chains, implementing uncertainty visualization techniques that\neffectively communicate multi-dimensional uncertainty to users, and designing uncertainty-aware planning\nalgorithms that appropriately balance different uncertainty types in decision contexts. These advances could\nenhance both system reliability and appropriate user trust calibration.\nBayesian Reasoning Integration. Probabilistic reasoning frameworks offer principled approaches to un-\ncertainty handling and knowledge integration. Future systems could incorporate explicit Bayesian rea-\nsoning components that systematically update beliefs based on evidence strength and prior knowledge,\nenhancing both accuracy and explainability. Early examples of this direction appear in systems like\n68\nXu et al.\ngrapeot/deep_research_agent [263], which implements basic evidence weighting within research workflows.\nMore sophisticated integration could enable principled uncertainty handling across domains.\nResearch directions include developing scalable Bayesian inference techniques compatible with large-scale\nlanguage models, implementing belief update explanation mechanisms that communicate reasoning in\nunderstandable terms, and designing domain-specific prior models that incorporate field-specific background\nknowledge for common analysis patterns. These advances could enhance reasoning quality for domains with\ninherent uncertainty or limited evidence.\n8.2\nMulti-Modal Deep Research\nExpanding beyond text to incorporate diverse information modalities represents a significant advancement\nopportunity.\n8.2.1\nVisual Information Integration. Image understanding dramatically expands information access and\nanalysis capabilities:\nScientific Image Analysis. Current systems demonstrate limited capabilities for extracting and interpreting\nvisual scientific content. Future research could develop specialized visual understanding components for\nscientific images including graphs, diagrams, experimental images, and visualizations across domains. Early\nsteps in this direction appear in systems like Gemini/DeepResearch [60], which incorporates basic chart\nextraction capabilities. Frameworks such as ChartCitor [96] provide fine-grained bounding box citations to\nenhance explainability for complex chart understanding, improving user trust and productivity. Specialized\nmodels like LHRS-Bot [180] demonstrate sophisticated reasoning capabilities for remote sensing imagery by\nleveraging geographic information and multimodal learning. The development of large-scale, domain-specific\nmultimodal datasets for areas like entomology [272] and seafloor geology [188] is crucial for training more\ncapable models. More comprehensive approaches could enable sophisticated analysis of visual scientific\ncommunication. Implementation opportunities include developing specialized scientific visualization parsers\nthat extract quantitative data from diverse chart types, implementing diagram understanding systems\nthat interpret complex scientific illustrations across domains, and designing domain-specific visual analysis\ncomponents optimized for field-specific imagery like medical scans or astronomical observations. These\nadvances could dramatically expand information access beyond text-centric sources.\nVisual Evidence Integration. Effective research increasingly requires integration of visual evidence alongside\ntextual sources. Future systems could implement sophisticated multimodal reasoning that incorporates\nvisual evidence within comprehensive analytical frameworks, enabling true multimodal research synthesis.\nRecent analyses have identified multi-modal integration as a key missing capability in current AI research\nsystems [315], highlighting the critical importance of cross-modal reasoning for scientific applications. Early\nexamples of this direction appear in systems like Gemini/DeepResearch [60], which provides basic integration\nof image-derived information. More sophisticated approaches could enable balanced evidence integration\nacross modalities.\nResearch directions include developing evidence alignment techniques that match textual and visual\ninformation addressing common questions, implementing cross-modal consistency verification that identifies\nconflicts between textual claims and visual evidence, and designing multimodal synthesis mechanisms that\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n69\ngenerate integrated understanding across information types. These advances could enhance research quality\nfor domains with significant visual information components.\n8.2.2\nMultimodal Source Analysis. Comprehensive understanding requires integrated analysis across diverse\ninformation formats:\nVideo Content Processing. Video represents an increasingly important but currently underutilized infor-\nmation source. Future research could develop specialized video understanding components that extract and\ninterpret temporal visual information, including presentations, interviews, demonstrations, and dynamic\nprocesses. Initial steps in this direction are emerging in systems like OpenAI’s DALL-E 3, though not yet\nintegrated into Deep Research workflows. Comprehensive integration could enable access to the extensive\nknowledge embedded in video content.\nImplementation opportunities include developing lecture understanding systems that extract structured\nknowledge from educational videos, implementing process analysis components that interpret demonstrations\nand procedures, and designing integrated audio-visual analysis that combines visual information with spoken\ncontent for comprehensive understanding. These advances could expand information access to the rapidly\ngrowing corpus of video knowledge.\nAudio Content Integration. Spoken information in podcasts, lectures, interviews, and discussions represents\na valuable knowledge source. Future systems could incorporate sophisticated audio processing that extracts,\ninterprets, and integrates spoken information within research workflows. Early examples of speech process-\ning appear in transcription services, but comprehensive research integration remains limited. Advanced\napproaches could enable seamless incorporation of spoken knowledge alongside traditional text sources.\nResearch directions include developing speaker identification and attribution systems that maintain\nappropriate source tracking for spoken content, implementing domain-specific terminology extraction that\naccurately captures specialized vocabulary in varied acoustic conditions, and designing temporal alignment\ntechniques that connect spoken information with related textual or visual content. These advances could\nexpand information access while maintaining appropriate attribution and context.\n8.2.3\nCross-Modal Reasoning Techniques. Effective multimodal research requires specialized reasoning\napproaches across information types:\nMulti-Modal Chain of Thought Reasoning. Current reasoning processes typically operate primarily within\nsingle modalities despite handling diverse information types. Future systems could implement true multi-\nmodal reasoning chains that explicitly incorporate diverse information types throughout the analytical\nprocess, not just in final outputs. Early steps appear in systems like Gemini/DeepResearch [60], which\ndemonstrates basic visual incorporation in reasoning steps. More sophisticated approaches could enable\nreasoning flows that seamlessly transition between textual analysis, visual processing, numerical computation,\nand spatial reasoning based on task requirements.\nResearch opportunities include developing explicit multi-modal reasoning protocols that formalize in-\nformation transfer between modalities, implementing cross-modal verification techniques that leverage\ncomplementary information types throughout reasoning chains, and designing unified representation frame-\nworks that enable coherent reasoning across diverse information formats. These advances could significantly\nenhance reasoning quality for complex research tasks requiring integrated understanding across modalities,\n70\nXu et al.\nmoving beyond the current text-centric reasoning paradigms to more human-like analytical processes that\nnaturally leverage the most appropriate modality for each reasoning component.\nCross-Modal Consistency Verification. Integrating diverse information modalities introduces new consistency\nchallenges. Future research could develop specialized verification mechanisms that assess consistency across\ntextual, visual, numerical, and temporal information, enhancing overall reliability. Early steps in this direction\nappear in systems like Gemini/DeepResearch [60], which implements basic cross-format validation. More\nsophisticated approaches could enable reliable integration of increasingly diverse information types.\nImplementation opportunities include developing cross-modal contradiction detection algorithms that\nidentify conflicts between information expressed in different formats, implementing uncertainty alignment\ntechniques that reconcile confidence estimates across modalities, and designing multimodal fact verification\nsystems that leverage complementary evidence types for enhanced reliability. These advances could address\nemerging challenges in multimodal information integration.\nMultimodal Explanation Generation. Effective communication often requires coordinated explanation across\nmodalities. Future systems could generate truly multimodal research outputs that combine textual, visual,\nand interactive components to enhance understanding and persuasiveness. Early examples of this direction\nappear in systems like mshumer/OpenDeepResearcher [249], which implements basic report visualization.\nMore comprehensive approaches could enable sophisticated multimodal communication tailored to content\nrequirements.\nResearch directions include developing coordinated generation architectures that produce aligned content\nacross modalities, implementing adaptive format selection algorithms that identify optimal representation\nformats for different content types, and designing multimodal narrative structures that effectively combine\ndiverse formats within coherent explanatory frameworks. These advances could enhance communication\neffectiveness across application domains.\n8.3\nDomain-Specific Optimization\nTailored enhancement for particular fields offers significant performance improvements for specialized\napplications.\n8.3.1\nScientific Domain Adaptation. Scientific research presents unique requirements and opportunities for\nspecialization:\nField-Specific Model Adaptation. Current systems employ relatively general architectures across scientific\ndomains. Future research could develop specialized adaptation techniques that optimize performance for\nparticular scientific fields including physics, chemistry, biology, and others with distinct knowledge structures\nand reasoning patterns. Early steps in this direction appear in systems like AutoGLM-Research [330], which\nimplements domain-specific prompting. Domain-specialized research agents have demonstrated particular\npromise in physics [305], chemistry [6, 34, 50, 326], materials science [189], oceanography [28], geospatial\nanalysis [165], patent research [227, 285], and broader scientific discovery workflows [84]. These specialized\nimplementations highlight the value of domain adaptation beyond general research capabilities. More\ncomprehensive adaptation could enable significant performance improvements for scientific applications.\nImplementation approaches might include domain-specific fine-tuning regimes that emphasize field-relevant\nreasoning patterns, specialized architectural modifications that enhance performance for domain-characteristic\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n71\ntasks, or hybrid systems that incorporate symbolic components for domain-specific formal reasoning. These\napproaches could address current limitations in scientific reasoning while maintaining general capabilities for\ncross-domain research.\nScientific Workflow Integration. Effective scientific application requires integration with existing research\nmethodologies and tools. Future systems could implement specialized interfaces for scientific workflows\nincluding experimental design, data analysis, literature integration, and theory development. Early examples\nof this direction appear in systems like n8n [183], which provides workflow automation for data processing.\nPlatforms designed to support machine learning development in fundamental science also illustrate this\ntrend, enabling research in federated cloud environments [9]. More comprehensive integration could enable\nseamless incorporation within scientific research processes. Research assistant tools employing prompt-based\ntemplates demonstrate domain-agnostic support for tasks such as enhanced literature search queries and\npreliminary peer review, facilitating standardized assistance across diverse scientific fields [245]. User studies\nhighlight varying automation needs across DS/ML workflows, suggesting targeted rather than complete\nend-to-end automation aligns with researcher preferences [284]. Research opportunities include developing\nexperimental design assistants that generate and refine research protocols based on literature and objectives,\nimplementing integrated analysis pipelines that combine automated and human analytical components, and\ndesigning theory development frameworks that link empirical findings with formal theoretical structures.\nThese advances could enhance practical scientific impact beyond general information access [44, 288].\n8.3.2\nLegal and Regulatory Domain Specialization. Legal applications present distinct challenges requiring\nspecialized adaptation:\nLegal Reasoning Enhancement. Current systems struggle with the precision and structure of legal analysis.\nFuture research could develop specialized legal reasoning components that incorporate case-based reasoning,\nstatutory interpretation, and doctrinal analysis within coherent legal frameworks. Early steps in this direction\nappear in systems like OpenAI/DeepResearch [197], which incorporates basic legal language handling. More\ncomprehensive specialization could enable sophisticated legal applications across practice areas.\nImplementation opportunities include developing case analysis systems that extract and apply relevant\nprecedent principles, implementing statutory interpretation frameworks that apply established analytical\nmethodologies to legislative text, and designing multi-jurisdictional reasoning approaches that navigate\nconflicts of law across legal boundaries. These advances could enhance practical utility for legal research and\nanalysis applications.\nRegulatory Compliance Specialization. Compliance applications require comprehensive coverage with\nexceptional precision. Future systems could implement specialized compliance components that ensure\ncomplete regulatory coverage, systematic obligation identification, and reliable guidance across complex\nregulatory landscapes. Early examples of this direction appear in general information retrieval, but true\ncompliance optimization remains limited. Advanced approaches could enable reliable automation of currently\nlabor-intensive compliance processes.\nResearch directions include developing regulatory change tracking systems that monitor and interpret\nevolving requirements, implementing obligation extraction techniques that identify and classify compliance\nrequirements across regulatory texts, and designing responsibility mapping approaches that connect regulatory\n72\nXu et al.\nobligations with organizational functions and processes. These advances could enhance practical utility for\ncompliance-intensive industries facing complex regulatory environments.\n8.3.3\nMedical and Healthcare Research Support. Healthcare applications present unique requirements and\nethical considerations:\nClinical Evidence Synthesis. Medical applications require exceptional precision and comprehensive evidence\nintegration. Future research could develop specialized medical components that synthesize clinical evidence\nacross studies, guidelines, and practice observations while maintaining rigorous evaluation standards. Recent\nefforts such as Google’s co-scientist project [97] demonstrate the potential for AI to assist in scientific research\nincluding medical domains. Early steps in this direction appear in systems like Perplexity/DeepResearch\n[209], which implements enhanced citation for medical claims. More comprehensive specialization could\nenable reliable clinical decision support.\nImplementation approaches might include evidence grading systems that apply established frameworks like\nGRADE [21] to clinical research, meta-analysis components that systematically integrate quantitative findings\nacross studies, and guideline alignment techniques that map evidence to established clinical recommendations.\nThese advances could enhance practical utility for evidence-based medicine while maintaining appropriate\ncaution for this high-stakes domain.\nPatient-Specific Research Adaptation. Personalized medicine requires adapting general knowledge to\nindividual patient contexts. Future systems could implement specialized personalization components that\nadapt research findings based on patient characteristics, comorbidities, preferences, and other individual\nfactors. Early examples of this direction appear in basic filtering of contraindications, but comprehensive\npersonalization remains limited. Advanced approaches could enable truly personalized evidence synthesis for\nclinical applications.\nResearch opportunities include developing comorbidity reasoning systems that adjust recommendations\nbased on condition interactions, implementing preference integration frameworks that incorporate patient\nvalues in evidence synthesis, and designing personalized risk-benefit analysis approaches that quantify\nindividual trade-offs for treatment options. These advances could enhance clinical utility while respecting\nthe complexity of individual patient contexts.\n8.4\nHuman-AI Collaboration and Standardization\nEnhancing human-AI partnership and establishing common standards represent crucial directions for\npractical research impact and ecosystem development.\n8.4.1\nInteractive Research Workflows. Effective collaboration requires sophisticated interaction throughout\nthe research process:\nAdaptive Query Refinement. Current systems offer limited interaction during query formulation and\nrefinement. Future research could develop sophisticated refinement interfaces that collaboratively develop\nresearch questions through iterative clarification, expansion, and focusing based on initial results and user\nfeedback. Early steps in this direction appear in systems like HKUDS/Auto-Deep-Research [112], which\nimplements basic clarification dialogues, and benchmarks such as QuestBench [141], which evaluates\nAI systems’ ability to identify missing information and formulate appropriate clarification questions in\nunderspecified reasoning tasks. More comprehensive approaches could enable truly collaborative question\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n73\ndevelopment. Frameworks like AutoAgent [262] demonstrate how zero-code interfaces can enable non-\ntechnical users to effectively guide deep research processes through intuitive interaction patterns, while other\nsystems are exploring methods that go beyond standard retrieval-augmented generation to better handle\nquestion identification in real-time conversations [4]. Implementation opportunities include developing intent\nclarification systems that identify potential ambiguities and alternatives in research questions, implementing\nscope adjustment interfaces that dynamically expand or narrow research focus based on initial findings, and\ndesigning perspective diversification tools that suggest alternative viewpoints relevant to research objectives.\nThese advances could enhance research quality by improving question formulation through human-AI\ncollaboration.\nInteractive Exploration Interfaces. Current systems typically present relatively static research outputs.\nFuture research could develop sophisticated exploration interfaces that enable dynamic navigation, drilling\ndown, and expansion across research findings based on evolving interests. Early examples of this direction\nappear in systems like OpenManus [193], which provides basic exploration capabilities. Advanced approaches\ncould enable truly interactive research experiences tailored to discovery patterns.\nResearch directions include developing information visualization techniques specifically designed for\nresearch navigation, implementing adaptive detail management that expands or collapses content areas\nbased on user interest signals, and designing seamless source transition mechanisms that enable smooth\nmovement between synthesis and original sources. These advances could enhance discovery by enabling more\nexploratory and serendipitous research experiences.\n8.4.2\nExpertise Augmentation Models. Effective augmentation requires adaptation to user expertise and\nobjectives:\nExpertise-Adaptive Interaction. Current systems offer limited adaptation to user knowledge levels and\nexpertise. Future research could develop sophisticated adaptation mechanisms that tailor research approaches,\nexplanations, and outputs based on user domain knowledge and research sophistication. Early steps in\nthis direction appear in systems like Perplexity/DeepResearch [209], which implements basic terminology\nadjustment. More comprehensive adaptation could enable truly personalized research assistance aligned\nwith individual expertise.\nImplementation approaches might include expertise inference systems that dynamically assess user knowl-\nedge through interaction patterns, explanation adaptation mechanisms that adjust detail and terminology\nbased on expertise models, and knowledge gap identification tools that highlight potentially unfamiliar\nconcepts within research contexts. Furthermore, mechanisms that learn to strategically request expert\nassistance when encountering gaps exceeding autonomous capability - as formalized in the Learning to Yield\nand Request Control (YRC) coordination problem [66] - are crucial for optimizing intervention timing and\nresolution effectiveness. These advances could enhance research effectiveness across diverse user populations\nwith varying domain familiarity.\nComplementary Capability Design. Optimal augmentation leverages complementary human and AI\nstrengths. Future systems could implement specialized interfaces designed around capability complementarity,\nemphasizing AI contributions in information processing while prioritizing human judgment for subjective\nevaluation and contextual understanding. Early examples of this direction appear in systems like Agent-\n74\nXu et al.\nRL/ReSearch [2], which implements basic division of analytical responsibilities. More sophisticated approaches\ncould enable truly synergistic human-AI research partnerships.\nResearch opportunities include developing explanation components specifically designed to facilitate\nhuman judgment rather than replace it, implementing confidence signaling mechanisms that highlight areas\nparticularly requiring human evaluation, and designing interactive critique frameworks that enable efficient\nhuman feedback on system reasoning. Feng Xiong et al. [303] redefine the collaborative dynamics between\nhuman researchers and AI systems. These advances could enhance collaborative effectiveness by optimizing\naround natural capability distributions.\n8.4.3\nFramework Standardization Efforts. Common architectures enable modular development and component\ninteroperability:\nComponent Interface Standardization. Advanced implementations employ standardized interfaces be-\ntween major system components. The OpenAI/AgentsSDK [199] defines explicit interface standards for\nagent components, enabling modular development and component substitution. Emerging industry stan-\ndards like Anthropic’s Model Context Protocol (MCP) [12] provide standardized interaction frameworks\nfor large language models and tools, enabling consistent integration patterns across implementations.\nSimilarly, Google’s Agent2Agent Protocol (A2A) [90, 92] establishes standardized communication pat-\nterns between autonomous agents, facilitating reliable multi-agent coordination. Open-source alternatives\nlike smolagents/open_deep_research [115] implement comparable messaging protocols between agent\ncomponents, highlighting industry convergence toward standardized interaction patterns. Projects like\nOpen_deep_search [8] further demonstrate how standardized protocols enable effective collaboration be-\ntween specialized research agents. Integration of diverse API interactions, as explored in Toolllm [223],\nprovides additional standardization opportunities for managing external tool usage within research workflows.\nEvaluation Metric Standardization. Current evaluation practices vary widely across implementations.\nFuture research could establish standardized evaluation frameworks that enable consistent assessment and\ncomparison across systems and components. Early examples of this direction appear in benchmarks like\nHLE [212] and MMLU [33], but comprehensive standardization remains limited. Advanced standardization\ncould enable more efficient development through reliable quality signals and clear improvement metrics.\nResearch opportunities include developing standardized benchmark suites targeting specific research\ncapabilities, implementing common evaluation methodologies across research domains and applications,\nand designing multi-dimensional assessment frameworks that provide nuanced performance profiles beyond\nsimple accuracy metrics. These advances could enhance ecosystem quality by establishing clear standards\nand highlighting genuine improvements.\n8.4.4\nCross-Platform Research Protocols. Interoperability across diverse systems enhances collective capabili-\nties:\nResearch Result Exchange Formats. Current systems typically produce outputs in incompatible formats.\nFuture research could develop standardized exchange formats that enable seamless sharing of research\nresults across platforms and systems, enhancing collective capabilities. Early steps in this direction appear\nin basic document formats, but true research-specific standardization remains limited. Comprehensive\nstandardization could enable research workflows spanning multiple specialized systems.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n75\nImplementation opportunities include defining standard structures for research findings with appropriate\nattribution and confidence metadata, establishing common formats for evidence representation across systems,\nand developing shared schemas for research questions and objectives to enable distributed processing. These\nadvances could enhance capability through specialization and complementary system utilization.\nDistributed Research Coordination. Advanced interoperability enables coordinated research across systems\nwith complementary capabilities. Future research could develop sophisticated coordination frameworks that\nenable multi-system research workflows with appropriate task allocation, result integration, and process\nmanagement. Early examples of this direction appear in workflows like those enabled by n8n [183], but\ncomprehensive research-specific coordination remains limited. Advanced approaches could enable truly\ndistributed research ecosystems with specialized components addressing distinct process elements.\nResearch directions include developing distributed search coordination protocols that efficiently leverage\nspecialized search capabilities, implementing cross-system result verification techniques that ensure consis-\ntency across distributed findings, and designing efficient coordination protocols that minimize communication\noverhead in distributed research workflows. These advances could enhance collective capability through\nspecialization and parallelization across the ecosystem.\n8.4.5\nJoint Human-AI Knowledge Creation. Moving beyond information retrieval to collaborative insight\ngeneration:\nCollaborative Creation Environments. Advanced collaboration requires sophisticated content co-creation\ncapabilities. Future research could develop specialized collaborative environments that enable fluid transition\nbetween human and AI contributions within unified document development. Early steps in this direction\nappear in systems like mshumer/OpenDeepResearcher, which implements basic collaborative document gener-\nation. Advanced interfaces like those explored in Self-Explanation in Social AI Agents [23] demonstrate how\nexplanation capabilities can enhance collaborative research through more transparent reasoning processes.\nSimilarly, innovative interaction paradigms like AI-Instruments [232] show how prompts can be embodied\nas instruments to abstract and reflect commands as general-purpose tools, suggesting novel approaches\nto research interface design that enhance collaborative capabilities through intuitive interaction patterns.\nApproaches where AI agents learn to assist other agents by observing them also show promise for developing\nmore effective collaborative behaviors [127]. Effidit demonstrates comprehensive writing support through\nmultifunctional capabilities including text polishing and context-aware phrase refinement, extending collabo-\nrative editing beyond basic generation [248]. More comprehensive approaches could enable truly integrated\nco-creation experiences.\nImplementation opportunities include developing section suggestion systems that propose potential\ncontent expansions based on document context, implementing stylistic adaptation mechanisms that align\nAI-generated content with established document voice and approach, and incorporating implicit feedback\nmechanisms that interpret rejected suggestions as negative signals to refine outputs while preserving original\nintent [271], and designing seamless revision interfaces that enable efficient editing across human and AI\ncontributions, like iterative human-AI co-editing as demonstrated by REVISE [302] – a framework allowing\nwriters to dynamically modify summary segments through fill-in-the-middle generation. These advances\ncould enhance collaborative productivity by reducing friction in joint content development [116].\n76\nXu et al.\nMixed-Initiative Research Design. Sophisticated collaboration includes shared determination of research\ndirection and approach. Future systems could implement mixed-initiative frameworks that dynamically\nbalance direction setting between human preferences and AI-identified opportunities throughout the research\nprocess. Early examples of this direction appear in systems like smolagents/open_deep_research [115],\nwhich implements basic suggestion mechanisms. Advanced approaches could enable truly collaborative\nresearch planning with balanced initiative distribution.\nResearch directions include developing opportunity identification systems that highlight promising but\nunexplored research directions, implementing trade-off visualization techniques that communicate potential\nresearch path alternatives and implications, and designing preference elicitation frameworks that efficiently\ncapture evolving research priorities throughout the process, and integrating explainable reward function\nmechanisms to enhance human understanding of AI’s decision logic, thereby improving collaborative efficiency\nin value alignment contexts [239]. These advances could enhance discovery by combining human insight\nwith AI-identified opportunities in balanced partnerships.\nThe future research directions outlined in this section highlight both the significant potential for advance-\nment and the multi-faceted nature of Deep Research development. Progress will likely emerge through comple-\nmentary advances across reasoning architectures, multimodal capabilities, domain specialization, human-AI\ncollaboration, and ecosystem standardization. While commercial implementations like OpenAI/DeepResearch\n[197], Gemini/DeepResearch [60], and Perplexity/DeepResearch [209] will undoubtedly drive significant\ninnovation, open-source alternatives and academic research will play crucial roles in expanding the boundaries\nof what’s possible and ensuring broad participation in this rapidly evolving field.\n9\nConclusion\nThis survey has examined the rapidly evolving domain of Deep Research systems, tracing their development\nfrom initial implementations in 2023 through the sophisticated ecosystem emerging in 2025. Through\ncomprehensive analysis of commercial offerings like OpenAI/DeepResearch [197], Gemini/DeepResearch\n[60], and Perplexity/DeepResearch [209], alongside open-source alternatives including HKUDS/Auto-Deep-\nResearch [112], dzhng/deep-research [321], and numerous others, we have identified key technical patterns,\nimplementation approaches, and application opportunities that characterize this transformative technology\ndomain.\n9.1\nKey Findings and Contributions\nOur analysis reveals several fundamental insights about the current state and trajectory of Deep Research\nsystems:\nTechnical Architecture Patterns. Effective Deep Research implementations demonstrate consistent architec-\ntural patterns across foundation models, environmental interaction, task planning, and knowledge synthesis\ndimensions. Commercial implementations like OpenAI/DeepResearch [197] and Gemini/DeepResearch [60]\ntypically leverage proprietary foundation models with extensive context lengths and sophisticated reasoning\ncapabilities, while open-source alternatives like Camel-AI/OWL [43] and QwenLM/Qwen-Agent [224] demon-\nstrate how effective research capabilities can be achieved with more accessible models through specialized\noptimization.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n77\nEnvironmental interaction capabilities show greater diversity, with specialized tools like Nanobrowser\n[184] and dzhng/deep-research [321] demonstrating exceptional effectiveness in web navigation and content\nextraction, while comprehensive platforms like Manus [164] and AutoGLM-Search [330] offer broader interaction\ncapabilities across multiple environments. These patterns highlight both the value of specialization and the\nimportance of comprehensive environmental access for effective research.\nTask planning and execution approaches reveal similar diversity, with frameworks like OpenAI/AgentsSDK\n[199] and Flowith/OracleMode [77] providing sophisticated planning capabilities, while systems like Agent-\nRL/ReSearch [2] and smolagents/open_deep_research [115] emphasize execution reliability and collabora-\ntive approaches respectively. Knowledge synthesis capabilities demonstrate consistent emphasis on information\nevaluation, though with varied approaches to presentation and interactivity across implementations like\nHKUDS/Auto-Deep-Research [112] and mshumer/OpenDeepResearcher [249].\nImplementation Approach Distinctions. Our analysis highlights meaningful distinctions between commer-\ncial and open-source implementation approaches. Commercial platforms typically offer optimized performance,\nsophisticated interfaces, and comprehensive capabilities, though with associated costs and customization\nlimitations. Systems like OpenAI/DeepResearch [197] and Perplexity/DeepResearch [209] demonstrate\nexceptional performance on standard benchmarks, though with significant variation in application focus and\ninteraction models.\nOpen-source implementations demonstrate greater architectural diversity and customization flexibil-\nity, though typically with increased deployment complexity and more limited performance on stan-\ndard benchmarks. Projects like dzhng/deep-research [321], nickscamara/open-deep-research [42], and\nHKUDS/Auto-Deep-Research [112] offer complete research pipelines with varied architectural approaches,\nwhile specialized components like Jina-AI/node-DeepResearch [121] and Nanobrowser [184] enable cus-\ntomized workflows addressing specific requirements. Frameworks such as AutoChain [78] provide lightweight\ntools to simplify the creation and evaluation of custom generative agents, enabling rapid iteration for\nspecialized applications.\nThese distinctions highlight complementary roles within the ecosystem, with commercial implementations\noffering accessibility and performance for general users, while open-source alternatives enable customization,\ncontrol, and potentially lower operational costs for specialized applications and high-volume usage. This\ndiversity enhances overall ecosystem health through competition, specialization, and diverse innovation\npaths.\nApplication Domain Adaptations. Our examination of application patterns reveals meaningful adaptations\nacross domains including academic research[118, 273, 276], scientific discovery[6, 10, 25, 47, 79, 83, 98, 99,\n110, 129, 130, 135, 155, 166, 169, 218, 255, 258, 264, 269, 310, 312, 322, 327], business intelligence[187],\nfinancial analysis, education[14, 215, 219, 317], and personal knowledge management[136, 336]. Academic\napplications exemplified by systems like OpenAI/DeepResearch [197] and Camel-AI/OWL [43] demonstrate\nparticular emphasis on comprehensive literature coverage, methodological understanding, and citation\nquality. Scientific implementations like Gemini/DeepResearch [60] and Agent-RL/ReSearch [2] emphasize\nexperimental design, data analysis, and theory development capabilities.\nBusiness applications leveraging systems like Manus [164] and n8n [183] show stronger focus on information\ncurrency, competitive analysis, and actionable insight generation. Educational implementations demonstrate\n78\nXu et al.\nadaptations for learning support, content development, and research skill training across systems like\nPerplexity/DeepResearch [209] and OpenManus [193]. These patterns highlight how general deep research\ncapabilities translate into domain value through specialized adaptation addressing field-specific requirements\nand workflows.\nEthical Consideration Approaches. Our analysis reveals both common patterns and implementation diver-\nsity in addressing crucial ethical dimensions including information accuracy, privacy protection, intellectual\nproperty respect, and accessibility. Commercial implementations typically demonstrate sophisticated ap-\nproaches to factual verification, with systems like OpenAI/DeepResearch [197] and Perplexity/DeepResearch\n[209] implementing multi-level verification and explicit attribution, while open-source alternatives like\ngrapeot/deep_research_agent [263] and HKUDS/Auto-Deep-Research [112] demonstrate pragmatic ap-\nproaches within more constrained technical environments.\nPrivacy protection shows similar patterns, with commercial systems implementing comprehensive safe-\nguards appropriate to their cloud-based operation, while open-source alternatives like OpenManus [193]\nemphasize local deployment for sensitive applications. Attribution and intellectual property approaches\ndemonstrate consistent emphasis on source transparency and appropriate utilization boundaries, though\nwith varied implementation sophistication across the ecosystem.\nThese patterns highlight both shared ethical priorities across the ecosystem and implementation diversity\nreflecting different technical constraints, deployment models, and user requirements. This diversity represents\na strength in addressing multi-faceted ethical challenges through complementary approaches and continuous\ninnovation.\n9.2\nLimitations and Outlook\nWhile this survey provides comprehensive analysis of current Deep Research systems and emerging trends,\nseveral limitations warrant acknowledgment:\nRapidly Evolving Landscape. The accelerating pace of development in this domain presents inherent\nchallenges for comprehensive analysis. New systems and capabilities continue to emerge, with commercial\nofferings like OpenAI/DeepResearch [197], Gemini/DeepResearch [60], and Perplexity/DeepResearch [209]\nreceiving frequent updates, while the open-source ecosystem continuously expands through new projects\nand enhancements to existing frameworks like dzhng/deep-research [321] and HKUDS/Auto-Deep-Research\n[112].\nThis survey captures the state of the art as of early 2025, but both technical capabilities and implementation\napproaches will continue to evolve rapidly. The classification framework and analysis methodology provided\nhere offer a structural foundation for continued assessment as the field progresses through subsequent\ndevelopment phases.\nImplementation Detail Limitations. Comprehensive technical analysis faces challenges due to limited\nimplementation transparency, particularly for commercial systems. While open-source implementations\nlike nickscamara/open-deep-research [42] and Agent-RL/ReSearch [2] enable detailed architectural exam-\nination, commercial systems like OpenAI/DeepResearch [197] and Gemini/DeepResearch [60] reveal limited\ninternal details, restricting comprehensive comparative analysis of certain technical dimensions.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n79\nOur approach addresses this limitation through behavioral analysis, publicly available documentation\nexamination, and consistent evaluation across standardized benchmarks and qualitative assessment frame-\nworks. These methods enable meaningful comparison despite transparency variations, though complete\narchitectural analysis remains challenging for proprietary implementations.\nApplication Impact Assessment. Evaluating real-world impact presents persistent challenges given the\nearly deployment stage of many Deep Research systems. While initial applications demonstrate promis-\ning capabilities across domains including academic research[17, 208, 225, 292], business intelligence, and\neducation[14, 215, 317], a comprehensive long-term impact assessment requires extended observation beyond\nthe scope of this survey. Potential transformative effects on research methodologies, knowledge work, and\ninformation access patterns remain partially speculative despite encouraging early indications.\nFuture research should incorporate longitudinal analysis of deployment patterns, usage evolution, and\norganizational integration to assess realized impact beyond technical capabilities and early applications.\nSuch analysis would complement the technical and architectural focus of the current survey with valuable\nperspectives on practical significance and societal implications.\n9.3\nBroader Implications\nBeyond specific findings, this survey highlights several broader implications for the future of knowledge work\nand information access:\nResearch Methodology Transformation. Deep Research systems demonstrate potential to fundamentally\ntransform research methodologies across domains. The comprehensive information access, advanced reasoning\ncapabilities, and efficient knowledge synthesis demonstrated by systems like OpenAI/DeepResearch [197],\nGemini/DeepResearch [60], and their open-source alternatives suggest significant opportunities to accelerate\ndiscovery, enhance comprehensiveness, and enable novel cross-domain connections beyond traditional research\napproaches.\nRather than simply automating existing processes, these systems enable fundamentally new research\napproaches leveraging capabilities exceeding human information processing in scale while complementing\nhuman insight, creativity, and contextual understanding. This complementarity suggests evolution toward\ncollaborative research models rather than replacement of human researchers, with significant potential\nfor productivity enhancement and discovery acceleration. However, Ashktorab et al. [15] highlight that in\nhuman-AI collaboration, users may exhibit overreliance behaviors, appending AI-generated responses even\nwhen conflicting, which can compromise data quality.\nKnowledge Access Democratization. The emergence of accessible Deep Research implementations across\ncommercial and open-source ecosystems demonstrates potential for broader knowledge democratization.\nSystems like Perplexity/DeepResearch [209] with free access tiers and open-source alternatives like\nnickscamara/open-deep-research [42] and HKUDS/Auto-Deep-Research [112] enable sophisticated research\ncapabilities previously requiring specialized expertise and substantial resources, potentially reducing barriers\nto high-quality information access and analysis.\nThis democratization carries significant implications for education, entrepreneurship, civic participation,\nand individual knowledge development. While accessibility challenges remain, particularly regarding technical\n80\nXu et al.\nexpertise requirements and computational resources, the overall trajectory suggests broadening access to\nadvanced research capabilities with potential positive impacts on knowledge equity across society.\nCollective Intelligence Enhancement. Beyond individual applications, Deep Research systems demonstrate\npotential for collective intelligence enhancement through improved knowledge integration, insight sharing, and\ncollaborative discovery. The capabilities demonstrated by systems like Manus [164], Flowith/OracleMode [77],\nand smolagents/open_deep_research [115] suggest opportunities for enhanced knowledge synthesis across\norganizational and disciplinary boundaries, potentially addressing fragmentation challenges in increasingly\ncomplex knowledge domains.\nRather than viewing these systems as isolated tools, their integration into collaborative knowledge\necosystems highlights potential for systemic enhancement of collective sense-making, evidence-based decision\nmaking, and shared understanding development. This perspective emphasizes the social and organizational\ndimensions of Deep Research impact beyond technical capabilities and individual productivity enhancement.\n9.4\nFinal Thoughts\nThe rapid emergence and evolution of Deep Research systems represent a significant advancement in the\napplication of artificial intelligence to knowledge discovery and utilization. While technical implementations\nwill continue to evolve and specific systems will emerge and recede, the fundamental capability shift enabled\nby these technologies appears likely to persist and expand.\nThe diverse ecosystem spanning commercial platforms like OpenAI/DeepResearch [197], Gemini/DeepResearch\n[60], and Perplexity/DeepResearch [209], alongside open-source alternatives like dzhng/deep-research\n[321], HKUDS/Auto-Deep-Research [112], and numerous specialized components, demonstrates innovation\nacross multiple technical dimensions, implementation approaches, and application domains. This diversity\nenhances overall ecosystem health through competition, specialization, and complementary development\ntrajectories.\nAs research continues across advanced reasoning architectures, multimodal capabilities, domain specializa-\ntion, human-AI collaboration, and ecosystem standardization, we anticipate continued rapid advancement\nbuilding on the foundation established by current implementations. This evolution will likely yield increas-\ningly sophisticated research capabilities with significant implications for knowledge work across domains,\npotentially transforming how information is discovered, validated, synthesized, and utilized throughout\nsociety.\nThe responsible development of these powerful capabilities requires continued attention to ethical consid-\nerations including information accuracy, privacy protection, intellectual property respect, and accessibility.\nBy addressing these considerations alongside technical advancement, the Deep Research ecosystem can fulfill\nits potential for positive impact on knowledge discovery and utilization while minimizing potential harms or\nmisuse.\nIn conclusion, Deep Research represents both a fascinating technical domain for continued research and a\npotentially transformative capability for practical knowledge work across society. The frameworks, analysis,\nand directions presented in this survey provide a foundation for continued examination of this rapidly\nevolving field with significant implications for the future of information access, knowledge synthesis, and\ndiscovery processes.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n81\nReferences\n[1] Adilzhan Adilkhanov, Amir Yelenov, Assylkhan Seitzhanov, Ayan Mazhitov, Azamat Abdikarimov, Danissa Sandyk-\nbayeva, Daryn Kenzhebek, Dinmukhammed Mukashev, Ilyas Umurbekov, Jabrail Chumakov, Kamila Spanova, Karina\nBurunchina, Madina Yergibay, Margulan Issa, Moldir Zabirova, Nurdaulet Zhuzbay, Nurlan Kabdyshev, Nurlan Zhani-\nyar, Rasul Yermagambet, Rustam Chibar, Saltanat Seitzhan, Soibkhon Khajikhanov, Tasbolat Taunyazov, Temirlan\nGalimzhanov, Temirlan Kaiyrbay, Tleukhan Mussin, Togzhan Syrymova, Valeriya Kostyukova, Yerkebulan Massalim,\nYermakhan Kassym, Zerde Nurbayeva, and Zhanat Kappassov. 2025. Survey on Vision-Language-Action Models.\narXiv:2502.06851 [cs.CL] https://arxiv.org/abs/2502.06851\n[2] Agent-RL. 2024. ReSearch. https://github.com/Agent-RL/ReSearch.\n[3] Agno-AGI. 2025. Agno. https://github.com/agno-agi/agno.\n[4] Garima Agrawal, Sashank Gummuluri, and Cosimo Spera. 2024. Beyond-RAG: Question Identification and Answer\nGeneration in Real-Time Conversations. arXiv:2410.10136 [cs.CL] https://arxiv.org/abs/2410.10136\n[5] Flowise AI. 2023. Flowise: Low-code LLM Application Building Tool. https://flowiseai.com/.\n[6] Nawaf Alampara, Mara Schilling-Wilhelmi, Martiño Ríos-García, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh\nGrover, N. M. Anoop Krishnan, and Kevin Maik Jablonka. 2025. Probing the limitations of multimodal language\nmodels for chemistry and materials research. arXiv:2411.16955 [cs.LG] https://arxiv.org/abs/2411.16955\n[7] AlphaProof and AlphaGeometry teams. 2024. AI achieves silver-medal standard solving International Mathematical\nOlympiad problems. https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/.\n[8] Salaheddin Alzubi, Creston Brooks, Purva Chiniya, Edoardo Contente, Chiara von Gerlach, Lucas Irwin, Yihan\nJiang, Arda Kaz, Windsor Nguyen, Sewoong Oh, Himanshu Tyagi, and Pramod Viswanath. 2025. Open Deep Search:\nDemocratizing Search with Open-source Reasoning Agents. arXiv:2503.20201 [cs.LG] https://arxiv.org/abs/2503.20201\n[9] Lucio Anderlini, Matteo Barbetti, Giulio Bianchini, Diego Ciangottini, Stefano Dal Pra, Diego Michelotto, Carmelo\nPellegrino, Rosa Petrini, Alessandro Pascolini, and Daniele Spiga. 2025. Supporting the development of Machine\nLearning for fundamental science in a federated Cloud with the AI_INFN platform.\narXiv:2502.21266 [cs.DC]\nhttps://arxiv.org/abs/2502.21266\n[10] Mehrad Ansari and Seyed Mohamad Moosavi. 2023. Agent-based Learning of Materials Datasets from Scientific\nLiterature. https://github.com/AI4ChemS/Eunomia. arXiv:2312.11690 [cs.AI] https://arxiv.org/abs/2312.11690\n[11] Anthropic. 2024. Building effective agents. https://www.anthropic.com/engineering/building-effective-agents.\n[12] Antropic. 2024. Model Context Protocol (MCP). https://docs.anthropic.com/en/docs/agents-and-tools/mcp.\n[13] Antropic. 2025. Claude takes research to new places. https://www.anthropic.com/news/research.\n[14] Prakash Aryan. 2024. LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive\nArguments. arXiv:2412.06229 [cs.AI] https://arxiv.org/abs/2412.06229\n[15] Zahra Ashktorab, Qian Pan, Werner Geyer, Michael Desmond, Marina Danilevsky, James M. Johnson, Casey Dugan,\nand Michelle Bachman. 2024. Emerging Reliance Behaviors in Human-AI Text Generation: Hallucinations, Data\nQuality Assessment, and Cognitive Forcing Functions. arXiv:2409.08937 [cs.HC] https://arxiv.org/abs/2409.08937\n[16] assafelovic. 2023. GPT-Researcher. https://github.com/assafelovic/gpt-researcher/.\n[17] Ahmet Yasin Aytar, Kemal Kilic, and Kamer Kaya. 2024. A Retrieval-Augmented Generation Framework for Academic\nLiterature Navigation in Data Science. arXiv:2412.15404 [cs.IR] https://arxiv.org/abs/2412.15404\n[18] Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, and Sung Ju Hwang. 2025. ResearchAgent: Iterative Research\nIdea Generation over Scientific Literature with Large Language Models. arXiv:2404.07738 [cs.CL] https://arxiv.org/\nabs/2404.07738\n[19] Dzmitry Bahdanau, Nicolas Gontier, Gabriel Huang, Ehsan Kamalloo, Rafael Pardinas, Alex Piché, Torsten Scholak,\nOleh Shliazhko, Jordan Prince Tremblay, Karam Ghanem, Soham Parikh, Mitul Tiwari, and Quaizar Vohra. 2024.\nTapeAgents: a Holistic Framework for Agent Development and Optimization.\narXiv:2412.08445 [cs.AI]\nhttps:\n//arxiv.org/abs/2412.08445\n[20] Gal Bakal, Ali Dasdan, Yaniv Katz, Michael Kaufman, and Guy Levin. 2025. Experience with GitHub Copilot for\nDeveloper Productivity at Zoominfo. arXiv:2501.13282 [cs.SE] https://arxiv.org/abs/2501.13282\n[21] Howard Balshem, Mark Helfand, Holger J Schünemann, Andrew D Oxman, Regina Kunzand Jan Brozek, Gunn E Vist,\nYngve Falck-Ytter, Joerg Meerpohl, Susan Norris, and Gordon H Guyatt. 2011. GRADE guidelines: 3. Rating the\nquality of evidence. https://pubmed.ncbi.nlm.nih.gov/21208779/.\n[22] Samuel Barham, Orion Weller, Michelle Yuan, Kenton Murray, Mahsa Yarmohammadi, Zhengping Jiang, Siddharth\nVashishtha, Alexander Martin, Anqi Liu, Aaron Steven White, Jordan Boyd-Graber, and Benjamin Van Durme.\n2023.\nMegaWika: Millions of reports and their sources across 50 diverse languages.\narXiv:2307.07049 [cs.CL]\nhttps://arxiv.org/abs/2307.07049\n82\nXu et al.\n[23] Rhea Basappa, Mustafa Tekman, Hong Lu, Benjamin Faught, Sandeep Kakar, and Ashok K. Goel. 2024. Social AI\nAgents Too Need to Explain Themselves. Springer Nature Switzerland, 351–360. doi:10.1007/978-3-031-63028-6_29\n[24] Joeran Beel, Min-Yen Kan, and Moritz Baumgart. 2025. Evaluating Sakana’s AI Scientist for Autonomous Research:\nWishful Thinking or an Emerging Reality Towards ’Artificial Research Intelligence’ (ARI)? arXiv:2502.14297 [cs.IR]\nhttps://arxiv.org/abs/2502.14297\n[25] Morad Behandish, John Maxwell III, and Johan de Kleer. 2022. AI Research Associate for Early-Stage Scientific\nDiscovery. arXiv:2202.03199 [cs.AI] https://arxiv.org/abs/2202.03199\n[26] Yoshua Bengio, Michael Cohen, Damiano Fornasiere, Joumana Ghosn, Pietro Greiner, Matt MacDermott, Sören\nMindermann, Adam Oberman, Jesse Richardson, Oliver Richardson, Marc-Antoine Rondeau, Pierre-Luc St-Charles,\nand David Williams-King. 2025. Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?\narXiv:2502.15657 [cs.AI] https://arxiv.org/abs/2502.15657\n[27] Karim Benharrak, Tim Zindulka, and Daniel Buschek. 2024. Deceptive Patterns of Intelligent and Interactive Writing\nAssistants. arXiv:2404.09375 [cs.HC] https://arxiv.org/abs/2404.09375\n[28] Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, and Huajun Chen. 2024. OceanGPT:\nA Large Language Model for Ocean Science Tasks.\nhttp://oceangpt.zjukg.cn/.\narXiv:2310.02031 [cs.CL]\nhttps:\n//arxiv.org/abs/2310.02031\n[29] Stefano Bianchini, Moritz Müller, and Pierre Pelletier. 2024. Drivers and Barriers of AI Adoption and Use in Scientific\nResearch. arXiv:2312.09843 [cs.CY] https://arxiv.org/abs/2312.09843\n[30] bindAI. 2025. ChatGPT Deep Research vs Perplexity – Which One Is Better? https://blog.getbind.co/2025/02/03/\nchatgpt-deep-research-is-it-better-than-perplexity/.\n[31] Francisco Bolanos, Angelo Salatino, Francesco Osborne, and Enrico Motta. 2024. Artificial Intelligence for Literature\nReviews: Opportunities and Challenges. arXiv:2402.08565 [cs.AI] https://arxiv.org/abs/2402.08565\n[32] Bolt. 2024. Bolt. https://bolt.new/.\n[33] bracai. 2025. MMLU benchmark: Testing LLMs multi-task capabilities. https://www.bracai.eu/post/mmlu-benchmark.\n[34] Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. 2023. ChemCrow:\nAugmenting large-language models with chemistry tools. arXiv:2304.05376 [physics.chem-ph] https://arxiv.org/abs/\n2304.05376\n[35] Chris Brown and Jason Cusati. 2024. Exploring the Evidence-Based Beliefs and Behaviors of LLM-Based Programming\nAssistants. arXiv:2407.13900 [cs.SE] https://arxiv.org/abs/2407.13900\n[36] browserbase. 2025. Open-operator. https://github.com/browserbase/open-operator.\n[37] btahir. 2024. open_deep_research. https://github.com/btahir/open-deep-research.\n[38] ByteDance. 2024. Coze Space. https://www.coze.cn/space-preview.\n[39] ByteDance. 2025. agent-tars. https://github.com/bytedance/UI-TARS-desktop/tree/main/apps/agent-tars.\n[40] Beatriz Cabrero-Daniel, Tomas Herda, Victoria Pichler, and Martin Eder. 2024. Exploring Human-AI Collaboration in\nAgile: Customised LLM Meeting Assistants. arXiv:2404.14871 [cs.SE] https://arxiv.org/abs/2404.14871\n[41] Filipe Calegario, Vanilson Burégio, Francisco Erivaldo, Daniel Moraes Costa Andrade, Kailane Felix, Nathalia Barbosa,\nPedro Lucas da Silva Lucena, and César França. 2023. Exploring the intersection of Generative AI and Software\nDevelopment. arXiv:2312.14262 [cs.SE] https://arxiv.org/abs/2312.14262\n[42] Nicholas Camara. 2025. open-deep-research. https://github.com/nickscamara/open-deep-research.\n[43] Camel AI. 2025. OWL. https://github.com/camel-ai/owl.\n[44] Franck Cappello, Sandeep Madireddy, Robert Underwood, Neil Getty, Nicholas Lee-Ping Chia, Nesar Ramachandra,\nJosh Nguyen, Murat Keceli, Tanwi Mallick, Zilinghan Li, Marieme Ngom, Chenhui Zhang, Angel Yanguas-Gil, Evan\nAntoniuk, Bhavya Kailkhura, Minyang Tian, Yufeng Du, Yuan-Sen Ting, Azton Wells, Bogdan Nicolae, Avinash Maurya,\nM. Mustafa Rafique, Eliu Huerta, Bo Li, Ian Foster, and Rick Stevens. 2025. EAIRA: Establishing a Methodology for\nEvaluating AI Models as Scientific Research Assistants. arXiv:2502.20309 [cs.AI] https://arxiv.org/abs/2502.20309\n[45] Peter Cardon, Carolin Fleischmann, Jolanta Aritz, Minna Logemann, and Jeanette Heidewald. 2023. The Challenges\nand Opportunities of AI-Assisted Writing: Developing AI Literacy for the AI Age. https://journals.sagepub.com/doi/\nabs/10.1177/23294906231176517.\n[46] Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya\nParameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, and Ion Stoica. 2025. Why Do\nMulti-Agent LLM Systems Fail? arXiv:2503.13657 [cs.AI] https://arxiv.org/abs/2503.13657\n[47] Eric Chamoun, Michael Schlichktrull, and Andreas Vlachos. 2024. Automated Focused Feedback Generation for\nScientific Writing Assistance. arXiv:2405.20477 [cs.CL] https://arxiv.org/abs/2405.20477\n[48] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023.\nChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. https://github.com/thunlp/ChatEval.\narXiv:2308.07201 [cs.CL] https://arxiv.org/abs/2308.07201\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n83\n[49] Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui\nZhu, Aili Chen, Nianqi Li, Lida Chen, Caiyu Hu, Siye Wu, Scott Ren, Ziquan Fu, and Yanghua Xiao. 2024. From\nPersona to Personalization: A Survey on Role-Playing Language Agents. arXiv:2404.18231 [cs.CL] https://arxiv.org/\nabs/2404.18231\n[50] Kexin Chen, Hanqun Cao, Junyou Li, Yuyang Du, Menghao Guo, Xin Zeng, Lanqing Li, Jiezhong Qiu, Pheng Ann\nHeng, and Guangyong Chen. 2024. An Autonomous Large Language Model Agent for Chemical Literature Data Mining.\narXiv:2402.12993 [cs.IR] https://arxiv.org/abs/2402.12993\n[51] Pengcheng Chen, Jin Ye, Guoan Wang, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang,\nYanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Junjun He, and Yu Qiao.\n2024. GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI. https:\n//uni-medical.github.io/GMAI-MMBench.github.io/. arXiv:2408.03361 [eess.IV] https://arxiv.org/abs/2408.03361\n[52] Tingting Chen, Srinivas Anumasa, Beibei Lin, Vedant Shah, Anirudh Goyal, and Dianbo Liu. 2025.\nAuto-\nBench: An Automated Benchmark for Scientific Discovery in LLMs. https://github.com/AutoBench/AutoBench.\narXiv:2502.15224 [cs.LG] https://arxiv.org/abs/2502.15224\n[53] Valerie Chen, Alan Zhu, Sebastian Zhao, Hussein Mozannar, David Sontag, and Ameet Talwalkar. 2025. Need Help?\nDesigning Proactive AI Assistants for Programming. arXiv:2410.04596 [cs.HC] https://arxiv.org/abs/2410.04596\n[54] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin\nHung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. 2023. AgentVerse:\nFacilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. arXiv:2308.10848 [cs.CL] https://arxiv.\norg/abs/2308.10848\n[55] Qinyuan Cheng, Tianxiang Sun, Xiangyang Liu, Wenwei Zhang, Zhangyue Yin, Shimin Li, Linyang Li, Zhengfu He,\nKai Chen, and Xipeng Qiu. 2024. Can AI Assistants Know What They Don’t Know? arXiv:2401.13275 [cs.CL]\nhttps://arxiv.org/abs/2401.13275\n[56] Zhao Cheng, Diane Wan, Matthew Abueg, Sahra Ghalebikesabi, Ren Yi, Eugene Bagdasarian, Borja Balle, Stefan Mellem,\nand Shawn O’Banion. 2024. CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data. https:\n//www.aimodels.fyi/papers/arxiv/ci-bench-benchmarking-contextual-integrity-ai-assistants. arXiv:2409.13903 [cs.AI]\nhttps://arxiv.org/abs/2409.13903\n[57] Bhavya Chopra, Ananya Singha, Anna Fariha, Sumit Gulwani, Chris Parnin, Ashish Tiwari, and Austin Z. Hen-\nley. 2023.\nConversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities.\narXiv:2310.16164 [cs.HC] https://arxiv.org/abs/2310.16164\n[58] Daniel J. H. Chung, Zhiqi Gao, Yurii Kvasiuk, Tianyi Li, Moritz Münchmeyer, Maja Rudolph, Frederic Sala, and\nSai Chaitanya Tadepalli. 2025. Theoretical Physics Benchmark (TPBench) – a Dataset and Study of AI Reasoning\nCapabilities in Theoretical Physics. https://tpbench.org/. arXiv:2502.15815 [cs.LG] https://arxiv.org/abs/2502.15815\n[59] Umut Cihan, Vahid Haratian, Arda İçöz, Mert Kaan Gül, Ömercan Devran, Emircan Furkan Bayendur, Baykal Mehmet\nUçar, and Eray Tüzün. 2024. Automated Code Review In Practice. arXiv:2412.18531 [cs.SE] https://arxiv.org/abs/\n2412.18531\n[60] Dave Citron. 2025. Deep Research is now available on Gemini 2.5 Pro Experimental. https://blog.google/products/\ngemini/deep-research-gemini-2-5-pro-experimental/.\n[61] Cline. 2024. Cline. https://github.com/cline/cline.\n[62] Cognition Labs. 2025. Devin.ai.\nhttps://devin.ai\n[63] Consensus. 2025. Consensus. https://consensus.app/.\n[64] crewAIInc. 2023. CrewAI. https://github.com/crewAIInc/crewAI.\n[65] Cursor. 2023. Cursor. https://www.cursor.com/.\n[66] Mohamad H. Danesh, Tu Trinh, Benjamin Plaut, and Nguyen X. Khanh. 2025. Learning to Coordinate with Experts.\nhttps://github.com/modanesh/YRC-Bench. arXiv:2502.09583 [cs.LG] https://arxiv.org/abs/2502.09583\n[67] Kristin M. de Payrebrune, Kathrin Flaßkamp, Tom Ströhla, Thomas Sattel, Dieter Bestle, Benedict Röder, Peter\nEberhard, Sebastian Peitz, Marcus Stoffel, Gulakala Rutwik, Borse Aditya, Meike Wohlleben, Walter Sextro, Maximilian\nRaff, C. David Remy, Manish Yadav, Merten Stender, Jan van Delden, Timo Lüddecke, Sabine C. Langer, Julius\nSchultz, and Christopher Blech. 2024. The impact of AI on engineering design procedures for dynamical systems.\narXiv:2412.12230 [eess.SY] https://arxiv.org/abs/2412.12230\n[68] DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong\nMa, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, et al. 2025. DeepSeek-R1: Incentivizing Reasoning\nCapability in LLMs via Reinforcement Learning. arXiv:2501.12948 [cs.CL] https://arxiv.org/abs/2501.12948\n[69] Akash Dhruv and Anshu Dubey. 2025.\nLeveraging Large Language Models for Code Translation and Software\nDevelopment in Scientific Computing. arXiv:2410.24119 [cs.SE] https://arxiv.org/abs/2410.24119\n84\nXu et al.\n[70] Talissa Dreossi. 2025. Bridging Logic Programming and Deep Learning for Explainability through ILASP. Electronic\nProceedings in Theoretical Computer Science 416 (Feb. 2025), 314–323. doi:10.4204/eptcs.416.31\n[71] Ian Drosos, Advait Sarkar, Xiaotong Xu, and Neil Toronto. 2025. \"It makes you think\": Provocations Help Restore\nCritical Thinking to AI-Assisted Knowledge Work. arXiv:2501.17247 [cs.HC] https://arxiv.org/abs/2501.17247\n[72] Omer Dunay, Daniel Cheng, Adam Tait, Parth Thakkar, Peter C Rigby, Andy Chiu, Imad Ahmad, Arun Ganesan,\nChandra Maddila, Vijayaraghavan Murali, Ali Tayyebi, and Nachiappan Nagappan. 2024. Multi-line AI-assisted Code\nAuthoring. arXiv:2402.04141 [cs.SE] https://arxiv.org/abs/2402.04141\n[73] Steffen Eger, Yong Cao, Jennifer D’Souza, Andreas Geiger, Christian Greisinger, Stephanie Gross, Yufang Hou,\nBrigitte Krenn, Anne Lauscher, Yizhi Li, Chenghua Lin, Nafise Sadat Moosavi, Wei Zhao, and Tristan Miller. 2025.\nTransforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation,\nContent Generation, and Evaluation. arXiv:2502.05151 [cs.CL] https://arxiv.org/abs/2502.05151\n[74] Elicit. 2025. Elicit. https://elicit.com/?redirected=true.\n[75] Michael D. Ernst. 2017. Natural Language is a Programming Language: Applying Natural Language Processing to\nSoftware Development. https://drops.dagstuhl.de/storage/00lipics/lipics-vol071-snapl2017/LIPIcs.SNAPL.2017.4/\nLIPIcs.SNAPL.2017.4.pdf.\n[76] Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024.\nA Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models. arXiv:2405.06211 [cs.CL]\nhttps://arxiv.org/abs/2405.06211\n[77] Flowith. 2024. Flowith Oracle Mode. https://flowith.net/.\n[78] Forethought-Technologies. 2023. AutoChain. https://github.com/Forethought-Technologies/AutoChain.\n[79] César França. 2023. AI empowering research: 10 ways how science can benefit from AI. arXiv:2307.10265 [cs.GL]\nhttps://arxiv.org/abs/2307.10265\n[80] Future-House. 2023. PaperQA. https://github.com/Future-House/paper-qa.\n[81] GAIR-NLP. 2025. DeepResearcher. https://github.com/GAIR-NLP/DeepResearcher.\n[82] Difei Gao, Lei Ji, Luowei Zhou, Kevin Qinghong Lin, Joya Chen, Zihan Fan, and Mike Zheng Shou. 2023. AssistGPT:\nA General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn.\narXiv:2306.08640 [cs.CV]\nhttps:\n//arxiv.org/abs/2306.08640\n[83] Shanghua Gao, Ada Fang, Yepeng Huang, Valentina Giunchiglia, Ayush Noori, Jonathan Richard Schwarz,\nYasha Ektefaie, Jovana Kondic, and Marinka Zitnik. 2024.\nEmpowering Biomedical Discovery with AI Agents.\narXiv:2404.02831 [cs.AI] https://arxiv.org/abs/2404.02831\n[84] Alireza Ghafarollahi and Markus J. Buehler. 2024. SciAgents: Automating scientific discovery through multi-agent\nintelligent graph reasoning. arXiv:2409.05556 [cs.AI] https://arxiv.org/abs/2409.05556\n[85] Luca Gioacchini, Marco Mellia, Idilio Drago, Alexander Delsanto, Giuseppe Siracusano, and Roberto Bifulco. 2024.\nAutoPenBench: Benchmarking Generative Agents for Penetration Testing. https://github.com/lucagioacchini/auto-\npen-bench. arXiv:2410.03225 [cs.CR] https://arxiv.org/abs/2410.03225\n[86] Github. 2021. Github Copilot. https://github.com/features/copilot?ref=nav.poetries.top.\n[87] Amr Gomaa, Michael Sargious, and Antonio Krüger. 2024. AdaptoML-UX: An Adaptive User-centered GUI-based\nAutoML Toolkit for Non-AI Experts and HCI Researchers. https://github.com/MichaelSargious/AdaptoML_UX.\narXiv:2410.17469 [cs.HC] https://arxiv.org/abs/2410.17469\n[88] Google. 2021. BIG-bench. https://github.com/google/BIG-bench.\n[89] Google. 2024. Try Deep Research and our new experimental model in Gemini, your AI assistant. https://blog.google/\nproducts/gemini/google-gemini-deep-research/.\n[90] Google. 2025. A2A. https://github.com/google/A2A.\n[91] Google. 2025. Agent Development Kit. https://google.github.io/adk-docs/.\n[92] Google. 2025. Announcing the Agent2Agent Protocol (A2A). https://developers.googleblog.com/en/a2a-a-new-era-of-\nagent-interoperability/.\n[93] Google. 2025. Gemini 2.0 Flash (Feb ’25): Intelligence, Performance and Price Analysis. https://artificialanalysis.ai/\nmodels/gemini-2-0-flash.\n[94] Google. 2025. gemini-fullstack-langgraph-quickstart. https://github.com/google-gemini/gemini-fullstack-langgraph-\nquickstart.\n[95] Google. 2025. NotebookLm. https://notebooklm.google/.\n[96] Kanika Goswami, Puneet Mathur, Ryan Rossi, and Franck Dernoncourt. 2025. ChartCitor: Multi-Agent Framework\nfor Fine-Grained Chart Visual Attribution. arXiv:2502.00989 [cs.CL] https://arxiv.org/abs/2502.00989\n[97] Juraj Gottweis, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, Felix\nWeissenberger, Keran Rong, Ryutaro Tanno, Khaled Saab, Dan Popovici, Jacob Blum, Fan Zhang, Katherine Chou,\nAvinatan Hassidim, Burak Gokturk, Amin Vahdat, Pushmeet Kohli, Yossi Matias, Andrew Carroll, Kavita Kulkarni,\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n85\nNenad Tomasev, Vikram Dhillon, Eeshit Dhaval Vaishnav, Byron Lee, Tiago R D Costa, José R Penadés, Gary Peltz,\nYunhan Xu, Annalisa Pawlosky, Alan Karthikesalingam, and Vivek Natarajan. 2025. Towards an AI co-scientist.\nhttps://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf.\n[98] Alexander H. Gower, Konstantin Korovin, Daniel Brunnsåker, Filip Kronström, Gabriel K. Reder, Ievgeniia A. Tiukova,\nRonald S. Reiserer, John P. Wikswo, and Ross D. King. 2024. The Use of AI-Robotic Systems for Scientific Discovery.\narXiv:2406.17835 [cs.LG] https://arxiv.org/abs/2406.17835\n[99] Tianyang Gu, Jingjin Wang, Zhihao Zhang, and HaoHong Li. 2025. LLMs can Realize Combinatorial Creativity:\nGenerating Creative Ideas via LLMs for Scientific Research. arXiv:2412.14141 [cs.AI] https://arxiv.org/abs/2412.14141\n[100] Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, and Kai Chen. 2025. Mask-DPO: Generalizable Fine-grained\nFactuality Alignment of LLMs. arXiv:2503.02846 [cs.CL] https://arxiv.org/abs/2503.02846\n[101] Chengquan Guo, Xun Liu, Chulin Xie, Andy Zhou, Yi Zeng, Zinan Lin, Dawn Song, and Bo Li. 2024.\nRed-\nCode: Risky Code Execution and Generation Benchmark for Code Agents. https://github.com/AI-secure/RedCode.\narXiv:2411.07781 [cs.SE] https://arxiv.org/abs/2411.07781\n[102] Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang, and Jun Wang. 2024. DS-Agent: Automated Data\nScience by Empowering Large Language Models with Case-Based Reasoning. https://github.com/guosyjlu/DS-Agent.\narXiv:2402.17453 [cs.LG] https://arxiv.org/abs/2402.17453\n[103] Xin Guo, Haotian Xia, Zhaowei Liu, Hanyang Cao, Zhi Yang, Zhiqiang Liu, Sizhe Wang, Jinyi Niu, Chuqi Wang,\nYanhui Wang, Xiaolong Liang, Xiaoming Huang, Bing Zhu, Zhongyu Wei, Yun Chen, Weining Shen, and Liwen\nZhang. 2024. FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models.\narXiv:2308.09975 [cs.CL] https://arxiv.org/abs/2308.09975\n[104] Hilda Hadan, Derrick Wang, Reza Hadi Mogavi, Joseph Tu, Leah Zhang-Kennedy, and Lennart E. Nacke. 2024. The\nGreat AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing.\nhttps:\n//arxiv.org/abs/2407.12015.\n[105] Sukjin Han. 2024. Mining Causality: AI-Assisted Search for Instrumental Variables. arXiv:2409.14202 [econ.EM]\nhttps://arxiv.org/abs/2409.14202\n[106] Ebtesam Al Haque, Chris Brown, Thomas D. LaToza, and Brittany Johnson. 2025. Towards Decoding Developer\nCognition in the Age of AI Assistants. arXiv:2501.02684 [cs.HC] https://arxiv.org/abs/2501.02684\n[107] Gaole He, Patrick Hemmer, Michael Vössing, Max Schemmer, and Ujwal Gadiraju. 2025. Fine-Grained Appropriate\nReliance: Human-AI Collaboration with a Multi-Step Transparent Decision Workflow for Complex Task Decomposition.\narXiv:2501.10909 [cs.AI] https://arxiv.org/abs/2501.10909\n[108] Kaveen Hiniduma, Suren Byna, Jean Luca Bez, and Ravi Madduri. 2024. AI Data Readiness Inspector (AIDRIN) for\nQuantitative Assessment of Data Readiness for AI. In Proceedings of the 36th International Conference on Scientific\nand Statistical Database Management (SSDBM 2024). ACM, 1–12. doi:10.1145/3676288.3676296\n[109] HKUDS. 2025. AI-Researcher. https://github.com/HKUDS/AI-Researcher.\n[110] Brendan Hogan, Anmol Kabra, Felipe Siqueira Pacheco, Laura Greenstreet, Joshua Fan, Aaron Ferber, Marta Ummus,\nAlecsander Brito, Olivia Graham, Lillian Aoki, Drew Harvell, Alex Flecker, and Carla Gomes. 2024. AiSciVision: A\nFramework for Specializing Large Multimodal Models in Scientific Image Classification. arXiv:2410.21480 [cs.LG]\nhttps://arxiv.org/abs/2410.21480\n[111] Sirui Hong, Mingchen Zhuge, Jiaqi Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven\nKa Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. 2024.\nMetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. https://github.com/geekan/MetaGPT.\narXiv:2308.00352 [cs.AI] https://arxiv.org/abs/2308.00352\n[112] Hong Kong University Data Science Lab. 2024.\nAuto-Deep-Research.\nhttps://github.com/HKUDS/Auto-Deep-\nResearch.\n[113] Betty Li Hou, Kejian Shi, Jason Phang, James Aung, Steven Adler, and Rosie Campbell. 2024. Large Language Models\nas Misleading Assistants in Conversation. arXiv:2407.11789 [cs.CL] https://arxiv.org/abs/2407.11789\n[114] Shulin Huang, Shirong Ma, Yinghui Li, Mengzuo Huang, Wuhe Zou, Weidong Zhang, and Hai-Tao Zheng. 2024.\nLatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles.\nhttps://github.com/THUKElab/LatEval. arXiv:2308.10855 [cs.CL] https://arxiv.org/abs/2308.10855\n[115] HuggingFace. 2025.\nsmolagents: open_deep_research.\nhttps://github.com/huggingface/smolagents/tree/main/\nexamples/open_deep_research.\n[116] Faria Huq, Abdus Samee, David Chuan-En Lin, Alice Xiaodi Tang, and Jeffrey P Bigham. 2025. NoTeeline: Supporting\nReal-Time, Personalized Notetaking with LLM-Enhanced Micronotes. In Proceedings of the 30th International\nConference on Intelligent User Interfaces (IUI ’25). ACM, 1064–1081. doi:10.1145/3708359.3712086\n[117] Kurando IIDA and Kenjiro MIMURA. 2024. CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-\nIndependent Paradigm in Translation Quality Evaluation. arXiv:2412.11261 [cs.CL] https://arxiv.org/abs/2412.11261\n86\nXu et al.\n[118] Seyed Mohammad Ali Jafari. 2024. Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using\nAI-Enabled GPT-4 Assistant API. arXiv:2402.18582 [cs.DL] https://arxiv.org/abs/2402.18582\n[119] Rishab Jain and Aditya Jain. 2023. Generative AI in Writing Research Papers: A New Type of Algorithmic Bias and\nUncertainty in Scholarly Work. arXiv:2312.10057 [cs.CY] https://arxiv.org/abs/2312.10057\n[120] Zhengyao Jiang, Dominik Schmidt, Dhruv Srikanth, Dixing Xu, Ian Kaplan, Deniss Jacenko, and Yuxiang Wu. 2025.\nAIDE: AI-Driven Exploration in the Space of Code. arXiv:2502.13138 [cs.AI] https://arxiv.org/abs/2502.13138\n[121] Jina AI. 2025. node-DeepResearch. https://github.com/jina-ai/node-DeepResearch.\n[122] Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du,\nand Dong Yu. 2025. DSBench: How Far Are Data Science Agents from Becoming Data Science Experts? https:\n//github.com/LiqiangJing/DSBench. arXiv:2409.07703 [cs.AI] https://arxiv.org/abs/2409.07703\n[123] Nicola Jones. 2025. OpenAI’s ‘deep research’ tool: is it useful for scientists? https://www.nature.com/articles/d41586-\n025-00377-9.\n[124] Vijay Joshi and Iver Band. 2024. Disrupting Test Development with AI Assistants: Building the Base of the Test\nPyramid with Three AI Coding Assistants. (Oct. 2024). doi:10.36227/techrxiv.173014488.82191966/v1\n[125] Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman, Austin Zachary Henley, Carina Negreanu, and Advait\nSarkar. 2024. Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition.\nIn Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology (UIST ’24). ACM,\n1–19. doi:10.1145/3654777.3676345\n[126] CTOL Editors Ken. 2025. Gemini Launches Deep Research on 2.5 Pro Aiming to Redefine AI-Powered Analysis with\nStrong Lead Over OpenAI. https://www.ctol.digital/news/gemini-deep-research-launch-2-5-pro-vs-openai/.\n[127] Antti Keurulainen, Isak Westerlund, Samuel Kaski, and Alexander Ilin. 2021. Learning to Assist Agents by Observing\nThem. arXiv:2110.01311 [cs.AI] https://arxiv.org/abs/2110.01311\n[128] Abdullah\nKhalili\nand\nAbdelhamid\nBouchachia.\n2022.\nToward\nBuilding\nScience\nDiscovery\nMachines.\narXiv:2103.15551 [cs.AI] https://arxiv.org/abs/2103.15551\n[129] Stefan Kramer, Mattia Cerrato, Sašo Džeroski, and Ross King. 2023. Automated Scientific Discovery: From Equation\nDiscovery to Autonomous Discovery Systems. arXiv:2305.02251 [cs.AI] https://arxiv.org/abs/2305.02251\n[130] Ilia Kuznetsov, Osama Mohammed Afzal, Koen Dercksen, Nils Dycke, Alexander Goldberg, Tom Hope, Dirk Hovy,\nJonathan K. Kummerfeld, Anne Lauscher, Kevin Leyton-Brown, Sheng Lu, Mausam, Margot Mieskes, Aurélie Névéol,\nDanish Pruthi, Lizhen Qu, Roy Schwartz, Noah A. Smith, Thamar Solorio, Jingyan Wang, Xiaodan Zhu, Anna\nRogers, Nihar B. Shah, and Iryna Gurevych. 2024. What Can Natural Language Processing Do for Peer Review?\narXiv:2405.06563 [cs.CL] https://arxiv.org/abs/2405.06563\n[131] Martin Lance. 2024. open_deep_research. https://github.com/langchain-ai/open_deep_research.\n[132] Hao Lang, Fei Huang, and Yongbin Li. 2025. Debate Helps Weak-to-Strong Generalization. arXiv:2501.13124 [cs.CL]\nhttps://arxiv.org/abs/2501.13124\n[133] LangChain. 2025. How to think about agent frameworks. https://blog.langchain.dev/how-to-think-about-agent-\nframeworks/.\nhttps://docs.google.com/spreadsheets/d/1B37VxTBuGLeTSPVWtz7UMsCdtXrqV5hCjWkbHN8tfAo/\n[134] langChain AI. 2024. LangGraph. https://github.com/langchain-ai/langgraph.\n[135] Andrew Laverick, Kristen Surrao, Inigo Zubeldia, Boris Bolliet, Miles Cranmer, Antony Lewis, Blake Sherwin, and\nJulien Lesgourgues. 2024. Multi-Agent System for Cosmological Parameter Analysis. arXiv:2412.00431 [astro-ph.IM]\nhttps://arxiv.org/abs/2412.00431\n[136] Eunhae Lee. 2024. Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term\nMemory. arXiv:2409.11192 [cs.CY] https://arxiv.org/abs/2409.11192\n[137] Yuho Lee, Taewon Yun, Jason Cai, Hang Su, and Hwanjun Song. 2024.\nUniSumEval: Towards Unified, Fine-\nGrained, Multi-Dimensional Summarization Evaluation for LLMs. https://github.com/DISL-Lab/UniSumEval-v1.0.\narXiv:2409.19898 [cs.CL] https://arxiv.org/abs/2409.19898\n[138] Letta-AI. 2023. Letta. https://github.com/letta-ai/letta.\n[139] Kyla Levin, Nicolas van Kempen, Emery D. Berger, and Stephen N. Freund. 2025. ChatDBG: An AI-Powered Debugging\nAssistant. arXiv:2403.16354 [cs.SE] https://arxiv.org/abs/2403.16354\n[140] James\nR.\nLewis.\n2018.\nThe\nSystem\nUsability\nScale:\nPast,\nPresent,\nand\nFuture.\nInternational\nJournal\nof\nHuman–Computer\nInteraction\n34,\n7\n(2018),\n577–590.\ndoi:10.1080/10447318.2018.1455307\narXiv:https://doi.org/10.1080/10447318.2018.1455307\n[141] Belinda Z. Li, Been Kim, and Zi Wang. 2025. QuestBench: Can LLMs ask the right question to acquire information in\nreasoning tasks? arXiv:2503.22674 [cs.AI] https://arxiv.org/abs/2503.22674\n[142] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. CAMEL:\nCommunicative Agents for \"Mind\" Exploration of Large Language Model Society. arXiv:2303.17760 [cs.AI]\nhttps:\n//arxiv.org/abs/2303.17760\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n87\n[143] Jiachen Li, Xiwen Li, Justin Steinberg, Akshat Choube, Bingsheng Yao, Xuhai Xu, Dakuo Wang, Elizabeth Mynatt,\nand Varun Mishra. 2025. Vital Insight: Assisting Experts’ Context-Driven Sensemaking of Multi-modal Personal\nTracking Data Using Visualization and Human-In-The-Loop LLM Agents. arXiv:2410.14879 [cs.HC] https://arxiv.\norg/abs/2410.14879\n[144] Xuefeng Li, Haoyang Zou, and Pengfei Liu. 2025. TORL: Scaling Tool-Integrated RL. https://github.com/GAIR-\nNLP/ToRL.\nhttps://arxiv.org/pdf/2503.23383\n[145] Yuan Li, Yixuan Zhang, and Lichao Sun. 2023. MetaAgents: Simulating Interactions of Human Behaviors for LLM-based\nTask-oriented Coordination via Collaborative Generative Agents. arXiv:2310.06500 [cs.AI] https://arxiv.org/abs/2310.\n06500\n[146] Zhuoyan Li, Chen Liang, Jing Peng, and Ming Yin. 2024. How Does the Disclosure of AI Assistance Affect the\nPerceptions of Writing? arXiv:2410.04545 [cs.CL] https://arxiv.org/abs/2410.04545\n[147] Zekun Li, Xianjun Yang, Kyuri Choi, Wanrong Zhu, Ryan Hsieh, HyeonJung Kim, Jin Hyuk Lim, Sungyoung Ji,\nByungju Lee, Xifeng Yan, Linda Ruth Petzold, Stephen D. Wilson, Woosang Lim, and William Yang Wang. 2025.\nMMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding. https://github.com/\nLeezekun/MMSci. arXiv:2407.04903 [cs.CL] https://arxiv.org/abs/2407.04903\n[148] Jenny T. Liang, Chenyang Yang, and Brad A. Myers. 2023. A Large-Scale Survey on the Usability of AI Programming\nAssistants: Successes and Challenges. arXiv:2303.17125 [cs.SE] https://arxiv.org/abs/2303.17125\n[149] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak\nNarayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove,\nChristopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal\nLadhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert\nYuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang,\nRyan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang,\nVishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. 2023. Holistic Evaluation\nof Language Models. arXiv:2211.09110 [cs.CL] https://arxiv.org/abs/2211.09110\n[150] Jialiang Lin, Jiaxin Song, Zhangping Zhou, Yidong Chen, and Xiaodong Shi. 2023. Automated scholarly paper review:\nConcepts, technologies, and challenges. Information Fusion 98 (Oct. 2023), 101830. doi:10.1016/j.inffus.2023.101830\n[151] Stephanie Lin, Jacob Hilton, and Owain Evans. 2022. TruthfulQA: Measuring How Models Mimic Human Falsehoods.\narXiv:2109.07958 [cs.CL] https://arxiv.org/abs/2109.07958\n[152] Shilong Liu, Hao Cheng, Haotian Liu, Hao Zhang, Feng Li, Tianhe Ren, Xueyan Zou, Jianwei Yang, Hang Su, Jun\nZhu, Lei Zhang, Jianfeng Gao, and Chunyuan Li. 2023. LLaVA-Plus: Learning to Use Tools for Creating Multimodal\nAgents. arXiv:2311.05437 [cs.CV] https://arxiv.org/abs/2311.05437\n[153] Xiao Liu, Bo Qin, Dongzhu Liang, Guang Dong, Hanyu Lai, Hanchen Zhang, Hanlin Zhao, Iat Long Iong, Jiadai\nSun, Jiaqi Wang, Junjie Gao, Junjun Shan, Kangning Liu, Shudan Zhang, Shuntian Yao, Siyi Cheng, Wentao Yao,\nWenyi Zhao, Xinghan Liu, Xinyi Liu, Xinying Chen, Xinyue Yang, Yang Yang, Yifan Xu, Yu Yang, Yujia Wang,\nYulin Xu, Zehan Qi, Yuxiao Dong, and Jie Tang. 2024.\nAutoGLM: Autonomous Foundation Agents for GUIs.\narXiv:2411.00820 [cs.HC] https://arxiv.org/abs/2411.00820\n[154] Xiao Liu, Bo Qin, Dongzhu Liang, Guang Dong, Hanyu Lai, Hanchen Zhang, Hanlin Zhao, Iat Long Iong, Jiadai\nSun, Jiaqi Wang, Junjie Gao, Junjun Shan, Kangning Liu, Shudan Zhang, Shuntian Yao, Siyi Cheng, Wentao Yao,\nWenyi Zhao, Xinghan Liu, Xinyi Liu, Xinying Chen, Xinyue Yang, Yang Yang, Yifan Xu, Yu Yang, Yujia Wang,\nYulin Xu, Zehan Qi, Yuxiao Dong, and Jie Tang. 2024.\nAutoGLM: Autonomous Foundation Agents for GUIs.\narXiv:2411.00820 [cs.HC] https://arxiv.org/abs/2411.00820\n[155] Zijun Liu, Kaiming Liu, Yiqi Zhu, Xuanyu Lei, Zonghan Yang, Zhenhe Zhang, Peng Li, and Yang Liu. 2024. AIGS:\nGenerating Science from AI-Powered Automated Falsification. arXiv:2411.11910 [cs.LG] https://arxiv.org/abs/2411.\n11910\n[156] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen,\nJuan Carlos Niebles, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2023. BOLAA:\nBenchmarking and Orchestrating LLM-augmented Autonomous Agents.\nhttps://github.com/salesforce/BOLAA.\narXiv:2308.05960 [cs.AI] https://arxiv.org/abs/2308.05960\n[157] Renze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yuxuan Sun, Yusen Zhang,\nJihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma, Xi Li, Kai Zhang, Congying Xia, Lifu Huang, and\nWenpeng Yin. 2025. AAAR-1.0: Assessing AI’s Potential to Assist Research. https://renzelou.github.io/AAAR-1.0/.\narXiv:2410.22394 [cs.CL] https://arxiv.org/abs/2410.22394\n[158] Cong Lu, Shengran Hu, and Jeff Clune. 2025.\nAutomated Capability Discovery via Model Self-Exploration.\narXiv:2502.07577 [cs.LG] https://arxiv.org/abs/2502.07577\n88\nXu et al.\n[159] Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. 2024. The AI Scientist: Towards\nFully Automated Open-Ended Scientific Discovery. arXiv:2408.06292 [cs.AI] https://arxiv.org/abs/2408.06292\n[160] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and\nAshwin Kalyan. 2022. Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering.\nhttps://scienceqa.github.io/. arXiv:2209.09513 [cs.CL] https://arxiv.org/abs/2209.09513\n[161] Chandra Maddila, Negar Ghorbani, Kosay Jabre, Vijayaraghavan Murali, Edwin Kim, Parth Thakkar, Nikolay Pavlovich\nLaptev, Olivia Harman, Diana Hsu, Rui Abreu, and Peter C. Rigby. 2024. AI-Assisted SQL Authoring at Industry\nScale. arXiv:2407.13280 [cs.SE] https://arxiv.org/abs/2407.13280\n[162] Srijoni Majumdar, Edith Elkind, and Evangelos Pournaras. 2025. Generative AI Voting: Fair Collective Choice is\nResilient to LLM Biases and Inconsistencies. arXiv:2406.11871 [cs.AI] https://arxiv.org/abs/2406.11871\n[163] Dung Nguyen Manh, Thang Phan Chau, Nam Le Hai, Thong T. Doan, Nam V. Nguyen, Quang Pham, and Nghi D. Q. Bui.\n2025. CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding & Reasoning Capabilities of CodeLLMs.\nhttps://github.com/FSoft-AI4Code/CodeMMLU. arXiv:2410.01999 [cs.SE] https://arxiv.org/abs/2410.01999\n[164] Manus. 2025. Manus. https://manus.im/.\n[165] Rohin Manvi, Samar Khanna, Gengchen Mai, Marshall Burke, David Lobell, and Stefano Ermon. 2024. GeoLLM:\nExtracting Geospatial Knowledge from Large Language Models. arXiv:2310.06213 [cs.CL] https://arxiv.org/abs/2310.\n06213\n[166] David M. Markowitz. 2024. From Complexity to Clarity: How AI Enhances Perceptions of Scientists and the Public’s\nUnderstanding of Science. arXiv:2405.00706 [cs.CL] https://arxiv.org/abs/2405.00706\n[167] Jonathan Mast. 2025.\nChatGPT’s Deep Research vs. Google’s Gemini 1.5 Pro with Deep Research: A Detailed\nComparison. https://whitebeardstrategies.com/ai-prompt-engineering/chatgpts-deep-research-vs-googles-gemini-1-5-\npro-with-deep-research-a-detailed-comparison/.\n[168] Mastra-AI. 2025. Mastra. https://github.com/mastra-ai/mastra.\n[169] Shray Mathur, Noah van der Vleuten, Kevin Yager, and Esther Tsai. 2024. VISION: A Modular AI Assistant for Natural\nHuman-Instrument Interaction at Scientific User Facilities. arXiv:2412.18161 [cs.AI] https://arxiv.org/abs/2412.18161\n[170] Gianmarco Mengaldo. 2025. Explain the Black Box for the Sake of Science: the Scientific Method in the Era of\nGenerative Artificial Intelligence. arXiv:2406.10557 [cs.AI] https://arxiv.org/abs/2406.10557\n[171] MGX Technologies. 2025. MGX.dev.\nhttps://mgx.dev\n[172] Gregoire Mialon, Clementine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023. GAIA:A\nBenchmark for General AI Assistants. https://huggingface.co/gaia-benchmark.\nhttps://arxiv.org/pdf/2311.12983\n[173] Microsoft. 2023. Microsoft Copilot. https://www.microsoft.com/en-us/microsoft-copilot/organizations.\n[174] Microsoft. 2023. Semantic-kernel. https://github.com/microsoft/semantic-kernel.\n[175] mirayayerdem. 2022. Github-Copilot-Amazon-Whisperer-ChatGPT. https://github.com/mirayayerdem/Github-Copilot-\nAmazon-Whisperer-ChatGPT.\n[176] Mlc-ai. 2023. web-llm. https://github.com/mlc-ai/web-llm.\n[177] ModelTC. 2025. lightllm. https://github.com/ModelTC/lightllm.\n[178] Devam Mondal and Atharva Inamdar. 2024. SeqMate: A Novel Large Language Model Pipeline for Automating RNA\nSequencing. arXiv:2407.03381 [q-bio.GN] https://arxiv.org/abs/2407.03381\n[179] Peya Mowar, Yi-Hao Peng, Jason Wu, Aaron Steinfeld, and Jeffrey P. Bigham. 2025. CodeA11y: Making AI Coding\nAssistants Useful for Accessible Web Development. arXiv:2502.10884 [cs.HC] https://arxiv.org/abs/2502.10884\n[180] Dilxat Muhtar, Zhenshi Li, Feng Gu, Xueliang Zhang, and Pengfeng Xiao. 2024.\nLHRS-Bot: Empowering Re-\nmote Sensing with VGI-Enhanced Large Multimodal Language Model. https://github.com/NJU-LHRS/LHRS-Bot.\narXiv:2402.02544 [cs.CV] https://arxiv.org/abs/2402.02544\n[181] Manisha Mukherjee, Sungchul Kim, Xiang Chen, Dan Luo, Tong Yu, and Tung Mai. 2025. From Documents to\nDialogue: Building KG-RAG Enhanced AI Assistants. arXiv:2502.15237 [cs.IR] https://arxiv.org/abs/2502.15237\n[182] Sheshera Mysore, Mahmood Jasim, Haoru Song, Sarah Akbar, Andre Kenneth Chase Randall, and Narges Mahyar.\n2023.\nHow Data Scientists Review the Scholarly Literature. In Proceedings of the 2023 Conference on Human\nInformation Interaction and Retrieval (CHIIR ’23). ACM, 137–152. doi:10.1145/3576840.3578309\n[183] n8n. 2023. n8n. https://github.com/n8n-io/n8n.\n[184] Nanobrowser Team. 2024. Nanobrowser. https://github.com/nanobrowser/nanobrowser.\n[185] Nathalia Nascimento, Everton Guimaraes, Sai Sanjna Chintakunta, and Santhosh Anitha Boominathan. 2024. LLM4DS:\nEvaluating Large Language Models for Data Science Code Generation. https://github.com/DataForScience/LLM4DS.\narXiv:2411.11908 [cs.SE] https://arxiv.org/abs/2411.11908\n[186] Khanh Nghiem, Anh Minh Nguyen, and Nghi D. Q. Bui. 2024. Envisioning the Next-Generation AI Coding Assistants:\nInsights & Proposals. arXiv:2403.14592 [cs.SE] https://arxiv.org/abs/2403.14592\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n89\n[187] Alex Nguyen, Zilong Wang, Jingbo Shang, and Dheeraj Mekala. 2024. DOCMASTER: A Unified Platform for Annotation,\nTraining, & Inference in Document Question-Answering. arXiv:2404.00439 [cs.CL] https://arxiv.org/abs/2404.00439\n[188] Kien X. Nguyen, Fengchun Qiao, Arthur Trembanis, and Xi Peng. 2024. SeafloorAI: A Large-scale Vision-Language\nDataset for Seafloor Geological Survey. https://github.com/deep-real/SeafloorAI. arXiv:2411.00172 [cs.CV] https:\n//arxiv.org/abs/2411.00172\n[189] Ziqi Ni, Yahao Li, Kaijia Hu, Kunyuan Han, Ming Xu, Xingyu Chen, Fengqi Liu, Yicong Ye, and Shuxin Bai.\n2024. MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration.\narXiv:2411.08063 [physics.soc-ph] https://arxiv.org/abs/2411.08063\n[190] Alexander Novikov, Ngân V˜u, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey\nShirobokov, Borislav Kozlovskii, Francisco J. R. Ruiz, Abbas Mehrabian, M. Pawan Kumar, Abigail See, Swarat Chaud-\nhuri, George Holland, Alex Davies, Sebastian Nowozin, Pushmeet Kohli, and Matej Balog. 2025. AlphaEvolve: A coding\nagent for scientific and algorithmic discovery. https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-\ncoding-agent-for-designing-advanced-algorithms/.\nhttps://storage.googleapis.com/deepmind-media/DeepMind.com/\nBlog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf\n[191] Koji Ochiai, Yuya Tahara-Arai, Akari Kato, Kazunari Kaizu, Hirokazu Kariyazaki, Makoto Umeno, Koichi Takahashi,\nGenki N. Kanda, and Haruka Ozaki. 2025. Automating Care by Self-maintainability for Full Laboratory Automation.\narXiv:2501.05789 [q-bio.QM] https://arxiv.org/abs/2501.05789\n[192] Ollama. 2023. Ollama. https://github.com/ollama/ollama.\n[193] Open Manus Team. 2025. OpenManus. https://github.com/mannaandpoem/OpenManus.\n[194] OpenAI. 2025. codex. https://github.com/openai/codex.\n[195] OpenAI. 2025. Compare models - OpenAI API. https://platform.openai.com/docs/models/compare?model=o3.\n[196] OpenAI. 2025. Deep Research System Card. https://cdn.openai.com/deep-research-system-card.pdf.\n[197] OpenAI. 2025. Introducing Deep Research. https://openai.com/index/introducing-deep-research/.\n[198] OpenAI. 2025. Introducing OpenAI o3 and o4-mini. https://openai.com/index/introducing-o3-and-o4-mini/.\n[199] OpenAI. 2025. OpenAI Agents SDK. https://github.com/openai/openai-agents-python.\n[200] OpenAI. 2025.\nOpenAI o3 and o4-mini System Card.\nhttps://cdn.openai.com/pdf/2221c875-02dc-4789-800b-\ne7758f3722c1/o3-and-o4-mini-system-card.pdf.\n[201] OpenAI. 2025. Thinking with images. https://openai.com/index/thinking-with-images/.\n[202] OpenBMB. 2023. XAgent. https://github.com/OpenBMB/XAgent.\n[203] Orkes. 2022. Orkes. https://orkes.io/use-cases/agentic-workflows.\n[204] Takauki Osogami. 2025.\nPosition: AI agents should be regulated based on autonomous action sequences.\narXiv:2503.04750 [cs.CY] https://arxiv.org/abs/2503.04750\n[205] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\nAgarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens,\nAmanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow\ninstructions with human feedback. arXiv:2203.02155 [cs.CL] https://arxiv.org/abs/2203.02155\n[206] Md Sultanul Islam Ovi, Nafisa Anjum, Tasmina Haque Bithe, Md. Mahabubur Rahman, and Mst. Shahnaj Akter Smrity.\n2024. Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and\nDebugging Assistants. arXiv:2409.19922 [cs.SE] https://arxiv.org/abs/2409.19922\n[207] Carlos\nAlves\nPereira,\nTanay\nKomarlu,\nand\nWael\nMobeirek.\n2023.\nThe\nFuture\nof\nAI-Assisted\nWriting.\narXiv:2306.16641 [cs.HC] https://arxiv.org/abs/2306.16641\n[208] Mike Perkins and Jasper Roe. 2024. Generative AI Tools in Academic Research: Applications and Implications for\nQualitative and Quantitative Research Methodologies. arXiv:2408.06872 [cs.HC] https://arxiv.org/abs/2408.06872\n[209] Perplexity. 2025. Introducing Perplexity Deep Research. https://www.perplexity.ai/hub/blog/introducing-perplexity-\ndeep-research.\n[210] Perplexity. 2025. Sonar by Perplexity. https://docs.perplexity.ai/guides/model-cards#research-models.\n[211] Tomas Petricek, Gerrit J. J. van den Burg, Alfredo Nazábal, Taha Ceritli, Ernesto Jiménez-Ruiz, and Christopher\nK. I. Williams. 2022. AI Assistants: A Framework for Semi-Automated Data Wrangling. arXiv:2211.00192 [cs.DB]\nhttps://arxiv.org/abs/2211.00192\n[212] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed\nShaaban, John Ling, Sean Shi, et al. 2025. Humanity’s Last Exam. arXiv:2501.14249 [cs.LG] https://arxiv.org/abs/\n2501.14249\n[213] Evangelos Pournaras. 2023. Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges\nfor Research Ethics and How to Respond. arXiv:2305.15299 [cs.CY] https://arxiv.org/abs/2305.15299\n[214] Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan Nguyen, Daniel Campos, Nick Craswell,\nand Jimmy Lin. 2024. Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented\n90\nXu et al.\nGeneration Track. arXiv:2406.16828 [cs.IR] https://arxiv.org/abs/2406.16828\n[215] James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen MacNeil, Narges Norouzi,\nSimone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, David H. Smith IV, Sven Strickroth, and\nDaniel Zingaro. 2024. Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research,\nTeaching Practices, and Tools. arXiv:2412.14732 [cs.CY] https://arxiv.org/abs/2412.14732\n[216] Pydantic. 2024. Pydantic-AI. https://github.com/pydantic/pydantic-ai.\n[217] Pythagora-io. 2024. gpt-pilot. https://github.com/Pythagora-io/gpt-pilot.\n[218] Jingyuan Qi, Zian Jia, Minqian Liu, Wangzhi Zhan, Junkai Zhang, Xiaofei Wen, Jingru Gan, Jianpeng Chen, Qin Liu,\nMingyu Derek Ma, Bangzheng Li, Haohui Wang, Adithya Kulkarni, Muhao Chen, Dawei Zhou, Ling Li, Wei Wang,\nand Lifu Huang. 2024. MetaScientist: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial\nDesign. arXiv:2412.16270 [cs.AI] https://arxiv.org/abs/2412.16270\n[219] Laryn Qi, J. D. Zamfirescu-Pereira, Taehan Kim, Björn Hartmann, John DeNero, and Narges Norouzi. 2024. A\nKnowledge-Component-Based Methodology for Evaluating AI Assistants. arXiv:2406.05603 [cs.CY] https://arxiv.org/\nabs/2406.05603\n[220] Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin\nCong, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun. 2024. ChatDev: Communicative Agents for Software\nDevelopment. https://github.com/OpenBMB/ChatDev.\nhttps://aclanthology.org/2024.acl-long.810.pdf\n[221] Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang,\nand Huajun Chen. 2025.\nBenchmarking Agentic Workflow Generation.\nhttps://github.com/zjunlp/WorfBench.\narXiv:2410.07869 [cs.CL] https://arxiv.org/abs/2410.07869\n[222] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian,\nSihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong\nSun. 2023. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. arXiv:2307.16789 [cs.AI]\nhttps://arxiv.org/abs/2307.16789\n[223] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian,\nSihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong\nSun. 2023. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. arXiv:2307.16789 [cs.AI]\nhttps://arxiv.org/abs/2307.16789\n[224] Qwen LM. 2024. Qwen-Agent. https://github.com/QwenLM/Qwen-Agent.\n[225] Joaquin Ramirez-Medina, Mohammadmehdi Ataei, and Alidad Amirfazli. 2025.\nAccelerating Scientific Research\nThrough a Multi-LLM Framework. arXiv:2502.07960 [physics.app-ph] https://arxiv.org/abs/2502.07960\n[226] Ruchit Rawal, Victor-Alexandru Pădurean, Sven Apel, Adish Singla, and Mariya Toneva. 2024. Hints Help Finding\nand Fixing Bugs Differently in Python and Text-based Program Representations. arXiv:2412.12471 [cs.SE]\nhttps:\n//arxiv.org/abs/2412.12471\n[227] Runtao Ren, Jian Ma, and Jianxi Luo. 2025. Large language model for patent concept generation. Advanced Engineering\nInformatics 65 (May 2025), 103301. doi:10.1016/j.aei.2025.103301\n[228] ResearchRabbit. 2025. ResearchRabbit. https://www.researchrabbit.ai/.\n[229] Restate. 2024. Restate. https://restate.dev/.\n[230] reworkd. 2023. AgentGPT. https://github.com/reworkd/AgentGPT.\n[231] Filippo Ricca, Alessandro Marchetto, and Andrea Stocco. 2025. A Multi-Year Grey Literature Review on AI-assisted\nTest Automation. https://arxiv.org/pdf/2408.06224.\n[232] Nathalie Riche, Anna Offenwanger, Frederic Gmeiner, David Brown, Hugo Romat, Michel Pahud, Nicolai Marquardt,\nKori Inkpen, and Ken Hinckley. 2025. AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect\nGraphical Interface Commands as General-Purpose Tools. https://arxiv.org/abs/2502.18736.\n[233] Anthony Cintron Roman, Jennifer Wortman Vaughan, Valerie See, Steph Ballard, Jehu Torres, Caleb Robinson, and\nJuan M. Lavista Ferres. 2024. Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible\nAI Assessments. arXiv:2312.06153 [cs.LG] https://arxiv.org/abs/2312.06153\n[234] Kaushik Roy, Vedant Khandelwal, Harshul Surana, Valerie Vera, Amit Sheth, and Heather Heckman. 2023. GEAR-Up:\nGenerative AI and External Knowledge-based Retrieval Upgrading Scholarly Article Searches for Systematic Reviews.\narXiv:2312.09948 [cs.IR] https://arxiv.org/abs/2312.09948\n[235] Run-llama. 2023. LlamaIndex. https://github.com/run-llama/llama_index.\n[236] Sergey V Samsonau, Aziza Kurbonova, Lu Jiang, Hazem Lashen, Jiamu Bai, Theresa Merchant, Ruoxi Wang, Laiba\nMehnaz, Zecheng Wang, and Ishita Patil. 2024. Artificial Intelligence for Scientific Research: Authentic Research\nEducation Framework. arXiv:2210.08966 [cs.CY] https://arxiv.org/abs/2210.08966\n[237] SamuelSchmidgall. 2025. AgentLaboratory. https://github.com/SamuelSchmidgall/AgentLaboratory.\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n91\n[238] Thomas Sandholm, Sarah Dong, Sayandev Mukherjee, John Feland, and Bernardo A. Huberman. 2024. Semantic\nNavigation for AI-assisted Ideation. arXiv:2411.03575 [cs.HC] https://arxiv.org/abs/2411.03575\n[239] Lindsay Sanneman and Julie Shah. 2021. Explaining Reward Functions to Humans for Better Human-Robot Collabo-\nration. arXiv:2110.04192 [cs.RO] https://arxiv.org/abs/2110.04192\n[240] Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, and\nEmad Barsoum. 2025.\nAgent Laboratory: Using LLM Agents as Research Assistants.\narXiv:2501.04227 [cs.HC]\nhttps://arxiv.org/abs/2501.04227\n[241] Martijn J. Schuemie, M. Soledad Cepeda, Marc A. Suchard, Jianxiao Yang, Yuxi Tian, Alejandro Schuler, Patrick B.\nRyan, David Madigan, and George Hripcsak. 2020. How Confident Are We About Observational Findings in Healthcare:\nA Benchmark Study. Harvard Data Science Review 2, 1 (2020). doi:10.1162/99608f92.147cc28e\n[242] Scispace. 2024. Scispace. https://scispace.com/.\n[243] Scite. 2025. Scite. https://scite.ai/.\n[244] Agnia Sergeyuk, Yaroslav Golubev, Timofey Bryksin, and Iftekhar Ahmed. 2025. Using AI-based coding assistants\nin practice: State of affairs, perceptions, and ways forward. Information and Software Technology 178 (Feb. 2025),\n107610. doi:10.1016/j.infsof.2024.107610\n[245] Mahsa\nShamsabadi\nand\nJennifer\nD’Souza.\n2024.\nA\nFAIR\nand\nFree\nPrompt-based\nResearch\nAssistant.\narXiv:2405.14601 [cs.CL] https://arxiv.org/abs/2405.14601\n[246] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023.\nHuggingGPT:\nSolving AI Tasks with ChatGPT and its Friends in Hugging Face. https://github.com/microsoft/JARVIS.\nhttps:\n//arxiv.org/pdf/2303.17580\n[247] Zejiang Shen, Tal August, Pao Siangliulue, Kyle Lo, Jonathan Bragg, Jeff Hammerbacher, Doug Downey, Joseph Chee\nChang, and David Sontag. 2023. Beyond Summarization: Designing AI Support for Real-World Expository Writing\nTasks. arXiv:2304.02623 [cs.CL] https://arxiv.org/abs/2304.02623\n[248] Shuming Shi, Enbo Zhao, Duyu Tang, Yan Wang, Piji Li, Wei Bi, Haiyun Jiang, Guoping Huang, Leyang Cui, Xinting\nHuang, Cong Zhou, Yong Dai, and Dongyang Ma. 2022. Effidit: Your AI Writing Assistant. arXiv:2208.01815 [cs.CL]\nhttps://arxiv.org/abs/2208.01815\n[249] Michael Shumer. 2025. OpenDeepResearcher. https://github.com/mshumer/OpenDeepResearcher.\n[250] Significant-Gravitas. 2023. AutoGPT. https://github.com/Significant-Gravitas/AutoGPT.\n[251] David Silver and Richard Sutton. 2025. Welcome to the Era of Experience. https://storage.googleapis.com/deepmind-\nmedia/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf.\n[252] Auste Simkute, Ewa Luger, Michael Evans, and Rhianne Jones. 2024. \"It is there, and you need it, so why do you not\nuse it?\" Achieving better adoption of AI systems by domain experts, in the case study of natural science research.\narXiv:2403.16895 [cs.HC] https://arxiv.org/abs/2403.16895\n[253] Michael Skarlinski, Tyler Nadolski, James Braza, Remo Storni, Mayk Caldas, Ludovico Mitchener, Michaela Hinks,\nAndrew White, and Sam Rodriques. 2025. FutureHouse Platform: Superintelligent AI Agents for Scientific Discovery.\nhttps://www.futurehouse.org/research-announcements/launching-futurehouse-platform-ai-agents.\n[254] Xinyi Song, Kexin Xie, Lina Lee, Ruizhe Chen, Jared M. Clark, Hao He, Haoran He, Jie Min, Xinlei Zhang, Simin\nZheng, Zhiyang Zhang, Xinwei Deng, and Yili Hong. 2025. Performance Evaluation of Large Language Models in\nStatistical Programming. arXiv:2502.13117 [stat.AP] https://arxiv.org/abs/2502.13117\n[255] Jamshid Sourati and James Evans. 2021.\nAccelerating science with human versus alien artificial intelligences.\narXiv:2104.05188 [cs.AI] https://arxiv.org/abs/2104.05188\n[256] Jamshid\nSourati\nand\nJames\nEvans.\n2023.\nAccelerating\nscience\nwith\nhuman-aware\nartificial\nintelligence.\narXiv:2306.01495 [cs.AI] https://arxiv.org/abs/2306.01495\n[257] StanfordNLP. 2024. DSPy. https://github.com/stanfordnlp/dspy.\n[258] Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli\nOuyang, Philip Torr, Bowen Zhou, and Nanqing Dong. 2025. Many Heads Are Better Than One: Improved Scientific\nIdea Generation by A LLM-Based Multi-Agent System. arXiv:2410.09403 [cs.AI] https://arxiv.org/abs/2410.09403\n[259] Ltd. Suzhou Yuling Artificial Intelligence Technology Co. 2023. Dify: Open-source LLM Application Development\nPlatform. https://dify.ai/.\n[260] Xin Tan, Xiao Long, Xianjun Ni, Yinghao Zhu, Jing Jiang, and Li Zhang. 2024. How far are AI-powered programming\nassistants from meeting developers’ needs? arXiv:2404.12000 [cs.SE] https://arxiv.org/abs/2404.12000\n[261] Brian Tang and Kang G. Shin. 2024.\nSteward: Natural Language Web Automation.\narXiv:2409.15441 [cs.AI]\nhttps://arxiv.org/abs/2409.15441\n[262] Jiabin Tang, Tianyu Fan, and Chao Huang. 2025. AutoAgent: A Fully-Automated and Zero-Code Framework for LLM\nAgents. arXiv:2502.05957 [cs.AI] https://arxiv.org/abs/2502.05957\n[263] Yan Tang. 2025. deep_research_agent. https://github.com/grapeot/deep_research_agent.\n92\nXu et al.\n[264] Tadahiro Taniguchi, Shiro Takagi, Jun Otsuka, Yusuke Hayashi, and Hiro Taiyo Hamada. 2024. Collective Predictive\nCoding as Model of Science: Formalizing Scientific Activities Towards Generative Science. arXiv:2409.00102 [physics.soc-\nph] https://arxiv.org/abs/2409.00102\n[265] Temporalio. 2020. Temporal. https://github.com/temporalio/temporal.\n[266] Enkeleda Thaqi, Mohamed Omar Mantawy, and Enkelejda Kasneci. 2024. SARA: Smart AI Reading Assistant for\nReading Comprehension. In Proceedings of the 2024 Symposium on Eye Tracking Research and Applications (ETRA\n’24). ACM, 1–3. doi:10.1145/3649902.3655661\n[267] TheBlewish. 2024. Automated-AI-Web-Researcher-Ollama. https://github.com/TheBlewish/Automated-AI-Web-\nResearcher-Ollama.\n[268] Minyang Tian, Luyu Gao, Shizhuo Dylan Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat\nKrongchon, Yao Li, Shengyan Liu, Di Luo, Yutao Ma, Hao Tong, Kha Trinh, Chenyu Tian, Zihan Wang, Bohao Wu,\nYanyu Xiong, Shengzhu Yin, Minhui Zhu, Kilian Lieret, Yanxin Lu, Genglin Liu, Yufeng Du, Tianhua Tao, Ofir Press,\nJamie Callan, Eliu Huerta, and Hao Peng. 2024. SciCode: A Research Coding Benchmark Curated by Scientists.\nhttps://scicode-bench.github.io/. arXiv:2407.13168 [cs.AI] https://arxiv.org/abs/2407.13168\n[269] Ievgeniia A. Tiukova, Daniel Brunnsåker, Erik Y. Bjurström, Alexander H. Gower, Filip Kronström, Gabriel K. Reder,\nRonald S. Reiserer, Konstantin Korovin, Larisa B. Soldatova, John P. Wikswo, and Ross D. King. 2024. Genesis:\nTowards the Automation of Systems Biology Research. arXiv:2408.10689 [cs.AI] https://arxiv.org/abs/2408.10689\n[270] Irina Tolstykh, Aleksandra Tsybina, Sergey Yakubson, Aleksandr Gordeev, Vladimir Dokholyan, and Maksim Kuprashe-\nvich. 2024. GigaCheck: Detecting LLM-generated Content. arXiv:2410.23728 [cs.CL] https://arxiv.org/abs/2410.23728\n[271] Benjamin Towle and Ke Zhou. 2024. Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback.\narXiv:2410.11009 [cs.CL] https://arxiv.org/abs/2410.11009\n[272] Thanh-Dat Truong, Hoang-Quan Nguyen, Xuan-Bac Nguyen, Ashley Dowling, Xin Li, and Khoa Luu. 2025. Insect-\nFoundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding. https:\n//uark-cviu.github.io/projects/insect-foundation/. arXiv:2502.09906 [cs.CV] https://arxiv.org/abs/2502.09906\n[273] Joseph Tu, Hilda Hadan, Derrick M. Wang, Sabrina A Sgandurra, Reza Hadi Mogavi, and Lennart E. Nacke. 2024.\nAugmenting the Author: Exploring the Potential of AI Collaboration in Academic Writing. arXiv:2404.16071 [cs.HC]\nhttps://arxiv.org/abs/2404.16071\n[274] Xinming Tu, James Zou, Weijie J. Su, and Linjun Zhang. 2023. What Should Data Science Education Do with Large\nLanguage Models? arXiv:2307.02792 [cs.CY] https://arxiv.org/abs/2307.02792\n[275] Michele Tufano, Anisha Agarwal, Jinu Jang, Roshanak Zilouchian Moghaddam, and Neel Sundaresan. 2024. AutoDev:\nAutomated AI-Driven Development. arXiv:2403.08299 [cs.SE] https://arxiv.org/abs/2403.08299\n[276] Aleksei\nTurobov,\nDiane\nCoyle,\nand\nVerity\nHarding.\n2024.\nUsing\nChatGPT\nfor\nThematic\nAnalysis.\narXiv:2405.08828 [cs.HC] https://arxiv.org/abs/2405.08828\n[277] Rasmus Ulfsnes, Nils Brede Moe, Viktoria Stray, and Marianne Skarpen. 2024. Transforming Software Development\nwith Generative AI: Empirical Insights on Collaboration and Workflow. arXiv:2405.01543 [cs.SE] https://arxiv.org/\nabs/2405.01543\n[278] Stanford University. 2025. STORM. https://storm.genie.stanford.edu/.\n[279] Edward Vendrow, Omiros Pantazis, Alexander Shepard, Gabriel Brostow, Kate E. Jones, Oisin Mac Aodha, Sara\nBeery, and Grant Van Horn. 2024. INQUIRE: A Natural World Text-to-Image Retrieval Benchmark. https://inquire-\nbenchmark.github.io/. arXiv:2411.02537 [cs.CV] https://arxiv.org/abs/2411.02537\n[280] Vercel. 2020. Vercel. https://vercel.com/.\n[281] Vllm-project. 2023. vllm. https://github.com/vllm-project/vllm.\n[282] Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Parsa Neshaei, Roman Rietsche, and Tanja Käser. 2023.\nUnraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance.\narXiv:2311.03311 [cs.CL] https://arxiv.org/abs/2311.03311\n[283] April Yi Wang, Dakuo Wang, Jaimie Drozdal, Michael Muller, Soya Park, Justin D. Weisz, Xuye Liu, Lingfei\nWu, and Casey Dugan. 2022. Documentation Matters: Human-Centered AI System to Assist Data Science Code\nDocumentation in Computational Notebooks. ACM Transactions on Computer-Human Interaction 29, 2 (Jan. 2022),\n1–33. doi:10.1145/3489465\n[284] Dakuo Wang, Q. Vera Liao, Yunfeng Zhang, Udayan Khurana, Horst Samulowitz, Soya Park, Michael Muller, and Lisa\nAmini. 2021. How Much Automation Does a Data Scientist Want? arXiv:2101.03970 [cs.LG] https://arxiv.org/abs/\n2101.03970\n[285] Suyuan Wang, Xueqian Yin, Menghao Wang, Ruofeng Guo, and Kai Nan. 2024. EvoPat: A Multi-LLM-based Patents\nSummarization and Analysis Agent. arXiv:2412.18100 [cs.DL] https://arxiv.org/abs/2412.18100\n[286] Tiannan Wang, Jiamin Chen, Qingrui Jia, Shuai Wang, Ruoyu Fang, Huilin Wang, Zhaowei Gao, Chunzhao Xie, Chuou\nXu, Jihong Dai, Yibin Liu, Jialong Wu, Shengwei Ding, Long Li, Zhiwei Huang, Xinle Deng, Teng Yu, Gangan Ma, Han\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n93\nXiao, Zixin Chen, Danjun Xiang, Yunxia Wang, Yuanyuan Zhu, Yi Xiao, Jing Wang, Yiru Wang, Siran Ding, Jiayang\nHuang, Jiayi Xu, Yilihamu Tayier, Zhenyu Hu, Yuan Gao, Chengfeng Zheng, Yueshu Ye, Yihang Li, Lei Wan, Xinyue\nJiang, Yujie Wang, Siyu Cheng, Zhule Song, Xiangru Tang, Xiaohua Xu, Ningyu Zhang, Huajun Chen, Yuchen Eleanor\nJiang, and Wangchunshu Zhou. 2024. Weaver: Foundation Models for Creative Writing. arXiv:2401.17268 [cs.CL]\nhttps://arxiv.org/abs/2401.17268\n[287] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny\nZhou. 2023. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv:2203.11171 [cs.CL]\nhttps://arxiv.org/abs/2203.11171\n[288] Yao Wang, Mingxuan Cui, and Arthur Jiang. 2025. Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic\nAlgorithm for Assessing Novelty. arXiv:2503.01508 [cs.AI] https://arxiv.org/abs/2503.01508\n[289] Ying-Mei Wang and Tzeng-J Chen. 2025. AI’s deep research revolution: Transforming biomedical literature analysis.\nhttps://journals.lww.com/jcma/citation/9900/ai_s_deep_research_revolution__transforming.508.aspx.\n[290] Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman,\nand William Fedus. 2024. Measuring short-form factuality in large language models. https://cdn.openai.com/papers/\nsimpleqa.pdf.\n[291] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny\nZhou. 2023. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL]\nhttps://arxiv.org/abs/2201.11903\n[292] Shufa Wei, Xiaolong Xu, Xianbiao Qi, Xi Yin, Jun Xia, Jingyi Ren, Peijun Tang, Yuxiang Zhong, Yihao Chen, Xiaoqin\nRen, Yuxin Liang, Liankai Huang, Kai Xie, Weikang Gui, Wei Tan, Shuanglong Sun, Yongquan Hu, Qinxian Liu,\nNanjin Li, Chihao Dai, Lihua Wang, Xiaohui Liu, Lei Zhang, and Yutao Xie. 2023. AcademicGPT: Empowering\nAcademic Research. arXiv:2311.12315 [cs.CL] https://arxiv.org/abs/2311.12315\n[293] Sarah Welsh. 2025. AI Benchmark Deep Dive: Gemini 2.5 and Humanity’s Last Exam. https://arize.com/blog/ai-\nbenchmark-deep-dive-gemini-humanitys-last-exam/.\n[294] Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, and Linyi Yang. 2025.\nCycleResearcher: Improving Automated Research via Automated Review. arXiv:2411.00816 [cs.CL] https://arxiv.org/\nabs/2411.00816\n[295] Man Fai Wong, Shangxin Guo, Ching Nam Hang, Siu Wai Ho, and Chee Wei Tan. 2023. Natural Language Generation\nand Understanding of Big Code for AI-Assisted Programming: A Review. Entropy 25, 6 (June 2023), 888. doi:10.\n3390/e25060888\n[296] Junchao Wu, Shu Yang, Runzhe Zhan, Yulin Yuan, Derek F. Wong, and Lidia S. Chao. 2024. A Survey on LLM-Generated\nText Detection: Necessity, Methods, and Future Directions. arXiv:2310.14724 [cs.CL] https://arxiv.org/abs/2310.14724\n[297] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. 2025. Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research.\narXiv:2502.04644 [cs.AI] https://arxiv.org/abs/2502.04644\n[298] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,\nJiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger, and Chi Wang. 2023. AutoGen: Enabling Next-Gen\nLLM Applications via Multi-Agent Conversation. https://github.com/microsoft/autogen. arXiv:2308.08155 [cs.AI]\nhttps://arxiv.org/abs/2308.08155\n[299] xAI. 2025. Grok 3 Beta - The age of reasoning agents. https://x.ai/news/grok-3.\n[300] Menglin Xia, Victor Ruehle, Saravan Rajmohan, and Reza Shokri. 2025. Minerva: A Programmable Memory Test Bench-\nmark for Language Models. https://github.com/gkamradt/LLMTest_NeedleInAHaystack. arXiv:2502.03358 [cs.CL]\nhttps://arxiv.org/abs/2502.03358\n[301] Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu,\nChe Liu, Leo Z. Liu, Yiheng Xu, Hongjin Su, Dongchan Shin, Caiming Xiong, and Tao Yu. 2023. OpenAgents: An\nOpen Platform for Language Agents in the Wild. arXiv:2310.10634 [cs.CL] https://arxiv.org/abs/2310.10634\n[302] Yujia Xie, Xun Wang, Si-Qing Chen, Wayne Xiong, and Pengcheng He. 2023. Interactive Editing for Text Summarization.\narXiv:2306.03067 [cs.CL] https://arxiv.org/abs/2306.03067\n[303] Feng Xiong, Xinguo Yu, and Hon Wai Leong. 2024. AI-Empowered Human Research Integrating Brain Science and\nSocial Sciences Insights. arXiv:2411.12761 [cs.HC] https://arxiv.org/abs/2411.12761\n[304] Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong\nGuo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi,\nLawrence Jang, Yiqing Xie, Shuyan Zhou, and Graham Neubig. 2024. TheAgentCompany: Benchmarking LLM Agents\non Consequential Real World Tasks. arXiv:2412.14161 [cs.CL] https://arxiv.org/abs/2412.14161\n[305] Xin Xu, Qiyun Xu, Tong Xiao, Tianhao Chen, Yuchen Yan, Jiaxin Zhang, Shizhe Diao, Can Yang, and Yang Wang.\n2025. UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models.\nhttps://github.com/YangLabHKUST/UGPhysics. arXiv:2502.00334 [cs.CL] https://arxiv.org/abs/2502.00334\n94\nXu et al.\n[306] Te-Lun Yang, Jyi-Shane Liu, Yuen-Hsien Tseng, and Jyh-Shing Roger Jang. 2025. Knowledge Retrieval Based on\nGenerative AI. arXiv:2501.04635 [cs.IR] https://arxiv.org/abs/2501.04635\n[307] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D.\nManning. 2018. HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. arXiv:1809.09600 [cs.CL]\nhttps://arxiv.org/abs/1809.09600\n[308] Yi Yao, Jun Wang, Yabai Hu, Lifeng Wang, Yi Zhou, Jack Chen, Xuming Gai, Zhenming Wang, and Wenjun Liu.\n2024. BugBlitz-AI: An Intelligent QA Assistant. arXiv:2406.04356 [cs.SE] https://arxiv.org/abs/2406.04356\n[309] Burak Yetiştiren, Işık Özsoy, Miray Ayerdem, and Eray Tüzün. 2023.\nEvaluating the Code Quality of AI-\nAssisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT.\narXiv:2304.10778 [cs.SE] https://arxiv.org/abs/2304.10778\n[310] Xiaoxin Yin. 2024.\n\"Turing Tests\" For An AI Scientist.\nhttps://github.com/MatthewFilipovich/pycharge.\narXiv:2405.13352 [cs.AI] https://arxiv.org/abs/2405.13352\n[311] yoheinakajima. 2024. BabyAGI. https://github.com/yoheinakajima/babyagi.\n[312] Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, and Tae In Ahn. 2025. Knowledge Synthesis of\nPhotosynthesis Research Using a Large Language Model. arXiv:2502.01059 [cs.CL] https://arxiv.org/abs/2502.01059\n[313] You.com. 2023. You.com. https://you.com/about.\n[314] Hengjie Yu and Yaochu Jin. 2025. Unlocking the Potential of AI Researchers in Scientific Discovery: What Is Missing?\narXiv:2503.05822 [cs.CY] https://arxiv.org/abs/2503.05822\n[315] Hengjie Yu and Yaochu Jin. 2025. Unlocking the Potential of AI Researchers in Scientific Discovery: What Is Missing?\narXiv:2503.05822 [cs.CY] https://arxiv.org/abs/2503.05822\n[316] Jiakang Yuan, Xiangchao Yan, Shiyang Feng, Bo Zhang, Tao Chen, Botian Shi, Wanli Ouyang, Yu Qiao, Lei Bai, and\nBowen Zhou. 2025. Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback.\narXiv:2501.03916 [cs.AI] https://arxiv.org/abs/2501.03916\n[317] Siyu Yuan, Cheng Jiayang, Lin Qiu, and Deqing Yang. 2024. Boosting Scientific Concepts Understanding: Can Analogy\nfrom Teacher Models Empower Student Models? arXiv:2406.11375 [cs.CL] https://arxiv.org/abs/2406.11375\n[318] Hector Zenil, Jesper Tegnér, Felipe S. Abrahão, Alexander Lavin, Vipin Kumar, Jeremy G. Frey, Adrian Weller,\nLarisa Soldatova, Alan R. Bundy, Nicholas R. Jennings, Koichi Takahashi, Lawrence Hunter, Saso Dzeroski, Andrew\nBriggs, Frederick D. Gregory, Carla P. Gomes, Jon Rowe, James Evans, Hiroaki Kitano, and Ross King. 2023. The\nFuture of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence.\narXiv:2307.07522 [cs.AI]\nhttps://arxiv.org/abs/2307.07522\n[319] Beiq Zhang, Peng Liang, Xiyu Zhou, Aakash Ahmad, and Muhammad Waseem. 2023. Practices and Challenges of Using\nGitHub Copilot: An Empirical Study. In Proceedings of the 35th International Conference on Software Engineering\nand Knowledge Engineering (SEKE2023, Vol. 2023). KSI Research Inc., 124–129. doi:10.18293/seke2023-077\n[320] Cedegao E. Zhang, Katherine M. Collins, Adrian Weller, and Joshua B. Tenenbaum. 2023. AI for Mathematics: A\nCognitive Science Perspective. arXiv:2310.13021 [q-bio.NC] https://arxiv.org/abs/2310.13021\n[321] David Zhang. 2025. deep-research. https://github.com/dzhng/deep-research.\n[322] Kevin Zhang and Hod Lipson. 2024. Aligning AI-driven discovery with human intuition. arXiv:2410.07397 [cs.LG]\nhttps://arxiv.org/abs/2410.07397\n[323] Xingjian Zhang, Yutong Xie, Jin Huang, Jinge Ma, Zhaoying Pan, Qijia Liu, Ziyang Xiong, Tolga Ergen, Dongsub\nShim, Honglak Lee, and Qiaozhu Mei. 2024. MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific\nWorkflows. https://github.com/xingjian-zhang/massw. arXiv:2406.06357 [cs.CL] https://arxiv.org/abs/2406.06357\n[324] Zheng Zhang, Jie Gao, Ranjodh Singh Dhaliwal, and Toby Jia-Jun Li. 2023. VISAR: A Human-AI Argumentative\nWriting Assistant with Visual Programming and Rapid Draft Prototyping. In Proceedings of the 36th Annual ACM\nSymposium on User Interface Software and Technology (UIST ’23). ACM, 1–30. doi:10.1145/3586183.3606800\n[325] Jinjin Zhao, Avidgor Gal, and Sanjay Krishnan. 2024.\nA System for Quantifying Data Science Workflows with\nFine-Grained Procedural Logging and a Pilot Study. arXiv:2405.17845 [cs.HC] https://arxiv.org/abs/2405.17845\n[326] Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Yansi\nLi, Zhongyang Dai, Xin Chen, and Kai Yu. 2024.\nChemDFM-X: towards large multimodal model for chemistry.\nhttps://github.com/OpenDFM/ChemDFM-X. Science China Information Sciences 67, 12 (Dec. 2024). doi:10.1007/\ns11432-024-4243-0\n[327] Raigul Zheldibayeva. 2025. The impact of AI and peer feedback on research writing skills: a study using the CGScholar\nplatform among Kazakhstani scholars. arXiv:2503.05820 [cs.CY] https://arxiv.org/abs/2503.05820\n[328] Dewu Zheng, Yanlin Wang, Ensheng Shi, Xilin Liu, Yuchi Ma, Hongyu Zhang, and Zibin Zheng. 2025. Top General\nPerformance = Top Domain Performance? DomainCodeBench: A Multi-domain Code Generation Benchmark. https:\n//github.com/DeepSoftwareAnalytics/MultiCodeBench. arXiv:2412.18573 [cs.SE] https://arxiv.org/abs/2412.18573\nA Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n95\n[329] Yuxiang Zheng, Dayuan Fu, Xiangkun Hu, Xiaojie Cai, Lyumanshan Ye, Pengrui Lu, and Pengfei Liu. 2025. DeepRe-\nsearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments. arXiv:2504.03160 [cs.AI]\nhttps://arxiv.org/abs/2504.03160\n[330] Zhipu AI. 2025. AutoGLM-Research. https://autoglm-research.zhipuai.cn/.\n[331] Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan\nDuan. 2023. AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models. arXiv:2304.06364 [cs.CL]\nhttps://arxiv.org/abs/2304.06364\n[332] Shuyan Zhou, Chengrun Chi, Ceyao Zheng, Bailin Zhang, Yonatan Bisk, Daniel Fried, Ishan Misra, Karthik Raghunathan,\nTongshuang Zhao, Baian Zhou, et al. 2024. WebArena: A Benchmark for Web Agents. https://github.com/web-arena-\nx/webarena.\n[333] Minjun Zhu, Yixuan Weng, Linyi Yang, and Yue Zhang. 2025. DeepReview: Improving LLM-based Paper Review with\nHuman-like Deep Thinking Process. arXiv:2503.08569 [cs.CL] https://arxiv.org/abs/2503.08569\n[334] Tonghe Zhuang and Zhicheng Lin. 2024.\nThe why, what, and how of AI-based coding in scientific research.\narXiv:2410.02156 [cs.CY] https://arxiv.org/abs/2410.02156\n[335] Dennis Zyska, Nils Dycke, Jan Buchmann, Ilia Kuznetsov, and Iryna Gurevych. 2023. CARE: Collaborative AI-Assisted\nReading Environment. arXiv:2302.12611 [cs.CL] https://arxiv.org/abs/2302.12611\n[336] Tolga Çöplü, Arto Bendiken, Andrii Skomorokhov, Eduard Bateiko, Stephen Cobb, and Joshua J. Bouw. 2024.\nPrompt-Time Symbolic Knowledge Capture with Large Language Models. https://github.com/HaltiaAI/paper-PTSKC.\narXiv:2402.00414 [cs.CL] https://arxiv.org/abs/2402.00414\n",
    "content": "### 1. What is the core content of this paper, and what are its main contributions?\n\nThe core content of this paper is a comprehensive survey and analysis of deep research systems (Deep Research). Specifically, the paper proposes a novel hierarchical taxonomy that categorizes these systems based on four foundational technical dimensions: base models and reasoning engines, tool utilization and environmental interaction, task planning and execution control, and knowledge synthesis and output generation. By studying over 80 commercial and non-commercial implementations, the paper highlights the significant capabilities of current systems as well as their technical and ethical challenges in terms of information accuracy, privacy, intellectual property, and accessibility.\n\n**Main Contributions:**\n- A new taxonomy is proposed to better understand the technical architecture of deep research systems.\n- A comparative analysis of representative systems is provided, highlighting the strengths and limitations of different approaches.\n- Key challenges and a roadmap for future development are outlined, particularly focusing on emerging architectures and integration opportunities.\n\n---\n\n### 2. What breakthroughs or innovations does this paper introduce?\n\n**Breakthroughs or Innovations:**\n- **Novel Taxonomy**: The paper introduces a new taxonomy based on technical architecture, enabling clearer descriptions and comparisons of the capabilities of different deep research systems.\n- **Cross-Domain Application Analysis**: Beyond academic research, the paper delves into applications in scientific discovery, business intelligence, financial analysis, education, and personal knowledge management.\n- **Multimodal Integration**: It emphasizes the importance of multimodal integration and explores how images, videos, and audio can enhance research capabilities.\n- **Ethical and Technical Challenges**: Systematically analyzes challenges such as information accuracy and privacy protection, along with strategies to address them.\n- **Future Directions**: Provides an in-depth discussion of potential research directions, including advanced reasoning architectures, multimodal integration, domain specialization, human-computer collaboration, and ecosystem standardization.\n\nThese innovations offer both theoretical frameworks and practical guidance for the design, development, and evaluation of deep research systems.\n\n---\n\n### 3. Based on the content of this paper, what are some good ideas for startup projects?\n\nHere are several startup ideas inspired by the paper's content:\n\n#### **1. Multimodal Scientific Assistant Platform**\n- **Core Functionality**: Develop a scientific assistant platform that supports multimodal data processing, capable of automatically parsing and generating scientific charts, experimental designs, and analytical reports.\n- **Application Scenarios**: Help scientists quickly process complex experimental data and generate high-quality research reports.\n- **Technical Highlights**: Combine large language models with computer vision to achieve comprehensive analysis of scientific literature, images, and data.\n\n#### **2. Automated Patent Analysis Tool**\n- **Core Functionality**: Use deep research systems to automatically generate patent summaries, analyze technology trends, and provide potential infringement detection.\n- **Application Scenarios**: Serve businesses and legal teams by accelerating patent reviews and technology innovation assessments.\n- **Technical Highlights**: Integrate domain-specific models and toolchains to ensure high-precision understanding and analysis of patent documents.\n\n#### **3. Personalized Learning Platform for Education**\n- **Core Functionality**: Create a personalized learning platform that generates customized learning paths and content based on users' knowledge levels and interests.\n- **Application Scenarios**: Target students and educational institutions, offering comprehensive support from basic knowledge to advanced research.\n- **Technical Highlights**: Combine natural language processing and recommendation algorithms to dynamically adjust learning materials and difficulty levels.\n\n#### **4. Business Intelligence Automation Tool**\n- **Core Functionality**: Develop a market analysis and competitive intelligence automation tool that collects and analyzes industry dynamics in real-time.\n- **Application Scenarios**: Assist business decision-makers in quickly obtaining market insights and formulating strategic plans.\n- **Technical Highlights**: Achieve efficient information extraction and analysis through API integration and multi-agent collaboration.\n\n#### **5. Open-Source Deep Research Tool Ecosystem**\n- **Core Functionality**: Build an open-source deep research tool ecosystem that allows developers to easily integrate and extend functionalities.\n- **Application Scenarios**: Attract community developers to promote the popularization and innovation of deep research technologies.\n- **Technical Highlights**: Provide modular components and standardized interfaces to lower the development threshold.\n\n#### **6. Intelligent Diagnostic Support System for Healthcare**\n- **Core Functionality**: Develop a medical diagnostic support system that integrates clinical data, literature, and expert opinions to generate diagnostic recommendations.\n- **Application Scenarios**: Serve doctors and medical institutions to improve diagnostic efficiency and accuracy.\n- **Technical Highlights**: Use causal reasoning and multimodal analysis techniques to ensure reliability and practicality.\n\n#### **7. Personal Knowledge Management Application**\n- **Core Functionality**: Create a personal knowledge management tool that automatically organizes, summarizes, and visualizes users' reading and research content.\n- **Application Scenarios**: Help individual users efficiently manage and utilize information resources.\n- **Technical Highlights**: Combine natural language processing and graphical interface technology to provide an intuitive user experience.\n\nThese projects not only solve real-world problems but also fully leverage the potential of deep research systems, driving technological progress and practical application in related fields.",
    "github": "https://github.com/scienceaix/deepresearch",
    "hf": ""
}