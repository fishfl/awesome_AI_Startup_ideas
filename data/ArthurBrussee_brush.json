{
    "id": "/ArthurBrussee/brush",
    "issues": "32",
    "watch": "46",
    "fork": "107",
    "star": "2.4k",
    "topics": [
        "graphics",
        "reconstruction",
        "gaussian-splatting"
    ],
    "license": "Apache License 2.0",
    "languages": [
        "Rust,86.4%",
        "WGSL,10.9%",
        "Python,1.1%",
        "TypeScript,0.7%",
        "Java,0.6%",
        "Dockerfile,0.2%",
        "JavaScript,0.1%"
    ],
    "contributors": [
        "https://avatars.githubusercontent.com/u/7014262?s=64&v=4",
        "https://avatars.githubusercontent.com/u/110295381?s=64&v=4",
        "https://avatars.githubusercontent.com/u/112249?s=64&v=4",
        "https://avatars.githubusercontent.com/u/5802849?s=64&v=4",
        "https://avatars.githubusercontent.com/u/771979?s=64&v=4",
        "https://avatars.githubusercontent.com/u/932467?s=64&v=4",
        "https://avatars.githubusercontent.com/u/11192474?s=64&v=4",
        "https://avatars.githubusercontent.com/u/11922599?s=64&v=4",
        "https://avatars.githubusercontent.com/u/68102860?s=64&v=4",
        "https://avatars.githubusercontent.com/u/77305074?s=64&v=4"
    ],
    "about": "3D Reconstruction for all",
    "is_AI": "y",
    "category": "Agent/Robot",
    "summary": "```markdown\n## 1. Core Project Content and Problems Solved\n\n**Brush** is a 3D reconstruction engine based on **Gaussian Splatting**, designed to enable cross-platform, high-performance, low-dependency real-time 3D scene reconstruction and rendering. It addresses several key challenges faced by current machine learning-driven 3D reconstruction technologies in practical applications:\n\n- **Poor Cross-Platform Compatibility**: Most 3D reconstruction tools rely on CUDA and specific hardware (e.g., NVIDIA GPUs), limiting their use on macOS, AMD/Intel graphics cards, or mobile devices.\n- **Complex Deployment**: Traditional ML frameworks require complex runtime environments and large dependency libraries, making it difficult to package them into lightweight applications.\n- **Lack of Real-Time Interaction**: Users cannot view reconstruction results in real time during training, leading to inefficient debugging and optimization.\n\nBy leveraging **WebGPU + the Burn deep learning framework**, Brush enables a 3D reconstruction system that runs natively across **Windows/macOS/Linux/Android/Browsers (Chrome/Edge)** without requiring additional dependencies—truly achieving \"train once, run anywhere.\"\n\n---\n\n## 2. Breakthroughs and Innovations\n\nBrush introduces significant technical and architectural innovations:\n\n### ✅ Unified Cross-Platform Architecture\n- Replaces Vulkan/CUDA/DirectX with **WebGPU**, supporting multiple GPU architectures (NVIDIA/AMD/Intel/Apple Silicon).\n- Built on the **Burn framework** (a pure Rust ML framework), eliminating dependence on PyTorch/TensorFlow/CUDA and enabling dependency-free binary distribution.\n\n### ✅ Full-Platform Training Capability\n- Supports direct 3D training **on mobile devices (Android) and within web browsers**, not limited to high-end servers or PCs.\n- Enables real-time interactive previews during training, allowing dynamic observation of the reconstruction process—greatly improving user experience and debugging efficiency.\n\n### ✅ Multi-Format Support and Animation Extension\n- Compatible with COLMAP and Nerfstudio datasets.\n- Supports loading `.ply`, compressed `.compressed.ply` files, and `.zip`-packaged multi-frame or delta-frame data, enabling **4D dynamic scene playback** (e.g., `cat-4D`, `Cap4D` examples).\n- Supports alpha channels and mask-based training for improved reconstruction accuracy.\n\n### ✅ Zero-Dependency Distributability\n- Outputs standalone binaries or WASM modules; no need for Python, CUDA, or other runtime environments—ideal for embedded systems, mobile apps, and web deployment.\n\n### ✅ Superior Real-Time Performance\n- Outperforms mainstream solutions like gsplat in both rendering and training speed, with kernel-level performance testing available via `cargo bench`.\n\n---\n\n## 3. Entrepreneurial Ideas Based on This Project\n\nBrush provides a powerful and flexible foundation. Here are several highly promising startup directions:\n\n### 🚀 Startup Idea 1: **\"One-Tap 3D Scan\" App for Creators**\n- **Product Form**: Mobile app (Android/iOS) + Web tool\n- **Features**: Users take photos with their phone → automatic upload → 3D reconstruction using Brush on-device or in the cloud → generate shareable 3D model links\n- **Use Cases**:\n  - Cultural heritage digitization, e-commerce product modeling, virtual try-ons, AR content creation\n  - Education: Students scan specimens to create 3D models\n- **Advantage**: High-quality reconstruction using only a standard smartphone—no professional equipment needed\n\n### 🌐 Startup Idea 2: **Web-Based 3D Content Collaboration Platform**\n- **Product Form**: SaaS platform (think Figma for 3D)\n- **Features**:\n  - Upload images → train models directly in-browser → enable real-time collaborative viewing, annotation, and editing of 3D scenes\n  - Version control, animation playback, export to GLB/PDF/PLY\n- **Target Customers**: Architecture firms, game studios, metaverse content teams\n- **Tech Edge**: Leverages Brush’s WebGPU support to perform full training and collaboration entirely in the browser\n\n### 🎮 Startup Idea 3: **AI + AR Real-Time Reconstruction SDK**\n- **Product Form**: SDK for AR/VR developers\n- **Features**:\n  - Connect camera stream → real-time generation and updating of Gaussian Splatting scenes → render in Unity/Unreal\n  - Ideal for SLAM enhancement, spatial computing, and mixed reality (MR) applications\n- **Differentiator**: Faster than NeRF, more realistic than traditional mesh reconstruction—perfect for consumer-grade AR devices\n\n### 📦 Startup Idea 4: **Edge Computing 3D Modeling Device**\n- **Product Form**: Compact hardware device (Raspberry Pi–class)\n- **Features**:\n  - Plug in a camera or USB drive → automatically performs 3D reconstruction → outputs 3D models\n  - Designed for offline scenarios such as factory quality inspection, agricultural monitoring, or archaeological fieldwork\n- **Selling Point**: No cloud dependency, enhanced privacy, plug-and-play usability\n\n### 💡 Startup Idea 5: **AI Art Generation × 3D Printing Integrated Platform**\n- **Product Form**: Web + Mobile App\n- **Workflow**:\n  - Input text description → AI generates concept art → user captures reference object → Brush reconstructs base shape → AI enhances into artistic 3D model → one-click order for 3D printing\n- **Target Market**: Customized art pieces, collectibles, and personalized memorabilia\n\n---\n> 🔥 Summary: Brush is more than just a tech demo—it's the key to democratizing 3D content creation. Whoever can transform its cross-platform, zero-dependency, real-time training capabilities into intuitive, user-friendly products could become a gateway player in the next generation of the 3D content ecosystem.\n```",
    "text": "Brush\nBrushSizzleCompressedFrame.mp4\nMassive thanks to\n@GradeEterna\nfor the beautiful scenes\nBrush is a 3D reconstruction engine using\nGaussian splatting\n. It works on a wide range of systems:\nmacOS/windows/linux\n,\nAMD/Nvidia/Intel\ncards,\nAndroid\n, and in a\nbrowser\n. To achieve this, it uses WebGPU compatible tech and the\nBurn\nmachine learning framework.\nMachine learning for real time rendering has tons of potential, but most ML tools don't work well with it: Rendering requires realtime interactivity, usually involve dynamic shapes & computations, don't run on most platforms, and it can be cumbersome to ship apps with large CUDA deps. Brush on the other hand produces simple dependency free binaries, runs on nearly all devices, without any setup.\nTry the web demo\nNOTE: Only works on Chrome and Edge. Firefox and Safari are hopefully supported soon)\nFeatures\nTraining\nBrush takes in COLMAP data or datasets in the Nerfstudio format. Training is fully supported natively, on mobile, and in a browser. While training you can interact with the scene and see the training dynamics live, and compare the current rendering to input views as the training progresses.\nIt also supports masking images:\nImages with transparency. This will force the final splat to match the transparency of the input.\nA folder of images called 'masks'. This ignores parts of the image that are masked out.\nViewer\nBrush also works well as a splat viewer, including on the web. It can load .ply & .compressed.ply files. You can stream in data from a URL (for a web app, simply append\n?url=\n).\nBrush also can load .zip of splat files to display them as an animation, or a special ply that includes delta frames (see\ncat-4D\nand\nCap4D\n!).\nCLI\nBrush can be used as a CLI. Run\nbrush --help\nto get an overview. Every CLI command can work with\n--with-viewer\nwhich also opens the UI, for easy debugging.\nRerun\nrerun_dash_compressed.mp4\nWhile training, additional data can be visualized with the excellent\nrerun\n. To install rerun on your machine, please follow their\ninstructions\n. Open the ./brush_blueprint.rbl in the viewer for best results.\nBuilding Brush\nFirst install rust 1.88+. You can run tests with\ncargo test --all\n. Brush uses the wonderful\nrerun\nfor additional visualizations while training, run\ncargo install rerun-cli\nif you want to use it.\nWindows/macOS/Linux\nSimply\ncargo run\nor\ncargo run --release\nfrom the workspace root. Brush can also be used as a CLI, run\ncargo run --release -- --help\nto use the CLI directly from source. See the notes about the CLI in the features section.\nWeb\nBrush can be compiled to WASM. Run\nnpm run dev\nto start the demo website using Next.js, see the brush_nextjs directory.\nBrush uses\nwasm-pack\nto build the WASM bundle. You can also use it without a bundler, see wasm-pack's documentation.\nWebGPU is still an upcoming standard, and as such, only Chrome 134+ on Windows and macOS is currently supported.\nAndroid\nAs a one time setup, make sure you have the Android SDK & NDK installed.\nCheck if ANDROID_NDK_HOME and ANDROID_HOME are set\nAdd the Android target to rust\nrustup target add aarch64-linux-android\nInstall cargo-ndk to manage building a lib\ncargo install cargo-ndk\nEach time you change the rust code, run\ncargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build\nNb:  Nb, for best performance, build in release mode. This is separate\nfrom the Android Studio app build configuration.\ncargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/  build --release\nYou can now either run the project from Android Studio (Android Studio does NOT build the rust code), or run it from the command line:\n./gradlew build\n./gradlew installDebug\nadb shell am start -n com.splats.app/.MainActivity\nYou can also open this folder as a project in Android Studio and run things from there. Nb: Running in Android Studio does\nnot\nrebuild the rust code automatically.\nBenchmarks\nRendering and training are generally faster than gsplat. You can run benchmarks of some of the kernels using\ncargo bench\n.\nAcknowledgements\ngSplat\n, for their reference version of the kernels\nPeter Hedman, George Kopanas & Bernhard Kerbl\n, for the many discussions & pointers.\nThe Burn team\n, for help & improvements to Burn along the way\nRaph Levien\n, for the\noriginal version\nof the GPU radix sort.\nGradeEterna\n, for feedback and their scenes.\nDisclaimer\nThis is\nnot\nan official Google product. This repository is a forked public version of\nthe google-research repository",
    "readme": "# Brush\n\n<video src=https://github.com/user-attachments/assets/5756967a-846c-44cf-bde9-3ca4c86f1a4d>A video showing various Brush features and scenes</video>\n\n<p align=\"center\">\n  <i>\n    Massive thanks to <a href=\"https://www.youtube.com/@gradeeterna\">@GradeEterna</a> for the beautiful scenes\n  </i>\n</p>\n\nBrush is a 3D reconstruction engine using [Gaussian splatting](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/). It works on a wide range of systems: **macOS/windows/linux**, **AMD/Nvidia/Intel** cards, **Android**, and in a **browser**. To achieve this, it uses WebGPU compatible tech and the [Burn](https://github.com/tracel-ai/burn) machine learning framework.\n\nMachine learning for real time rendering has tons of potential, but most ML tools don't work well with it: Rendering requires realtime interactivity, usually involve dynamic shapes & computations, don't run on most platforms, and it can be cumbersome to ship apps with large CUDA deps. Brush on the other hand produces simple dependency free binaries, runs on nearly all devices, without any setup.\n\n[**Try the web demo** <img src=\"https://cdn-icons-png.flaticon.com/256/888/888846.png\" alt=\"chrome logo\" width=\"24\"/>\n](https://arthurbrussee.github.io/brush-demo)\n_NOTE: Only works on Chrome and Edge. Firefox and Safari are hopefully supported soon)_\n\n[![](https://dcbadge.limes.pink/api/server/https://discord.gg/TbxJST2BbC)](https://discord.gg/TbxJST2BbC)\n\n# Features\n\n## Training\n\nBrush takes in COLMAP data or datasets in the Nerfstudio format. Training is fully supported natively, on mobile, and in a browser. While training you can interact with the scene and see the training dynamics live, and compare the current rendering to input views as the training progresses.\n\nIt also supports masking images:\n- Images with transparency. This will force the final splat to match the transparency of the input.\n- A folder of images called 'masks'. This ignores parts of the image that are masked out.\n\n## Viewer\nBrush also works well as a splat viewer, including on the web. It can load .ply & .compressed.ply files. You can stream in data from a URL (for a web app, simply append `?url=`).\n\nBrush also can load .zip of splat files to display them as an animation, or a special ply that includes delta frames (see [cat-4D](https://cat-4d.github.io/) and [Cap4D](https://felixtaubner.github.io/cap4d/)!).\n\n## CLI\nBrush can be used as a CLI. Run `brush --help` to get an overview. Every CLI command can work with `--with-viewer` which also opens the UI, for easy debugging.\n\n## Rerun\n\nhttps://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c\n\nWhile training, additional data can be visualized with the excellent [rerun](https://rerun.io/). To install rerun on your machine, please follow their [instructions](https://rerun.io/docs/getting-started/installing-viewer). Open the ./brush_blueprint.rbl in the viewer for best results.\n\n## Building Brush\nFirst install rust 1.88+. You can run tests with `cargo test --all`. Brush uses the wonderful [rerun](https://rerun.io/) for additional visualizations while training, run `cargo install rerun-cli` if you want to use it.\n\n### Windows/macOS/Linux\nSimply `cargo run` or `cargo run --release` from the workspace root. Brush can also be used as a CLI, run `cargo run --release -- --help` to use the CLI directly from source. See the notes about the CLI in the features section.\n\n### Web\nBrush can be compiled to WASM. Run `npm run dev` to start the demo website using Next.js, see the brush_nextjs directory.\n\nBrush uses [`wasm-pack`](https://rustwasm.github.io/wasm-bindgen/introduction.html) to build the WASM bundle. You can also use it without a bundler, see [wasm-pack's documentation](hhttps://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html).\n\nWebGPU is still an upcoming standard, and as such, only Chrome 134+ on Windows and macOS is currently supported.\n\n### Android\n\nAs a one time setup, make sure you have the Android SDK & NDK installed.\n- Check if ANDROID_NDK_HOME and ANDROID_HOME are set\n- Add the Android target to rust `rustup target add aarch64-linux-android`\n- Install cargo-ndk to manage building a lib `cargo install cargo-ndk`\n\nEach time you change the rust code, run\n- `cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build`\n- Nb:  Nb, for best performance, build in release mode. This is separate\n  from the Android Studio app build configuration.\n- `cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/  build --release`\n\nYou can now either run the project from Android Studio (Android Studio does NOT build the rust code), or run it from the command line:\n```\n./gradlew build\n./gradlew installDebug\nadb shell am start -n com.splats.app/.MainActivity\n```\n\nYou can also open this folder as a project in Android Studio and run things from there. Nb: Running in Android Studio does _not_ rebuild the rust code automatically.\n\n## Benchmarks\n\nRendering and training are generally faster than gsplat. You can run benchmarks of some of the kernels using `cargo bench`.\n\n# Acknowledgements\n\n[**gSplat**](https://github.com/nerfstudio-project/gsplat), for their reference version of the kernels\n\n**Peter Hedman, George Kopanas & Bernhard Kerbl**, for the many discussions & pointers.\n\n**The Burn team**, for help & improvements to Burn along the way\n\n**Raph Levien**, for the [original version](https://github.com/googlefonts/compute-shader-101/pull/31) of the GPU radix sort.\n\n**GradeEterna**, for feedback and their scenes.\n\n# Disclaimer\n\nThis is *not* an official Google product. This repository is a forked public version of [the google-research repository](https://github.com/google-research/google-research/tree/master/brush_splat)\n",
    "author": "ArthurBrussee",
    "project": "brush",
    "date": "2025-09-18"
}