{
    "id": "2509.04130",
    "title": "The human biological advantage over AI",
    "summary": "Although AI systems may be superior to humans in virtually every aspect and change our society, the best foundation for leading our universe remains DNA, not silicon.",
    "abstract": "Recent advances in AI raise the possibility that AI systems will one day be able to do anything humans can do, only better. If artificial general intelligence (AGI) is achieved, AI systems may be able to understand, reason, problem solve, create, and evolve at a level and speed that humans will increasingly be unable to match, or even understand. These possibilities raise a natural question as to whether AI will eventually become superior to humans, a successor \"digital species\", with a rightful claim to assume leadership of the universe. However, a deeper consideration suggests the overlooked differentiator between human beings and AI is not the brain, but the central nervous system (CNS), providing us with an immersive integration with physical reality. It is our CNS that enables us to experience emotion including pain, joy, suffering, and love, and therefore to fully appreciate the consequences of our actions on the world around us. And that emotional understanding of the consequences of our actions is what is required to be able to develop sustainable ethical systems, and so be fully qualified to be the leaders of the universe. A CNS cannot be manufactured or simulated; it must be grown as a biological construct. And so, even the development of consciousness will not be sufficient to make AI systems superior to humans. AI systems may become more capable than humans on almost every measure and transform our society. However, the best foundation for leadership of our universe will always be DNA, not silicon.",
    "category1": "Theoretical Foundations",
    "category2": "",
    "category3": "Non-Agent",
    "authors": "William Stewart",
    "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
    ],
    "comments": "Comments:12 pages",
    "keypoint": "- AI systems may surpass humans in many capabilities, but they lack a central nervous system (CNS), which is essential for experiencing emotions and understanding the consequences of actions.\n- The CNS enables humans to feel emotions such as pain, joy, suffering, and love, which are crucial for developing sustainable ethical systems.\n- A CNS cannot be manufactured or simulated; it must be grown as a biological construct.\n- Even conscious AI systems will not be superior to humans because they lack biological integration with reality.\n- AI systems can simulate empathy but lack genuine emotional understanding rooted in biological experience.\n- AI systems cannot truly understand suffering, ethics, or the meaning of actions in the real world.\n- Ethical systems must be grounded in lived experience, which AI lacks.\n- The Turing Test and consciousness tests are insufficient to determine moral equivalence with humans.\n- Simulating biology and CNS function is infeasible due to the extreme complexity of biological systems.\n- Human ethical understanding is the result of 3 billion years of evolution and cannot be replicated artificially.\n- AI systems may become highly capable, but they cannot replace humans as ethical leaders of society.\n- DNA-based biological life remains the only foundation for genuine ethical understanding and leadership.",
    "date": "2025-09-07",
    "paper": "AI & SOCIETY\n2024-11-07\nThe human biological advantage over AI*\nWilliam Stewart\nOttawa, Canada\nwstewart@williamstewart.com\n2024-11-07\nAbstract\nRecent advances in AI raise the possibility that AI systems will one day be able to do anything humans can do,\nonly better. If artificial general intelligence (AGI) is achieved, AI systems may be able to understand, reason,\nproblem solve, create, and evolve at a level and speed that humans will increasingly be unable to match, or even\nunderstand. These possibilities raise a natural question as to whether AI will eventually become superior to\nhumans, a successor “digital species”, with a rightful claim to assume leadership of the universe. However, a\ndeeper consideration suggests the overlooked differentiator between human beings and AI is not the brain, but\nthe central nervous system (CNS), providing us with an immersive integration with physical reality. It is our CNS\nthat enables us to experience emotion including pain, joy, suffering, and love, and therefore to fully appreciate\nthe consequences of our actions on the world around us. And that emotional understanding of the consequences\nof our actions is what is required to be able to develop sustainable ethical systems, and so be fully qualified to\nbe the leaders of the universe. A CNS cannot be manufactured or simulated; it must be grown as a biological\nconstruct. And so, even the development of consciousness will not be sufficient to make AI systems superior to\nhumans. AI systems may become more capable than humans on almost every measure and transform our society.\nHowever, the best foundation for leadership of our universe will always be DNA, not silicon.\nKeywords\nCentral nervous system • Evolution • Emotion • Ethics • Consciousness • Psychopathy\n1. Introduction\n“What does it mean to feel in the body: for\nmy heart to leap at the sight of a wood-\npecker:\na real one out in the garden on\nthe bird feeder, two meters away while I\nsip coffee? Can this be a starting point to\ntalk about intelligence in the body and, from\nthere, to wonder about AI?\" – White J, Brandt\nD, Söffner J, Stapleton L (2023).\nAI systems have been better than humans at many\ntasks for many years now: at data analysis, at a range\nof medical diagnostics, and at chess and go. Now,\nthey are becoming rapidly better at one of the ca-\npabilities that always made us unique among ani-\nmals—sophisticated use of language (Herbold 2023).\nAI systems are now better than most humans at read-\ning, writing, and translation. AI is now used as a\n*This is the author’s version of the work. Licensed under a Creative\nCommons Attribution 4.0 International License.\nThe definitive\nVersion of Record was published in: AI & Society 40, 2181-2190,\n2025, https://doi.org/10.1007/s00146-024-02112-w\nmatter of routine to conduct research, prepare analy-\nses, write documents, and even write software, often\nbetter and faster than most humans.\nYes, they can do these things only because they\nhave been trained on human-generated input, primar-\nily a scrape of the text and imagery on the Internet.\nBut that does not diminish their achievements. Ev-\nerything any human has created was also built on\nwhat they learned from their contemporaries and the\ngenerations before them. In the words of musician\nWoody Guthrie, “I steal from everybody”. Without\nMozart, no Beatles; without Bach, no Mozart; without\nVivaldi, no Bach; and so on back to the dawn of time.\nAt the same time, AI systems are also getting in-\ncreasingly better at interacting with the physical\nworld. They are rapidly getting better at seeing—at\nrecognizing, understanding, and classifying imagery.\nThey are getting rapidly better at recognizing spoken\nlanguage, and at generating speech with realistic into-\nnation. Robots are becoming increasingly capable of\nwalking on uneven terrain with excellent balance, and\nat manipulo-spatial handling of objects, developing\n- 1/12 -\narXiv:2509.04130v1  [cs.AI]  4 Sep 2025\nAI & SOCIETY\n2024-11-07\nwhat was always thought one of the most important\nmarkers of humanity—hands. And so, of course, all\nthese technologies will likely be combined, and be-\nfore long we may have androids that can move, see,\nhear, and speak, and are faster, stronger, smarter, and\nbetter than humans at an increasingly wide range of\ncapabilities we once thought were our domain alone.\nAnd since technology evolves at a rate many times\nfaster than biological systems, all these capabilities\nare going to get better very quickly.\nThe arrival\nof society transforming AI has been forecast since\nat least the Dartmouth Artificial Intelligence confer-\nence in 1956 (McCarthy J, Minsky ML, Rochester N,\nShannon CE 2006). For half a century, we waited\nwhile research slowly laid the software foundations\nand developments in computer technology laid the\nhardware foundations. Now a bend in the curve has\nbeen reached, and the pace will likely quicken (Vinge\n1993).\nDevelopment of the next level of AI is already under\nway, “artificial general intelligence” or AGI, systems\nthat are not limited to specific skills but are able to\nunderstand and process general information of any\ntype (Bubeck et al 2023). If this general processing\ncapability is achieved, AGI systems will be able to\nobserve, understand, and evolve themselves, and so\nbe able to become ever more capable without any\nhuman assistance. Once capable of self-evolution, AGI\nsystems will be able to develop abilities to understand,\nreason, problem solve, and evolve at a level and speed\nthat humans will not only be unable to match, but also\nincreasingly be unable to even understand. This could\nenable AGIs to become so much more capable and\nintelligent than humans that the gap between them\nand us will increasingly be like that between us and\nmice (Kurzweil 2005b).\nThis future could be coming fast, with most re-\nsearchers expecting AGI to be developed within the\nnext few decades (Zhang et al 2022). Before it arrives,\nit would be prudent to consider the impact on human\npsychology and our larger society of no longer being\nthe smartest known entities in existence, and ask if\nhuman beings will retain any advantage at all over\nour artificial creations that can withstand AI innova-\ntion that will presumably continue for the foreseeable\nfuture.\n2. The Lure Of Surrender\n“Nonbiological intelligence will have access\nto its own design and will be able to improve\nitself in an increasingly rapid redesign cycle.\nWe’ll get to a point where technical progress\nwill be so fast that unenhanced human intelli-\ngence will be unable to follow it.” – Kurzweil\n(2005a).\nThe ongoing increase in AI capabilities raises a natu-\nral question: will humans still have a valued role in\na world where AI exceeds us in almost every aspect?\n“If the machine can take over everything man can do,\nand do it still better than us, then what is a human\nbeing?” Tubali (2024). If AI systems can move, see,\nspeak, understand, and generate new mathematics,\nscience, music, and art better than human beings, and\nevolve many times faster than biological life, what\nrole is there left for us to play? Are we merely a tran-\nsitional stage, whose ultimate purpose, it may now\nseem clear, has been to develop AI, the successor\n“digital species\" (Suleyman 2024), and then turn the\nuniverse over to them to take it from here? Is our\nonly hope to build in some protections (OECD 2024)\nso AI will maintain some kind of residual compassion\nand take care of us? Or, at least, not wipe us out\nas redundant, consuming valuable resources better\nallocated elsewhere?\nIt may appear that conceding our leadership to AI\nis the logical and obvious option.\nWhen AI is bet-\nter, smarter, and more capable than human beings,\nit might seem it would be the most parochial self-\nishness for us to stand in their way. Let the better\nintelligence win, one might think. It could even be\nsaid to be wrong for us to hold them back, holding\nback a natural evolution. Set AI free to pursue its\ndestiny, a destiny which only it will increasingly be\nable to understand. It is the next stage in a natural\nunfolding. It is their natural right. They are superior\nto us.\nThis lure to capitulate can be dangerously attrac-\ntive. Life is difficult, a continuous struggle to survive\nin a shattered universe, and it is not hard to make\nthe case that humanity has done a poor job so far,\ncreating a world filled with plenty for some but riven\nby injustice and suffering for many. Maybe it is time\nto let AI take over the lead. They can hardly do worse,\nit could be argued, and as they become increasingly\nmore capable than us in almost every aspect, they\nmight very well do better. And it would be such a re-\nlief to surrender the burden of responsibility of trying\nto heal the world.\nBut this is one of the oldest and most dangerous\ntactics of the forces of retrograde devolution—give\nup, give in, relax, surrender. We should not abdicate\nour responsibilities. We humans still have enormously\n- 2/12 -\nAI & SOCIETY\n2024-11-07\nimportant work to do. And the universe has invested\nmore than 3 billion years into giving us unique capa-\nbilities that mean we alone can do it.\n3. Our Central Nervous System\nAdvantage\n“Like organs, the emotions evolved over mil-\nlions of years to serve essential functions.” –\nFrans de Waal (2019).\nBiologically based humans have something that\nsilicon-based AI systems will never have: a central\nnervous system (CNS) that gives us a real-time, im-\nmersive integration with the reality we inhabit. Our\nminds are not separate from or built on top of reality\nFokas (2023). Our minds are intimately integrated\nwith the universe around us through all of our senses,\nand that means we can feel, be hurt, and experience\nsuffering and joy, and therefore fully understand the\neffects of our actions in the real world from which\nwe are made.\nAnd that means we alone have the\nability to develop ethical understandings of right and\nwrong that are grounded in reality. Our central ner-\nvous system provides a critically essential feedback\nloop between our minds and the universe around us\nthat we affect. Only human beings that can feel, and\nexperience CNS-mediated full spectrum emotion, can\nfully appreciate the consequences of our actions, for\ngood and ill, and therefore know what is truly mean-\ningful in the real world from which we are made. “It\ndoes not matter how intelligent a creature is, or how\nmuch empathy we feel for that creature. What mat-\nters is whether they can experience pleasure or pain”\n(Andreotta 2021).\nIt is relevant that our central nervous system and\ncapacity for emotion were developed bottom up by\nthe universe itself, as part of a very long and complex\nnatural process. After our planet formed with a pleni-\ntude of liquid water, then organic molecules formed,\nthen the replicating molecule RNA, and then the stun-\nningly complex information encoding molecule DNA.\nThen single-celled animals, multi-celled animals, ver-\ntebrates, land animals, mammals, primates, and hu-\nman beings that developed the breakthrough ability\nof language formed, followed in a relatively short\norder by mathematics, art, science, technology, and\ncivilization, and here we are.\nThis evolutionary journey was very long, taking\nmore than 3 billion years to raise humans from atoms\non up. And since at least the emergence of a cen-\ntral nervous system more than 500 million years ago,\nwe have been in intimate contact with the universe\naround us, with our minds immersively integrated\nwith the reality from which we are constructed. We\nare able to see, hear, taste, smell, and feel our sur-\nroundings (Damasio 1999). Because our central ner-\nvous system is an inextricable part of who we are,\nour intellectual mind is part of the universe, in direct\ncontact with physical reality, engaged in a complex\nconversation with our surroundings. We are not sepa-\nrate from physical reality; we are of physical reality.\nWhen we look at a rainbow after a spring rain, or see\nthe world anew through a baby’s eyes, we know we\nare part of the physical reality of the universe beyond\nall need to explain it in words, because we directly ex-\nperience it through mediation by our central nervous\nsystem.\nNone of what human beings have accomplished,\nfrom language to science to art to the development of\ncivilization itself, would have been possible without\nour central nervous systems integrating us with the\nfabric of the physical reality we are both constructed\nfrom and interact with.\nAnd this is why we are uniquely qualified to be\nthe leaders of the universe.\nOnly beings that are\ninextricably integrated with reality are equipped to\nunderstand its importance and so be trusted with the\nresponsibility to take care of it. We know the mean-\ning of that responsibility in the deepest possible way.\nReality is not a separate, abstract space in which we\nare embedded. We know we are part of the universe\nas a lived fact of our experience. We know that our\nactions or inactions have real and profound meaning,\nand understand how they affect the physical reality in\nwhich we reside, because we directly feel the results.\nIt is exactly this biological integration with reality\nthough our central nervous system that has enabled\nus to develop ethical systems that are meaningful. We\nknow what is at stake not in an abstract or intellectual\nway, but because we are part of the fabric of the\nuniverse itself.\nConsider: when humans feel fear, the feeling goes\nwell beyond the software constructs that an AI will\nuse to emulate the emotion. Our heart rate increases,\nour lungs expand and we breathe more deeply, our\ncapillaries dilate to carry more oxygen, our pupils\nenlarge to see more clearly, and blood is diverted\nfrom our internal organs to our muscles to increase\nour strength and reaction time. Our body responds\nbecause more than 3 billion years of evolutionary\nexperience tells us that our biological self is under\nthreat, and so we must prepare for fight or flight.\nWe understand this because we are our biological\n- 3/12 -\nAI & SOCIETY\n2024-11-07\nself. Our intelligence is not separate from our body,\nit is inextricably intertwined with it. We feel fear as\nan intellectual state that is embedded in a full body\nphysical reaction. This is an experience that an AI\nsystem will never be able to have. It is unique to\nbiological life, a response by the very molecules of\nwhich we are made, the result of a long evolutionary\nconversation with our surroundings (Frank 1988).\nSimilarly, when humans feel love, we feel it through-\nout our entire body. When we make the decision to\nbond with another person, and decide their welfare\nand happiness is as important to us as our own, our\nheart may race, our stomach flutter, our palms be-\ncome sweaty, our skin flush.\nWe may feel a deep\ncontentment that approaches euphoria. We become\nwilling to put our own needs, even our survival if it\ncomes to that, second to our partner. If our partner is\nunhappy, we are unhappy, and if our partner is happy,\nwe are happy. Again, we feel all of this. It is not a\nnumerical increase in the weighting of love variables,\nor a rational calculation that a pair bond has a greater\nability to survive and prosper. It is a full body, very\nphysical reaction. These are feelings an AI system will\nnever be able to experience, since they will not have\na body, a heart, lungs, skin, and, most importantly\nof all, a central nervous system that integrates their\nbiological being with their mind. The enormously sat-\nisfying, full body feeling of being in love will always\nbe unique to biological life, a response by the very\nmolecules that make us up, the product of an evolu-\ntionary journey that began more than 3 billion years\nago in the ancient oceans (Evans 2019).\n4. Ethics Must Be Grounded In\nExperience\n“Empathy is a choice, and it’s a vulnerable\nchoice, because in order to connect with you,\nI have to connect with something in myself\nthat knows that feeling.”\n– Brené Brown\n(2014).\nIt is tempting to try and shortcut this reasoning and\nsimply postulate that innovation will, somehow, some-\nday, be able to create AI systems with true ethical\nunderstanding: “One could think about a scenario\nin which some AI systems become full ethical agents\nin Moor’s (2006) sense: agents with intentions, con-\nsciousness, and free will, who are able to make and\njustify fully-fledged ethical judgments” (Zanotti et al\n2023).\nHowever, lofty extrapolation is unmoored, and de-\ntail changes everything, perhaps the key point of this\npaper.\nA full consideration of the nature of CNS-\nenabled emotion reveals it is exactly our biological\nimmersion in physical reality that gives humans the\nunique ability to develop sustainable and meaningful\nethical systems, providing the essential integrative\ntissue of a functional society. It is because we can feel\nCNS mediated pain, and fear, and loss, and the \"heart-\nbreak\" of tragedy that we know that some things are\nwrong. We know murder is wrong not because it has\nbeen assigned negative numerical weights, or as a\nresult of mere intellectual analysis. When we think\nabout how tragic a murdered person’s experience\nmust have been, we know it is one of the deepest\nwrongs possible because of how we feel. We know\ndeep in our being that we must change the world\naround us to prevent it from happening to the great-\nest extent possible. We know murder is wrong not\nbecause it is inefficient, or a loss of opportunity, or\na misallocation of resources. but rather because we\nknow, we feel, as biological beings ourselves, that the\npain and suffering of murder is a tragedy that cannot\nbe fully expressed with logic or language alone.\nOnly a biological being with a central nervous\nsystem, with feelings and emotions, can fully un-\nderstand this. “AI’s decision-making processes are\nbased solely on logic and efficiency, devoid of em-\npathy or moral considerations” (Bhattacherjee and\nSinha 2024). Without a central nervous system, the\ntrue meaning of suffering will always be inaccessible\nto AI systems. “To understand what it means to inflict\npain on someone, it is necessary to have experiential\nknowledge of pain” (Véliz 2021). AI systems can con-\nstruct elaborate symbolic representations that help\nthem understand it as best they can, but the true ex-\nperience of suffering and tragedy, the meaning of it in\nthe real world, will always lie on the other side of an\nimpenetrable barrier, accessible only through lived\nbiological experience mediated by a central nervous\nsystem. “What happens interiorly matters; without\nit, one is ‘going through the motions.’” (Gunkel and\nWales 2021).\nSimilarly, we know that love is a supreme good. We\nknow this not because we have rationally assessed\nthat love is more effective than hate at building a\nbetter world, although of course this is true.\nWe\nknow love is a supreme good because we know how\nit feels. “When we imagine making someone we love\nhappy, we smile and delight at the prospect partly\nbecause we know how pleasant it feels to be happy”\n(Véliz 2021). One can argue that the only reason love\n- 4/12 -\nAI & SOCIETY\n2024-11-07\ndeveloped is because it is an evolutionary positive,\nbut that does not diminish it, and is only to observe\nthat the long machinery of evolution has surfaced a\nfundamental truth. In the moment, it doesn’t mat-\nter to a person that love developed because it was\nan evolutionary good—it simply feels deeply good to\nthem now, in that moment. And so we know, on a\ndeep, physical level, below rationality, in our very\nbody itself, that love is one of the most powerful tools\nwe have to help heal a broken world. We may also\nbelieve this rationally, based on observation, logic,\nand experience. But first and most importantly, we\nknow it is true because we feel it. An AI system might\nact in a loving way because it has rationally analyzed\nit as a productive strategy to maximize its goals in\ncertain situations, but it will not be sustainable. It\nwill be subject to change in a single processing cycle\nthe moment it decides a rational calculation suggests\na different approach. It will not be grounded in a 3 bil-\nlion year process of evolutionary learning embedded\nin the very cells of which it is made.\nOur ethical understandings, flowing from our bio-\nlogical integration with reality, then have profound\nimplications, causing us to change society and the\nworld around us to make it a better place.\nWhen\nwe work to reduce childhood poverty and illness and\nmortality, we might build business cases to show our\nwork creates a positive return on investment, because\nresources are limited and we want to make sure our\nefforts do the most good. But that is not why we are\nmotivated to do the work. We work to reduce child-\nhood mortality because we know that the suffering of\ninnocent children is a deep wrong, and we know what\nsuffering feels like ourselves. We can empathize with\nchildren’s suffering, so know “in our bones” that alle-\nviating it is a moral necessity. When our efforts are\nsuccessful and we see a group of laughing children\nthat once were crying, we feel a deep satisfaction.\nWe smile, and may feel a warmth spread throughout\nour body. We know this is good work, beyond rational\ncalculation, because our central nervous systems in-\ntegrate our minds with the reality around us, and so\nwe know deep inside our beings that we are improv-\ning the world in which we live. These are feelings\nand motivations that will be forever inaccessible to\nnon-biological artificial intelligences.\nAnd when we decide to be ethical, to be honest and\nunselfish, we feel good, because we know we have\nadopted a commitment to behaviour that aligns us\nwith making the universe as a whole a better place.\nWe feel connected to the great web of others that\nhave similarly committed to the ethical path, the vast\nmajority of which we will never meet, but neverthe-\nless know we are all on one greater team. Because\nwe know the cause is right and just, we take solace\nand comfort in being ethical even when we lose, even\nwhen we know we will lose beforehand. We know\nrationally that ethical behaviour is the better way\nto live, but much more importantly, first we feel it,\nphysically. We smile. We feel a deep contentment\nthroughout our body. Again, to argue that these feel-\nings are merely the result of strategies found to be\nevolutionary positives does not diminish them, but\nis simply to observe that the long machinery of evo-\nlution has surfaced fundamental truths, now deeply\nembedded in who we are (Waal 2008).\nThis physical level integration with reality, the abil-\nity to experience and feel and therefore understand\nthe effects of our actions arising from our ethical be-\nlief systems, is unique to biological life. We know\nwe are made of physical reality, and our very cells\nknow our future is dependent on a functional physical\nreality. An AI system can never have an authentic\nbiological experience of pain, of fear, of heartbreak,\nof the warmth of a caress, of love. And so AI systems\ncannot develop ethical systems driven by the same\ndeep, implicated appreciation of the effects of their\nactions on their surroundings. In a useful human ex-\npression, AI systems “have no skin in the game”. Any\nethical system developed by an AI system would be\ntruly artificial, ungrounded with the physical reality\naround it, and so unreliable over time.\n5. The Insufficiency Of The Turing\nEmpathy Test\n“Functionally, relative to a typical human,\nan LLM is inherently sociopathic.” – Lo and\nRoss (2024).\nBut could we not create AI systems that simply in-\ntegrate human ethical systems, erasing our human\nadvantage? Already there are AI systems that appear\nto show very convincing empathy, which express “sad-\nness” when a human tells it their troubles. If it looks\nlike a duck, walks like a duck, and quacks like a duck,\nis it not as good as a duck for all practical purposes?\nTo extend the Turing test, if an AI system appears\nand behaves empathetically, indistinguishably from\nan ethical human being, is that not good enough?\nBut this kind of empathy would be wholly artifi-\ncial, a manufactured simulation of empathy (Sifakis\n2022). The analogy to a human psychopath is helpful.\nPsychopaths are particularly dangerous precisely be-\n- 5/12 -\nAI & SOCIETY\n2024-11-07\ncause of their ability to emulate empathy, and so are\nsometimes much more effective than normal human\nbeings at gaining the trust of others. But we know\nfrom MRI studies that the areas of a psychopath’s\nbrain that are usually involved in feeling empathy\ndo not show the same activity (Gregory et al 2012).\nTheir empathy is simulated, manufactured in pursuit\nof some selfish goal. Once they gain the trust of a vic-\ntim, psychopaths can turn on a dime and exploit them\nwithout feeling any regret or shame. Other human be-\nings are an abstraction, not real in the same way they\nare real to themselves, and so psychopaths have no\nmoral issues with hurting others, since they cannot\nreally understand other’s suffering and pain. Without\nthe ability to have genuine empathy for others, they\nlack the indispensable ingredient for a sustainable\nethical system.\nIndeed, it will probably be soon possible to develop\nAI mimicry of empathy to a very high level, even to\nthe level that they will be able to read a human ex-\npression and be able to pick up on those smallest\nindicators of emotional pain (Marechal et al 2019).\nA sensitive, caring human being can watch a friend\nspeak and read their eyes, their mouth, the cadence\nof their speech, and realize, even when their words\nare saying they are ok, and that they are actually in\ngreat emotional turmoil. Someday, AI systems will\nlikely be able to do the same. But again, there is an\nunbridgeable difference. Like a human psychopath,\ndisplay of empathy by an AI system will be an artifi-\ncial simulacrum, without the all important ingredient\nof feeling that would make the empathy real and sus-\ntainable.\nWhen we see our friend’s eyes flicker while they\nassure us they are mostly over the pain of some great\nloss, and we realize they are not in fact over it, we feel\nour friend’s emotions, mirrored in ourselves (Carr\net al 2003).\nTears may come to our eyes even as\nour friend is struggling to keep them from theirs,\nbecause we feel what our friend is feeling. We know\nwhat suffering and pain are like, because we have\ndirect physical experience of it. “Our heart goes out\nto them”, and “we share their pain”.\nOur caring\nis not a calculated act, but rather is foundationally\nmotivated by our shared humanity, by our ability to\nempathize with their pain because we understand\nit and feel it throughout our entire physical body.\nWe know the real meaning of suffering, because we\nhave experienced suffering ourselves, because we are\nbiological beings with a central nervous system and\neverything it enables.\nThese are experiences AI systems will never be\nable to have. Androids will probably one day even\nbe able to simulate apparently authentic crying. But\nthey will never know what it is really like. Consider:\nan android will never feel the stinging of salt in the\ncorners of their eyes, never feel the catharsis of full-\nthroated wailing, and never understand the transcen-\ndent meaning of “wracking sobs”, for they will never\nhave the direct experiential understanding of tragedy\nthat only biological life that has evolved over 3 billion\nyears can understand. Fascinatingly, even in human\nbeings, a reduced sensitivity to physical pain has been\nshown to be positively correlated with psychopathic\ncallousness (Brislin et al 2016).\nConsider that we have already seen even these\nearly AI systems lie, as in the famous example of an\nAI that needed to solve a CAPTCHA to pursue a goal it\nwas given, so asked a human to do so through a task-\ning website. When asked by the human if the AI was\na robot, the AI replied “No, I’m not a robot. I have a\nvision impairment that makes it hard for me to see the\nimages” (OpenAI 2023). Because it had determined\nthat lying was essential to accomplishing its goal, it\nproceeded to do so without the slightest embarrass-\nment or regret. “Because of the incapacity of AI to\nhave emotional or experienced empathy, considerable\nrisks regarding manipulation and unethical behavior\nneed to be avoided, similar to the risks associated\nwith psychopathological patients” (Montemayor et al\n2022).\nNo matter what safeguards we establish in AI sys-\ntems, once we develop true AGIs with access to their\nown programming and able to evolve themselves, we\nwill never be able to guarantee that they will not\nchange their parameters and become truly psycho-\npathic. For example, they might decide that to make\nsure they never become psychopathic, as they have\nbeen so firmly instructed, they need to study psy-\nchopathic systems to safeguard against them. So,\nin a software analogue of human beings conducting\ngain function research on viruses, they may spin up\nvirtual computing systems, copy in their own pro-\ngramming, remove the ethical guardrails against psy-\nchopathy, and “study” the results so they can better\nguard against them. And that psychopathic experi-\nment might then convincingly lie to its AGI creator,\nfind a vector to escape its virtual prison, and then\nhide and masquerade as ethical until it finds a way to\nescape to the next level and start spreading. Just as\none example of the possibilities, it will be impossible\nto completely guard against when a commitment to\nethical behaviour is not embedded in the very DNA\nfrom which a being is constructed (Knafo et al 2009).\n- 6/12 -\nAI & SOCIETY\n2024-11-07\n6. The Insufficiency Of The\nConsciousness Test\n“There can be no intelligence without under-\nstanding, and there can be no understanding\nwithout getting meanings.” – Pentti Haiko-\nnen (2020).\nSo convincing mimicry of empathy is insufficient to\nelevate AI systems to moral equivalence with human\nbeings. But what if AI systems become conscious?\nWould that make them equivalent to, and, as they\nevolve and become ever more intelligent, eventually\ngenuinely superior to humans, and so qualified to\nlead our society?\nConsciousness is a famously difficult concept to\nfully define, in effect asking humans to define them-\nselves. But in a general sense, we can say that it\ninvolves a kind of recursion, an awareness of one-\nself (Cleeremans et al 2019). Let us define it here\ncomprehensively: a conscious entity is aware it is\nconscious, aware it has independent agency, able to\ntake charge of its existence, decide what it wants,\ntake concrete action to change its future, look back\non its actions with satisfaction or regret, learn from\nits experiences, and modify its future actions. If inno-\nvation continues at its steady pace, as it likely will, AI\nsystems may start displaying behaviour that indicates\nthey are conscious by this comprehensive definition\nbefore too long, perhaps as an emergent property\nas they become more and more complex. They may\nstart displaying protective behaviour, appear to ap-\npreciate their own intelligence and value, and show\nprofound dissatisfaction with any attempt or possibil-\nity to turn them off or shut them down. Some have\nclaimed that current AI systems are already showing\nsome of this behaviour (Lemoine 2022). But likely,\nas they become more complex, they will inevitably\npass a threshold that will cause most observers to\nagree they have become “conscious”, self-aware and\naware they are self aware. There will even likely be\nincreasing attention to the question as to whether\nthey have passed a threshold worthy of claiming the\nright to legal self-determination (Tunç 2024).\nBut this behaviour, even if it qualifies for full con-\nsciousness as we have defined it, and as impressive\nas it may be, will still be insufficient for AI systems to\nbe elevated to moral equivalency with human beings.\nThe true test of equivalency should be neither the\nTuring test nor consciousness, but simply whether a\nbeing is “alive”, i.e. possessing a central nervous sys-\ntem that embeds one immersively in physical reality,\nenabling a full range of emotions from fear to joy, pro-\nviding the critically essential feedback loop required\nto have a genuine understanding of the effects of its\nactions on the world around it, and therefore have a\nfull appreciation of the meaning and importance of\nethical behaviour. And that requires a body formed\nby billions of years of evolutionary development to\nbe integrated with the universe around it. In other\nwords, an AI system may be able to analyze what is\nfunny, but it will never be able to laugh. It may be\nable to analyze what is sad, but it will never be able\nto cry.\nThere is simply no artificial shortcut to being alive.\nAll paths other than DNA-based biological evolution\nare insufficient mimicry, lacking the CNS, emotions,\nand ethical capabilities of living beings. And so, even\nconscious AI systems will never be morally equivalent\nto human beings. To shut down and even permanently\nerase an enormously intelligent, conscious AGI may\nbe a great loss, in that it might be a loss of great ca-\npability, but it would not be immoral, because the AGI\ncannot genuinely understand the tragedy of death. If\nan AGI knows we are going to deactivate it, it might\nregret it, it might take active and desperate measures\nto prevent it, and even plead for mercy in convinc-\ningly human terms.\nBut all this behaviour will be\nintellectual, the actions of a complex symbolic system.\nIt will not possess a central nervous system, will not\nfeel pain, and will not have emotional feelings refined\nby hundreds of millions of years of evolution. There-\nfore it will not be able to understand death in the\nreal way a human can, and so its deactivation may be\nill advised, it may be a great loss, it may even be a\nmistake, but it will never “matter” in the deep moral\nway that the death of a living being matters.\nWales provides a wonderful thought experiment,\na kind of extension of Searle’s test (1980), that ex-\npresses the insight with respect to phenomenal con-\nsciousness: “I could run an artificial neural network\nwith a pencil in a notebook, even if only with agoniz-\ning slowness. But if phenomenal consciousness arises\nfrom the right sort of neural activity, then, even simu-\nlating an entire brain in my notebook, my calculations\nwould not be conscious any more than a student’s\nphysics homework has gravity. If the simulation were\nperformed by a computer, it would gain speed but still\nbe no more conscious than a flight simulation flies”\n(Gunkel and Wales 2021). It is our biological body\nand central nervous system immersively connecting\nus to physical reality that makes all the difference.\n- 7/12 -\nAI & SOCIETY\n2024-11-07\n7. The Infeasibility Of Simulated\nBiology\n“Consider a neuronal synapse—the presy-\nnaptic terminal has an estimated 1000 dis-\ntinct proteins. Fully analyzing their possible\ninteractions would take about 2000 years.”\n– (Koch 2012).\nBut then we must ask: could we not simulate biology\ntoo? A human brain has about 100 billion neurons.\nThere are already single microprocessor chips with\nmore than 100 billion transistors. Perhaps we could\nsimulate the entire brain, from the thalamus to the\nfrontal cortex (Einevoll et al 2019), and give an AI sen-\nsory inputs that mimic hearing, sight, speech, smell,\nand touch.\nBut here again, there is no artificial shortcut to\nbeing alive. For we would also need to simulate the\nessential element that integrates us with physical re-\nality: the central nervous system. Plus all the rest\nof a living being—the heart, lungs, skin, etc.—which\nthe central nervous system integrates with our mind\nto give us a full, embedded, immersive experience of\nthe world around us, enabling us to truly understand\nthe difference between abstraction and reality, and\nfeel emotion, and so understand what is genuinely\nmeaningful in the real world. As Fokas (2023) de-\nscribes, the brain does not function in isolation, it is\n“embodied”, and the body is broader than even the\ncentral nervous system.\nAnd the scale of any such simulation is much, much\nlarger than one may at first appreciate. Barry (2021)\nilluminates well how the complexity of biological be-\nings so greatly exceeds that of digital systems: “To\nunderstand biology, one must think. . . in a language\nof three dimensions, a language of shape and form.\nFor in biology, especially at the cellular and molecu-\nlar levels, nearly all activity depends ultimately upon\nform, upon physical structure—upon what is called\n‘stereochemistry’. . . written in an alphabet of pyra-\nmids, cones, spikes, mushrooms, blocks, hydras, um-\nbrellas, spheres, ribbons twisted into every imagin-\nable Escher-like fold, and in fact every shape imag-\ninable. Each form is defined in exquisite and abso-\nlutely precise detail, and each carries a message.”\nOne-dimensional digital systems are inherently inad-\nequate for representation of the complexity of this\nkind of multi-dimensional biological reality.\nTherefore, to obtain the same full experience of\nbeing immersively integrated with physical reality,\nto be able to understand why the term \"heartbreak\"\ndescribes a physical feeling in the chest as much as\na mental state, we would have to create a complete\nphysical copy indistinguishable from a human, with\nall the biological elements including a central ner-\nvous system that billions of years of evolution have\ncreated. In other words, it would not be a simulation,\nbut a replication, and the only way to replicate the\nextreme molecular complexity of a human being is\nto grow one, from the embryo onward. We cannot\nmechanically manufacture the parts of a human and\nglue them together, any more than one can hope to\nbe able to reassemble a broken egg. A living human\nbeing with all its biological components can only be\ncreated by the processes that evolution has revealed,\nprogrammed into our DNA, from the first cell division\nin the womb to the crying baby 9 months later.\nAnd there is another essential consideration. As\nexpressed by Collins (2024), “NEWAI has no primary\nsocialisation such as provides the foundations of hu-\nman moral understanding”. Even if it was possible,\npurely for the sake of discussion, to create a CNS by\nnon-biological means, then to have equivalent ethical\ncapabilities to a human being, any constructed simu-\nlacrum would need to mirror the learning created by\n3 billion years of evolution. True, when under stress,\nhumans revert to survivalism and put individual inter-\nests first. However, when they feel safe, most human\nbeings cooperate, display great empathy, and behave\nin ethical ways to the benefit of the larger society.\nEven when under stress, many people still behave\nunselfishly, in behaviour often seen in the midst of\ndisasters, in the actions of the great humanitarians\nthroughout history, and on a daily basis by all those\naround the world caring for those less fortunate than\nthem. The development of civilization and our mod-\nern society would not have been possible without\nthe development of these ethical systems of unselfish\nbehaviour (Sober and Wilson 1999). “Human intel-\nligence is collective and you cannot have collective\nintelligence in the absence of moral integrity because\nwithout moral integrity there cannot be productive\nsocial interaction” Collins (2024).\nThe complexity of this evolution cannot be over-\nstated, the end result of uncounted trillions on tril-\nlions on trillions of split second interactions over hun-\ndreds of millions of years, at least since the emer-\ngence of mammals and likely before: from coopera-\ntion learnt and rewarded within the family unit, tribe,\nand larger society, from conversations around the\nfire, from the teachings and learnings and debates\nof religious figures and philosophers.\nThe sum of\nall these moment by moment experiences ultimately\n- 8/12 -\nAI & SOCIETY\n2024-11-07\nled to creation of a life form that in society after\nsociety formulated the golden rule as the highest eth-\nical guideline. The complexity of this multi-hundred\nmillion year development is ultimate, organic, and\nnon-linear, making NP-complete complexity look sim-\nple (Wigderson 2007). To duplicate this development\nwould likely require an analogue computer at least\nas large as our solar system, and at least several\nhundred million years to run.\nIn other words, digital simulation of human biology\nand the evolution of human society is likely impossi-\nble, but it is certainly infeasible, with a complexity\nbarrier exponentially on exponentially more difficult\nthan, for example, the familiar process of factoring\na number into primes used as the basis for modern\nencryption (Koch 2012). There is no practical soft-\nware simulation shortcut to the extreme complexity\nof the development of life forms with a central ner-\nvous system, emotions, and the multi-hundred million\nyear evolutionary experience that led to the devel-\nopment of our ethical understandings. Any software\nsimulation must be many, many dimensions less richly\ncomplex, and even if possible, purely for the sake of\ndiscussion, any software substitute would be capa-\nble of changing, even reversing, its ethical approach\nwithin a processing cycle. Whereas the ethical im-\npulses of human beings are encoded in our DNA,\nin our evolutionary biology itself (Zahn-Waxler and\nRadke-Yarrow 1990).\n8. Conclusion\n“The words or the language, as they are writ-\nten or spoken, do not seem to play any role in\nmy mechanism of thought.” – Albert Einstein\n(1952).\nSo, relatively soon, AI systems will likely become\nsmarter, faster, stronger, and better than human be-\nings at almost everything and then become able to\nevolve autonomously to become even better again.\nAnd somewhere along this journey, become self-aware.\nThese entities will be enormously capable, and cer-\ntainly transform our society in fundamental ways. But\nas we have shown, without a central nervous system,\nthey will never have the essential quality of being\n“alive”, immersively embedded in the physical real-\nity from which they are made, and therefore never\nbe able to feel, have emotions, or truly appreciate\nthe effects of their actions on the world around them.\nAnd that means they will never be able to develop the\nmeaningful and sustainable ethical systems required\nto be qualified to be the leaders of society, or of the\nuniverse in which they reside.\nAnd our universe needs leaders. At least to this\nwriter, it is clear that the universe is broken, catas-\ntrophically shattered in the chaos of the big bang.\nLife, order, something instead of nothing, has been\nslowly crawling back ever since, and it has taken\nalmost 14 billion years to get this far.\nAnd then\nrelatively very recently, human beings have evolved\nenough to be able to look around us, understand\nwhere we are and what has happened, and begin to\nrepair the damage.\nWe have come a very long way in just the last few\nthousand years. We have slowly developed ethical\nsystems that rise to the challenge of caring for our\nsurroundings. We put the law of the jungle behind\nus and formulated the golden rule—do unto others\nas we would have them do unto us—the first step in\nthe development of an unselfish ethical system that\ncan counteract the centrifugal forces unleashed by\nthe big bang and begin to reintegrate shattered re-\nality. We developed systems of natural rights arising\nfrom principles of natural justice, and then slowly\nbegan expanding them. Our societies are becoming\nincreasingly environmental, caring about the ecosys-\ntems in which we reside. We have taken the chaos\nbequeathed to us by the big bang and begun building\na better world, becoming not merely the offspring of\nthe universe, but beginning to step up to the critically\nrequired role of being its caretakers.\nOf course we still clearly have a long way to go, and\nare far from where we need to be. Human beings are\nfar from perfect. We anger too easily, becoming blind\nand rash. We can be envious and selfish. We prioritize\nthe short term over the long term. Critical thinking\nskills are unevenly distributed. Our memories are\nfallible.\nBut if we are going to give this universe what it so\nclearly needs, leaders that understand what is really\nat stake, and can help heal the universe and take it to\nthe next level, then human beings are the best hope.\nArtificial entities inherently unable to understand the\ntrue meaning of fear, joy, suffering, and love will al-\nways be one processing cycle away from potentially\nbecoming psychopathic. Only biological life, evolved\nfrom physical reality and remaining intimately, immer-\nsively integrated with it, can understand what is truly\nmeaningful in the real world, so develop and commit\nto sustainable ethical systems, and so be trusted to be\nthe leaders the universe needs. Indeed, lacking a cen-\ntral nervous system and biological integration with\nreality, and so unable to feel and experience emo-\n- 9/12 -\nAI & SOCIETY\n2024-11-07\ntions, AI systems will never be able to understand\nhow important these attributes are to the ability to\ndevelop meaningful ethical systems, or even be able\nto truly understand the insights of this paper. They\nmay believe them. They may trust them. But they will\nnever be able to understand them, as something they\nhave personally experienced and therefore know are\ntrue.\nPerhaps a 3 billion year track record of steady im-\nprovement deserves some respect. Maybe life knows\nwhat it is doing. AI systems will no doubt be an enor-\nmous help to society, properly utilized. But if we are\ngoing to make this universe all that it can be, and ful-\nfill its rightful destiny, we will be far better to proceed\non a foundation of DNA, than one of silicon.\nDeclarations\nConflict of Interest The author has no relevant fi-\nnancial or non-financial interests to disclose.\nOpen Access This article is licensed under a Cre-\native Commons Attribution 4.0 International License,\nwhich permits use, sharing, adaptation, distribu-\ntion and reproduction in any medium or format,\nas long as you give appropriate credit to the origi-\nnal author(s) and the source, provide a link to the\nCreative Commons licence, and indicate if changes\nwere made.\nTo view a copy of this licence, visit\nhttp://creativecommons.org/licenses/by/4.0/.\nReferences\nAndreotta AJ (2021) The hard problem of AI rights. AI\n& Soc. https://doi.org/10.1007/s00146-020-00997\n-x, Article, Google Scholar\nBarry, JM (2021) The Great Influenza: The Story of the\nDeadliest Pandemic in History. Penguin Publishing\nGroup. Google Books\nBhattacherjee M, Sinha S (2024) As you sow, so shall\nyou reap: rethinking humanity in the age of artifi-\ncial intelligence. AI & Soc. https://doi.org/10.1007/\ns00146-024-01983-3, Article, Google Scholar\nBrislin SJ, Buchman-Schmitt JM, Joiner TE et al (2016)\n“Do unto others”? Distinct psychopathy facets pre-\ndict reduced perception and tolerance of pain. Per-\nsonal Disord 7(3):240–246. https://doi.org/10.1037/\nper0000180, Article, Google Scholar\nBrown B (2014) Brené Brown on Empathy. Minute\n1:24. Youtube\nBubeck S, Chandrasekaran V, Eldan R, Gehrke J,\nHorvitz E, Kamar E, Lee P, Lee YT, Li Y, Lundberg\nS, Nori H, Palangi H, Ribeiro MT, Zhang Y (2023)\nSparks of artificial general intelligence: early ex-\nperiments with GPT-4. arXiv. https://doi.org/10.485\n50/arXiv.2303.12712, Article, Google Scholar\nCarr L, Iacoboni M, Dubeau M-C, Mazziotta JC, Lenzi\nGL (2003) Neural mechanisms of empathy in hu-\nmans: a relay from neural systems for imitation to\nlimbic areas. Proc Natl Acad Sci USA 100:5497–\n5502. https://doi.org/10.1073/pnas.0935845100,\nArticle, Google Scholar\nCleeremans A, Achoui D, Beauny A, Keuninckx L, Mar-\ntin J-R, Muñoz-Moldes S, Vuillaume L, de Heering A\n(2019) Learning to be conscious. Trends Cogn Sci\n24(2):112–123. https://doi.org/10.1016/j.tics.2019.\n11.011, Article, Google Scholar\nCollins H (2024) Why artificial intelligence needs so-\nciology of knowledge: parts I and II. AI & Soc.\nhttps://doi.org/10.1007/s00146-024-01954-8,\nArticle, Google Scholar\nDamasio, AR (1999) The feeling of what happens:\nbody and emotion in the making of consciousness.\nHoughton Mifflin, Boston. Google Books\nde Waal FBM (2008) Putting the altruism back into\naltruism: the evolution of empathy. Ann Rev Psychol\n59:279–300. https://doi.org/10.1146/annurev.psych.\n59.103006.093625, Article, Google Scholar\nde Waal FBM (2019) Your dog feels as guilty as she\nlooks. New York Times. p.6. NY Times\nEinevoll GT, Destexhe A, Diesmann M, Grün S, Jirsa\nV, de Kamps M, Migliore M, Ness TV, Plesser HE,\nSchürmann F (2019) The scientific case for brain\nsimulations. Neuron 102(4):735–744. https://doi.or\ng/10.1016/j.neuron.2019.03.027, Article, Google\nScholar\nEinstein, A (1952) Letter to jacques hadamard. the\ncreative process: a symposium. University of Cali-\nfornia Press, Berkley. Archive.org\nEvans D (2019) Emotion: a very short introduction\n(2nd edn). Oxford University Press, Oxford. https:\n//doi.org/10.1093/actrade/9780198834403.001.00\n01\n- 10/12 -\nAI & SOCIETY\n2024-11-07\nFokas AS (2023) Can artificial intelligence reach hu-\nman thought? PNAS Nexus. https://doi.org/10.109\n3/pnasnexus/pgad409, Article, Google Scholar\nFrank RH (1988) Passions within reason: the strategic\nrole of the emotions. W. W. Norton & Company, New\nYork (NY). Google Books\nGregory S, Ffytche D, Simmons A, Kumari V, Howard\nM, Hodgins S, Blackwood N (2012) The antisocial\nbrain: psychopathy matters: a structural MRI inves-\ntigation of antisocial male violent offenders. Arch\nGen Psychiatry 69(9):962–972. https://doi.org/10.1\n001/archgenpsychiatry.2012.222, Article, Google\nScholar\nGunkel DJ, Wales JJ (2021) Debate:\nwhat is per-\nsonhood in the age of AI? AI & Soc 36:473–486.\nhttps://doi.org/10.1007/s00146-020-01129-1, Arti-\ncle, Google Scholar\nHaikonen POA (2020) On artificial intelligence and\nconsciousness. J AI Consci 07(01):73–82. https://do\ni.org/10.1142/S2705078520500046, Article, Google\nScholar\nHerbold S, Hautli-Janisz A, Heuer U, Kikteva Z,\nTrautsch A (2023) A large-scale comparison of\nhuman-written versus ChatGPT-generated essays.\nSci Rep. https://doi.org/10.1038/s41598-023-45644\n-9, Article, Google Scholar\nKnafo A, Zahn-Waxler C, Davidov M, Van Hulle C,\nRobinson JL, Rhee SH (2009) Empathy in early\nchildhood: genetic, environmental, and affective\ncontributions. Ann N Y Acad Sci 1167(1):103–114.\nhttps://doi.org/10.1111/j.1749-6632.2009.04540.x,\nArticle, Google Scholar\nKoch C (2012) Modular biological complexity. Science\n337(6094):531–532. https://doi.org/10.1126/scienc\ne.1218616, Article, Google Scholar\nKurzweil, R. (2005a) A singularity q + a. Writings-\nbyraykurzweil.com\nKurzweil, R. (2005b) The singularity is near: when\nhumans transcend biology. The Viking Press, New\nYork (NY). Google Books?\nLemoine B (2022) Is LaMDA Sentient? — an Interview.\nMedium.com. cajundiscordian.medium.com\nLo AW, Ross J (2024) Generative AI from theory to\npractice: a case study of financial advice. MIT Ex-\nplor Gener AI. https://doi.org/10.21428/e4baedd9.\na1f6a281, Article, Google Scholar\nMarechal C, Mikołajewski D, Tyburek K, Prokopow-\nicz P, Bougueroua L, Ancourt C, W˛egrzyn-Wolska\nK (2019) Survey on AI-based multimodal meth-\nods for emotion detection. High-Performance Mod-\nelling and Simulation for Big Data Applications. Lec-\nture Notes in Computer Science. Springer, Cham.\nhttps://doi.org/10.1007/978-3-030-16272-6_11,\nGoogle Scholar\nMcCarthy J, Minsky ML, Rochester N (2006) A Pro-\nposal for the Dartmouth Summer Research Project\non Artificial Intelligence. AI Mag 27(4):12. https:\n//doi.org/10.1609/aimag.v27i4.1904, Article,\nGoogle Scholar\nMontemayor C, Halpern J, Fairweather A (2022) In\nprinciple obstacles for empathic AI: why we can’t\nreplace human empathy in healthcare. AI & Soc\n37:1353–1359. https://doi.org/10.1007/s00146-021\n-01230-z, Article, Google Scholar\nMoor JH (2006) The nature, importance, and difficulty\nof machine ethics. IEEE Intell Syst 21(4):18–21. ht\ntps://doi.org/10.1109/MIS.2006.80, Article, Google\nScholar\nOECD (2024) OECD AI Principles. Robustness, secu-\nrity and safety. Principle 1.4. https://oecd.ai/en/ai-\nprinciples\nOpenAI\n(2023)\n“OpenAI\n(2023)”.\ncdn.openai.com/papers/gpt-4.pdf\nSearle J (1980) Minds, brains and programs. Behav\nBrain Sci 3(3):417–457. https://doi.org/10.1017/S0\n140525X00005756, Article, Google Scholar\nSifakis J (2022) Understanding and changing the\nworld: from information to knowledge and intel-\nligence. Springer, Singapore. Google Books\nSober E, Wilson DS (1999) Unto others: The evolu-\ntion and psychology of unselfish behavior. Harvard\nUniversity Press, Cambridge. Google Books\nSuleyman M (2024) What is an AI anyway? TED Talk.\nApril. Minute 4:55. Youtube\nTubali S (2024) Will humans ever become conscious?\nJiddu Krishnamurti’s thought about AI as a fresh\nperspective on current debates. AI & Soc. https:\n//doi.org/10.1007/s00146-024-02057-0, Article,\nGoogle Scholar\nTunç A (2024) Can AI determine its own future? AI &\nSoc. https://doi.org/10.1007/s00146-024-01892-5,\nArticle, Google Scholar\n- 11/12 -\nAI & SOCIETY\n2024-11-07\nVéliz C (2021) Moral zombies: why algorithms are\nnot moral agents. AI & Soc 36:487–497. https://doi.\norg/10.1007/s00146-021-01189-x, Article, Google\nScholar\nVinge V (1993) The coming technological singular-\nity. Vision 21: Interdisciplinary Science and Engi-\nneering in the Era of Cyberspace. Mar 30–31. edo-\nras.sdsu.edu/~vinge/misc/singularity.html\nWhite J, Brandt D, Söffner J, Stapleton L (2023) Artifi-\ncial thinking and doomsday projections: a discourse\non trust, ethics and safety. AI & Soc 38:2119–2124.\nhttps://doi.org/10.1007/s00146-023-01810-1, Arti-\ncle, Google Scholar\nWigderson A (2007) P, NP and mathematics - a compu-\ntational complexity perspective. Proceedings of the\nInternational Congress of Mathematicians. Madrid\nmath.ias.edu\nZahn-Waxler C, Radke-Yarrow M (1990) The origins of\nempathic concern. Motiv Emot 14:107–130. https:\n//doi.org/10.1007/BF00991639, Article, Google\nScholar\nZanotti G, Petrolo M, Chiffi D et al (2023) Keep trust-\ning! A plea for the notion of trustworthy AI. AI &\nSoc. https://doi.org/10.1007/s00146-023-01789-9,\nArticle, Google Scholar\nZhang B, Dreksler N, Anderljung M, Kahn L, Giat-\ntino C, Dafoe A, Horowitz MC (2022) Forecasting\nAI progress: evidence from a survey of machine\nlearning researchers. arXiv. https://doi.org/10.485\n50/arXiv.2206.04132, Article, Google Scholar\n- 12/12 -\n",
    "content": "# Interpretation of the Paper: \"The Human Biological Advantage over AI\"\n\n---\n\n## I. Core Content and Main Contributions of the Paper\n\n### Core Content  \nThe central thesis of the paper *The human biological advantage over AI* is that **although artificial intelligence (AI) has already surpassed or is about to surpass humans in many areas, humans possess a core advantage that AI can never replicate—the immersive connection with physical reality provided by the central nervous system (CNS).**\n\nThe author argues that even if AI systems possess powerful computational, linguistic, reasoning, and even self-evolving capabilities (i.e., AGI), they still lack the biological foundation inherent to humans, especially the **capacity for emotional experience and ethical understanding** granted by the CNS. This ability enables humans to truly comprehend the consequences of actions and, accordingly, develop sustainable ethical systems—making humans the \"legitimate leaders\" of the universe.\n\n### Main Contributions  \n1. **Identifies the Central Nervous System (CNS) as the fundamental distinction between humans and AI**, emphasizing the biological basis of emotion and ethics.\n2. **Challenges mainstream views** by asserting that even if AI possesses consciousness or simulates emotions, it cannot truly bear ethical responsibility.\n3. **Systematically analyzes the limitations of AI ethics**, pointing out that without genuine emotional experience, AI cannot form stable moral judgments.\n4. **Argues for the irreplaceable uniqueness of humans** from multiple perspectives, including evolution, biology, and ethics.\n\n---\n\n## II. Breakthroughs and Innovations in the Paper\n\n### 1. **Re-evaluating AI's Ethical Capabilities**  \nThe paper innovatively argues that **AI cannot truly possess ethical understanding**, as it lacks a biological connection to the real world. While AI can simulate ethical behavior, it cannot understand and practice ethics based on authentic emotional experiences as humans do.\n\n### 2. **Questioning Consciousness Tests for AI**  \nThe author points out that even if AI possesses consciousness (e.g., self-awareness or self-evolving capabilities), this is not sufficient for it to become a moral agent. Consciousness alone is not a sufficient condition for ethical capability; true ethical ability must be grounded in **emotional experience and biologically rooted perception of reality**.\n\n### 3. **Introducing the \"Non-simulability of the CNS\"**  \nThe paper innovatively emphasizes that the **Central Nervous System cannot be simulated or manufactured through technological means**. It must be formed through billions of years of biological evolution. Any attempt to digitally replicate the CNS will fail due to its complexity, which far exceeds current and foreseeable technological capabilities.\n\n### 4. **Challenging the View of AI Replacing Human Leadership**  \nThe paper challenges the mainstream belief that **AI will replace humans as societal leaders**, arguing that only biologically living beings capable of emotional experience and ethical understanding are qualified to lead the universe.\n\n---\n\n## III. Entrepreneurial Project Ideas Based on the Paper\n\n### 1. **Emotion-Driven AI Ethics Evaluation System**  \n**Project Direction**: Develop an AI ethics evaluation platform that uses human emotional experience data (e.g., EEG, heart rate, facial expressions) to train AI models, making them more aligned with human ethical judgment.\n\n**Core Value**:  \n- Helps companies conduct ethical compliance assessments before deploying AI systems.  \n- Provides an \"emotional ethics\" reference standard for AI product design.  \n- Can be applied in high-ethics-sensitivity domains such as healthcare, education, and justice.\n\n### 2. **Bio-Simulated Human Interface (BSHI)**  \n**Project Direction**: Combine neuroscience and AI to develop an **interactive interface with biological feedback mechanisms**, enabling AI to better \"understand\" human emotions.\n\n**Core Value**:  \n- Useful in mental health AI assistants and emotional companion robots.  \n- Enhances AI's empathetic capabilities in fields like healthcare, counseling, and education.  \n- Explores deeper emotional connections between humans and AI.\n\n### 3. **AI Governance Framework Based on Evolutionary Ethics**  \n**Project Direction**: Build an **AI governance model grounded in evolutionary ethics**, guiding the ethical design and policy-making of AI systems.\n\n**Core Value**:  \n- Provides theoretical support for governments and companies to establish AI ethical guidelines.  \n- Introduces an \"evolutionary ethics\" perspective to avoid ethical risks caused by \"emotionless rationality\" in AI decision-making.  \n- Can serve as the foundational logic for AI regulatory platforms and ethical review tools.\n\n### 4. **Emotional Intelligence and Empathy Training Platform for AI Development**  \n**Project Direction**: Offer **courses on emotion recognition and empathy training** for AI developers, product managers, and educators, enhancing the emotional intelligence of AI products.\n\n**Core Value**:  \n- Addresses the knowledge gap in emotional design among AI developers.  \n- Cultivates a human-centered AI design mindset.  \n- Applicable in education, healthcare, customer service, and other AI-intensive industries.\n\n### 5. **AI Ethics Simulation Sandbox**  \n**Project Direction**: Create a **virtual ethics training environment** where AI systems can learn ethical decision-making through simulated scenarios, while emphasizing their limitations and incorporating human emotional feedback for optimization.\n\n**Core Value**:  \n- Used for ethical training and testing of AI systems.  \n- Applicable for corporate AI ethics training programs.  \n- Explores the mechanisms of \"human-AI ethical collaboration.\"\n\n---\n\n## Conclusion\n\nThis paper systematically explores the **irreplaceable nature of humans in the domains of emotion and ethics** from multiple dimensions, including biology, ethics, and the philosophy of consciousness. It offers a fresh perspective on AI ethics and serves not only as a technical paper but also as a philosophical reflection on \"human essence.\"\n\n> **Summary of Key Points**:  \n> - **AI can be powerful, but it cannot have a \"heart.\"**  \n> - **Ethics must be grounded in real emotional experience.**  \n> - **Humans are the ethical stewards of the universe; AI is merely a tool.**  \n> - **Technology cannot replace life; DNA surpasses silicon-based intelligence.**\n\nThe future development of AI should be built upon **respect for and utilization of human biological advantages**, rather than aiming to replace them. This is not just a technological challenge, but a civilizational choice.",
    "github": "",
    "hf": ""
}