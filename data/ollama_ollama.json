{
    "id": "/ollama/ollama",
    "issues": "1.6k",
    "watch": "828",
    "fork": "12.1k",
    "star": "144k",
    "topics": [
        "go",
        "golang",
        "llama",
        "gemma",
        "mistral",
        "llm",
        "llms",
        "llava",
        "llama2",
        "ollama",
        "qwen",
        "deepseek",
        "llama3",
        "phi3",
        "gemma2",
        "phi4",
        "gemma3"
    ],
    "license": "MIT License",
    "languages": [
        "Go,94.2%",
        "C,2.2%",
        "Shell,1.0%",
        "TypeScript,0.9%",
        "PowerShell,0.6%",
        "Inno Setup,0.4%"
    ],
    "contributors": [
        "https://avatars.githubusercontent.com/u/2372640?s=64&v=4",
        "https://avatars.githubusercontent.com/u/251292?s=64&v=4",
        "https://avatars.githubusercontent.com/u/4033016?s=64&v=4",
        "https://avatars.githubusercontent.com/u/5853428?s=64&v=4",
        "https://avatars.githubusercontent.com/u/75239?s=64&v=4",
        "https://avatars.githubusercontent.com/u/633681?s=64&v=4",
        "https://avatars.githubusercontent.com/u/6468499?s=64&v=4",
        "https://avatars.githubusercontent.com/u/46?s=64&v=4",
        "https://avatars.githubusercontent.com/u/3325447?s=64&v=4",
        "https://avatars.githubusercontent.com/u/76125168?s=64&v=4",
        "https://avatars.githubusercontent.com/u/29360864?s=64&v=4",
        "https://avatars.githubusercontent.com/u/65097070?s=64&v=4",
        "https://avatars.githubusercontent.com/u/14946854?s=64&v=4",
        "https://avatars.githubusercontent.com/u/175530?s=64&v=4"
    ],
    "about": "Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.",
    "is_AI": "y",
    "category": "Language Model Frameworks",
    "summary": "### 1. The **Core Content** of This Project: What Major Problem Does It Solve?\n\nOllama is a lightweight, scalable framework focused on building and running language models directly on local machines. It provides a simple API for creating, running, and managing models, along with a pre-built model library that can be easily applied to various scenarios. Ollama addresses the following issues:\n\n- **Simplifying the Deployment and Use of Large Language Models (LLMs):** By providing a unified toolchain, users can quickly download, install, and run multiple LLMs.\n- **Reducing Resource Consumption:** Supports models of various sizes, allowing users to choose appropriate models based on their hardware capabilities.\n- **Enhancing Privacy Protection:** All models run locally, avoiding the risk of data being uploaded to the cloud.\n- **High Flexibility:** Allows users to customize model parameters and prompts to suit specific task requirements.\n\n---\n\n### 2. The **Breakthrough or Innovation** of This Project\n\nThe breakthroughs and innovations of Ollama are mainly reflected in the following areas:\n\n- **Ease of Use:** Provides a one-click installation and operation experience, making it easy for macOS, Windows, and Linux users to get started.\n- **Model Diversity:** Supports a variety of mainstream language models, including Llama, DeepSeek-R1, Phi-4, etc., meeting the needs of different application scenarios.\n- **Customization Capability:** Allows users to customize model behavior through Modelfiles, such as adjusting temperature parameters or setting system messages.\n- **Cross-Platform Support:** In addition to desktop applications, mobile apps like SwiftChat and Enchanted are also provided, facilitating use anytime, anywhere.\n- **Rich Community Ecosystem:** Has a large network of community contributors who have developed many third-party plugins and tools (such as Promptery, Flufy), further expanding its functionality.\n- **REST API Support:** Provides RESTful interfaces for developers, facilitating integration into other applications.\n\n---\n\n### 3. Good Ideas for Startup Projects Using This Project\n\nBased on Ollama's characteristics, here are some potential startup directions:\n\n#### (1) **Localized AI Assistant**\n   - Develop a completely offline personal assistant application leveraging Ollama's powerful natural language processing capabilities to help users complete daily tasks (e.g., writing emails, generating reports).\n   - Feature: Emphasizes privacy protection, enabling efficient workflows without an internet connection.\n\n#### (2) **Intelligent Tools for Education**\n   - Build an interactive learning platform for students and teachers, combining multi-modal models (such as visual recognition and text generation) to design course assistance functions.\n   - Example: Develop an app that can answer complex math problems with detailed step-by-step explanations.\n\n#### (3) **Enterprise Knowledge Management Solution**\n   - Use Ollama's RAG (Retrieval-Augmented Generation) technology to create a custom knowledge base query system for businesses.\n   - Function: Extract key information from internal documents, quickly respond to employee inquiries, and improve work efficiency.\n\n#### (4) **Creative Content Generation Service**\n   - Launch tools for writers, screenwriters, or marketers to generate stories, ad copy, etc.\n   - Advantage: Supports switching between multiple styles to ensure output content aligns with target audience preferences.\n\n#### (5) **NPC Dialogue Engine in Game Development**\n   - Integrate Ollama into game frameworks to give non-player characters (NPCs) more natural and fluent language interaction capabilities.\n   - Scenario: Suitable for open-world RPG games, enhancing immersion.\n\n#### (6) **Health Consultation Assistant**\n   - Use domain-specific versions of LLMs to build health management advisors for general users.\n   - Considerations: Must strictly comply with relevant laws and regulations to ensure accurate and reliable diagnostic recommendations.\n\n#### (7) **Legal Document Automation Platform**\n   - Based on Ollama's text generation capabilities, assist lawyers in drafting contracts, complaints, and other professional documents.\n   - Business Model: Pay-per-use or subscription-based, attracting small and medium-sized law firm clients.\n\nIn summary, Ollama's strong performance and its open-source nature provide entrepreneurs with vast space to explore new business models and technical application scenarios!",
    "text": "Ollama\nGet up and running with large language models.\nmacOS\nDownload\nWindows\nDownload\nLinux\ncurl -fsSL https://ollama.com/install.sh\n|\nsh\nManual install instructions\nDocker\nThe official\nOllama Docker image\nollama/ollama\nis available on Docker Hub.\nLibraries\nollama-python\nollama-js\nCommunity\nDiscord\nReddit\nQuickstart\nTo run and chat with\nGemma 3\n:\nollama run gemma3\nModel library\nOllama supports a list of models available on\nollama.com/library\nHere are some example models that can be downloaded:\nModel\nParameters\nSize\nDownload\nGemma 3\n1B\n815MB\nollama run gemma3:1b\nGemma 3\n4B\n3.3GB\nollama run gemma3\nGemma 3\n12B\n8.1GB\nollama run gemma3:12b\nGemma 3\n27B\n17GB\nollama run gemma3:27b\nQwQ\n32B\n20GB\nollama run qwq\nDeepSeek-R1\n7B\n4.7GB\nollama run deepseek-r1\nDeepSeek-R1\n671B\n404GB\nollama run deepseek-r1:671b\nLlama 4\n109B\n67GB\nollama run llama4:scout\nLlama 4\n400B\n245GB\nollama run llama4:maverick\nLlama 3.3\n70B\n43GB\nollama run llama3.3\nLlama 3.2\n3B\n2.0GB\nollama run llama3.2\nLlama 3.2\n1B\n1.3GB\nollama run llama3.2:1b\nLlama 3.2 Vision\n11B\n7.9GB\nollama run llama3.2-vision\nLlama 3.2 Vision\n90B\n55GB\nollama run llama3.2-vision:90b\nLlama 3.1\n8B\n4.7GB\nollama run llama3.1\nLlama 3.1\n405B\n231GB\nollama run llama3.1:405b\nPhi 4\n14B\n9.1GB\nollama run phi4\nPhi 4 Mini\n3.8B\n2.5GB\nollama run phi4-mini\nMistral\n7B\n4.1GB\nollama run mistral\nMoondream 2\n1.4B\n829MB\nollama run moondream\nNeural Chat\n7B\n4.1GB\nollama run neural-chat\nStarling\n7B\n4.1GB\nollama run starling-lm\nCode Llama\n7B\n3.8GB\nollama run codellama\nLlama 2 Uncensored\n7B\n3.8GB\nollama run llama2-uncensored\nLLaVA\n7B\n4.5GB\nollama run llava\nGranite-3.3\n8B\n4.9GB\nollama run granite3.3\nNote\nYou should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\nCustomize a model\nImport from GGUF\nOllama supports importing GGUF models in the Modelfile:\nCreate a file named\nModelfile\n, with a\nFROM\ninstruction with the local filepath to the model you want to import.\nFROM ./vicuna-33b.Q4_0.gguf\nCreate the model in Ollama\nollama create example -f Modelfile\nRun the model\nollama run example\nImport from Safetensors\nSee the\nguide\non importing models for more information.\nCustomize a prompt\nModels from the Ollama library can be customized with a prompt. For example, to customize the\nllama3.2\nmodel:\nollama pull llama3.2\nCreate a\nModelfile\n:\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\nNext, create and run the model:\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\nFor more information on working with a Modelfile, see the\nModelfile\ndocumentation.\nCLI Reference\nCreate a model\nollama create\nis used to create a model from a Modelfile.\nollama create mymodel -f ./Modelfile\nPull a model\nollama pull llama3.2\nThis command can also be used to update a local model. Only the diff will be pulled.\nRemove a model\nollama rm llama3.2\nCopy a model\nollama cp llama3.2 my-model\nMultiline input\nFor multiline input, you can wrap text with\n\"\"\"\n:\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\nMultimodal models\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\nOutput\n: The image features a yellow smiley face, which is likely the central focus of the picture.\nPass the prompt as an argument\nollama run llama3.2\n\"\nSummarize this file:\n$(\ncat README.md\n)\n\"\nOutput\n: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\nShow model information\nollama show llama3.2\nList models on your computer\nollama list\nList which models are currently loaded\nollama ps\nStop a model which is currently running\nollama stop llama3.2\nStart Ollama\nollama serve\nis used when you want to start ollama without running the desktop application.\nBuilding\nSee the\ndeveloper guide\nRunning local builds\nNext, start the server:\n./ollama serve\nFinally, in a separate shell, run a model:\n./ollama run llama3.2\nREST API\nOllama has a REST API for running and managing models.\nGenerate a response\ncurl http://localhost:11434/api/generate -d\n'\n{\n\"model\": \"llama3.2\",\n\"prompt\":\"Why is the sky blue?\"\n}\n'\nChat with a model\ncurl http://localhost:11434/api/chat -d\n'\n{\n\"model\": \"llama3.2\",\n\"messages\": [\n{ \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n]\n}\n'\nSee the\nAPI documentation\nfor all endpoints.\nCommunity Integrations\nWeb & Desktop\nOpen WebUI\nSwiftChat (macOS with ReactNative)\nEnchanted (macOS native)\nHollama\nLollms-Webui\nLibreChat\nBionic GPT\nHTML UI\nSaddle\nTagSpaces\n(A platform for file-based apps,\nutilizing Ollama\nfor the generation of tags and descriptions)\nChatbot UI\nChatbot UI v2\nTypescript UI\nMinimalistic React UI for Ollama Models\nOllamac\nbig-AGI\nCheshire Cat assistant framework\nAmica\nchatd\nOllama-SwiftUI\nDify.AI\nMindMac\nNextJS Web Interface for Ollama\nMsty\nChatbox\nWinForm Ollama Copilot\nNextChat\nwith\nGet Started Doc\nAlpaca WebUI\nOllamaGUI\nOpenAOE\nOdin Runes\nLLM-X\n(Progressive Web App)\nAnythingLLM (Docker + MacOs/Windows/Linux native app)\nOllama Basic Chat: Uses HyperDiv Reactive UI\nOllama-chats RPG\nIntelliBar\n(AI-powered assistant for macOS)\nJirapt\n(Jira Integration to generate issues, tasks, epics)\nojira\n(Jira chrome plugin to easily generate descriptions for tasks)\nQA-Pilot\n(Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\nChatOllama\n(Open Source Chatbot based on Ollama with Knowledge Bases)\nCRAG Ollama Chat\n(Simple Web Search with Corrective RAG)\nRAGFlow\n(Open-source Retrieval-Augmented Generation engine based on deep document understanding)\nStreamDeploy\n(LLM Application Scaffold)\nchat\n(chat web app for teams)\nLobe Chat\nwith\nIntegrating Doc\nOllama RAG Chatbot\n(Local Chat with multiple PDFs using Ollama and RAG)\nBrainSoup\n(Flexible native client with RAG & multi-agent automation)\nmacai\n(macOS client for Ollama, ChatGPT, and other compatible API back-ends)\nRWKV-Runner\n(RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\nOllama Grid Search\n(app to evaluate and compare models)\nOlpaka\n(User-friendly Flutter Web App for Ollama)\nCasibase\n(An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)\nOllamaSpring\n(Ollama Client for macOS)\nLLocal.in\n(Easy to use Electron Desktop Client for Ollama)\nShinkai Desktop\n(Two click install Local AI using Ollama + Files + RAG)\nAiLama\n(A Discord User App that allows you to interact with Ollama anywhere in Discord)\nOllama with Google Mesop\n(Mesop Chat Client implementation with Ollama)\nR2R\n(Open-source RAG engine)\nOllama-Kis\n(A simple easy-to-use GUI with sample custom LLM for Drivers Education)\nOpenGPA\n(Open-source offline-first Enterprise Agentic Application)\nPainting Droid\n(Painting app with AI integrations)\nKerlig AI\n(AI writing assistant for macOS)\nAI Studio\nSidellama\n(browser-based LLM client)\nLLMStack\n(No-code multi-agent framework to build LLM agents and workflows)\nBoltAI for Mac\n(AI Chat Client for Mac)\nHarbor\n(Containerized LLM Toolkit with Ollama as default backend)\nPyGPT\n(AI desktop assistant for Linux, Windows, and Mac)\nAlpaca\n(An Ollama client application for Linux and macOS made with GTK4 and Adwaita)\nAutoGPT\n(AutoGPT Ollama integration)\nGo-CREW\n(Powerful Offline RAG in Golang)\nPartCAD\n(CAD model generation with OpenSCAD and CadQuery)\nOllama4j Web UI\n- Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j\nPyOllaMx\n- macOS application capable of chatting with both Ollama and Apple MLX models.\nCline\n- Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding\nCherry Studio\n(Desktop client with Ollama support)\nConfiChat\n(Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\nArchyve\n(RAG-enabling document library)\ncrewAI with Mesop\n(Mesop Web Interface to run crewAI with Ollama)\nTkinter-based client\n(Python tkinter-based Client for Ollama)\nLLMChat\n(Privacy focused, 100% local, intuitive all-in-one chat interface)\nLocal Multimodal AI Chat\n(Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\nARGO\n(Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux)\nOrionChat\n- OrionChat is a web interface for chatting with different AI providers\nG1\n(Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\nWeb management\n(Web management page)\nPromptery\n(desktop client for Ollama.)\nOllama App\n(Modern and easy-to-use multi-platform client for Ollama)\nchat-ollama\n(a React Native client for Ollama)\nSpaceLlama\n(Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\nYouLama\n(Webapp to quickly summarize any YouTube video, supporting Invidious as well)\nDualMind\n(Experimental app allowing two models to talk to each other in the terminal or in a web interface)\nollamarama-matrix\n(Ollama chatbot for the Matrix chat protocol)\nollama-chat-app\n(Flutter-based chat app)\nPerfect Memory AI\n(Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)\nHexabot\n(A conversational AI builder)\nReddit Rate\n(Search and Rate Reddit topics with a weighted summation)\nOpenTalkGpt\n(Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\nVT\n(A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\nNosia\n(Easy to install and use RAG platform based on Ollama)\nWitsy\n(An AI Desktop application available for Mac/Windows/Linux)\nAbbey\n(A configurable AI interface server with notebooks, document storage, and YouTube support)\nMinima\n(RAG with on-premises or fully local workflow)\naidful-ollama-model-delete\n(User interface for simplified model cleanup)\nPerplexica\n(An AI-powered search engine & an open-source alternative to Perplexity AI)\nOllama Chat WebUI for Docker\n(Support for local docker deployment, lightweight ollama webui)\nAI Toolkit for Visual Studio Code\n(Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)\nMinimalNextOllamaChat\n(Minimal Web UI for Chat and Model Control)\nChipper\nAI interface for tinkerers (Ollama, Haystack RAG, Python)\nChibiChat\n(Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)\nLocalLLM\n(Minimal Web-App to run ollama models on it with a GUI)\nOllamazing\n(Web extension to run Ollama models)\nOpenDeepResearcher-via-searxng\n(A Deep Research equivalent endpoint with Ollama support for running locally)\nAntSK\n(Out-of-the-box & Adaptable RAG Chatbot)\nMaxKB\n(Ready-to-use & flexible RAG Chatbot)\nyla\n(Web interface to freely interact with your customized models)\nLangBot\n(LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)\n1Panel\n(Web-based Linux Server Management Tool)\nAstrBot\n(User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)\nReins\n(Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\nFlufy\n(A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)\nEllama\n(Friendly native app to chat with an Ollama instance)\nscreenpipe\nBuild agents powered by your screen history\nOllamb\n(Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the\nweb demo\n.)\nWriteopia\n(Text editor with integration with Ollama)\nAppFlowy\n(AI collaborative workspace with Ollama, cross-platform and self-hostable)\nLumina\n(A lightweight, minimal React.js frontend for interacting with Ollama servers)\nTiny Notepad\n(A lightweight, notepad-like interface to chat with ollama available on PyPI)\nmacLlama (macOS native)\n(A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)\nGPTranslate\n(A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)\nollama launcher\n(A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)\nCloud\nGoogle Cloud\nFly.io\nKoyeb\nTerminal\noterm\nEllama Emacs client\nEmacs client\nneollama\nUI client for interacting with models from within Neovim\ngen.nvim\nollama.nvim\nollero.nvim\nollama-chat.nvim\nogpt.nvim\ngptel Emacs client\nOatmeal\ncmdh\nooo\nshell-pilot\n(Interact with models via pure shell scripts on Linux or macOS)\ntenere\nllm-ollama\nfor\nDatasette's LLM CLI\n.\ntypechat-cli\nShellOracle\ntlm\npodman-ollama\ngollama\nParLlama\nOllama eBook Summary\nOllama Mixture of Experts (MOE) in 50 lines of code\nvim-intelligence-bridge\nSimple interaction of \"Ollama\" with the Vim editor\nx-cmd ollama\nbb7\nSwollamaCLI\nbundled with the Swollama Swift package.\nDemo\naichat\nAll-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\nPowershAI\nPowerShell module that brings AI to terminal on Windows, including support for Ollama\nDeepShell\nYour self-hosted AI assistant. Interactive Shell, Files and Folders analysis.\norbiton\nConfiguration-free text editor and IDE with support for tab completion with Ollama.\norca-cli\nOllama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.\nGGUF-to-Ollama\n- Importing GGUF to Ollama made easy (multiplatform)\nAWS-Strands-With-Ollama\n- AWS Strands Agents with Ollama Examples\nollama-multirun\n- A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (\nDemo\n)\nApple Vision Pro\nSwiftChat\n(Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")\nEnchanted\nDatabase\npgai\n- PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\nGet started guide\nMindsDB\n(Connects Ollama models with nearly 200 data platforms and apps)\nchromem-go\nwith\nexample\nKangaroo\n(AI-powered SQL client and admin tool for popular databases)\nPackage managers\nPacman\nGentoo\nHomebrew\nHelm Chart\nGuix channel\nNix package\nFlox\nLibraries\nLangChain\nand\nLangChain.js\nwith\nexample\nFirebase Genkit\ncrewAI\nYacana\n(User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\nSpring AI\nwith\nreference\nand\nexample\nLangChainGo\nwith\nexample\nLangChain4j\nwith\nexample\nLangChainRust\nwith\nexample\nLangChain for .NET\nwith\nexample\nLLPhant\nLlamaIndex\nand\nLlamaIndexTS\nLiteLLM\nOllamaFarm for Go\nOllamaSharp for .NET\nOllama for Ruby\nOllama-rs for Rust\nOllama-hpp for C++\nOllama4j for Java\nModelFusion Typescript Library\nOllamaKit for Swift\nOllama for Dart\nOllama for Laravel\nLangChainDart\nSemantic Kernel - Python\nHaystack\nElixir LangChain\nOllama for R - rollama\nOllama for R - ollama-r\nOllama-ex for Elixir\nOllama Connector for SAP ABAP\nTestcontainers\nPortkey\nPromptingTools.jl\nwith an\nexample\nLlamaScript\nllm-axe\n(Python Toolkit for Building LLM Powered Apps)\nGollm\nGollama for Golang\nOllamaclient for Golang\nHigh-level function abstraction in Go\nOllama PHP\nAgents-Flex for Java\nwith\nexample\nParakeet\nis a GoLang library, made to simplify the development of small generative AI applications with Ollama.\nHaverscript\nwith\nexamples\nOllama for Swift\nSwollama for Swift\nwith\nDocC\nGoLamify\nOllama for Haskell\nmulti-llm-ts\n(A Typescript/JavaScript library allowing access to different LLM in a unified API)\nLlmTornado\n(C# library providing a unified interface for major FOSS & Commercial inference APIs)\nOllama for Zig\nAbso\n(OpenAI-compatible TypeScript SDK for any LLM provider)\nNichey\nis a Python package for generating custom wikis for your research topic\nOllama for D\nOllamaPlusPlus\n(Very simple C++ library for Ollama)\nMobile\nSwiftChat\n(Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)\nEnchanted\nMaid\nOllama App\n(Modern and easy-to-use multi-platform client for Ollama)\nConfiChat\n(Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\nOllama Android Chat\n(No need for Termux, start the Ollama service with one click on an Android device)\nReins\n(Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\nExtensions & Plugins\nRaycast extension\nDiscollama\n(Discord bot inside the Ollama discord channel)\nContinue\nVibe\n(Transcribe and analyze meetings with Ollama)\nObsidian Ollama plugin\nLogseq Ollama plugin\nNotesOllama\n(Apple Notes Ollama plugin)\nDagger Chatbot\nDiscord AI Bot\nOllama Telegram Bot\nHass Ollama Conversation\nRivet plugin\nObsidian BMO Chatbot plugin\nCliobot\n(Telegram bot with Ollama support)\nCopilot for Obsidian plugin\nObsidian Local GPT plugin\nOpen Interpreter\nLlama Coder\n(Copilot alternative using Ollama)\nOllama Copilot\n(Proxy that allows you to use Ollama as a copilot like GitHub Copilot)\ntwinny\n(Copilot and Copilot chat alternative using Ollama)\nWingman-AI\n(Copilot code and chat alternative using Ollama and Hugging Face)\nPage Assist\n(Chrome Extension)\nPlasmoid Ollama Control\n(KDE Plasma extension that allows you to quickly manage/control Ollama model)\nAI Telegram Bot\n(Telegram bot using Ollama in backend)\nAI ST Completion\n(Sublime Text 4 AI assistant plugin with Ollama support)\nDiscord-Ollama Chat Bot\n(Generalized TypeScript Discord Bot w/ Tuning Documentation)\nChatGPTBox: All in one browser extension\nwith\nIntegrating Tutorial\nDiscord AI chat/moderation bot\nChat/moderation bot written in python. Uses Ollama to create personalities.\nHeadless Ollama\n(Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)\nTerraform AWS Ollama & Open WebUI\n(A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)\nnode-red-contrib-ollama\nLocal AI Helper\n(Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\nvnc-lm\n(Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)\nLSP-AI\n(Open-source language server for AI-powered functionality)\nQodeAssist\n(AI-powered coding assistant plugin for Qt Creator)\nObsidian Quiz Generator plugin\nAI Summmary Helper plugin\nTextCraft\n(Copilot in Word alternative using Ollama)\nAlfred Ollama\n(Alfred Workflow)\nTextLLaMA\nA Chrome Extension that helps you write emails, correct grammar, and translate into any language\nSimple-Discord-AI\nLLM Telegram Bot\n(telegram bot, primary for RP. Oobabooga-like buttons,\nA1111\nAPI integration e.t.c)\nmcp-llm\n(MCP Server to allow LLMs to call other LLMs)\nSimpleOllamaUnity\n(Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)\nUnityCodeLama\n(Unity Edtior tool to analyze scripts via Ollama)\nSupported backends\nllama.cpp\nproject founded by Georgi Gerganov.\nObservability\nOpik\nis an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.\nLunary\nis the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.\nOpenLIT\nis an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\nHoneyHive\nis an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.\nLangfuse\nis an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.\nMLflow Tracing\nis an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.",
    "readme": "<div align=\"center\">\nÂ  <a href=\"https://ollama.com\">\n    <img alt=\"ollama\" height=\"200px\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n  </a>\n</div>\n\n# Ollama\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama-darwin.zip)\n\n### Windows\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```shell\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n### Community\n\n- [Discord](https://discord.gg/ollama)\n- [Reddit](https://reddit.com/r/ollama)\n\n## Quickstart\n\nTo run and chat with [Gemma 3](https://ollama.com/library/gemma3):\n\n```shell\nollama run gemma3\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library 'ollama model library')\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                         |\n| ------------------ | ---------- | ----- | -------------------------------- |\n| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |\n| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |\n| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |\n| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |\n| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |\n| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |\n| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |\n| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |\n| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |\n| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n| Granite-3.3         | 8B         | 4.9GB | `ollama run granite3.3`          |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```shell\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```shell\n   ollama run example\n   ```\n\n### Import from Safetensors\n\nSee the [guide](docs/import.md) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:\n\n```shell\nollama pull llama3.2\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```shell\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```shell\nollama pull llama3.2\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```shell\nollama rm llama3.2\n```\n\n### Copy a model\n\n```shell\nollama cp llama3.2 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\n```\n\n> **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.\n\n### Pass the prompt as an argument\n\n```shell\nollama run llama3.2 \"Summarize this file: $(cat README.md)\"\n```\n\n> **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n\n### Show model information\n\n```shell\nollama show llama3.2\n```\n\n### List models on your computer\n\n```shell\nollama list\n```\n\n### List which models are currently loaded\n\n```shell\nollama ps\n```\n\n### Stop a model which is currently running\n\n```shell\nollama stop llama3.2\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```shell\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```shell\n./ollama run llama3.2\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```shell\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```shell\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)\n- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)\n- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\n- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)\n- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)\n- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)\n- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)\n- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)\n- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\n- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux)\n- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers\n- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\n- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)\n- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)\n- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\n- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)\n- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)\n- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)\n- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)\n- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)\n- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)\n- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)\n- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\n- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\n- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)\n- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)\n- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)\n- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)\n- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)\n- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine & an open-source alternative to Perplexity AI)\n- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)\n- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)\n- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)\n- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)\n- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)\n- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)\n- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)\n- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)\n- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box & Adaptable RAG Chatbot)\n- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use & flexible RAG Chatbot)\n- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)\n- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)\n- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)\n- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)\n- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)\n- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history\n- [Ollamb](https://github.com/hengkysteen/ollamb) (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the [web demo](https://hengkysteen.github.io/demo/ollamb/).)\n- [Writeopia](https://github.com/Writeopia/Writeopia) (Text editor with integration with Ollama)\n- [AppFlowy](https://github.com/AppFlowy-IO/AppFlowy) (AI collaborative workspace with Ollama, cross-platform and self-hostable)\n- [Lumina](https://github.com/cushydigit/lumina.git) (A lightweight, minimal React.js frontend for interacting with Ollama servers)\n- [Tiny Notepad](https://pypi.org/project/tiny-notepad) (A lightweight, notepad-like interface to chat with ollama available on PyPI)\n- [macLlama (macOS native)](https://github.com/hellotunamayo/macLlama) (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.) \n- [GPTranslate](https://github.com/philberndt/GPTranslate) (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)\n- [ollama launcher](https://github.com/NGC13009/ollama-launcher) (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)\n\n### Cloud\n\n- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)\n- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)\n- [Koyeb](https://www.koyeb.com/deploy/ollama)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [neollama](https://github.com/paradoxical-dev/neollama) UI client for interacting with models from within Neovim\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)(Interact with models via pure shell scripts on Linux or macOS)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [ParLlama](https://github.com/paulrobello/parllama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n- [vim-intelligence-bridge](https://github.com/pepo-ec/vim-intelligence-bridge) Simple interaction of \"Ollama\" with the Vim editor\n- [x-cmd ollama](https://x-cmd.com/mod/ollama)\n- [bb7](https://github.com/drunkwcodes/bb7)\n- [SwollamaCLI](https://github.com/marcusziade/Swollama) bundled with the Swollama Swift package. [Demo](https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage)\n- [aichat](https://github.com/sigoden/aichat) All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\n- [PowershAI](https://github.com/rrg92/powershai) PowerShell module that brings AI to terminal on Windows, including support for Ollama\n- [DeepShell](https://github.com/Abyss-c0re/deepshell) Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.\n- [orbiton](https://github.com/xyproto/orbiton) Configuration-free text editor and IDE with support for tab completion with Ollama.\n- [orca-cli](https://github.com/molbal/orca-cli) Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.\n- [GGUF-to-Ollama](https://github.com/jonathanhecl/gguf-to-ollama) - Importing GGUF to Ollama made easy (multiplatform)\n- [AWS-Strands-With-Ollama](https://github.com/rapidarchitect/ollama_strands) - AWS Strands Agents with Ollama Examples\n- [ollama-multirun](https://github.com/attogram/ollama-multirun) - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. ([Demo](https://attogram.github.io/ai_test_zone/))\n\n### Apple Vision Pro\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\n   - [Get started guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md)\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n- [Kangaroo](https://github.com/dbkangaroo/kangaroo) (AI-powered SQL client and admin tool for popular databases)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Homebrew](https://formulae.brew.sh/formula/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/chat/ollama/) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [Yacana](https://remembersoftwares.github.io/yacana/) (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\n- [Spring AI](https://github.com/spring-projects/spring-ai) with [reference](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html) and [example](https://github.com/tzolov/ollama-tools)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LangChain for .NET](https://github.com/tryAGI/LangChain) with [example](https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs)\n- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama)\n- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/gbaptista/ollama-ai)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [llm-axe](https://github.com/emirsahin1/llm-axe) (Python Toolkit for Building LLM Powered Apps)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Gollama for Golang](https://github.com/jonathanhecl/gollama)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) with [example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama)\n- [Parakeet](https://github.com/parakeet-nest/parakeet) is a GoLang library, made to simplify the development of small generative AI applications with Ollama.\n- [Haverscript](https://github.com/andygill/haverscript) with [examples](https://github.com/andygill/haverscript/tree/main/examples)\n- [Ollama for Swift](https://github.com/mattt/ollama-swift)\n- [Swollama for Swift](https://github.com/marcusziade/Swollama) with [DocC](https://marcusziade.github.io/Swollama/documentation/swollama/)\n- [GoLamify](https://github.com/prasad89/golamify)\n- [Ollama for Haskell](https://github.com/tusharad/ollama-haskell)\n- [multi-llm-ts](https://github.com/nbonamy/multi-llm-ts) (A Typescript/JavaScript library allowing access to different LLM in a unified API)\n- [LlmTornado](https://github.com/lofcz/llmtornado) (C# library providing a unified interface for major FOSS & Commercial inference APIs)\n- [Ollama for Zig](https://github.com/dravenk/ollama-zig)\n- [Abso](https://github.com/lunary-ai/abso) (OpenAI-compatible TypeScript SDK for any LLM provider)\n- [Nichey](https://github.com/goodreasonai/nichey) is a Python package for generating custom wikis for your research topic\n- [Ollama for D](https://github.com/kassane/ollama-d)\n- [OllamaPlusPlus](https://github.com/HardCodeDev777/OllamaPlusPlus) (Very simple C++ library for Ollama)\n\n### Mobile\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Ollama Android Chat](https://github.com/sunshine0523/OllamaServer) (No need for Termux, start the Ollama service with one click on an Android device)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Vibe](https://github.com/thewh1teagle/vibe) (Transcribe and analyze meetings with Ollama)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox) with [Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)\n- [Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm) (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)\n- [node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)\n- [Local AI Helper](https://github.com/ivostoykov/localAI) (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\n- [vnc-lm](https://github.com/jake83741/vnc-lm) (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n- [Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)\n- [AI Summmary Helper plugin](https://github.com/philffm/ai-summary-helper)\n- [TextCraft](https://github.com/suncloudsmoon/TextCraft) (Copilot in Word alternative using Ollama)\n- [Alfred Ollama](https://github.com/zeitlings/alfred-ollama) (Alfred Workflow)\n- [TextLLaMA](https://github.com/adarshM84/TextLLaMA) A Chrome Extension that helps you write emails, correct grammar, and translate into any language\n- [Simple-Discord-AI](https://github.com/zyphixor/simple-discord-ai)\n- [LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot) (telegram bot, primary for RP. Oobabooga-like buttons, [A1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) API integration e.t.c)\n- [mcp-llm](https://github.com/sammcj/mcp-llm) (MCP Server to allow LLMs to call other LLMs)\n- [SimpleOllamaUnity](https://github.com/HardCodeDev777/SimpleOllamaUnity) (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)\n- [UnityCodeLama](https://github.com/HardCodeDev777/UnityCodeLama) (Unity Edtior tool to analyze scripts via Ollama)\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp) project founded by Georgi Gerganov.\n\n### Observability\n- [Opik](https://www.comet.com/docs/opik/cookbook/ollama) is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.\n- [Lunary](https://lunary.ai/docs/integrations/ollama) is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.\n- [OpenLIT](https://github.com/openlit/openlit) is an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\n- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.\n- [Langfuse](https://langfuse.com/docs/integrations/ollama) is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.\n- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing) is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.\n",
    "author": "ollama",
    "project": "ollama",
    "date": "2025-06-22"
}