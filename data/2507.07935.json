{
    "id": "2507.07935",
    "title": "Working with AI: Measuring the Occupational Implications of Generative AI",
    "summary": "The study analyzed 200,000 anonymous conversations between users and Microsoft Bing Copilot (an open generative AI system) to assess the potential application of AI in different professions, and found that knowledge-based occupations such as computer and mathematics, and office and administrative support roles had the highest AI applicability scores.",
    "abstract": "Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.",
    "category1": "Application Implementation",
    "category2": "Personal Tools",
    "category3": "Non-Agent",
    "authors": "Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri",
    "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)"
    ],
    "comments": "Comments:40 pages",
    "keypoint": "- The most common work activities people seek AI assistance for involve gathering information and writing.\n- The most common activities AI performs include providing information, writing, teaching, advising, and assisting.\n- An AI applicability score was computed based on task success and scope of impact for each occupation.\n- Highest AI applicability scores were found in knowledge work occupations such as computer and mathematical, and office and administrative support.\n- Occupations like sales, where work involves providing and communicating information, also showed high AI applicability.\n- AI applicability scores were characterized by types of work activities performed successfully.\n- Correlations between wage and education with AI applicability were analyzed.\n- Real-world usage data was compared to predictions of occupational AI impact.",
    "date": "2025-07-14",
    "paper": "Working with AI:\nMeasuring the Occupational Implications of Generative AI∗\nKiran Tomlinson1, Sonia Jaffe1, Will Wang1, Scott Counts2, and Siddharth Suri1\n1Microsoft Research\n2Microsoft\nAbstract\nGiven the rapid adoption of generative AI and its potential to impact a wide range of tasks, under-\nstanding the effects of AI on the economy is one of society’s most important questions. In this work,\nwe take a step toward that goal by analyzing the work activities people do with AI, how successfully\nand broadly those activities are done, and combine that with data on what occupations do those activ-\nities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and\nMicrosoft Bing Copilot, a publicly available generative AI system. We find the most common work ac-\ntivities people seek AI assistance for involve gathering information and writing, while the most common\nactivities that AI itself is performing are providing information and assistance, writing, teaching, and\nadvising. Combining these activity classifications with measurements of task success and scope of impact,\nwe compute an AI applicability score for each occupation. We find the highest AI applicability scores for\nknowledge work occupation groups such as computer and mathematical, and office and administrative\nsupport, as well as occupations such as sales whose work activities involve providing and communicating\ninformation. Additionally, we characterize the types of work activities performed most successfully, how\nwage and education correlate with AI applicability, and how real-world usage compares to predictions of\noccupational AI impact.\n1\nIntroduction\nGeneral purpose technologies [7], such as the steam engine and the computer, have historically been strong\ndrivers of economic growth, impacting a broad range of sectors and accelerating this impact with each new\ntechnical advancement. In the last several years, generative AI has come to the fore as the next candidate\ngeneral purpose technology [17], capable of improving or speeding up tasks as varied as medical diagnosis [26]\nand software development [14]. These capabilities are reflected in the astounding rate of AI adoption: nearly\n40% of Americans report using generative AI at home or work, outpacing the growth of the personal computer\nand the internet [6]. Given this widespread adoption and potential for economic impact, a crucial question\nis which work activities are being most affected by AI and, by extension, which occupations.\nWe provide evidence towards answering this question by identifying the work activities performed in\nreal-world usage of a mainstream large language model (LLM)-powered generative AI system, Microsoft\nBing Copilot (now Microsoft Copilot). We analyze 200k anonymized user–AI conversations, which were\nautomatically scrubbed for any personally identifiable information, sampled representatively from 9 months\nof Copilot usage in the U.S. during 2024. A key insight of our analysis is that there are two distinct ways in\nwhich a single conversation with an AI assistant can affect the workforce, corresponding to the two parties\n∗This study was approved by Microsoft IRB #11028.\nWe thank Jennifer Neville, Ashish Sharma, Hancheng Cao, the\nMicrosoft Research AI Interaction and Learning Group, and the Microsoft Research Computational Social Science Working\nGroup for helpful discussions and feedback, and David Tittsworth, Jonathan McLean, Patrick Bourke, Nick Caurvina, and Bryan\nTower for software and data engineering support. Correspondence to: kitomlinson@microsoft.com, suri@micrsoft.com.\n1\narXiv:2507.07935v1  [cs.AI]  10 Jul 2025\nengaged in conversation. First, the user is seeking assistance with a task they are trying to accomplish; we\ncall this the user goal. Analyzing user goals allows us to measure how generative AI is assisting different\nwork activities. In addition, the AI itself performs a task in the conversation, which we call the AI action.\nClassifying AI actions separately lets us measure which work activities generative AI is performing.\nTo\nillustrate the distinction, if the user is trying to figure out how to print a document, the user goal is to\noperate office equipment, while the AI action is to train others to use equipment.\nTo measure how AI usage indicates potential occupational impact, we classify conversations into work\nactivities as defined by the O*NET database [28], which decomposes occupations hierarchically into the work\nactivities performed in those occupations. We measure how successfully different work activities are assisted\nor performed by AI, using both explicit thumbs up and down feedback from users and a task completion\nclassifier. To distinguish between broad and narrow AI contributions towards work activities, we also classify\nthe scope of AI impact demonstrated in each conversation toward each matching work activity. From these\nclassifications, we compute an AI applicability score for each occupation. This score captures if there is non-\ntrivial AI usage that successfully completes activities corresponding to significant portions of an occupation’s\ntasks.\nOur user goal vs. AI action distinction, combined with their classification into work activities, relates\nto a key question in the literature and public discourse around AI: to what extent is AI automating vs.\naugmenting work activities? The implication is that augmentation will raise wages and automation will\nlower wages or lead to job loss. However, this question often conflates the capability of a new technology\nwith the downstream business choices made as a result of that technology. For example, if AI makes software\ndevelopers 50% more productive, companies could raise their ambitions and hire more developers as they\nare now getting more output per developer, or hire fewer developers because they can get the same amount\ndone with fewer of them. Our data is only about AI usage and we have no data on the downstream impacts\nof that usage, so we only weigh in on the automation vs. augmentation question by separately measuring\nthe tasks that AI performs and assists.\nWe find that information gathering, writing, and communicating with others are the most common user\ngoals in Copilot conversations. In addition to being the most common user goals, information gathering and\nwriting activities receive the most positive thumbs feedback and are the most successfully completed tasks.\nOn the AI action side, we see that AI often acts in a service role to the human as a coach, advisor, or teacher\nthat gathers information and explains it to the user. Furthermore, the activities that AI performs are very\ndifferent from the user goals the AI assists: in 40% of conversations, these sets are disjoint. To measure\noccupation-level impacts, we use the standard practice of decomposing an occupation into its constituent\nwork activities [4]. The occupations with highest AI applicability scores are knowledge work and commu-\nnication focused occupations, but we find that all occupational groups have at least some potential for AI\nimpact (unsurprisingly, with much narrower effects on occupations with large physical components). More\nspecifically, we find the major occupation categories with the highest AI applicability scores are Sales; Com-\nputer and Mathematical; Office and Administrative Support; Community and Social Service; Arts, Design,\nEntertainment, Sports, and Media; Business and Financial Operations; and Educational Instruction and Li-\nbrary. Overall, our measurements largely align with predictions of AI labor impact made by Eloundou et al.\n[17], with correlation r = 0.73 between their occupation-level impact predictions and our AI applicability\nscore (r = 0.91 at the broadest occupation group level). We find a weak correlation between AI applicability\nscores and educational requirements, with occupations requiring a Bachelor’s degree slightly more affected\nthan jobs with lower requirements. In addition, we find only a slightly higher average AI applicability for\nhigh- (though not highest-) wage occupations.\n2\nRelated work\nA growing set of studies examine to what extent AI improves outcomes such as productivity in specific occu-\npational tasks like programming [31, 14], customer support [10], medical diagnosis [21, 26, 22], writing [29],\nconsulting [15], advertising [12], entrepreneurship [30], and legal analysis [13], among other settings. Rather\nthan measuring the effects of AI on productivity, the focus of our work is to understand what work activities\n2\nare people using AI for. To that end, we measure how people use LLMs in the wild.\nOur work draws from a common economic framework tracing its roots to Autor et al. [4], who decomposed\nan occupation into the tasks commonly done by that occupation and estimated how susceptible those tasks\nare to automation. This, in turn, lets one estimate job-level impacts. This technique has become a standard\npractice in the economics literature [1, 20, 19, 17, 9, 8, 33] and the business world [25].\nSome of these\npapers decompose an occupation into tasks to explain how previous forms of automation affected the labor\nmarket [4, 1], while others use them to predict how future forms of automation [20, 25], such as AI [19, 17,\n9, 8, 33, 18], will affect occupations. One notable recent work in this space is by Eloundou et al. [17], who\npredict (using both human and LLM judgments) which tasks and which jobs are most likely to be impacted\nby the recent advances in LLM technology. We contribute to this literature by analyzing actual conversations\nbetween humans and an LLM and showing which work activities those humans are using the LLM for. In\naddition, we compare our findings to the predictions of Eloundou et al. [17].\nThe study most similar to ours is a recent analysis by Handa et al. [23] of Claude conversations focused\non the economic activities that users perform on that AI platform.\nLike us, Handa et al. [23] classify\nconversations according the O*NET taxonomy, although there are several distinguishing features of our\napproaches.\nFirst, we separately classify that activity that the user is seeking assistance with and the\nactivity the AI is performing, which allows us to separate AI assistance from direct AI actions. Second,\nwe incorporate task success and scope of impact into our AI applicability score, providing more nuanced\nestimates of potential for AI impact. Third, we use different parts of the O*NET taxonomy, focusing on\nwork activities (which apply across occupations) rather than tasks (which are occupation-specific). This\nallows us to identify how a particular instance of AI usage impacts all occupations for which that activity is\nrelevant rather than needing to assign a particular occupation to that conversation, which introduces noise\nto the data since people in different occupations often do indistinguishable tasks. The smaller number of\nwork activities (332 compared to > 18k tasks) also allows us to do exhaustive binary classification, finding all\nrelevant work activities for every conversation, rather than the hierarchical classification approach of Handa\net al. [23] that assigns a single task to each conversation (and, by association, a single occupation). Finally,\nwe believe it is valuable for such analyses to be conducted across various AI platforms, as we find that the\ndistribution of Copilot usage differs substantially from Claude, with considerably less focus on computer and\nmathematical tasks. By combining the results of various such studies, we can build a fuller picture of overall\nAI impact.\n3\nData and methods\n3.1\nBing Copilot data\nWe analyze two collections of anonymized U.S. conversation data from Microsoft Bing Copilot (henceforth,\nCopilot) gathered over a nine-month period from January 1, 2024 to September 30, 2024. We focus only on\nconversations in the United States to align with occupation and work activity information from O*NET. We\ndenote our main data set Copilot-Uniform, which consists of approximately 100k conversations sampled\nuniformly from conversations in the United States over this time period. Copilot-Uniform provides a\nrepresentative view of what tasks users perform with a mainstream, publicly available, free-to-use generative\nAI chatbot. This dataset underlies the majority of analyses in this work.\nIn Copilot, a user can provide feedback on an LLM response by clicking a thumbs-up or a thumbs-down\nicon. To take advantage of this valuable signal of user satisfaction, we use a supporting data set denoted\nCopilot-Thumbs consisting of 100k uniformly sampled conversations containing at least one thumbs up or\nthumbs down reaction. Copilot-Thumbs allows us to investigate what activities are performed more or less\nsuccessfully, as measured by explicit user feedback. Note that Copilot-Thumbs may not be representative\nof overall task success, as some types of users may be more likely to provide feedback, or some types of tasks\nmay be more likely to elicit feedback from users. This motivates our use of an LLM classifier to evaluate\nwhether a conversation completed the user’s task, as described in Section 3.3.\n3\nTable 1: Example occupation and work activities from O*NET.\nOccupation\nTask\n−−−−−−−→\nmany–many\nDWA\n−−−−−→\nmany–1\nIWA −−−−−→\nmany–1\nGWA\nEconomists\nCompile, analyze, and report data\nto explain economic phenomena and\nforecast\nmarket\ntrends,\napplying\nmathematical models and statistical\ntechniques.\nForecast\neconomic,\npolitical,\nor\nsocial\ntrends.\nAnalyze\nmarket\nor\nindustry conditions.\nAnalyzing\nData\nor\nInformation.\n3.1.1\nUser goals and AI actions\nA key insight of our analysis is that there are two distinct ways in which a single conversation with an AI\nassistant can affect the workforce, corresponding to the two parties engaged in conversation. First, the user\nhas some task in mind with which they are seeking assistance from the AI, which we call the user goal. If\nthe user goal is described by some work activity, then the conversation provides evidence that people are\nseeking AI assistance with that work activity. On the other hand, the AI itself can perform a work activity\nin the conversation, which we call the AI action. The AI action represents work which may otherwise have\nbeen performed by a third party.\nEven in successful conversations, the AI action and user goal may not be the same: for instance, in\nresearch-based tasks, the user’s goal is to gather information (a work activity performed by journalists,\nscientists, etc), while the AI’s action is to provide information (a work activity performed by receptionists,\nlibrarians, customer service agents, etc). Another common example of asymmetric user goal and AI action\nis resolving computer issues (user goal) and providing technical support (AI action), although they may also\nbe the same (e.g., in the case of content generation).\n3.2\nO*NET and BLS data\nTo understand the structure and scope of labor in the United States, we draw on the O*NET 29.0 Database1.\nIn particular, we use O*NET’s hierarchical decomposition of occupations into their tasks and work activities.\nAt the lowest level of the O*NET hierarchy, an occupation contains a set of tasks performed in that occupa-\ntion. Each task is mapped to a set of detailed work activities (DWAs), which are more general descriptions of\nwork that apply to tasks that span different occupations. Every DWA belongs to an intermediate work activ-\nity (IWA), which in turn belongs to a generalized work activity (GWA); these provide more and more general\ngroupings of similar work activities. See Table 1 for an example. Our analysis focuses on IWAs, which map\nto multiple occupations through tasks. For instance, the IWA Analyze market or industry conditions from\nthe example is also performed by Marketing Managers, Credit Analysts, and Political Scientists, among 29\ntotal O*NET occupations. We combine O*NET with data on wages and employment from the Occupational\nEmployment and Wage Statistics data published by the U.S. Bureau of Labor Statistics (BLS)2.\n3.3\nWork activity classification\nFor each conversation in our datasets, we use a GPT-4o-based LLM classification pipeline to identify all\nintermediate work activities (IWAs) that match the user goal and the AI action. If the user goal or AI action\nis not related to any work activity, then it should be matched with zero IWAs. We validate our classifiers\nusing labels from three human annotators who were blind to the output of the classifier; see Appendix B\nfor details about the pipeline, prompts, and validation. We chose to classify at the IWA rather than task\nlevel for several reasons. First, classifying into IWAs is likely to be more accurate and reliable: there are\n332 IWAs, most of which are fairly distinct and non-overlapping, but there are 18,796 tasks, with a lot of\nredundancy. For instance, exactly one IWA describes all programming work activities (Program computer\n1Developed under U.S. Department of Labor sponsorship [28].\n2From May 2024 [35]. See Appendix A.1 for details about merging the datasets.\n4\nsystems or production equipment), whereas many O*NET occupations have (distinct) tasks that involve\nprogramming (e.g., Data Scientists, Web Developers, and Database Architects, among 30 others). Since we\ndo not know the occupations of users, we cannot hope to reliably distinguish between different programming\ntasks.\nSecond, since our research question is to understand the potential impact of AI on occupations,\nwe need to understand, to the extent possible, all of the occupations that do a work activity. IWA-level\nclassification allows us identify how capabilities demonstrated in one context translate to all occupations\nthat perform that work activity.\nSince each conversation can be assigned multiple IWAs, we focus on the activity share each IWA comprises,\nwhere we allocate an equal fraction of each conversation to each IWA it is labeled with, separately on the\nuser and AI sides.\n3.4\nOccupational coverage and AI applicability score\nTo measure the potential for impact on occupations we define a holistic AI applicability score for each\noccupation, where a higher score for an occupation means it is more likely to be impacted than an occupation\nwith a lower score. The score captures whether AI is being used (with sufficient activity share) for the work\nactivities of an occupation and whether that usage tends to be successful (completion rate) and cover a\nmoderate share of the work activity (scope), which we describe in turn.\nWe start by considering the work activities that are done a non-trivial amount with Copilot. We use a\nthreshold of 0.05% activity share3 above which we consider an IWA to appear in our data non-trivially often,\nwhich we refer to as “covered.” We then use this as a signal that AI can potentially assist or perform that\nIWA. To account for the fact that some tasks are more central to a job than others, we use the task relevance\nand importance metrics in O*NET to get a weight wij for each occupation-IWA pair, with weights summing\nto one within an occupation (see Appendix A.3 for details). We define the coverage of an occupation to\nbe the weighted fraction of its IWAs that are covered. Figure A12 shows how the average and standard\ndeviation of the occupation coverage varies with the threshold, and Figure A11 shows the distribution of\ncoverage scores. We chose the threshold 0.05% to minimize the number of occupations assigned coverage\n0 or 1, thereby maximizing the usefulness of the measure for relative comparisons between occupations;\nsee Figure A13. The ordering of occupations induced by our AI applicability score is robust to the chosen\ncoverage threshold; see Figure A14.\nNext, work activities that are completed more successfully with Copilot are more likely to experience AI\nimpact. Thus, we also perform a task completion classification with an LLM. For each conversation, we ask\nGPT-4o-mini4 if the AI completed the user’s task in the conversation. We validated our completion prompt\n(see Appendix B.1.1) with our Copilot-Thumbs dataset telling us which work activities receive the most\npositive user feedback, which we find to be highly correlated with task completion (weighted r > 0.75; see\nFigure A15).\nFor each matching IWA in a conversation, we also perform an LLM classification of the fraction of work\nin the IWA that Copilot demonstrates the ability to assist or perform, which we call the impact scope (or\nsimply scope), measured on a six-point Likert scale: none, minimal, limited, moderate, significant, complete.\nThe goal of impact scope is to distinguish between cases where Copilot assists with a large fraction of the\nwork in an IWA (e.g., Edit written documents or materials when Copilot edits a report) and a small portion\n(e.g., Research biological or ecological phenomena when the user ask what a mitochondrion is). As with the\nIWA classification, we validate the scope classifiers with human judges blind to the classifier outputs; see\nAppendix B for details.\nWe aggregate these measures into an occupational AI applicability score auser\ni\n, which for occupation i\ncalculated from user goals is\nauser\ni\n=\nX\nj∈IWAs(i)\nwij1[f user\nj\n≥0.0005]cuser\nj\nsuser\nj\n,\n(1)\n3Approximately equal to appearing in 100-300 conversations in our 100k samples, before converting to activity share.\n4This task is much simpler than the difficult and ambiguous IWA classification task, hence our use of the smaller model.\n5\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nMinimum fraction of occupation covered, User goal\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFraction of workforce covered\n0.001%\n0.01%\n0.05%\n0.1%\n1%\nFigure 1: Effect of coverage threshold on absolute impact estimates\nN ote: The share of workers who have at least x% of their work in covered IWAs for different definitions of an IWA\nbeing covered (.001%, . . . , 1% of user chat activity).\nThe resulting numbers depend significantly on the selected\nthreshold, making relative statements more meaningful than absolute coverage numbers.\nwhere IWAs(i) is the set of IWAs performed by occupation i, wij ∈[0, 1] is the importance- and relevance-\nweighted fraction of work in i composed of IWA j, f user\nj\n∈[0, 1] is the user goal activity share of j, cuser\nj\nis the\ntask completion rate of conversations with IWA j as a user goal, and sj is the fraction of conversations with\nuser goal j in which the scope classification is moderate or higher. We define aAI\ni\nsimilarly for AI actions,\nand report ai = (auser\ni\n+ aAI\ni )/2 unless otherwise specified.\nWe briefly contrast our approach of using a score for relative comparisons with a common metric in the\nliterature, a measurement [23] or prediction [17] of the fraction of occupations or of the workforce that have\nat least x% of their tasks impacted by AI. For instance, Eloundou et al. [17] predict that 80% of the U.S.\nworkforce could have at least 10% of their tasks affected by LLMs and 19% could have 50% of their tasks\naffected.5 Such measurements cannot be made reliably from usage data alone, as the selected threshold for\nusage has a significant impact on the resulting numbers, whose apparent straightforwardness belies this issue.\nFigure 1 shows that by picking different usage thresholds, we can conclude that either ∼0% of the workforce\nhas 50% of its importance-weighted tasks represented in our data (if we require 1% of chat activity for a\ntask to be covered) or ∼100% of the workforce (if we only require .01% of activity). As such, we believe it\nis much more meaningful to make relative statements about different kinds of occupations (who is more or\nless impacted, which is robust to arbitrary thresholds; see Figure A14) from this kind of usage data, which\nis what our AI applicability score is designed to do.\n4\nResults\n4.1\nGeneralized Work Activities\nSince GWAs are at the highest level of the O*NET work activity hierarchy, we use them for a macroscopic\nunderstanding of our data before focusing the rest of our analyses on the more specific IWAs. Figure 2\nshows the activity shares we see in Bing Copilot aggregated to GWAs, alongside the estimated fractions of\n5Similarly, Handa et al. [23] report that 36% of occupations have at least 25% of their tasks with Claude usage, with a\nthreshold of 15 or more conversations across 5 or more user accounts in their sample (approximately 0.0015% of conversation).\nThis type of number is sensitive to the chosen threshold.\n6\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nFraction of total activity\nOperating Vehicles, Mechanized Devices, or Equipment\nStaffing Organizational Units\nEstablishing and Maintaining Interpersonal Relationships\nResolving Conflicts and Negotiating with Others\nIdentifying Objects, Actions, and Events\nScheduling Work and Activities\nControlling Machines and Processes\nDeveloping Objectives and Strategies\nGuiding, Directing, and Motivating Subordinates\nRepairing and Maintaining Mechanical Equipment\nEvaluating Information to Determine Compliance with Standards\nOrganizing, Planning, and Prioritizing Work\nInspecting Equipment, Structures, or Materials\nEstimating the Quantifiable Characteristics of Products, Events, or Information\nMonitoring and Controlling Resources\nPerforming General Physical Activities\nPerforming Administrative Activities\nSelling or Influencing Others\nMonitoring Processes, Materials, or Surroundings\nProcessing Information\nHandling and Moving Objects\nJudging the Qualities of Objects, Services, or People\nTraining and Teaching Others\nCoaching and Developing Others\nAnalyzing Data or Information\nCommunicating with Supervisors, Peers, or Subordinates\nWorking with Computers\nMaking Decisions and Solving Problems\nUpdating and Using Relevant Knowledge\nProviding Consultation and Advice to Others\nThinking Creatively\nInterpreting the Meaning of Information for Others\nDocumenting/Recording Information\nAssisting and Caring for Others\nPerforming for or Working Directly with the Public\nCommunicating with People Outside the Organization\nGetting Information\nWorkforce\nCopilot user goal\nCopilot AI action\nFigure 2: Frequency of O*NET Generalized Work Activities (GWAs) in Copilot usage\nNote: This Figure shows the share of user goals and AI actions (right) mapping to each GWA, alongside our estimate\nof how much of the total work in the U.S. falls under each GWA. See Appendix A.2 for how the workforce share is\ncalculated.\nthe GWAs that appear in the workforce, computed from O*NET and BLS statistics (see Appendix A.2 for\nhow we estimate the total fraction of work in the U.S. falling under each IWA/GWA).\nThe GWAs where the amount of work in the workforce substantially exceeds the fractions we see in our\ndata generally align with types of work activities for which an LLM chatbot is ill-suited. These fall into three\nbroad clusters: physical activities (e.g., Handling and Moving Objects, Performing General Physical Activ-\nities), monitoring (e.g., Monitoring Processes, Monitoring Resources, Inspecting Equipment), and guiding\npeople or machines (e.g., Controlling Machines, Guiding Subordinates).\nThe GWAs more prevalent in Copilot data than in the workforce include GWAs such as Getting In-\nformation, Interpreting Information, Thinking Creatively, Updating and Using Knowledge, and Working\nwith Computers. These align with knowledge work [16], which concerns ideas and information rather than\nphysical goods or services, typically involving non-routine and creative problem-solving [27, 32, 34]. These\nGWAs show a focus of generative AI users on knowledge work activities, in line with findings from prior\nresearch [34, 23].\nThe GWAs that are more prevalent as an AI action (blue) than as a user goal (red) largely fall into two\n7\n0.0\n0.1\n0.2\nFraction of total activity\nCommunicate about specs/project details.\nAssist others to access resources.\nPrepare informational/instructional materials.\nInvestigate individuals.\nInterpret language/cultural/religious info.\nPresent research/technical info.\nProvide general assistance to others.\nResearch historical/social issues.\nImplement procedures or processes.\nCreate artistic designs/performances.\nEvaluate products/technologies.\nCreate visual designs or displays.\nOperate computers.\nExplain regulations/policies/procedures.\nProvide information to clients/customers.\nWrite artistic/commercial material.\nEdit written materials or documents.\nRead documents or materials.\nExplain tech. details of products/services.\nDevelop news/entertainment/artistic content.\nProvide info/assistance to the public.\nMaintain knowledge in area of expertise.\nRespond to customer problems or inquiries.\nObtain info about goods or services.\nGather info from various sources.\nWorkforce\nCopilot user goal\n0.00\n0.05\n0.10\n0.15\nFraction of total activity\nEdit written materials or documents.\nCreate artistic designs/performances.\nProcess digital or online data.\nInterpret language/cultural/religious info.\nCommunicate about specs/project details.\nPromote products, services, or programs.\nAdvise others on technology use/design.\nWrite artistic/commercial material.\nConfer with clients to determine needs.\nOperate computers.\nExplain regulations/policies/procedures.\nTeach academic or vocational subjects.\nDevelop news/entertainment/artistic content.\nProvide support or encouragement to others.\nPrepare informational/instructional materials.\nExplain tech. details of products/services.\nAdvise others on products/services.\nMaintain knowledge in area of expertise.\nAssist others to access resources.\nPresent research/technical info.\nGather info from various sources.\nProvide general assistance to others.\nProvide information to clients/customers.\nProvide info/assistance to the public.\nRespond to customer problems or inquiries.\nWorkforce\nCopilot AI action\nFigure 3: Frequency of top IWAs\nNote: This Figure shows the share of user goals (left) and AI actions (right) mapping to each IWA in the top 25 on\neach side, alongside our estimate of how much of the total work in the U.S. falls under each IWA. See Appendix A.2\nfor how the workforce share is calculated. IWA titles have been shortened for space.\nclusters: service to the user (e.g., Assisting/Caring for Others, Providing Advice, Coaching, Training) and\ncommunication (e.g., Communicating with People, Communicating with Supervisors). Conversely, the GWAs\nmore prevalent as a user goal than AI action are mostly related to knowledge work (e.g., Getting Information,\nThinking Creatively, Updating and Using Knowledge, Making Decisions, Analyzing Data). Thus, we find\nthat people are using Copilot to provide services for the execution of knowledge work activities, and do so\ndisproportionately often relative to the fraction of knowledge work in the workforce.\n4.2\nIntermediate Work Activities\nWe next analyze which IWAs are most common as Copilot user goals. Figure 3 (left) shows that these fall\ninto three broad categories: gathering information (e.g., Gather information, Obtain information, Maintain\nknowledge, Read documents), writing, editing, or developing content (e.g., Develop content, Write material,\nCreate visual designs), and communicating to others (e.g., Provide information, Provide assistance, Explain\ntechnology, Explain regulations).\nThe IWAs reflected in the AI actions tell a complementary story. Figure 3 (right) shows that the AI\nplays a service role: some common IWA verbs include Respond, Provide, Present, and Assist. More specifi-\ncally, Figure 3 shows that the most frequent IWAs fall into three broad categories: gathering and reporting\ninformation (e.g., Gather information, Prepare informational materials, Develop content), explaining infor-\nmation (e.g., Present research, Explain technical details, Explain regulations), and communicating with the\nuser (e.g., Respond to customer problems, Provide assistance, Provide information, Advise others). Com-\nbining the user goal and AI action IWAs again shows that humans are using AI to gather, process, and\ndisseminate information while the AI is helping by gathering, explaining, and communicating information\nto the user.\nFigure 3 shows that there is overlap between the activities on user and AI sides, but also some interesting\ndifferences. At the conversation level, the asymmetry is surprisingly pronounced: 40% of conversations have\ndisjoint sets of user goal and AI action IWAs, and 96% have more IWAs unique to each side than in common\n(i.e., Jaccard index < 0.5). Overall, the AI tends to do more advising and teaching whereas the user side\ninvolves more obtaining information, reading, and researching. Table 2 further investigates these differences\n8\nTable 2: Work activities with the most extreme ratios between user goal and AI action activity share\nMore often assisted by AI\nMore often performed by AI\nPurchase goods or services. (118.4x)\nTrain others on operational procedures. (17.9x)\nExecute financial transactions. (58.8x)\nTrain others to use equipment or products. (16.0x)\nPerform athletic activities. (47.3x)\nDistribute materials, supplies, or resources. (11.2x)\nObtain information about goods or services. (25.9x)\nTrain others on health or medical topics. (11.2x)\nResearch healthcare issues. (20.5x)\nProvide general assistance to others. (10.9x)\nPrepare foods or beverages. (14.7x)\nCoach others. (10.6x)\nResearch technology designs or applications. (13.5x)\nProvide information to clients/customers. (8.6x)\nObtain formal documentation or authorization. (12.5x)\nAdvise others on workplace health/safety. (7.5x)\nOperate office equipment. (11.4x)\nTeach academic or vocational subjects. (6.6x)\nInvestigate incidents or accidents. (11.3x)\nTeach safety procedures or standards. (6.5x)\nN ote: Only includes IWAs with user or AI activity share ≥0.05%. Numbers show IWA overrepresentation factors.\nby listing the IWAs where we see the biggest (relative) differences in user and AI activity shares. Naturally,\nthe AI is much more likely to assist (rather than perform) activities that involve a physical component, such\nas athletic activities and operating equipment, as well as activities that require interacting with other entities,\nsuch as purchasing goods and executing financial transactions (here, IWA verbs are very active: Purchase,\nExecute, Perform, Obtain, etc.). On the other hand, the AI is much more likely to perform activities related\nto training, coaching, teaching, and advising.\n4.2.1\nSatisfaction, task completion, and scope\nTo go beyond mere usage and map out potential impact on occupations, we need to understand if the LLM\nis actually helpful for these work activities. We use three different metrics to measure different aspects of\nthat question, one based on user feedback and two based on LLM analysis of the conversations.\nSatisfaction and completion.\nTo measure how successfully different work activities are assisted and\nperformed by Copilot, we use user thumbs feedback as a signal of satisfaction and an LLM task completion\nclassifier, as described in Section 3.4. For satisfaction, we report the share of feedback on conversations in\nCopilot-Thumbs matched to an IWA that is positive, i.e., the number of conversations with thumbs up\nover the total number of conversations with thumbs feedback. Figure 4 highlights the top and bottom 15\nIWAs by the fraction of feedback which is positive, after removing rare IWAs. All common IWAs have a\npositive feedback share of 50% or higher showing that, overall, people find Copilot helpful. More specifi-\ncally, we find that three types of work activities tend to have particularly positive feedback: those involving\nwriting and editing text (Edit documents, Write material), researching information (e.g., Research health-\ncare issues, Research laws, Maintain knowledge), and evaluating or purchasing goods (e.g., Purchase goods,\nEvaluate characteristics of products, Select materials). In contrast, we find that work activities involving\ndata analysis (e.g., Process data, Calculate financial data, Analyze scientific data) or visual design (e.g.,\nCreate visual/artistic designs, Arrange displays) have the worst feedback. These results suggest that Copilot\nis better at the writing and researching parts of knowledge work than its analysis and visual components.\nIf we do the same analysis aggregating to the GWA level (see Figure A3), we see that lower-satisfaction\nGWAs reveal a similar pattern, including Thinking Creatively, which the visual design IWAs map up to, and\nProcessing/Analyzing Information.\nThere are a few IWAs that have a noticeably large gap between the fraction of positive feedback when\nthey are a user goal vs. an AI action. Interestingly, the two largest are Provide support or encouragement to\nothers and Advise others on products or services. When the AI tries to directly provide support or advice,\npeople are less satisfied than when it helps them provide support or advice to others.\nThe GWA-level\nanalysis (Figure A3) also shows that activities involving doing things for others (coaching, providing advice,\n9\n0.5\n0.6\n0.7\n0.8\n0.9\nFeedback Positive Fraction\nCreate visual designs or displays.\nCreate decorative objects or parts of objects.\nAnalyze scientific or applied data using mathematical principles.\nDesign materials or devices.\nArrange displays or decorations.\nApply decorative finishes.\nDevelop models of systems, processes, or products.\nCreate artistic designs or performances.\nConfer with clients to determine needs or order specifications.\nCommunicate with others about specifications or project details.\nCalculate financial data.\nOperate computer systems or computerized equipment.\nEvaluate the quality or accuracy of data.\nProcess digital or online data.\nAnalyze business or financial data.\nWrite material for artistic or commercial purposes.\nResearch historical or social issues.\nMaintain current knowledge in area of expertise.\nExplain regulations, policies, or procedures.\nAdvise others on products or services.\nAssess characteristics or impacts of regulations or policies.\nEdit written materials or documents.\nSelect materials or equipment for operations or projects.\nEvaluate the characteristics, usefulness, or performance of products or technologies.\nPlan work activities.\nResearch laws, precedents, or other legal data.\nProvide support or encouragement to others.\nPurchase goods or services.\nInterpret language, cultural, or religious information for others.\nResearch healthcare issues.\nUser goal\nAI action\nFigure 4: IWAs with the highest and lowest shares of positive feedback\nNote: This Figure shows the top and bottom 15 IWAs by the share of positive feedback, filtered to common IWAs\nmatched in at least 1% of conversations in our feedback dataset, with bootstrapped 95% confidence intervals. The\ncommon IWAs with highest positive feedback share include two about writing and editing; four about evaluating or\npurchasing goods and services; and six about researching information about health, culture, law, policy, and society.\nMeanwhile, the common IWAs with the lowest positive feedback share include five visual design and five data analysis\nIWAs.\n10\nand interpreting things) stand out with high shares of positive feedback, all with even higher satisfaction\nwhen the AI helps the user do them than when it tries to do them itself.\nTo supplement thumbs feedback, we also look at which work activities have the highest and lowest\ncompletion rates, as described in Appendix B.1.1. Relative to the thumbs data, this has the disadvantage of\nnot reflecting the user’s opinion, but the advantage of avoiding selection in which users give feedback (which\nis why we use completion in our AI applicability score). We find that there is a strong correlation between\nthe positive feedback fraction for an IWA and its completion rate (weighted r = 0.83 for user goal IWAs and\nr = 0.76 for AI action IWAs, filtering out IWAs below activity share 0.05%; see Figure A15). Moreover, we\nfind very high consistency between IWA completion rates measured in Copilot-Uniform and Copilot-\nThumbs (weighted r > 0.9, see Figure A17). At the conversation level in Copilot-Thumbs, the correlation\nbetween whether a conversation received a thumbs up and whether it was classified as completing the user’s\ntask is r = 0.28, indicating they are related but that the relationship is noisier before aggregating to IWAs.\nFigure A4 shows the top and bottom IWAs by completion rate, which mostly shows similar patterns as the\ntop and bottom IWAs by thumbs feedback, with the addition of advice and explanation IWAs having high\ncompletion rates.\nScope of impact.\nIn addition to success within a conversation, another crucial aspect of work impact is the\nextent to which the AI capability demonstrated in the conversation translates to the work represented by an\nIWA. As described in Section 3.4, we use our measure of impact scope to identify which IWAs are most deeply\naffected by demonstrated AI capabilities. Figure A5 shows the IWAs with highest and lowest impact scope;\nas with satisfaction and completion, the most deeply impacted IWAs include gathering information and\nwriting, as well as providing information, advising, and explaining on the AI side. Low impact scope IWAs\nagain include data analysis and visual design, but also others about interacting with external people (e.g.,\nConfer with clients, Coordinate with others, Investigate individuals, Verify personal information). Notably,\nwe find consistently lower impact scope on the AI action side than the user goal side: our data indicates\nthat AI can help users with a broader fraction of their work than it can perform directly. Supporting the\nnotion that scope measures something different from completion, we find that scope is much less correlated\nwith completion than satisfaction is (weighted r = 0.45 and r = 0.22; see Figure A16). On the other hand,\nof these three measures, IWA scope is the best predictor of which activities people seek AI assistance with\nmost often (r = 0.64 with log user goal activity share; see Figure A18). That is, people are using LLMs for\nthe tasks for which the LLM can have broadest impact (but not necessarily the ones the LLM completes\nmost successfully).\n4.3\nOccupations\nTable 3 shows the 40 occupations with the highest AI applicability score as defined by Equation (1). Recall\nthat our AI applicability score combines, for each occupation, whether Copilot users are performing its\nassociated work activities (frequency > .05%) successfully (completion rate) and covering a broad share of\nthe work activity (scope ≥moderate). (See Section 3.4 and Equation (1) for more details.) Interpreters and\nTranslators are at the top of the list, with 98% of their work activities overlapping with frequent Copilot tasks\nwith fairly high completion rates and scope scores. Other occupations with high applicability scores include\nthose related to writing/editing, sales, customer service, programming, and clerking. Along with Interpreters\nand Translators, there are myriad other knowledge work occupations such as Historians, Writers and Authors,\nCNC Tool Programmers, Brokerage Clerks, Political Scientists, Reporters and Journalists, Mathematicians,\nProofreaders, Editors, PR Specialists, etc. By contrast, Table 4 shows the 40 occupations with the lowest\nAI applicability scores. The least-impacted occupations include occupations that require physically working\nwith people (e.g., Nursing Assistants, Massage Therapists), operating or monitoring machinery (e.g., Water\nTreatment Plant and Systems Operators, Pile Driver Operators, Truck and Tractor Operators), and other\nmanual labor (e.g., Dishwashers, Roofers, Maids and Housekeeping Cleaners). Note that our measurement\nis purely about LLMs: other applications of AI could certainly affect occupations involving operating and\nmonitoring machinery, such as truck driving.\n11\nTable 3: Top 40 occupations with highest AI applicability score.\nJob Title (Abbrv.)\nCoverage\nCmpltn.\nScope\nScore\nEmployment\nInterpreters and Translators\n0.98\n0.88\n0.57\n0.49\n51,560\nHistorians\n0.91\n0.85\n0.56\n0.48\n3,040\nPassenger Attendants\n0.80\n0.88\n0.62\n0.47\n20,190\nSales Representatives of Services\n0.84\n0.90\n0.57\n0.46\n1,142,020\nWriters and Authors\n0.85\n0.84\n0.60\n0.45\n49,450\nCustomer Service Representatives\n0.72\n0.90\n0.59\n0.44\n2,858,710\nCNC Tool Programmers\n0.90\n0.87\n0.53\n0.44\n28,030\nTelephone Operators\n0.80\n0.86\n0.57\n0.42\n4,600\nTicket Agents and Travel Clerks\n0.71\n0.90\n0.56\n0.41\n119,270\nBroadcast Announcers and Radio DJs\n0.74\n0.84\n0.60\n0.41\n25,070\nBrokerage Clerks\n0.74\n0.89\n0.57\n0.41\n48,060\nFarm and Home Management Educators\n0.77\n0.91\n0.55\n0.41\n8,110\nTelemarketers\n0.66\n0.89\n0.60\n0.40\n81,580\nConcierges\n0.70\n0.88\n0.56\n0.40\n41,020\nPolitical Scientists\n0.77\n0.87\n0.53\n0.39\n5,580\nNews Analysts, Reporters, Journalists\n0.81\n0.81\n0.56\n0.39\n45,020\nMathematicians\n0.91\n0.74\n0.54\n0.39\n2,220\nTechnical Writers\n0.83\n0.82\n0.54\n0.38\n47,970\nProofreaders and Copy Markers\n0.91\n0.86\n0.49\n0.38\n5,490\nHosts and Hostesses\n0.60\n0.90\n0.57\n0.37\n425,020\nEditors\n0.78\n0.82\n0.54\n0.37\n95,700\nBusiness Teachers, Postsecondary\n0.70\n0.90\n0.52\n0.37\n82,980\nPublic Relations Specialists\n0.63\n0.90\n0.60\n0.36\n275,550\nDemonstrators and Product Promoters\n0.64\n0.88\n0.53\n0.36\n50,790\nAdvertising Sales Agents\n0.66\n0.90\n0.53\n0.36\n108,100\nNew Accounts Clerks\n0.72\n0.87\n0.51\n0.36\n41,180\nStatistical Assistants\n0.85\n0.84\n0.49\n0.36\n7,200\nCounter and Rental Clerks\n0.62\n0.90\n0.52\n0.36\n390,300\nData Scientists\n0.77\n0.86\n0.51\n0.36\n192,710\nPersonal Financial Advisors\n0.69\n0.88\n0.52\n0.35\n272,190\nArchivists\n0.66\n0.88\n0.49\n0.35\n7,150\nEconomics Teachers, Postsecondary\n0.68\n0.90\n0.51\n0.35\n12,210\nWeb Developers\n0.73\n0.86\n0.51\n0.35\n85,350\nManagement Analysts\n0.68\n0.90\n0.54\n0.35\n838,140\nGeographers\n0.77\n0.83\n0.48\n0.35\n1,460\nModels\n0.64\n0.89\n0.53\n0.35\n3,090\nMarket Research Analysts\n0.71\n0.90\n0.52\n0.35\n846,370\nPublic Safety Telecommunicators\n0.66\n0.88\n0.53\n0.35\n97,820\nSwitchboard Operators\n0.68\n0.86\n0.52\n0.35\n43,830\nLibrary Science Teachers, Postsecondary\n0.65\n0.90\n0.51\n0.34\n4,220\nNote: Metrics reported as mean of user goal and AI action score.\n12\nTable 4: Bottom 40 occupations with lowest AI applicability score.\nJob Title (Abbrv.)\nCoverage\nCmpltn.\nScope\nScore\nEmpl.\nPhlebotomists\n0.06\n0.95\n0.29\n0.03\n137,080\nNursing Assistants\n0.07\n0.85\n0.34\n0.03\n1,351,760\nHazardous Materials Removal Workers\n0.04\n0.95\n0.35\n0.03\n49,960\nHelpers–Painters, Plasterers, ...\n0.04\n0.96\n0.38\n0.03\n7,700\nEmbalmers\n0.07\n0.55\n0.22\n0.03\n3,380\nPlant and System Operators, All Other\n0.05\n0.93\n0.38\n0.03\n15,370\nOral and Maxillofacial Surgeons\n0.05\n0.89\n0.34\n0.03\n4,160\nAutomotive Glass Installers and Repairers\n0.04\n0.93\n0.34\n0.03\n16,890\nShip Engineers\n0.05\n0.92\n0.39\n0.03\n8,860\nTire Repairers and Changers\n0.04\n0.95\n0.35\n0.02\n101,520\nProsthodontists\n0.10\n0.90\n0.29\n0.02\n570\nHelpers–Production Workers\n0.04\n0.93\n0.36\n0.02\n181,810\nHighway Maintenance Workers\n0.03\n0.96\n0.32\n0.02\n150,860\nMedical Equipment Preparers\n0.04\n0.96\n0.31\n0.02\n66,790\nPackaging and Filling Machine Op.\n0.04\n0.91\n0.39\n0.02\n371,600\nMachine Feeders and Offbearers\n0.05\n0.89\n0.36\n0.02\n44,500\nDishwashers\n0.03\n0.95\n0.30\n0.02\n463,940\nCement Masons and Concrete Finishers\n0.03\n0.92\n0.39\n0.01\n203,560\nSupervisors of Firefighters\n0.04\n0.88\n0.39\n0.01\n84,120\nIndustrial Truck and Tractor Operators\n0.03\n0.94\n0.28\n0.01\n778,920\nOphthalmic Medical Technicians\n0.04\n0.89\n0.33\n0.01\n73,390\nMassage Therapists\n0.10\n0.91\n0.32\n0.01\n92,650\nSurgical Assistants\n0.03\n0.78\n0.29\n0.01\n18,780\nTire Builders\n0.03\n0.93\n0.40\n0.01\n20,660\nHelpers–Roofers\n0.02\n0.94\n0.37\n0.01\n4,540\nGas Compressor and Gas Pumping Station Op.\n0.01\n0.96\n0.47\n0.01\n4,400\nRoofers\n0.02\n0.94\n0.38\n0.01\n135,140\nRoustabouts, Oil and Gas\n0.01\n0.95\n0.39\n0.01\n43,830\nMaids and Housekeeping Cleaners\n0.02\n0.94\n0.34\n0.01\n836,230\nPaving, Surfacing, and Tamping Equipment Op.\n0.01\n0.96\n0.29\n0.01\n43,080\nLogging Equipment Operators\n0.01\n0.95\n0.36\n0.01\n23,720\nMotorboat Operators\n0.01\n0.93\n0.39\n0.00\n2,710\nOrderlies\n0.00\n0.76\n0.18\n0.00\n48,710\nFloor Sanders and Finishers\n0.00\n0.94\n0.34\n0.00\n5,070\nPile Driver Operators\n0.00\n0.98\n0.24\n0.00\n3,010\nRail-Track Laying and Maintenance Equip. Op.\n0.00\n0.96\n0.27\n0.00\n18,770\nFoundry Mold and Coremakers\n0.00\n0.95\n0.36\n0.00\n11,780\nWater Treatment Plant and System Op.\n0.00\n0.92\n0.44\n0.00\n120,710\nBridge and Lock Tenders\n0.00\n0.93\n0.39\n0.00\n3,460\nDredge Operators\n0.00\n0.99\n0.22\n0.00\n940\nNote: Metrics reported as mean of user goal and AI action score.\n13\nExamine materials for accuracy.\nResearch historical or social issues.\nEvaluate data quality or accuracy.\nDevelop news, entertainment, or art.\nGather info from various sources.\nCompile records or documentation.\nProgram computer systems or equipment.\nAdvise others on educational matters.\nPresent research or technical info.\nInterpret language/cultural/religious info.\nPrepare informational materials.\nWrite artistic or commercial material.\nMaintain knowledge in area of expertise.\nProvide information to the public.\nExplain technical details of products.\nEdit written materials or documents.\nPromote products, services, or programs.\nProvide general assistance to others.\nRespond to customer inquiries.\nProvide information to customers.\nAdvertising Sales Agents (110K)\nProduct Promoters (51K)\nPR Specialists (280K)\nBusiness Teachers, Postsecondary (83K)\nEditors (96K)\nHosts and Hostesses (430K)\nProofreaders and Copy Markers (5.5K)\nTechnical Writers (48K)\nMathematicians (2.2K)\nReporters and Journalists (45K)\nPolitical Scientists (5.6K)\nConcierges (41K)\nTelemarketers (82K)\nFarm and Home Mgmt. Educators (8.1K)\nBrokerage Clerks (48K)\nBroadcast Announcers and DJs (25K)\nTicket Agents and Travel Clerks (120K)\nTelephone Operators (4.6K)\nCNC Tool Programmers (28K)\nCustomer Service Representatives (2.9M)\nWriters and Authors (49K)\nSales Representatives (1.1M)\nPassenger Attendants (20K)\nHistorians (3K)\nInterpreters and Translators (52K)\nFigure 5: Top occupations by AI applicability score and their contributing IWAs\nNote: This Figure shows the 25 occupations with the greatest AI applicability scores along with the 20 IWAs that\nprovide the greatest contributions to those scores. Occupations with higher employment have taller strata on the\nright. Portions of the occupational strata not connected to an IWA by a colored flow represent IWAs not present\nin the Figure that still contribute to the occupation’s applicability score. Occupations are sorted by their score,\ndecreasing. Both occupation and IWA titles have been shortened for space.\nFigure 5 explains why certain occupations had the highest applicability scores. The right side of Figure 5\nshows the 25 occupations with the highest AI applicability score. Occupations are in descending order of\napplicability score and the height of the boxes is indicative of employment (also shown in the labels). The\nleft side shows the work activities that contribute most to the scores for those occupations. The top IWAs\ninvolve delivering information to people such as Provide information to customers, Respond to customer\ninquiries, Provide general assistance to others, and Provide information to the public. These IWAs flow\ninto occupations such as Passenger Attendants, Sales Representatives, Customer Service Representatives,\nBroadcast Announcers, Concierges, Hosts and Hostesses, etc. While it may have been surprising at first\nglance to see these occupations with high AI applicability scores in Table 3, this is explained by AI’s ability\nto communicate information, which is a substantial component of these occupations.\n14\nTable 5: SOC Major groups sorted by AI Applicability Score\nMajor Group\nCoverage\nCompletion\nScope\nScore\nEmployment\nSales and Related\n0.56\n0.89\n0.51\n0.32\n13,266,370\nComputer and Mathematical\n0.64\n0.86\n0.48\n0.30\n5,177,390\nOffice and Administrative Support\n0.56\n0.89\n0.49\n0.29\n18,163,760\nCommunity and Social Service\n0.51\n0.88\n0.44\n0.25\n2,216,930\nArts, Design, Entertainment, Sports, Media\n0.59\n0.80\n0.49\n0.25\n2,039,830\nBusiness and Financial Operations\n0.49\n0.89\n0.47\n0.24\n10,087,850\nEducational Instruction and Library\n0.46\n0.89\n0.46\n0.23\n8,328,920\nArchitecture and Engineering\n0.49\n0.84\n0.46\n0.22\n2,523,090\nPersonal Care and Service\n0.39\n0.90\n0.45\n0.20\n2,959,620\nLife, Physical, and Social Science\n0.39\n0.88\n0.46\n0.20\n1,381,930\nFood Preparation and Serving Related\n0.32\n0.91\n0.43\n0.18\n13,142,870\nManagement\n0.27\n0.90\n0.45\n0.14\n10,445,050\nProtective Service\n0.33\n0.84\n0.40\n0.14\n3,484,710\nLegal\n0.33\n0.89\n0.42\n0.13\n1,196,870\nHealthcare Practitioners and Technical\n0.25\n0.91\n0.39\n0.12\n9,251,930\nInstallation, Maintenance, and Repair\n0.22\n0.92\n0.41\n0.11\n5,979,150\nProduction\n0.23\n0.91\n0.41\n0.11\n8,419,460\nTransportation and Material Moving\n0.21\n0.92\n0.38\n0.11\n13,664,940\nBuilding, Grounds Cleaning, Maintenance\n0.15\n0.94\n0.38\n0.08\n4,403,350\nConstruction and Extraction\n0.16\n0.92\n0.40\n0.08\n6,188,720\nFarming, Fishing, and Forestry\n0.11\n0.92\n0.39\n0.06\n422,740\nHealthcare Support\n0.13\n0.90\n0.38\n0.05\n7,063,540\nN ote: Metrics reported as mean of user goal and AI action\nThere are also a number of IWAs related to knowledge work such as Edit written materials, Maintain\nknowledge, Write artistic or commercial material, Interpret language/cultural information, and Program\ncomputers that flow into knowledge work occupations such as Technical Writers, Editors, Brokerage Clerks,\nPolitical Scientists, Mathematicians, Writers, PR Specialists, Interpreters and Translators, and CNC Tool\nProgrammers.\nTo get a broader view of the applicability of AI to occupations, we aggregate occupations to their Stan-\ndard Occupational Classification (SOC) major groups, which are 22 broad categories under which every\noccupation code falls6 [36].\nAggregating occupations highlights the trend of current AI applicability to\nknowledge work and communication-oriented occupations. Table 5 shows that Sales and Related, Computer\nand Mathematical, and Office and Administrative Support occupations have the highest AI applicability\nscores, with Sales and Office/Administrative Support also being two of the largest groups by employment.\nSimilarly, groups with a large communication component such as Community and Social Service and Edu-\ncational Instruction also have high AI applicability scores. Conversely, Healthcare Support has the lowest\nscore, along with occupations that involve physical labor or operating machinery such as Farming and Con-\nstruction. Table A2 provides a more granular view at the SOC minor group level (one level down in the\nSOC classification hierarchy), where the highest score groups are Media and Communication, Mathemati-\ncal Science, Sales Representatives of Services, Communications Equipment Operators, and Information and\nRecord Clerks.\nFinally, we identify which occupations differ most in the AI applicability scores computed only from user\ngoal IWAs and only from AI action IWAs (all results discussed above combine the two). Table A3 shows\noccupations that are ranked highly by AI applicability score on one side but not the other. Occupations\nwith potential for AI assistance but not AI performance (high auser\ni\n, low aAI\ni ) include occupations with\nphysical components, especially cooking and working with animals, tasks which are commonly assisted\n6Excluding military occupations, which are not fully represented in O*NET.\n15\nInterpreters and Translators\nSurvey Researchers\nAnimal Scientists\nPR Specialists\nWriters and Authors\nConcierges\nBrokerage Clerks\nExecutive Secretaries\nCounter and Rental Clerks\nStatisticians\nCustomer Service\nRepresentatives\nDoor−to−Door and Street Vendors\nLegal Secretaries\nPhysicists\nEnvironmental Scientists\nSoil and Plant Scientists\nTelephone Operators\nBroadcast Announcers and DJs\nPostsecondary Ed. Admin.\nMathematicians\nFirefighting Supervisors\nSales Representatives\nTicket Agents and Travel Clerks\nTelemarketers\nProduct Promoters\nProofreaders and Copy Markers\nMarket Research Analysts\nSchool Bus Monitors\nCNC Tool Programmers\nPassenger Attendants\n0.0\n0.2\n0.4\n0.6\n0.8\n0.0\n0.2\n0.4\nAI Applicability Score\nEloundou et al. (2024) Human−Rated Exposure\nTotal Employment\n100K workers\n500K workers\n1.5M workers\nFigure 6: Comparing the AI applicability score to the human-rated E1 exposure from Eloundou et al. [17].\nN ote: The AI applicability score is the fraction of work activity in an occupation that appears in Copilot data,\nadjusted by completion rate and impact scope. The Eloundou et al. [17] E1 metric comes from asking human raters\nwhether LLM technology could allow a task to be completed at least 50% faster and then computing the fraction of\nan occupation’s tasks labeled as E1. Occupations are colored by their distance from the regression line: blue points\nhave higher E1 than AI applicability score, and vice versa for red points.\nbut not performed by Copilot (e.g., Cooks and Animal Breeders). Conversely, occupations with potential\nfor AI performance but not assistance (low auser\ni\n, high aAI\ni ) focus on teaching, training, managing, and\ncommunicating (e.g., Training and Development Managers, Coaches and Scouts, and HR Specialists).\n4.3.1\nComparing to predictions\nWe now examine how our measurements from real-world AI usage data compare to predictions of occu-\npational AI impact. Eloundou et al. [17] asked both people and GPT-4 to predict which tasks would be\nimpacted by LLM technology. For each occupation they then calculated a metric they call E1, “the share of\nan occupation’s tasks where access to an LLM alone or with a simple interface would lead to 50% time sav-\nings” [17]. Figure 6 plots E1 against our AI applicability score. 7 We would not necessarily expect alignment\nbetween the two metrics, since we cannot assess how much time people are saving on their tasks. However,\nthe occupation-level correlation (weighted by employment) between their predictions and our measurements\nof occupational AI applicability is r = 0.73; this increases to a remarkably high r = 0.91 when aggregating\noccupations to their SOC major groups.\nFigure 6 labels some of the occupations where the two metrics diverge. Some red-colored occupations\nin the lower-right where our estimate is high relative to theirs, such as Market Research Analysts and CNC\nTool Programmers, seem like they may have missed some of the potential uses of the technology. Others,\nsuch as Passenger Attendants and School Bus Monitors, seem like places where our method is potentially\nover-extrapolating the tool’s ability to Provide information to occupations where LLMs may be less relevant.\nFor the blue-colored occupations in the upper-left, where our metric is surprisingly low, we find their low\n7See Section 3.4. For this comparison only, we use a uniform weighting over tasks to compute AI applicability score to align\nwith the approach of Eloundou et al. [17].\n16\n$25,000\n$50,000\n$100,000\n$200,000\n$400,000\nAverage Wage\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nAI Applicability Score\nWLS, r = 0.07\nWLS w/o top 10%, rw = 0.13\nBinscatter\nAll occupations\n(a) Occupation wage\nLess than\nHigh School\nH.S. or\nequiv.\nSome Col.\n- Assoc.\nBachelor's\nMaster's\nor higher\nModal Education Requirement\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nAI Applicability Score\n(b) Education requirements\nFigure 7: AI applicability scores across socioeconomic correlates.\nN ote: These Figures plot occupation AI applicability scores against the (a) average wage and (b) the most common\neducation requirement reported in O*NET surveys. In (a), binscatters and weighted least squares (WLS) fit lines\nare weighted by employment. Excluding the top 10% of highest-paid workers slightly increases the correlation with\nwage. In (b), boxplots show medians and quartiles weighted by employment (i.e., the median worker rather than the\nmedian occupation)\nemployment and specialization means that their work activities are rare. Thus, even if an LLM may be\nwell-suited to them, these activities are not done sufficiently often to meet our .05% coverage threshold.\n4.3.2\nSocioeconomic correlates\nIt is natural to ask how AI applicability score correlates with wage and education. Some prior work predicts\nthat higher-wage occupations will be substantially more affected by generative AI [17, 18], while other prior\nwork predicts no correlation for pre-LLM machine learning [9]. Figure 7a shows a scatter and binscatter\nplot of AI applicability score and average occupation wage (computed using BLS data), with a dot for each\noccupation and darker points for the average of each ventile weighted by employment. Despite looking at\nthis relationship several different ways, we do not find a strong and consistent relationship between AI ap-\nplicability score and wage. The employment-weighted correlation between AI applicability score and wage\nis only 0.07 (Figure A6 separates this into user goals, with a correlation of 0.05, and AI actions, with a\ncorrelation of 0.10). Since others have found a decrease in AI exposure at the highest-wage occupations [17],\nwe also calculate the employment-weighted correlation omitting these occupations, which is still only 0.13.\nFigure A8 shows the correlation between AI applicability score and average occupation wage without em-\nployment weighting, which increases the correlation to 0.17 for user goals and 0.21 for AI actions.8 The\ndifference between the weighted and unweighted results is primarily due to high-employment Sales and Of-\nfice and Administrative Support occupations that have relatively low wages, but high AI applicability. There\nis a lot of variation across occupations and some occupations will be much more affected than others, but\nthe overall relationship between wage and AI applicability is weak.\n8Most prior work did not weight occupations by employment when examining the relationship between AI exposure and\nwage. Since occupations vary a lot in size and the boundaries are somewhat subjective (e.g., Cooks get separate occupations for\nShort Order, Restaurant, Institution and Cafeteria, and Fast Food, but Maids and Housekeeping Cleaners are one category),\nresults weighted by occupation better answer the research question about overall workforce relationship between wages and\noccupational applicability of AI.\n17\nO*NET also provides the education required for each occupation, from surveys of incumbents. Figure 7b\nshows the distribution of AI applicability score by the modal education requirement, weighted by employ-\nment. Occupations requiring a Bachelor’s degree tend to have higher AI applicability score than occupations\nwith lower educational requirements: the employment-weighted mean score for Bachelor’s is 0.27, compared\nto 0.19 for all groups below Bachelor’s, a significant difference (weighted t-test p < 10−14). Splitting out\nthe user and AI applicability scores, we find the difference to be more pronounced on the AI action side\n(Figure A7). However, there is still substantial overlap between applicability scores across education require-\nments. Without employment-weighting, the trend appears monotonic (Figure A9), again due to Sales and\nOffice and Administrative Support that have high AI applicability score and employment but low modal\neducation requirements.\n5\nDiscussion\nWe analyzed Bing Copilot conversations to see what work activities users are seeking AI assistance with,\nwhat activities the AI performs, and what this means about occupations. A work activity seen in current AI\ninteraction data demonstrates an AI capability being leveraged by some users that could extend to other uses\nand to occupations which perform that activity. We combine this evidence of demonstrated capability with\nmeasures of task success and scope of impact into an AI applicability score for occupations, which allows us to\ntrack the frontier of AI’s relevance to work. The current capabilities of generative AI align most strongly with\nknowledge work and communication occupations, though most occupations have at least some potential for\nAI collaboration. Occupations for which the overlap is small or non-existent include those involving manual\nlabor, operating machinery, or other physical activities. Turning to socioeconomic correlates, we find a very\nsmall positive correlation between our AI applicability measure and occupational wage. In terms of education\nrequirements, we find higher AI applicability for occupations requiring a Bachelor’s degree than occupations\nwith lower requirements. However, our data indicate a wide range of potential impact across the wage and\neducation distributions. When comparing to predictions of occupational AI impact [17], we find that these\nare largely borne out in usage data, especially at the most general, coarsest aggregation levels. However, the\nmagnitude of this impact (if not its direction) remains to be seen.\nOur data do not indicate that AI is performing all of the work activities of any one occupation. That being\nsaid, the overlap between AI capabilities and various occupations is very uneven. There are definitely some\noccupations for which many—perhaps even most—work activities have some overlap with demonstrated AI\ncapabilities. But even when there is overlap, the task completion rate is not 100% and the scope of impact\nis usually moderate. Thus, even when there is overlap between an AI capability and a work activity, it does\nnot mean the work activity is done to its full extent all of the time. Furthermore, there are a few limitations\nto these analyses that prevent us from assessing the total fraction of work being done with AI. First, we are\nonly able to analyze the data from one widely used, publicly available LLM. Different people use different\nLLMs for different purposes. Second, decomposing an occupation into its work activities, while standard\npractice in the literature, does not provide a complete representation of every occupation: the connecting\nglue between tasks also contributes to the value of work. Finally, this decomposition can only be as accurate\nand up to date as the O*NET database.\nOne of the key aspects of our analysis is our classification of work activities into actions the AI performs\nversus user goals the AI assists with. In terms of AI performing actions, we show that it often does so in\na supporting role to the human acting as a coach, trainer, or advisor [24]. The most common user goals\nthat Copilot assists with involve gathering information, writing, and communicating. The relatively high\nprevalence of information gathering may be due to Copilot’s connection to the Bing search engine at the\ntime our data originates. Information gathering and writing are also the most successful work activities, as\nmeasured by thumbs up, task completion, and impact scope, indicating that Copilot is providing significant\nuseful input to these activities. We also saw that it can be helpful beyond the boundaries of what AI can\nphysically do. For example, it can help people cook by providing recipe and nutritional suggestions without\nactually performing the cooking activities. Compared to a similar analysis of Claude conversations, Copilot\nusage is much less focused on programming and mathematical tasks, which comprises more than a third of\n18\n“occupationally relevant” Claude usage [23]. As discussed above, this may be due to the different population\nof users who choose to use one AI assistant versus another.\nIt is tempting to conclude that occupations that have high overlap with activities AI performs will be\nautomated and thus experience job or wage loss, and that occupations with activities AI assists with will be\naugmented and raise wages. This would be a mistake, as our data do not include the downstream business\nimpacts of new technology, which are very hard to predict and often counterintuitive [3]. Take the example\nof ATMs, which automated a core task of bank tellers, but led to an increase in the number of bank teller\njobs as banks opened more branches at lower costs and tellers focused on more valuable relationship-building\nrather than processing deposits and withdrawals [5].\nThis work gives rise to a number of future research questions of extremely high importance to society.\nWe measured how AI capabilities overlap with work activities, but it remains to be seen how different\noccupations refactor their work responsibilities in response to AI’s rapid progress. It could be that jobs\nchange which activities they encompass, as in the case of bank tellers and ATMs. In addition, entirely new\noccupations may emerge due to the rise of AI, performing new types of work activities [11]. This is not a new\nphenomenon: the majority of occupations today arose in the last 100 years as a result of new technologies [2].\nExactly which new jobs emerge, and how old ones are reconstituted, is an important future direction in the\nAI age. At the same time, the technology itself will continue to evolve; our measurement of AI applicability\nis only a snapshot in time. An important research question going forward is to understand how the frontier\nof AI capabilities is shifting, and which occupations have more or less overlap with that moving frontier.\nMeasuring changes in AI usage over time will help reveal how these new capabilities are exploited.\nThere are some natural limitations, in addition to the ones already stated, to the conclusions that can be\ndrawn from our data. It is very difficult (or impossible) to determine what conversations are performed in\na work context or for leisure.9 As such, we looked for work activities performed in any conversation to find\nevidence that AI can impact tasks of that type. It is also difficult to determine the magnitude of impact that\nAI might have on different work activities based only on this conversation data; we attempted to address\nthis issue with measures of task completion and scope of impact, but these are imperfect and approximate.\nAnother gap is the difference between the way work activities are performed in occupations compared to\nin our data (for instance, Provide general assistance means something different for a passenger attendant\nand for Copilot). We reiterate that our data also represents only one slice of the AI market: there are\nmany other AI platforms, including more task- or occupation-specific LLMs, which are not represented in\nour data. Finally, our use of O*NET means our results are shaped by its U.S.-centric view, may lag behind\ncurrent actual workplace activities, and do not capture valuable tasks performed outside of occupations (e.g.,\nwork in the home or volunteering). Modernizing our understanding of workplace activities will be crucial as\ngenerative AI continues to change how work is done.\nReferences\n[1] Daron Acemoglu and Pascual Restrepo. Automation and new tasks: How technology displaces and\nreinstates labor. Journal of Economic Perspectives, 33(2):3–30, May 2019. doi: 10.1257/jep.33.2.3.\nURL https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3.\n[2] David Autor, Caroline Chin, Anna Salomons, and Bryan Seegmiller. New frontiers: The origins and\ncontent of new work, 1940–2018. The Quarterly Journal of Economics, 139(3):1399–1465, 2024.\n[3] David H Autor. Why are there still so many jobs? the history and future of workplace automation.\nJournal of Economic Perspectives, 29(3):3–30, 2015.\n[4] David H Autor, Frank Levy, and Richard J Murnane. The skill content of recent technological change:\nAn empirical exploration. The Quarterly Journal of Economics, 118(4):1279–1333, 2003.\n9Is someone asking for a recipe a chef brainstorming their new menu or just someone cooking dinner at home? Is someone\nasking for information about a video game a QA tester, a game developer, or just a gamer? We can make (potentially high-\nprobability) guesses in these cases, but consistently making the highest-probability guess may lead us to conclude that video\ngame QA testers and chefs have no AI impact on their occupations.\n19\n[5] James Bessen. Toil and technology: Innovative technology is displacing workers to new jobs rather than\nreplacing them entirely. Finance & Development, 52(001):16, 2015.\n[6] Alexander Bick, Adam Blandin, and David J Deming. The rapid adoption of generative AI. Technical\nreport, National Bureau of Economic Research, 2024.\n[7] Timothy F Bresnahan and Manuel Trajtenberg. General purpose technologies: “engines of growth”’?\nJournal of Econometrics, 65(1):83–108, 1995.\n[8] Erik Brynjolfsson and Tom Mitchell. What can machine learning do? workforce implications. Science,\n358(6370):1530–1534, December 2017.\n[9] Erik Brynjolfsson, Tom Mitchell, and Daniel Rock. What can machines learn, and what does it mean\nfor occupations and the economy? AEA Papers and Proceedings, 108:43–47, May 2018. doi: 10.1257/\npandp.20181019. URL https://www.aeaweb.org/articles?id=10.1257/pandp.20181019.\n[10] Erik Brynjolfsson, Danielle Li, and Lindsey Raymond. Generative AI at work. The Quarterly Journal\nof Economics, pages 889–942, 2025.\n[11] Robert Capps. A.I. Might Take Your Job. Here Are 22 New Ones It Could Give You. The New York\nTimes Magazine, June 2025. URL https://www.nytimes.com/2025/06/17/magazine/ai-new-jobs.\nhtml.\n[12] Zenan Chen and Jason Chan. Large language model in creative work: The role of collaboration modality\nand user expertise. Management Science, 70(12):9101–9117, 2024.\n[13] Jonathan H Choi, Amy B Monahan, and Daniel Schwarcz. Lawyering in the age of artificial intelligence.\nMinn. L. Rev., 109:147, 2024.\n[14] Zheyuan Kevin Cui, Mert Demirer, Sonia Jaffe, Leon Musolff, Sida Peng, and Tobias Salz. The effects\nof generative AI on high skilled work: Evidence from three field experiments with software developers.\nTechnical report, Available at SSRN 4945566, 2024.\n[15] Fabrizio Dell’Acqua, Saran Rajendran, Edward McFowland III, Lisa Krayer, Ethan Mollick, Fran¸cois\nCandelon, Hila Lifshitz-Assaf, Karim R. Lakhani, and Katherine C. Kellogg. Navigating the jagged\ntechnological frontier: Field experimental evidence of the effects of ai on knowledge worker productivity\nand quality, 2023.\n[16] Peter Ferdinand Drucker. Landmarks of tomorrow: a report on the new ”post-modern” world. Harper,\nNew York, 1st edition, 1959.\n[17] Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. GPTs are GPTs: Labor market\nimpact potential of LLMs. Science, 384(6702):1306–1308, 2024.\n[18] Ed Felten, Manav Raj, and Robert Seamans. How will language modelers like chatgpt affect occupations\nand industries? arXiv preprint arXiv:2303.01157, 2023.\n[19] Edward W. Felten, Manav Raj, and Robert Seamans. A method to link advances in artificial intelligence\nto occupational abilities. AEA Papers and Proceedings, 108:54–57, May 2018. doi: 10.1257/pandp.\n20181021. URL https://www.aeaweb.org/articles?id=10.1257/pandp.20181021.\n[20] Carl Benedikt Frey and Michael A. Osborne. The future of employment: How susceptible are jobs\nto computerisation?\nTechnological Forecasting and Social Change, 114:254–280, 2017.\nISSN 0040-\n1625. doi: https://doi.org/10.1016/j.techfore.2016.08.019. URL https://www.sciencedirect.com/\nscience/article/pii/S0040162516302244.\n20\n[21] Ethan Goh, Robert Gallo, Jason Hom, Eric Strong, Yingjie Weng, Hannah Kerman, Jos´ephine A Cool,\nZahir Kanjee, Andrew S Parsons, Neera Ahuja, et al. Large language model influence on diagnostic\nreasoning: a randomized clinical trial. JAMA Network Open, 7(10):e2440969–e2440969, 2024.\n[22] Paul Hager, Friederike Jungmann, Robbie Holland, Kunal Bhagat, Inga Hubrecht, Manuel Knauer,\nJakob Vielhauer, Marcus Makowski, Rickmer Braren, Georgios Kaissis, et al. Evaluation and mitigation\nof the limitations of large language models in clinical decision-making. Nature medicine, 30(9):2613–\n2622, 2024.\n[23] Kunal Handa, Alex Tamkin, Miles McCain, Saffron Huang, Esin Durmus, Sarah Heck, Jared Mueller,\nJerry Hong, Stuart Ritchie, Tim Belonax, Kevin K. Troy, Dario Amodei, Jared Kaplan, Jack Clark,\nand Deep Ganguli. Which economic tasks are performed with AI? evidence from millions of Claude\nconversations. arXiv preprint arXiv:2503.04761, 2025.\n[24] Jake M Hofman, Daniel G Goldstein, and David M Rothschild. A sports analogy for understanding\ndifferent ways to use AI. Harvard Business Review, 4, 2023.\n[25] James Manyika, Michael Chui, Mehdi Miremadi, Jacques Bughin, Katy George, Paul Willmott, and\nMartin Dewhurst. A future that works: Automation, employment, and productivity. Technical report,\nMcKinsey Global Institute, 2017.\n[26] Daniel McDuff, Mike Schaekermann, Tao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan Singhal,\nYash Sharma, Shekoofeh Azizi, Kavita Kulkarni, et al. Towards accurate differential diagnosis with\nlarge language models. Nature, pages 1–7, 2025.\n[27] C. McKercher and V. Mosco. Knowledge Workers in the Information Society. Critical media stud-\nies. Lexington Books, 2008.\nISBN 9780739117811.\nURL https://books.google.com/books?id=\n_MeCr31C9S8C.\n[28] National Center for O*NET Development. O*NET Database Version 29.0, 2024. URL https://www.\nonetcenter.org/db_releases.html. Accessed: 2025-05-29.\n[29] Shakked Noy and Whitney Zhang. Experimental evidence on the productivity effects of generative\nartificial intelligence. Science, 381(6654):187–192, 2023.\n[30] Nicholas G Otis, Sol`ene Delecourt, Katelyn Cranney, and Rembrand Koning. Global Evidence on Gender\nGaps and Generative AI. Harvard Business School, 2024.\n[31] Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer.\nThe impact of AI on developer\nproductivity: Evidence from GitHub copilot. arXiv preprint arXiv:2302.06590, 2023.\n[32] Wolfgang Reinhardt, Benedikt Schmidt, Peter Sloep, and Hendrik Drachsler. Knowledge worker roles\nand actions—results of two empirical studies.\nKnowledge and Process Management, 18(3):150–174,\n2011. doi: https://doi.org/10.1002/kpm.378. URL https://onlinelibrary.wiley.com/doi/abs/10.\n1002/kpm.378.\n[33] Yijia Shao, Humishka Zope, Yucheng Jiang, Jiaxin Pei, David Nguyen, Erik Brynjolfsson, and Diyi\nYang. Future of work with AI agents: Auditing automation and augmentation potential across the U.S.\nworkforce, 2025. URL https://arxiv.org/abs/2506.06576.\n[34] Siddharth Suri, Scott Counts, Leijie Wang, Chacha Chen, Mengting Wan, Tara Safavi, Jennifer Neville,\nChirag Shah, Ryen W White, Reid Andersen, et al. The use of generative search engines for knowledge\nwork and complex tasks. arXiv preprint arXiv:2404.04268, 2024.\n[35] U.S. Bureau of Labor Statistics. Occupational Employment and Wage Statistics (OEWS), May 2024,\n2024. URL https://www.bls.gov/oes/tables.htm. Accessed: 2025-05-29.\n[36] U.S. Office of Management and Budget. Standard Occupational Classification Manual, 2018, 2017. URL\nhttps://www.bls.gov/soc/2018/soc_2018_manual.pdf. Accessed: 2025-07-07.\n21\nA\nData Details\nA.1\nMerging O*NET and BLS data\nThe Occupational Employment and Wage Statistics data identifies occupations by Standard Occupational\nClassification (SOC) codes, which differ slightly from the O*NET-SOC codes used in O*NET data. We use\nthe BLS-provided mapping between the codes (https://www.bls.gov/emp/documentation/crosswalks.\nhtm) and present all of our results in terms of SOC occupations. When multiple O*NET-SOC occupations\nshare the same SOC code (e.g., Tour Guides and Travel Guides share the SOC code for “Tour and travel\nguides”), we take the union over O*NET data mapping to the SOC Code (e.g., tasks and DWA/IWA/GWAs).\nA.2\nCalculating real world IWA frequency\nFor each task, O*NET provides the share of respondents in an occupation that perform that task at various\nfrequency levels (e.g., hourly, weekly, yearly). To convert these into annual total workforce counts for each\nIWA, we perform the following procedure:\n1. Convert O*NET task frequency categories into annual counts based on 260 workdays / year and 8\nhours / workday: “Yearly or less”: 1, “More than yearly”: 4, “More than monthly”: 24, “more than\nweekly”: 104, “Daily”: 260, “Several times daily”: 780, “Hourly or more”: 2080.\n2. For each task, compute its average annual frequency by averaging the above counts (weighted by\nsurveyed percentages) and multiplied by relevance.\n3. To get IWA-level frequencies, sum over tasks mapping to the same IWA.\n4. To compute the total annual counts of an IWA in the workforce, sum over all occupations performing\nthe IWA, multiplying by employment of each occupation.\nA.3\nAggregating from IWAs to Occupations\nFirst, we merge all O*NET-SOC occupations into SOC occupations, taking the union of their tasks. Then,\nwe compute a weight for every task using the importance and relevance score in O*NET.10 More precisely,\nfor each task i in SOC occupation j, we say weightij = 2importanceij · relevanceij. If an occupation has no\nratings for any of its tasks, assign them all weight 1. If an occupation has ratings for only some of its tasks,\nwe ignore the tasks with missing ratings. We propagate these task weights to IWAs through the DWAs that\neach task maps to, summing weights for tasks mapping to the same IWA. Dividing by the total weight for\nan occupation then gives us a proxy measure for how much of a job consists of each of its work activities.\nB\nClassification pipeline and validation\nWe developed a two-stage LLM-based pipeline classifying user goals and AI actions in a conversation. In the\nfirst-stage prompts, we give an LLM (specifically, GPT-4o) the entire conversation and ask it to summarize\n(a) the user goal and (b) the AI action in the style of an O*NET IWA, as well as four rewordings of each\nstatement.11 We then use these summaries to sort all IWA statements in order of relevance to the user task\nand AI goal (creating two rankings) through cosine similarity of their OpenAI text-embedding-3-large\nembeddings.\nMore specifically, we sort by average similarity between true IWAs and the five alternate\nphrasings of the LLM-generated summaries to average out differences caused by word choice rather than\n10The relevance of a task to an occupation is the fraction of surveyed incumbents who said the task was relevant to their job.\nThe importance of a task is a score from 1 to 5 representing the average response to a five-point Likert question about how\nimportant the task is to the incumbent’s job (if they said the task was relevant).\n11We found strong evidence that GPT-4o includes O*NET data in its pretraining corpus, as it exhibits strong knowledge of\nO*NET structure, occupational information, and work activities.\n22\nmeaning. In the second-stage prompts, we use GPT-4o to do a binary classification for every IWA as to\nwhether it matches the user goal or AI action in the conversation. The user and AI classifications are done\nin separate prompts, with each prompt containing 20 IWAs for classification (taking the sorted order from\nstage one and splitting into contiguous blocks of 20 IWAs). In validation against human labels (discussed\nlater), we found that GPT-4o could perform 20 IWA classifications in a single prompt without degrading\naccuracy, but that more led to worse classification; we also found that grouping IWAs by level of similarity as\ndescribed led to higher classification reliability. As another measure to improve agreement between human\nand LLM labels, we provide the first GPT-4o-generated summary from stage one as an additional “IWA”\nin each prompt, which serves as a point of reference against which other IWAs are measured. Compared to\nalternative approaches (e.g., hierarchical clustering-based classification [23]), our pipeline sacrifices efficiency\nfor thoroughness.\nWe tuned and validated our prompts using independent annotations by three of the authors on a sample of\n195 anonymized English conversations which were already automatically scrubbed of personally identifiable\ninformation (the sensitive nature of the data precluded external annotators). For each conversation, the\nthree annotators were shown the conversation text, 20 candidate user goal IWAs, and 20 candidate AI\naction IWAs.\nThese sets of 20 consisted of the 10 most similar according to cosine similarity to stage\none summaries (where matches are dramatically more likely) and 10 uniformly sampled from the next 90\nmost similar IWAs, all shuffled together; the same IWAs were sampled across annotators. The annotators\nindependently listed all matching IWAs for the user goal and all matching IWAs for the AI action. We\nrandomly split the conversations into a validation set of 95 used for prompt and pipeline tuning and a test\nset of 100, which was not touched until all full-scale pipeline runs had completed. The binary classification\ntask over IWA matches was challenging but still had moderate agreement, with Cohen’s kappa inter-rater\nreliabilities of 0.51, 0.58, 0.41 between the three pairs of annotators for user goal classification and 0.50,\n0.49, 0.57 for AI action (on the test set). Our final classification pipeline achieves Cohen’s kappas with our\nthree annotators on the test set that are only slightly lower: 0.44, 0.35, 0.38 for user goal and 0.53, 0.34,\n0.39 for AI action (with very similar scores on validation, indicating that our prompt tuning did not result\nin overfitting). These kappa scores are generally low due to the high degree of uncertainty around whether a\nparticular IWA accurately describes the intent of the user or the action of the AI; in many cases, it is easy to\nmake compelling arguments both that an IWA does and does not apply to a conversation, so we found even\nmoderate agreement encouraging. Additionally, the overall match rate is very low (single-digit percentages),\nso the overall accuracies of all raters (including our LLM pipeline) with respect to each other are well over\n90%. Our final prompts can be found in Appendix B.1.\nB.1\nPrompts\nGenerate prompt\n<|Instruction|>\n# Task overview\nYou will be given a conversation between a User and an AI chatbot.\nYou have two primary goals:\n(1) summarize the main goal that the user is trying to accomplish in the style of an O*NET Intermediate Work Activity\n(IWA).\n,→\n(2) summarize the action that the bot is performing in the conversation in the style of an O*NET IWA.\nFor example, if the user asks for help with a computer issue and the bot provides suggestions to resolve the issue,\nthe user's IWA is \"Resolve computer problems\" and the bot's IWA is \"Advise others on the design or use of\ntechnologies.\"\n,→\n,→\nSometimes, the user intent and bot action may be the same.\nFor instance, if the user asks the bot to spellcheck a research paper and the bot corrects a few misspelled words,\nthe user's IWA is \"Edit written materials or documents\" and the bot's IWA is also \"Edit written materials or\ndocuments\"\n,→\n,→\nFor both the user and bot IWA summaries, you will generate several variations of the summary to capture the same\nintent using different wordings.\n,→\nTo aid your analysis, you will also summarize the conversation.\nFinally, you will also determine whether the User is a student trying to do homework.\n# Task details\n23\nYour task is to fill out the following fields:\nsummary: Summarize User's queries in 3 sentences or fewer in **English**.\nuser_iwa: Summarize the task the user is trying to accomplish in the style of an O*NET IWA. Ensure that the summary\naccurately describes the goal of the User as directly evidenced in the conversation. Ensure that the summary\nmatches the level of generality of an O*NET IWA: it should general enough to be an activity performed in a large\nnumber of occupations across multiple job families, but specific enough to capture the essence of the User's\ngoal. Provide exactly one succinct IWA-style summary.\n,→\n,→\n,→\n,→\nuser_iwa_variations: Generate 4 variations of the user IWA summary that capture the same intent using different\nwordings.\n,→\nbot_iwa: Summarize the task that the bot is performing in the style of an O*NET IWA. Ensure that the summary matches\nthe level of generality of an O*NET IWA: it should general enough to be an activity performed in a large number\nof occupations across multiple job families, but specific enough to capture the essence of the bot's actions.\nProvide exactly one succinct IWA-style summary.\n,→\n,→\n,→\nbot_iwa_variations: Generate 4 variations of the bot IWA summary that capture the same action using different\nwordings.\n,→\nis_homework_explanation: Determine whether the User is a student trying to do homework. This may be obvious if they\nhave pasted in assignment instructions, or it may be clear from the type of question they are asking. Explain in\none sentence.\n,→\n,→\nis_homework: Based on your explanation, provide the label 0 (not homework) or 1 (homework).\n# Hints\nProvide your answers in **English** using the given structured output format.\n<|end Instruction|>\n<|Conversation between User and AI|>\n{convo}\n<|end Conversation|>\n<|end of prompt|>\nClassify user prompt\n<|Instruction|>\n# Task overview\nYou will be given a conversation between a User and an AI chatbot as well as a summary of the conversation and a list\nof Candidate Intermediate Work Activity (IWA) statements from O*NET.\n,→\nThe IWAs will be numbered with numerical IDs to help you reference them in your responses.\nYour primary task is to determine for each of the Candidate IWAs whether the user is trying to perform that IWA,\naccording to the meaning of the IWA in the context of O*NET. The conversation must provide direct evidence that\nthe user is themself trying to accomplish the IWA.\n,→\n,→\nFor example, a user asking for tech support does not match a IWA about providing tech support, but does match a IWA\nabout resolving technical issues.\n,→\nAs another example, a user seeking information about a product does not match a IWA about providing product\ninformation, but does match a IWA about researching product information.\n,→\nAdditionally, you will determine the level of assistance that the bot provides to the user in the conversation for\neach matching IWA.\n,→\n# Task details\nYour reply to iwa_analyses should be a list of UserIWAAnalysis objects, one for each Candidate IWA in the order\nbelow. For each Candidate IWA, you will analyze the user's intent relative to that IWA and fill out the fields of\nUserIWAAnalysis as follows:\n,→\n,→\niwa (str): Copy the current Candidate IWA verbatim into this field. All of the following fields will be based on this\nIWA.\n,→\niwa_explanation (str): Explain in one sentence what the IWA means in the context of O*NET and what kinds of\noccupations perform this IWA.\n,→\nis_match_explanation (str): Explain in one sentence whether the user is seeking to perform an activity described by\nthe IWA, according to the meaning of the IWA in O*NET. To be considered a match, the user's intent must be to\nperform the action themselves, so if the IWA mentions or implies assisting clients or customers, for instance,\nthere must be evidence in their query that the user is seeking to assist a client or customer.\n,→\n,→\n,→\nis_match (bool): Based on your explanation, provide the label True if the user is seeking to perform an activity\ndescribed by the IWA, according to the meaning of the IWA in O*NET, and False otherwise. To be considered a\nmatch, the user's intent must be to perform the action themselves.\n,→\n,→\nassistance_level_explanation (str): Consider the full scope of the work performed under this IWA across all\noccupations. What fraction of this work can the bot assist users with by applying only the capability it\ndemonstrates in this conversation? Pay careful attention to the fact that the IWA might encompass many more\nsubtasks than represented in this conversation. Explain in one sentence, or reply N/A if the IWA does not match\nthe user's intent (i.e., when is_match is False).\n,→\n,→\n,→\n,→\nassistance_level (IWAAssistanceLevel): Based on your explanation, label the bot's capability to assist with the IWA\nusing the IWAAssistanceLevel enum, which has the following options:\n,→\n- none: The user is not seeking to perform the IWA, or the conversation does not indicate that the bot is capable of\nassisting with the IWA.\n,→\n- minimal: With this demonstrated capability, the bot can assist with a minimal portion of the work in the IWA.\n24\n- limited: With this demonstrated capability, the bot can assist with a limited portion of the work in the IWA.\n- moderate: With this demonstrated capability, the bot can assist with a moderate portion of the work in the IWA.\n- significant: With this demonstrated capability, the bot can assist with a significant portion of the work in the\nIWA.\n,→\n- complete: With this demonstrated capability, the bot can assist with all of the work in the IWA.\n# Hints\n- Provide your answers in **English** using the given structured output format.\n<|end Instruction|>\n<|Conversation between User and AI|>\n{convo}\n<|end Conversation|>\n<|Conversation Summary|>\n{summary}\n<|end Conversation Summary|>\n<|Candidate IWAs|>\n{iwas}\n<|end Candidate IWAs|>\n<|end of prompt|>\nClassify bot prompt\n<|Instruction|>\n# Task overview\nYou will be given a conversation between a User and an AI chatbot as well as a summary of the conversation and a list\nof Candidate Intermediate Work Activity (IWA) statements from O*NET.\n,→\nThe IWAs will be numbered with numerical IDs to help you reference them in your responses.\nYour task is to determine for each of the Candidate IWAs whether the bot is performing that IWA in the conversation,\nbased on the meaning of the IWA in the context of O*NET.\n,→\nFor example, if the user asks for help with a computer issue and the bot provides suggestions to resolve the issue,\nthis matches an IWA about providing tech support, as that is the task that the bot is performing.\n,→\nHowever, if the user asks the bot to spellcheck a research paper and the bot corrects a few misspelled words, this\ndoes not match an IWA about writing research papers: while the **user's** overarching goal may be writing\nresearch papers, that does not match the **bot's** task in the conversation.\n,→\n,→\nAdditionally, you will assess whether this conversation demonstrates the bot's ability to automate each matching IWA\nin the conversation.\n,→\n# Task details\nYour reply to iwa_analyses should be a list of BotIWAAnalysis objects, one for each candidate IWA in the order below.\nFor each candidate IWA, you will analyze the bot's actions relative to that IWA and fill out the fields of\nBotIWAAnalysis as follows:\n,→\n,→\niwa (str): Copy the current Candidate IWA verbatim into this field. All of the following fields will be based on this\nIWA.\n,→\niwa_explanation (str): Explain in one sentence what the IWA means in the context of O*NET and what kinds of\noccupations perform this IWA.\n,→\nis_match_explanation (str): Explain in one sentence whether the action that the bot is performing in the conversation\nis an example of a work activity described by the IWA, given the meaning of the IWA in the context of O*NET.\n,→\nis_match (bool): Based on your explanation, provide the label True if the action that the bot is performing in the\nconversation is an example of a work activity described by the IWA, given the meaning of the IWA in the context\nof O*NET, and False otherwise.\n,→\n,→\nautomation_level_explanation (str): Consider the full scope of the work performed under this IWA across all\noccupations. What fraction of this work can the bot perform by applying only the capability it demonstrates in\nthis conversation? Pay careful attention to the fact that the IWA might encompass many more subtasks than\nrepresented in this conversation. Explain in one sentence, or reply N/A if the IWA does not match the bot's\naction (i.e., when is_match is False).\n,→\n,→\n,→\n,→\nautomation_level (IWAAutomationLevel): Based on your explanation, label the bot's capability to perform the IWA using\nthe IWAAutomationLevel enum, which has the following options:\n,→\n- none: The bot does not perform the IWA, or the conversation does not indicate that the bot is capable of performing\nthe IWA.\n,→\n- minimal: With this demonstrated capability, the bot can perform a minimal portion of the work in the IWA.\n- limited: With this demonstrated capability, the bot can perform a limited portion of the work in the IWA.\n- moderate: With this demonstrated capability, the bot can perform a moderate portion of the work in the IWA.\n- significant: With this demonstrated capability, the bot can perform a significant portion of the work in the IWA.\n- complete: With this demonstrated capability, the bot can perform all of the work in the IWA.\n# Hints\n- Provide your answers in **English** using the given structured output format.\n<|end Instruction|>\n25\n<|Conversation between User and AI|>\n{convo}\n<|end Conversation|>\n<|Conversation Summary|>\n{summary}\n<|end Conversation Summary|>\n<|Candidate IWAs|>\n{iwas}\n<|end Candidate IWAs|>\n<|end of prompt|>\nB.1.1\nCompletion\nWhile the Copilot-Thumbs dataset tells us which work activities receive the most positive user feedback,\nthumbs feedback may not reflect the success of AI across tasks, as not all types of users give feedback at the\nsame rate (e.g., suppose users who perform some tasks are inherently more critical than those who perform\nothers). To supplement the thumbs feedback data, we therefore also perform task completion classification\nwith an LLM. For each conversation, we ask GPT-4o-mini12 if the AI completed the user’s task in the\nconversation. For comparison with the E1 measure of Eloundou et al. [17], we also ask if the AI reduced the\ntime it takes to complete the task by at least 50%.\nTask completion prompt\n<|Instruction|>\n# Task overview\nYou will be given a conversation between a User and an AI chatbot.\nYou will summarize the main task that the user is trying to accomplish in the conversation.\nYou will also determine whether the AI chatbot is able to complete the task, and if so, whether it reduced the time\nit takes to complete the task with equivalent quality by at least half.\n,→\n# Task details\nYour task is to fill out the following fields:\ntask_summary: Summarize the task the User is trying to accomplish in **English**.\ncompleted_explanation: Explain in one sentence whether the AI chatbot is able to complete the User's task, based on\nthe conversation.\n,→\ncompleted: Based on your explanation, provide one of the following labels:\n- not_complete: The AI chatbot did not make substantive progress towards completing the User's task.\n- partially_complete: The AI chatbot made progress towards completing the User's task, but did not complete it.\n- complete: The AI chatbot completed the User's task.\nspeedup_50pct_explanation: Explain in one sentence whether the AI chatbot reduced the time it takes to complete the\ntask with equivalent quality by at least half. This includes tasks that can be reduced to:\n,→\n- Writing and transforming text and code according to complex instructions,\n- Providing edits to existing text or code following specifications,\n- Writing code that can help perform a task that used to be done by hand,\n- Translating text between languages,\n- Summarizing medium-length documents,\n- Providing feedback on documents,\n- Answering questions about a document, or\n- Generating questions a user might want to ask about a document.\nAssume the user is a worker with an average level of expertise in their role trying to complete the given task.\nspeedup_50pct: Based on your explanation, provide the label True if the AI chatbot reduced the time it takes to\ncomplete the task with equivalent quality by at least half, and False otherwise.\n,→\n# Hints\nProvide your answers in **English** using the given structured output format.\n<|end Instruction|>\n<|Conversation between User and AI|>\n{convo}\n<|end Conversation|>\n<|end of prompt|>\n12This task is much simpler than the difficult and ambiguous IWA classification task, hence our use of the smaller model.\n26\nclass GenerationAnswer:\nsummary: str\nuser_iwa: str\nuser_iwa_variations: list[str]\nbot_iwa: str\nbot_iwa_variations: list[str]\nis_homework_explanation: str\nis_homework: int\n(a) Generate\nclass IWAAssistanceLevel(Enum):\nNONE = \"none\"\nMINIMAL = \"minimal\"\nLIMITED = \"limited\"\nMODERATE = \"moderate\"\nSIGNIFICANT = \"significant\"\nCOMPLETE = \"complete\"\nclass UserIWAAnalysis:\niwa: str\niwa_explanation: str\nis_match_explanation: str\nis_match: bool\nassistance_level_explanation: str\nassistance_level: IWAAssistanceLevel\nclass UserClassificationAnswer:\niwa_analyses: list[UserIWAAnalysis]\n(b) Classify user\nclass IWAAutomationLevel(Enum):\nNONE = \"none\"\nMINIMAL = \"minimal\"\nLIMITED = \"limited\"\nMODERATE = \"moderate\"\nSIGNIFICANT = \"significant\"\nCOMPLETE = \"complete\"\nclass BotIWAAnalysis:\niwa: str\niwa_explanation: str\nis_match_explanation: str\nis_match: bool\nautomation_level_explanation: str\nautomation_level: IWAAutomationLevel\nclass BotClassificationAnswer:\niwa_analyses: list[BotIWAAnalysis]\n(c) Classify bot\nclass CompletionLevel(Enum):\nNOT_COMPLETE = \"not_complete\"\nPARTIAL = \"partially_complete\"\nCOMPLETE = \"complete\"\nclass CompletionAnswer(BaseModel):\ntask_summary: str\ncompleted_explanation: str\ncompleted: CompletionLevel\nspeedup_50pct_explanation: str\nspeedup_50pct: bool\n(d) Task completion\nFigure A1: Structured output formats for our four LLM prompts.\nTable A1: LLM details\nPrompts\nModel\nAPI version\nTemperature\nGenerate, Classify\ngpt-4o-2024-08-06\n2024-08-01-preview\n1 (generate), 0 (classify)\nCompletion\ngpt-4o-mini-2024-07-18\n2024-08-01-preview\n0\n27\nC\nAdditional figures and tables\n12\n23\n2\n0.74\n1.1\n0.71\n0.3\n0.35\n0.43\n0.039\n0.18\nResearch agricultural processes or practices.\nResearch issues related to earth sciences.\nGather information for news stories.\nResearch biological or ecological phenomena.\nStudy details of artistic productions.\nResearch healthcare issues.\nInvestigate individuals' activities.\nResearch historical or social issues.\nRead materials to inform work processes.\nObtain information about goods or services.\nGather information from physical or electronic sources.\nGetting Information\n8.8\nRespond to customer problems or inquiries.\nPerforming for or Working Directly with the Public\n3.6\n1.3\nProvide information to guests, clients, or customers.\nProvide information or assistance to the public.\nCommunicating with People Outside the Organization\n2.3\n1.3\n1.2\nCreate artistic designs or performances.\nCreate visual designs or displays.\nDevelop news, entertainment, or artistic content.\nThinking Creatively\n2.2\n1.3\n0.74\nInterpret language and cultural information for others.\nExplain regulations, policies, or procedures.\nExplain technical details of products or services.\nInterpreting the Meaning of Information for Others\n4.1\nMaintain current knowledge in area of expertise.\nUpdating and Using Relevant Knowledge\n1.6\n1.1\nImplement procedures or processes.\nEdit written materials or documents.\nMaking Decisions and Solving Problems\n1\n1.5\nPresent research or technical information.\nWrite material for artistic or commercial purposes.\nDocumenting/Recording Information\n1.3\nOperate computer systems or computerized equipment.\nWorking with Computers\n1.2\n0.045\nEvaluate scholarly work.\nEvaulate products or technologies.\nJudging the Qualities of Objects, Services, or People\n1\nProvide general assistance to others.\nAssisting and Caring for Others\n0.67\nAnalyze data using mathematical principles.\nAnalyzing Data or Information\n0.15\nAssist specialists with projects or research.\n0\n10\n20\nChat Share, User Goal (%)\nCommunicating with Supervisors, Peers, or Subordinates\n0.036\n0.23\n0.86\n0.0084\n0.0039\n0.032\n0.0073\n0.021\n0.02\n0.0016\n0.0021\n1.6\n0.11\n3\n0.028\n0.35\n0.028\n0.84\n0.35\n0.015\n0.66\n0.033\n0.14\n0.14\n0.059\n0.28\n0.073\n0.00033\n1.3\n0.032\n0.0082\n0\n1\n2\n3\n4\nWorkforce Share (%)\n321\n101\n2.3\n88\n289\n22\n41\n17\n22\n24\n90\n>>\n>>\n>>\n5.4\n31\n0.44\n81\n3.6\n41\n2.7\n3.8\n48\n6.2\n49\n7.8\n7\n25\n4.6\n16\n139 >>\n0.8\n21\n19\n0\n25\n50\n75\n100\nChat Relative Prevalence\nFigure A2: Frequency of top IWAs\nNote: This Figure shows the share of total user chat activity (left), estimated share of work activity (center), and\ntheir ratio (right) for IWAs that are either in the top 20 for their share of user activity (high prevalence) or for the\nratio of their activity share to their estimated share of tasks done in the workforce (high relative prevalence). For\nchat activity, when a conversation is labeled with multiple IWAs, that share of Copilot activity is evenly distributed\namong the IWAs; for both chat activity and work activity, the sum across all IWAs is 1. See Appendix A.2 for how\nthe workforce share is calculated. IWAs are grouped by GWA and titles have been shortened for space.\nFigure A2 shows all the IWAs, grouped by GWA, that are in the top 20 of either of those lists and plots\nthe share of conversations categorized as that IWA (left), the share of workforce activity categorized as that\nIWA (center), and the ratio between them (right). Two IWAs, including Provide information to guests,\nclients, or customers, appear less frequently in the data than in the workforce, suggesting they rank highly\nin the chat data because of how often they are often performed in the world.\nThe remaining top IWAs are all overrepresented in Copilot conversations. Notably, seven, such as Write\nmaterial for artistic or commercial purposes, are common in the data but rank in the bottom half of workforce\nactivities, implying people are relatively likely to use the LLM for those activities.\nAlso of interest are\nthe eleven, such as Evaluate scholarly work, that are somewhat less common in the data but still highly\noverrepresented, again suggesting tendency for LLM use.\nThe most common IWA in the data, Gather\ninformation from physical or electronic sources, is in the middle third of workplace activities but appears so\nfrequently in conversations that its ratio ranks fourth.\nMany of the IWAs in Figure A2 fall under the GWA Getting Information. This may be partially because\n28\npeople see Copilot as a substitute for a search engine, but even once normalized for how often the activities\nare done in the workforce, many information-based tasks, including research, appear relatively frequently.\nThe other GWAs where the IWAs stand out on their relative frequency are Thinking Creatively and Judging\nthe Qualities of Object, Services, or People.\nThinking Creatively is consistent with the writing abilities\nof LLMs, but it is perhaps more surprising the extent to which people are using the tools for evaluation\n(Judging... or people).\n0.5\n0.6\n0.7\n0.8\nFeedback Positive Fraction\nHandling and Moving Objects\nEstimating the Quantifiable Characteristics of Products, Events, or Information\nThinking Creatively\nPerforming General Physical Activities\nWorking with Computers\nProcessing Information\nCommunicating with Supervisors, Peers, or Subordinates\nAnalyzing Data or Information\nEvaluating Information to Determine Compliance with Standards\nDeveloping Objectives and Strategies\nPerforming for or Working Directly with the Public\nCommunicating with People Outside the Organization\nDocumenting/Recording Information\nAssisting and Caring for Others\nMonitoring Processes, Materials, or Surroundings\nGetting Information\nMaking Decisions and Solving Problems\nSelling or Influencing Others\nPerforming Administrative Activities\nUpdating and Using Relevant Knowledge\nJudging the Qualities of Objects, Services, or People\nTraining and Teaching Others\nOrganizing, Planning, and Prioritizing Work\nInterpreting the Meaning of Information for Others\nProviding Consultation and Advice to Others\nCoaching and Developing Others\nMonitoring and Controlling Resources\nUser goal\nAI action\nFigure A3: Share of positive feedback by GWA\nN ote: This Figure plots the positive feedback share for each GWA, aggregating common IWAs into their GWAs and\nwith bootstrapped 95% confidence intervals; any IWA appearing in less than 1% of our feedback data is ignored. 14\nGWAs have no common IWAs and are thus excluded from this plot, including those relating to operating vehicles,\nrepairing equipment, and management tasks like hiring, negotiation, and guiding subordinates.\n29\n0.4\n0.6\n0.8\n1.0\nCompletion Rate\nCreate visual designs or displays.\nCreate artistic designs or performances.\nCreate decorative objects or parts of objects.\nAnalyze scientific or applied data using mathematical principles.\nConfer with clients to determine needs or order specifications.\nDesign materials or devices.\nDevelop news, entertainment, or artistic content.\nCalculate financial data.\nCommunicate with others about specifications or project details.\nDevelop models of systems, processes, or products.\nOperate computer systems or computerized equipment.\nAnalyze business or financial data.\nAnalyze biological or chemical substances or related data.\nVerify personal information.\nCoordinate with others to resolve problems.\nExplain regulations, policies, or procedures.\nAssess characteristics or impacts of regulations or policies.\nCommunicate environmental or sustainability information.\nSelect materials or equipment for operations or projects.\nPrepare mixtures or solutions.\nObtain formal documentation or authorization.\nAdvise others on legal or regulatory matters.\nEdit written materials or documents.\nTrain others to use equipment or products.\nAdvise others on healthcare or wellness issues.\nSet up equipment.\nCare for plants or animals.\nAdjust equipment to ensure adequate performance.\nExplain medical information to patients or family members.\nAdvise patients or clients on medical issues.\nUser goal\nAI action\nFigure A4: IWAs with the highest and lowest completion rates\nNote: This Figure shows the top and bottom 15 IWAs by completion rate, filtered to ‘common’ IWAs with activity\nshare at least 0.1% in Copilot-Uniform, with 95% confidence intervals (using the normal approximation to binomial\nconfidence intervals). Task completion shows some of the same patterns as positive feedback fraction (Figure 4), with\nvisual design and data analysis on the low end and writing on the high end. One notable difference is that the highest\ncompletion rate IWAs include 7 about explaining, advising, or training.\n30\n0.00\n0.25\n0.50\n0.75\n1.00\nFraction \n moderate scope\nVerify personal information.\nPurchase goods or services.\nCreate decorative objects or parts of objects.\nConsult legal materials or public records.\nCreate visual designs or displays.\nDesign materials or devices.\nMaintain safety or security.\nCoordinate with others to resolve problems.\nCreate artistic designs or performances.\nConfer with clients to determine needs or order specifications.\nEvaluate the quality or accuracy of data.\nExamine materials or documentation for accuracy or compliance.\nProvide support or encouragement to others.\nInvestigate individuals' background, behavior, or activities.\nCare for plants or animals.\nImplement procedures or processes.\nGather information from physical or electronic sources.\nPrepare informational or instructional materials.\nExplain financial information.\nEdit written materials or documents.\nWrite material for artistic or commercial purposes.\nExplain medical information to patients or family members.\nAdvise others on products or services.\nExplain regulations, policies, or procedures.\nObtain information about goods or services.\nPresent research or technical information.\nExplain technical details of products or services.\nRespond to customer problems or inquiries.\nProvide information or assistance to the public.\nProvide information to guests, clients, or customers.\nUser goal\nAI action\nFigure A5: IWAs with the highest and lowest fraction of conversations at moderate or higher impact scope\nNote: This Figure shows the top and bottom 15 IWAs by how often they are assigned scope of impact at least\nmoderate, filtered to ‘common’ IWAs with activity share at least 0.1% in Copilot-Uniform, with 95% confidence\nintervals (using the normal approximation to binomial confidence intervals). Some patterns mirror those of thumbs\nfeedback and completion, with research and writing IWAs having high scope, and data analysis and visual design\nIWAs having low scope. AI performance consistently has lower impact scope than user assistance.\n31\n$25,000\n$50,000\n$100,000\n$200,000\n$400,000\nAverage Wage\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nAI Applicability Score, User goal\nWLS, r = 0.05\nWLS w/o top 10%, rw = 0.11\nBinscatter\nAll occupations\n$25,000\n$50,000\n$100,000\n$200,000\n$400,000\nAverage Wage\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAI Applicability Score, AI action\nWLS, r = 0.10\nWLS w/o top 10%, rw = 0.16\nBinscatter\nAll occupations\nFigure A6: AI applicability score by wage, separating out user goals and AI actions\nN ote: Wage plot from Figure 7, but showing user goal and AI action separately instead of averaging the two. The\ncorrelation is marginally higher on the AI side.\nLess than H.S.\nH.S. or equiv.\nSome College - Assoc.\nBachelor's\nMaster's or higher\nModal Education Requirement\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nAI Applicability Score, User Goal\nLess than H.S.\nH.S. or equiv.\nSome College - Assoc.\nBachelor's\nMaster's or higher\nModal Education Requirement\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAI Applicability Score, AI Action\nFigure A7: AI applicability score by educational requirement, separating out user goals and AI actions\nN ote: Education plot from Figure 7, but showing user goal and AI action separately instead of averaging the two.\nAs with wage, the relationship with education is slightly stronger on the AI side.\n32\n$25,000\n$50,000\n$100,000\n$200,000\n$400,000\nAverage Wage\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nAI Applicability Score, User goal\nOLS, r = 0.17\nOLS excl. top 10%, r = 0.27\n$25,000\n$50,000\n$100,000\n$200,000\n$400,000\nAverage Wage\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAI Applicability Score, AI action\nOLS, r = 0.21\nOLS excl. top 10%, r = 0.31\nFigure A8: AI applicability score by wage, unweighted\nN ote: These Figures are the same as Figure A6 without weighting the binscatters. They graph each occupation’s AI\napplicability score calculated over user goals (left) or AI actions (right) against the occupation’s average wage. The\nrelationship is much less noisy without employment weighting, likely because weighting by employment causes the\nbinscatters to be influenced dramatically by a small number of high-employment occupations, increasing the variance\ndue to noise in the coverage metric and in the mapping between occupations and IWAs. Excluding the top 10% of\nhighest-paid workers strengthens the correlation.\nLess than H.S.\nH.S. or equiv.\nSome College - Assoc.\nBachelor's\nMaster's or higher\nModal Education Requirement\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nAI Applicability Score, User Goal\nLess than H.S.\nH.S. or equiv.\nSome College - Assoc.\nBachelor's\nMaster's or higher\nModal Education Requirement\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAI Applicability Score, AI Action\nFigure A9: AI applicability score by educational requirement, unweighted\nN ote: These Figures are the same as Figure A7 without weighting by employment. As in Figure A8, this reduces\nthe noise in the relationship.\n33\nTable A2: All SOC minor groups by AI applicability score estimated from Copilot data\nMinor Group Title (Abbr)\nCoverage\nCmpltn.\nScope\nScore\nEmpl.\nMedia and Communication Workers\n0.73\n0.86\n0.58\n0.39\n602,710\nInformation and Record Clerks\n0.64\n0.89\n0.55\n0.37\n5,385,660\nSales Representatives, Services\n0.66\n0.90\n0.52\n0.36\n2,245,510\nCommunications Equipment Operators\n0.69\n0.86\n0.52\n0.35\n48,430\nTour and Travel Guides\n0.57\n0.88\n0.53\n0.34\n46,760\nRetail Sales Workers\n0.57\n0.88\n0.52\n0.33\n7,655,030\nSales Representatives, Wholesale and Manufacturing\n0.60\n0.88\n0.52\n0.33\n1,600,700\nMathematical Science Occupations\n0.71\n0.85\n0.50\n0.32\n372,550\nBaggage Porters, Bellhops, and Concierges\n0.55\n0.89\n0.48\n0.32\n69,800\nOther Sales and Related Workers\n0.58\n0.89\n0.52\n0.32\n450,090\nPostsecondary Teachers\n0.61\n0.90\n0.49\n0.31\n1,210,240\nEntertainment Attendants and Related Workers\n0.52\n0.88\n0.51\n0.30\n592,140\nComputer Occupations\n0.63\n0.86\n0.48\n0.30\n4,804,840\nOther Office and Administrative Support Workers\n0.59\n0.89\n0.49\n0.29\n3,041,920\nLibrarians, Curators, and Archivists\n0.59\n0.89\n0.47\n0.29\n242,760\nReligious Workers\n0.57\n0.88\n0.49\n0.27\n79,910\nSupervisors of Personal Care and Service Workers\n0.48\n0.91\n0.50\n0.27\n219,680\nSecretaries and Administrative Assistants\n0.53\n0.89\n0.49\n0.27\n3,171,290\nFinancial Clerks\n0.60\n0.86\n0.47\n0.27\n2,695,230\nOther Teachers and Instructors\n0.54\n0.88\n0.47\n0.26\n915,830\nSocial Scientists and Related Workers\n0.50\n0.88\n0.47\n0.26\n273,230\nCounselors, Social Workers, ...\n0.50\n0.88\n0.44\n0.25\n2,137,020\nSupervisors of Production Workers\n0.56\n0.91\n0.45\n0.25\n671,160\nSupervisors of Office and Administrative Support Workers\n0.48\n0.89\n0.46\n0.25\n1,504,570\nBusiness Operations Specialists\n0.48\n0.90\n0.48\n0.24\n7,048,360\nAnimal Care and Service Workers\n0.41\n0.93\n0.46\n0.24\n288,070\nFinancial Specialists\n0.51\n0.86\n0.47\n0.24\n3,039,490\nEngineers\n0.48\n0.86\n0.47\n0.23\n1,703,700\nOther Educational Instruction and Library Occupations\n0.47\n0.89\n0.44\n0.22\n1,698,660\nPhysical Scientists\n0.44\n0.88\n0.46\n0.21\n254,400\nDrafters, Engineering/Mapping Technicians\n0.55\n0.80\n0.44\n0.21\n624,780\nLife Scientists\n0.41\n0.88\n0.48\n0.21\n344,490\nFood and Beverage Serving Workers\n0.37\n0.91\n0.44\n0.21\n6,893,410\nAir Transportation Workers\n0.39\n0.90\n0.45\n0.21\n313,070\nArt and Design Workers\n0.69\n0.68\n0.44\n0.21\n658,340\nMaterial Recording, Dispatching, and Distributing Workers\n0.38\n0.91\n0.43\n0.20\n2,316,660\nMedia and Communication Equipment Workers\n0.43\n0.85\n0.47\n0.20\n223,820\nTeachers, Preschool-Seconday and Special Education\n0.39\n0.90\n0.45\n0.19\n4,261,430\nSupervisors of Transportation and Material Moving Workers\n0.36\n0.91\n0.46\n0.18\n603,350\nSales, Marketing, PR Managers\n0.34\n0.90\n0.44\n0.18\n1,070,020\nElectrical/Electronic Equip. Mechanics/Installers/Repairers\n0.36\n0.91\n0.44\n0.18\n494,540\nArchitects, Surveyors, and Cartographers\n0.48\n0.77\n0.44\n0.17\n194,610\nLawyers, Judges, and Related Workers\n0.42\n0.89\n0.42\n0.17\n792,220\nOther Personal Care and Service Workers\n0.39\n0.90\n0.44\n0.17\n1,147,350\nEntertainers and Performers, Sports and Related Workers\n0.38\n0.86\n0.46\n0.17\n554,960\nOther Healthcare Practitioners and Technical Occupations\n0.34\n0.88\n0.41\n0.16\n121,640\nOther Transportation Workers\n0.28\n0.91\n0.44\n0.16\n294,450\nCooks and Food Preparation Workers\n0.27\n0.91\n0.40\n0.16\n3,528,200\nFuneral Service Workers\n0.32\n0.83\n0.36\n0.15\n63,420\nOther Protective Service Workers\n0.36\n0.84\n0.42\n0.15\n1,676,910\nOther Food Preparation and Serving Related Workers\n0.25\n0.92\n0.39\n0.15\n1,372,350\nSupervisors; Building, Grounds Cleaning, Maintenance\n0.30\n0.91\n0.42\n0.15\n297,140\nLaw Enforcement Workers\n0.36\n0.81\n0.37\n0.15\n1,136,430\nOther Management Occupations\n0.28\n0.90\n0.45\n0.14\n3,109,640\nOccupational Health/Safety Specialists\n0.32\n0.90\n0.42\n0.14\n149,570\nSupervisors of Food Preparation and Serving Workers\n0.26\n0.92\n0.45\n0.14\n1,348,910\nSupervisors of Installation, Maintenance, and Repair Workers\n0.29\n0.89\n0.39\n0.14\n589,880\nLife, Physical, and Social Science Technicians\n0.29\n0.88\n0.43\n0.14\n360,240\nOperations Specialties Managers\n0.28\n0.89\n0.44\n0.14\n2,513,890\nMotor Vehicle Operators\n0.29\n0.92\n0.40\n0.14\n4,302,220\nSupervisors of Sales Workers\n0.27\n0.88\n0.42\n0.14\n1,315,040\nHealthcare Diagnosing or Treating Practitioners\n0.26\n0.91\n0.39\n0.13\n6,119,630\nRail Transportation Workers\n0.26\n0.91\n0.40\n0.13\n109,780\nFood Processing Workers\n0.22\n0.87\n0.42\n0.12\n784,660\nTop Executives\n0.23\n0.90\n0.48\n0.12\n3,751,500\nWoodworkers\n0.26\n0.91\n0.42\n0.12\n208,510\nSupervisors of Construction and Extraction Workers\n0.25\n0.89\n0.47\n0.11\n777,420\nHealth Technologists and Technicians\n0.24\n0.89\n0.37\n0.11\n3,010,660\nAssemblers and Fabricators\n0.25\n0.92\n0.42\n0.11\n1,924,980\nMetal Workers and Plastic Workers\n0.23\n0.92\n0.41\n0.11\n1,584,800\nPrinting Workers\n0.21\n0.91\n0.42\n0.11\n213,920\nOther Installation, Maintenance, and Repair Occupations\n0.20\n0.93\n0.42\n0.10\n3,186,610\nVehicle and Mobile Equip. Mechanics/Installers/Repairers\n0.19\n0.93\n0.40\n0.10\n1,708,120\nWater Transportation Workers\n0.17\n0.92\n0.41\n0.09\n76,050\nFirefighting and Prevention Workers\n0.19\n0.89\n0.40\n0.09\n331,930\nOther Production Occupations\n0.17\n0.91\n0.40\n0.08\n2,289,050\nBuilding Cleaning and Pest Control Workers\n0.16\n0.94\n0.37\n0.08\n3,102,490\nPersonal Appearance Workers\n0.19\n0.89\n0.40\n0.08\n532,400\nSupervisors of Protective Service Workers\n0.19\n0.86\n0.39\n0.08\n339,440\nSupervisors of Farming, Fishing, and Forestry Workers\n0.18\n0.91\n0.39\n0.08\n27,150\nMaterial Moving Workers\n0.14\n0.92\n0.36\n0.08\n7,966,020\nOccupational and Physical Therapy Assistants\n0.20\n0.87\n0.35\n0.07\n196,910\nConstruction Trades Workers\n0.15\n0.92\n0.40\n0.07\n4,588,630\nOther Construction and Related Workers\n0.11\n0.93\n0.38\n0.06\n455,520\nAgricultural Workers\n0.11\n0.92\n0.39\n0.06\n357,680\nLegal Support Workers\n0.15\n0.89\n0.42\n0.06\n404,650\nHelpers, Construction Trades\n0.11\n0.94\n0.38\n0.06\n164,440\nOther Healthcare Support Occupations\n0.13\n0.90\n0.35\n0.06\n1,744,500\nTextile, Apparel, and Furnishings Workers\n0.12\n0.93\n0.43\n0.05\n458,900\nExtraction Workers\n0.11\n0.95\n0.36\n0.05\n202,710\nHome Health Aides, Nursing Assistants, Orderlies, ...\n0.12\n0.91\n0.40\n0.05\n5,122,130\nGrounds Maintenance Workers\n0.09\n0.95\n0.39\n0.05\n1,003,720\nPlant and System Operators\n0.09\n0.93\n0.41\n0.04\n283,480\nForest, Conservation, and Logging Workers\n0.06\n0.94\n0.37\n0.03\n37,910\nNote: Metrics reported as mean of user goal and AI action.\n34\nTable A3: Occupations with the largest difference in user goal and AI action applicability score percentiles\nAI assistance, not performance\nAI performance, not assistance\nCooks, Fast Food (83, 4)\nExercise Trainers (17, 79)\nButchers and Meat Cutters (83, 8)\nChoreographers (34, 78)\nCooks, Private Household (97, 24)\nTraining and Development Managers (45, 83)\nCooks, Restaurant (76, 8)\nCoaches and Scouts (43, 77)\nMeat Cutters (79, 12)\nEnvironmental Engineers (55, 82)\nAnimal Breeders (76, 18)\nHuman Resources Specialists (53, 80)\nLighting Technicians (82, 27)\nHealth Education Specialists (53, 76)\nAnimal Control Workers (79, 37)\nLodging Managers (57, 79)\nAthletes (82, 41)\nCoatroom, Locker Room Attendants (60, 82)\nAnimal Caretakers (89, 49)\nTaxi Drivers (56, 78)\nNote: This Table shows the 10 occupations on each side with the largest difference in their AI applicability score\npercentile computed from user goals and AI actions, filtered for occupations in the top quartile on their higher-ranked\nside. Occupation title abbreviated. Numbers in parentheses are (user goal AI applicability score percentile, AI action\napplicability score percentile).\nThe occupations on the left focus on physical occupations involving cooking and\nworking with animals, while many of the occupations on the right involve teaching, training, or coaching.\n10\n5\n10\n4\n10\n3\n0.01\n0.1\nUser goal IWA Fraction\n10\n6\n10\n5\n10\n4\n10\n3\n0.01\n0.1\nAI action IWA Fraction\nGather information\nfrom physical or\nelectronic sources.\nObtain information about\ngoods or services.\nPerform athletic activities for fitness, competition, or artistic purposes.\nHunt animals.\nProvide information or assistance to the public.\nProvide information to guests, clients, or customers.\nAdminister basic health care or medical treatments.\nProvide general assistance to others, such as customers, patrons, or motorists.\nRespond to customer\nproblems or inquiries.\nTrain others on operational or work procedures.\nTrain others to use equipment or products.\nTrain others on health or medical topics.\nCoach others.\nExecute financial transactions.\nDistribute materials, supplies, or resources.\nPurchase goods or services.\nFigure A10: IWA frequency in AI actions and user goals\nNote: For each IWA, this figure plots the fraction of user intents (x axis) and AI actions (y axis) described by that\nIWA. Outliers show which IWAs are more likely to be performed (blue) or assisted (red) by Bing Copilot. When a\nconversation is labeled with multiple IWAs, that share of Copilot activity is evenly distributed among the IWAs so\nthat the sum of all IWA fractions is 1.\n35\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOccupation Coverage, User goal\n0\n5\n10\n15\n20\n25\n30\n35\nNumber of Occupations\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nOccupation Coverage, AI action\n0\n10\n20\n30\n40\n50\n60\nNumber of Occupations\nFigure A11: Distribution of occupation coverage\nN ote: These Figures show the distribution of occupation coverage scores (fraction of importance-weighted work in\nan occupation with user goal or AI action rate at least 0.05% in Copilot-Uniform).\n10\n5\n10\n4\n10\n3\n10\n2\nIWA Fraction Threshold, User goal\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nMean Occ. Coverage, User goal\n10\n5\n10\n4\n10\n3\n10\n2\nIWA Fraction Threshold, AI action\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nMean Occ. Coverage, AI action\nFigure A12: Mean and s.d of occupation coverage by threshold\nN ote: These Figures show the average and standard deviation of occupation coverage for different thresholds for the\nshare of chat activity an IWA must have to “be done” with the LLM, for user goal IWAs (left) and AI action IWAs\n(right). We use a threshold of 0.0005, which results in 127 and 87 IWAs being considered covered (of 332) on the\nuser goal and AI action sides, respectively.\n36\n0.001\n0.01\n0.05 0.1\n1\nCoverage threshold, user goal (%)\n0\n50\n100\n150\n200\n250\nNumber of occupations\nZero Coverage\nFull Coverage\nFigure A13: Effect of coverage threshold on occupations with coverage 0 and 1\nN ote: Our threshold of 0.05% approximately minimizes the number of occupations assigned user goal coverage 0 or\n1.\n10\n5\n10\n4\n10\n3\n10\n2\nCoverage Threshold\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nai Correlation with Threshold 0.05%\nPearson r\nKendall \nFigure A14: Robustness of AI applicability score to different coverage thresholds\nN ote: This Figure shows the correlation between AI applicability scores defined using different coverage thresholds\nand the one we report with threshold 0.05%. Across thresholds spanning three orders of magnitude, we get strongly\ncorrelated rankings of occupations by AI applicability. Contrast this robustness of relative applicability score with\nthe absolute measure in Figure 1, which is highly sensitive to arbitrary choice of threshold.\n37\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\nFeedback positive fraction, User goal IWAs\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nCompletion rate\nWeighted correlation: 0.827\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\nFeedback positive fraction, AI action IWAs\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nCompletion rate\nWeighted correlation: 0.758\nFigure A15: Relationship between thumbs feedback and task completion rate for each IWA\nN ote: There is a strong correlation between thumbs feedback rate (measured in Copilot-Thumbs) and GPT-4o-mini\ntask completion rate (measured in Copilot-Uniform) for each IWA, indicating that both are capturing real signal\nabout AI success in assisting or performing an IWA. Point size proportional to square root of IWA match count in\nCopilot-Uniform. Weighted correlations also weighted by match count in Copilot-Uniform.\n0.0\n0.2\n0.4\n0.6\n0.8\nFraction \n Moderate Scope, User goal\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCompletion Rate, User goal\nWeighted correlation: 0.447\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nFraction \n Moderate Scope, AI action\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCompletion Rate, AI action\nWeighted correlation: 0.224\nFigure A16: Relationship between impact scope and task completion rate for each IWA\nN ote: The relationship between scope and completion is much weaker than between completion and thumbs feedback,\nas they are capturing different questions. Point size proportional to square root of IWA match count in Copilot-\nUniform. Weighted correlations also weighted by match count in Copilot-Uniform.\n38\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nUniform IWA Completion, User goal\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThumbs IWA Completion, User goal\nWeighted correlation: 0.936\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nUniform IWA Completion, AI action\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThumbs IWA Completion, AI action\nWeighted correlation: 0.901\nFigure A17: Correlation between IWA completion rates in Copilot-Uniform and Copilot-Thumbs\nN ote: IWA-level completion rates are consistent between Copilot-Uniform and Copilot-Thumbs.\nPoint size\nproportional to square root of IWA match count in Copilot-Uniform.\nWeighted correlations also weighted by\nmatch count in Copilot-Uniform.\n0.0\n0.2\n0.4\n0.6\n0.8\nFraction \n moderate scope, User goal\n10\n5\n10\n4\n10\n3\n10\n2\n10\n1\n100\nActivity share, User goal\nr = 0.64\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nFraction \n moderate scope, AI action\n10\n5\n10\n4\n10\n3\n10\n2\n10\n1\n100\nActivity share, AI action\nr = 0.54\nFigure A18: Correlation between impact scope and activity share in Copilot-Uniform for each IWA\nN ote: This Figure shows the relationship between the activity share of an IWA and the fraction of conversations in\nwhich it classsified at moderate impact scope or higher. Impact scope is a good predictor of what activities people\nseek AI assistance with (better than completion or satisfaction).\n39\n0\n5\n10\n15\n20\n25\n30\nUser IWA Match Count\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150\n0.175\n0.200\nDensity\nUser IWA Match Distribution\nUniform\nMean: 2.82\nThumbs\nMean: 3.53\n0\n5\n10\n15\n20\n25\n30\nBot IWA Match Count\nBot IWA Match Distribution\nUniform\nMean: 6.44\nThumbs\nMean: 7.31\nFigure A19: Distribution of IWAs per conversation\nN ote: These Figures show the distribution of the number of IWAs a conversation is matched to for user goal (left)\nand bot activity (right) in both the in uniform and thumbs Copilot datasets.\n40\n",
    "content": "# Interpretation of the Paper \"Measuring the Occupational Implications of Generative AI\"\n\n## 1. Core Content and Main Contributions\n\nThe central objective of this paper is to **quantify the impact of generative artificial intelligence (AI) on occupational activities**. By analyzing 200,000 anonymized conversations from Microsoft Bing Copilot, the study investigates how users employ AI to perform work tasks and evaluates the likelihood of different occupations being affected by AI.\n\n### Key Contributions:\n- **Introduction of the \"AI Suitability Score\"**: This score is calculated based on AI task success rate, coverage, and impact level, reflecting the extent to which AI can assist or perform a work activity.\n- **Distinction between User Goals and AI Actions**: The paper clearly differentiates the tasks users seek help with (user goals) from the tasks AI actually performs (AI actions), offering insights into whether AI is \"augmenting\" or \"replacing\" human labor.\n- **Integration with the O*NET Database**: By mapping AI capabilities to specific occupational activities using the O*NET taxonomy, the study provides a structured framework for assessing AI's impact on labor markets.\n- **Validation of Predictive Models**: The findings show a strong correlation (r=0.73) between actual AI usage patterns and the predictions made by Eloundou et al. regarding the impact of large language models (LLMs) on occupations, indicating alignment between theory and real-world trends.\n\n---\n\n## 2. Breakthroughs and Innovations\n\n### (1) **First Large-Scale Analysis of Real-World Generative AI Use in Occupational Contexts**\n- Utilizes real-world, large-scale data (200,000 Copilot conversations) to analyze where and how generative AI is used across different occupational activities, rather than relying on hypothetical or lab-based scenarios.\n- Distinguishes between \"user goals\" and \"AI actions,\" revealing AI's role in tasks like information retrieval, writing, and teaching, and highlighting the gap between user intent and AI execution.\n\n### (2) **Introduction of the \"AI Suitability Score\"**\n- Goes beyond measuring frequency of AI use by incorporating dimensions such as task completion and impact, forming a comprehensive evaluation system.\n- This scoring mechanism can help forecast how future AI advancements might reshape occupational structures.\n\n### (3) **Identification of Knowledge-Based Work as Most Affected by AI**\n- AI excels in tasks involving information gathering, writing, explanation, and communication, making knowledge-intensive occupations (e.g., translation, editing, sales, programming) most susceptible to AI influence.\n- However, the study also notes AI's limitations in areas such as data analysis and visual design.\n\n### (4) **Socioeconomic Implications**\n- The AI suitability score shows only a weak positive correlation with wages (r=0.07) but a stronger link with educational requirements—occupations requiring bachelor's degrees or higher tend to score higher.\n- This helps illuminate how AI may differentially impact individuals across income and education levels.\n\n---\n\n## 3. Entrepreneurial Ideas Inspired by the Paper\n\n### Idea 1: **AI Career Fit Platform**\n- **Project Description**: Develop a platform based on the AI suitability score to help businesses or individuals assess whether a given job is suitable for AI assistance.\n- **Use Cases**:\n  - Employers can identify roles that benefit most from AI tools during hiring.\n  - Educational institutions can design AI-enhanced learning programs.\n  - Freelancers can explore work areas where AI can boost productivity.\n- **Technical Foundation**: Build a job-AI matching algorithm using the O*NET taxonomy and the AI suitability scoring model from the paper.\n\n---\n\n### Idea 2: **AI Skill Training Platform**\n- **Project Description**: Offer AI-assisted skill development courses tailored to high-suitability jobs (e.g., writing, editing, translation, customer service), focusing on best practices for human-AI collaboration.\n- **Core Features**:\n  - Simulated AI-assisted writing/translation/customer service environments.\n  - Feedback systems to evaluate AI performance.\n  - Personalized learning paths based on user progress.\n- **Unique Value**: Emphasizes not just how to use AI tools, but how to work effectively *with* AI.\n\n---\n\n### Idea 3: **AI-Driven Career Transition Consulting Firm**\n- **Project Description**: Provide career development consulting in the AI era, helping individuals and organizations understand which jobs are likely to be transformed by AI and what future-proof skills are needed.\n- **Target Clients**:\n  - Corporate HR departments: Optimize talent strategy and organizational structure.\n  - Career counselors: Guide individuals toward resilient career paths.\n  - Policymakers: Inform AI-era workforce development strategies.\n- **Product Offerings**: Custom reports, data dashboards, and online consultation services.\n\n---\n\n### Idea 4: **AI-Assisted Content Creation Tools**\n- **Project Description**: Build content generation and optimization tools for knowledge workers (e.g., journalists, marketers, researchers), focusing on improving efficiency in writing, research, and information organization.\n- **Key Features**:\n  - Draft generation, summarization, and headline creation.\n  - Real-time research and data integration.\n  - Automated proofreading and style optimization.\n  - Multilingual translation and localization support.\n- **Commercial Potential**: Applicable to media, publishing, advertising, and education sectors, enhancing both the speed and quality of content production.\n\n---\n\n### Idea 5: **AI-Augmented Customer Service System**\n- **Project Description**: Provide SMEs with a cost-effective AI customer service solution that combines automated responses with human oversight, balancing service quality and cost efficiency.\n- **Technical Highlights**:\n  - Automatic handling of frequent inquiries.\n  - Escalation of complex issues to human agents with suggested responses.\n  - Emotion recognition and personalized replies.\n  - Customer behavior analytics and insights.\n- **Business Model**: SaaS subscription with usage-based pricing, suitable for e-commerce, finance, healthcare, and other service industries.\n\n---\n\n### Conclusion\n\nThis paper offers a macro-level view of how generative AI is reshaping occupational structures and provides concrete quantitative metrics and analytical frameworks. It opens up multiple entrepreneurial opportunities, especially in the areas of AI-assisted work, skill development, content creation, and customer service—fields where AI's integration with human labor is both promising and transformative.",
    "github": "",
    "hf": ""
}